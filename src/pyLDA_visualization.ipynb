{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pre_clean as clean\n",
    "from numpy import array\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For using pyLDAvis visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biology_flashcards.txt              full_corpus_cleaned.txt\r\n",
      "biology_flashcards_cleaned.txt      history_flashcards.txt\r\n",
      "datascience_flashcards.txt          history_flashcards_cleaned.txt\r\n",
      "datascience_flashcards_cleaned.txt\r\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%ls ../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '../data/datascience_flashcards.txt'\n",
    "df_datascience = clean.read_cards(data)\n",
    "#   biology cards\n",
    "data = '../data/biology_flashcards.txt'\n",
    "df_biology = clean.read_cards(data)\n",
    "#   history cards\n",
    "data = '../data/history_flashcards.txt'\n",
    "df_history = clean.read_cards(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concat to build full corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36188"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_datascience, df_biology, df_history]\n",
    "corpus = pd.concat(frames)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79                                                     \n",
      "79                                              neutral\n",
      "79    tobacco. didn't have much food though. john sm...\n",
      "Name: answer, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# clean corpus\n",
    "corpus_clean = clean.clean_dataframe(corpus)\n",
    "corpus_collapsed = clean.collapse_df(corpus_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(min_df=5, max_df=0.80, stop_words='english', lowercase=True, token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.80, stop_words='english', lowercase=True, token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf_vectorizer.fit_transform(corpus_collapsed)\n",
    "corpus_count = count_vectorizer.fit_transform(corpus_collapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36188, 9436)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit LDA mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_components=10, n_jobs=1, n_topics=3,\n",
       "             perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Count Vector, running with default 10 iterations\n",
    "lda_corpus_count = LatentDirichletAllocation(n_topics=3, random_state=0)\n",
    "lda_corpus_count.fit(corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_components=10, n_jobs=1, n_topics=3,\n",
       "             perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With TF-IDF matrix, running with default 10 iterations\n",
    "lda_corpus_tfidf = LatentDirichletAllocation(n_topics=3, random_state=0)\n",
    "lda_corpus_tfidf.fit(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing with pyLDAvis on Full Corpus (all topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First on TF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First with Count Vector\n",
    "pyl_data = pyLDAvis.sklearn.prepare(lda_corpus_count, corpus_count, count_vectorizer, R=15)\n",
    "pyLDAvis.display(pyl_data)\n",
    "# pyLDAvis.save_html(pyl_data, \"../images/count_vect_topics.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now on TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyl_data = pyLDAvis.sklearn.prepare(lda_corpus_tfidf, corpus_tfidf, tfidf_vectorizer, R=15)\n",
    "pyLDAvis.display(pyl_data)\n",
    "# pyLDAvis.save_html(pyl_data, \"../images/tfidf_vect_topics.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
