"What three summary statistics do all four of these scatterplots have in common? <br /><img src=""Screen shot 2012-06-26 at 10.00.02 PM.png"" />"	mean, standard deviation, and Pearson correlation (http://en.wikipedia.org/wiki/Anscombe's_quartet) <div>&gt; the moral is that these summary statistics can be misleading and it's good to look at the actual distribution&nbsp;</div>
One round of [...] involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the testing set). 	cross-validation (http://en.wikipedia.org/wiki/Cross-validation_(statistics)) 
The purpose of cross-validation is to test the degree of model [...].	overfitting (http://en.wikipedia.org/wiki/Cross-validation_(statistics)) 
Data [...] refers to the application of a deterministic mathematical function to each point in a data set -- that is, each data point zi is replaced with the value yi = f(zi), where f is a function.	transformation (http://en.wikipedia.org/wiki/Data_transformation_(statistics)) 
Data transformation refers to the application of a [...] to each point in a data set -- that is, each data point zi is replaced with the value yi = f(zi), where f is a function.<br />	deterministic mathematical function (http://en.wikipedia.org/wiki/Data_transformation_(statistics)) <div>&gt; as opposed to a probabilistic math function</div>
The [...] of an estimate of a parameter is equal to the number of independent data points that go into the estimate minus the number of parameters used as intermediate steps in the estimation. 	degrees of freedom (http://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) 
"<img src=""pastehwh8td.jpg"" /> what is lambda?"	"<img src=""pastexpdhpn.jpg"" />"
"Regularization: Setting a Lambda value too high can produce <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Regularization: Setting a Lambda value too high can produce <span style=""font-weight:600; color:#0000ff;"">underfitting</span>"
"Regularized linear regression - cost function<br /><img src=""pastehcjscn.jpg"" />... ?"	"<img src=""pastehkbfdu.jpg"" />Note: you can also use lambda/2m * sum(theta.^2)"
2 types of linear regression	- Gradient descent<br>- Normal equation
2 types of logistic regression	- Gradient descent<br />- Advanced optimization method
"Overfitting can happen with not only higher polynomial features but with just <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Overfitting can happen with not only higher polynomial features but with just <span style=""font-weight:600; color:#0000ff;"">a lot of features</span>"
"Overfitting can happen with not only <span style=""font-weight:600; color:#0000ff;"">[...]</span> but with just <span style=""color:#000000;"">a lot of features</span>"	"Overfitting can happen with not only <span style=""font-weight:600; color:#0000ff;"">higher polynomial features</span> but with just <span style=""font-weight:600; color:#0000ff;"">a lot of features</span>"
When using regularized logistic regression, give a good equation to plot and monitor whether the gradient descent is working correctly?	"<img src=""pastewjm7ys.jpg"" />"
"Regularized logistic regression - gradient descent<br><img src=""paste3llusz.jpg"" />...?"	"<img src=""paster3x_zz.jpg"" />"
"Regularized logistic regression - cost function<br /><img src=""pasteualjie.jpg"" />...?"	"<img src=""pasteyo8efy.jpg"" /><br>Note: theta0 should <span style=""font-weight:600; text-decoration: underline;"">not</span> be regularized"
"Adding a new feature to the model always results in equal or better performance <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"Adding a new feature to the model always results in equal or better performance <span style=""font-weight:600; color:#0000ff;"">on the training set</span> (overfitting)."
"Regularization penalizes <span style=""font-weight:600; color:#0000ff;"">[...]</span> (with large values of θ)."	"Regularization penalizes <span style=""font-weight:600; color:#0000ff;"">complex models</span> (with large values of θ)."
"Regularization<br />Using a very large value of λ can lead to the <span style=""font-weight:600; color:#0000ff;"">[...]</span> of the training set."	"Regularization<br />Using a very large value of λ can lead to the <span style=""font-weight:600; color:#0000ff;"">underfitting</span> of the training set."
"Normalizing helps to <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"Normalizing helps to <span style=""font-weight:600; color:#0000ff;"">converge faster</span>."
Why do you have to do theta*X instead of theta' * X ?	dim(X) = m*n and dim(theta) = n*1:<br />X:<br />m examples * n features<br />&nbsp;&nbsp;-----------------------&gt;n<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X0&nbsp;&nbsp;&nbsp;X1&nbsp;&nbsp;&nbsp;X2 ... Xn<br />&nbsp;&nbsp;&nbsp;&nbsp;-----------------------<br /> |&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;0.57&nbsp;&nbsp;0.2&nbsp;&nbsp;&nbsp;0.1<br /> |&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;...<br /> |<br /> |<br /> v<br />m<br /><br />theta:<br /><br />n theta (n features) * 1<br /> ---&gt; 1<br />|t0|<br />|t1|<br />|t2|<br />|...|<br />|tn|<br />v<br />n
"Matrices multiplication:<br />mxn * nxo = <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Matrices multiplication:<br />mxn * nxo = <span style=""font-weight:600; color:#0000ff;"">mxo</span>"
"In mathematics as in Octave, the first dimension of a matrix is always the <span style=""font-weight:600; color:#0000ff;"">[...]</span> and then the <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"In mathematics as in Octave, the first dimension of a matrix is always the <span style=""font-weight:600; color:#0000ff;"">lines</span> and then the <span style=""font-weight:600; color:#0000ff;"">columns</span>.<br><br>&nbsp;&nbsp;---------------&gt; columns<br>|<br>| lines x columns<br>|<br>v<br>lines"
"Simply explained, regularization is <span style=""font-weight:600; color:#0000ff;"">[... what to add in the equation?]</span>"	"Simply explained, regularization is <span style=""color:#0000ff;"">the addition of the cost of the parameters Thetas to penalize the parameters:</span><br /><span style=""color:#0000ff;"">roughly: costfunction=cost(data)+cost(theta)</span>"
"Regularization<br />In the regularized cost equation, what L1 and L2 correspond in the following image:<br /><img src=""pastew6wbvo.jpg"" />"	"L1 = power 1 : cost(parameters)^1<br />L2 = power 2 : cost(parameters)^2<br /><img src=""pastecvtes3.jpg"" />"
"Kernel trick = <span style=""font-weight:600; color:#0000ff;"">[... definition ...]</span>"	"Kernel trick = <span style=""font-weight:600; color:#0000ff;"">Adding artificial new features from combining and highering polynomes degrees, with the goal to complexify the model.</span>"
"Using kernel trick (adding artificial quadratic/cubic/etc. features) can be too much <span style=""font-weight:600; color:#0000ff;"">[...]</span> for computation time"	"Using kernel trick (adding artificial quadratic/cubic/etc. features) can be too much <span style=""font-weight:600; color:#0000ff;"">expensive</span> for computation time<br><span style=""font-style:italic; color:#acacac;"">eg: O(n) = (n^2)/2 for quadratic features, O(n) = (n^3) for cubic features, etc...</span>"
"In a neural network, there is one <b>input</b> layer, one <b>output</b> layer, and <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"In a neural network, there is one input layer, one output layer, and <span style=""font-weight:600; color:#0000ff;"">one or several hidden layer </span><span style=""font-style:italic; color:#acacac;"">(what is not an inpput layer or output layer is a hidden layer)</span>"
"In neural networks, computing from the inputs to hidden layers to output is called <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"In neural networks, computing from the inputs to hidden layers to output is called <span style=""font-weight:600; color:#0000ff;"">forward propagation</span>"
"Neural network forward propagation vectorized equation:<br><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Neural network forward propagation vectorized equation:<br><span style=""font-weight:600; color:#0000ff;"">a(j)0 = 1</span><br><span style=""font-weight:600; color:#0000ff;"">z(j+1) = theta(j) * a(j)<br />a(j+1) = g(z(j+1))<br />with g() being the sigmoid (logistic) function</span><br><span style=""font-weight:600; color:#0000ff;"">and with a(1) = x</span><br><span style=""font-weight:600; color:#0000ff;""></span><br><img src=""paste7tpgnw.jpg"" />"
"If network has s(j) units in layer j, s(j+1) units in layer j+1, then theta(j) will be of dimension <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"If network has s(j) units in layer j, s(j+1) units in layer j+1, then theta(j) will be of dimension <span style=""font-weight:600; color:#0000ff;"">s(j+1) * s(j) + 1</span><br><span style=""font-style:italic; color:#acacac;"">Note: after adding a(j)0 = 1 (the bias unit), dimensions will be s(j+1)+1 * s(j) + 1</span><br><br><img src=""paste1yyax5.jpg"" />"
"A neural network <span style=""font-weight:600; color:#0000ff;"">[...]</span> defines how the different neurons are connected to each other (how many hidden layers and how many hidden units)."	"A neural network <span style=""font-weight:600; color:#0000ff;"">architecture</span> defines how the different neurons are connected to each other (and how many hidden layers).<br /><span style=""font-style:italic; color:#acacac;"">Alternative answer: the connectivity pattern between neurons</span><br />eg:<br /><img src=""paste9quwbn.jpg"" />"
"If z alias theta*X &gt;= 0, then <span style=""font-weight:600; color:#0000ff;"">[h(X)...y...]</span>"	"If z alias theta*X &gt;= 0, then <span style=""font-weight:600; color:#0000ff;"">g(z) alias h(X) &gt;= 0.5 and y = 1</span>"
"If z (theta*X) &lt; 0, then <span style=""font-weight:600; color:#0000ff;"">[h(X)...y...]</span>"	"If z (theta*X) &lt; 0, then <span style=""font-weight:600; color:#0000ff;"">g(z) alias h(X) &lt; 0.5 and y = 0</span>"
"g(-10) = <span style=""font-weight:600; color:#0000ff;"">[approximately...]</span>"	"g(-10) = <span style=""font-weight:600; color:#0000ff;"">0</span>"
"g(20) = <span style=""font-weight:600; color:#0000ff;"">[approximately...]</span>"	"g(20) = <span style=""font-weight:600; color:#0000ff;"">1</span>"
"g(4.6) = <span style=""font-weight:600; color:#0000ff;"">[approximately...]</span>"	"g(4.6) = <span style=""font-weight:600; color:#0000ff;"">0.99 = 1</span>"
"g(-4.6) = <span style=""font-weight:600; color:#0000ff;"">[approximately...]</span>"	"g(-4.6) = <span style=""font-weight:600; color:#0000ff;"">0.01 = 0</span>"
"In a neural network, the input and first hidden layers compute simple functions, then subsequent layers compute more and more <span style=""font-weight:600; color:#0000ff;"">[...]</span> functions"	"In a neural network, the input and first hidden layers compute simple functions, then subsequent layers compute more and more <span style=""font-weight:600; color:#0000ff;"">complex</span> functions"
"If a neural network is overfitting the data, we can <span style=""font-weight:600; color:#0000ff;"">[...]</span> the regularization parameter lambda to fix that"	"If a neural network is overfitting the data, we can <span style=""font-weight:600; color:#0000ff;"">increase</span> the regularization parameter lambda to fix that"
"If a and b are vectors and a' is a transposed, then<br />a' * b = <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"If a and b are vectors and a' is a transposed, then<br />a' * b = <span style=""font-weight:600; color:#0000ff;"">b' * a</span>"
"When <b>vectorizing</b>, one common strategy for debugging is to <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"When <b>vectorizing</b>, one common strategy for debugging is to <span style=""font-weight:600; color:#0000ff;"">print out the sizes of the matrices you are working with</span>"
[...] is the phenomenon that if a variable is extreme on its first measurement, it will tend to be closer to the average on a second measurement, and vice versa. <br />	regression toward the mean
If the probability p is unknown, how do previous (independent) outcomes in a Bernoulli process provide any information about future outcomes? <br />	through inference about the parameter p (http://en.wikipedia.org/wiki/Bernoulli_distribution) 
What do you call a factor in an ANOVA that is deliberately arranged by the experimenter?	a fixed effect (http://www.statsoft.com/textbook/statistics-glossary/f/button/f/) 
A one-way ANOVA tests the null hypothesis that there are [...] of three or more independent groups. <br />	no differences in the means (note that it can also be used for two groups, but in that case a t-test is typically employed instead) 
If you assume that your two groups have equal variance when calculating a t statistic, how will this change the value of the t statistic? 	it will increase it (by decreasing the denominator) 
In a t-test, are the two compared populations assumed to follow a normal distribution? 	yes
In a t-test, are the two populations being compared assumed to be sampled independently? 	yes
In a t-test, are the two population means being compared assumed to be equal? 	no (that's typically the point of the test) 
What is the main difference between the shape of the Student's t-distribution and the normal distribution? <br />	the t-distribution has heavier tails (i.e., it is more prone to produce values far from its mean) (http://en.wikipedia.org/wiki/Student's_t-distribution) 
"In the below chart of Student's t distributions, what is the order of the colors in decreasing degrees of freedom (df)?<br /><img src=""Screen shot 2012-06-06 at 1.02.37 AM.png"" />"	"<img src=""Screen shot 2012-05-22 at 9.55.15 PM.png"" /> (yellow = 1 &lt; magenta = 2 &lt; blue = 5 &lt; black = ∞) (http://en.wikipedia.org/wiki/Student's_t-distribution) <div>&gt; higher df = more data points = more confidence = narrower bounds</div>"
The [...] is the cumulative distribution function associated with the actual data, and is thus a step function that jumps 1/n at each of the n data points.	empirical distribution function 
The time complexity of an algorithm quantifies [...] an algorithm to run as a function of the size of the input to the problem.	the amount of time taken by (average, worst-case, etc, can be specified a bit later) 
"Two types of classification:<br><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Two types of classification:<br><span style=""font-weight:600; color:#0000ff;"">- Binary classification</span><br><span style=""font-weight:600; color:#0000ff;"">- Multiclass classification (K classes)</span>"
"In a multi-class classification problem, we usually have (number of classes) K &gt;= <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"In a multi-class classification problem, we usually have (number of classes) K &gt;= <span style=""font-weight:600; color:#0000ff;"">3 </span><span style=""font-style:italic; color:#acacac;"">(because for 2 or 1 class we use the binary classification)</span>"
"The cost function used for neural networks is a generalization of <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The cost function used for neural networks is a generalization of <span style=""font-weight:600; color:#0000ff;"">the logistic regression cost function </span><span style=""font-style:italic; color:#acacac;"">(basically: adding multi-class y and multi layers of computation instead of just one)</span><br /><img src=""pastes7diaj.jpg"" /><br />"
"With logistic regression and neural network cost functions, we <span style=""font-weight:600; color:#0000ff;"">[...need or don't need...]</span> to avoid regularizing theta0"	"With logistic regression and neural network cost functions, we <span style=""font-weight:600; color:#0000ff;"">don't need</span> to avoid regularizing theta0 <span style=""font-style:italic; color:#acacac;"">as this is only a common convention</span>"
"Neural network cost function:<br /><img src=""pastenmcqvy.jpg"" /><br />+<span style=""font-weight:600; color:#0000ff;"">[...regularization term...]</span>"	"Neural network cost function:<br /><img src=""pasteittewd.jpg"" />"
"To use an advanced optimization method (fminunc, conjugate gradient, BFGS, L-BFGS, etc.), we need to supply <span style=""font-weight:600; color:#0000ff;"">[...arguments of the function...]</span>"	"To use an advanced optimization method (fminunc, conjugate gradient, BFGS, L-BFGS, etc.), we need to supply <span style=""font-weight:600;color:#0000ff"">cost function J(theta) and the (partial) derivative terms </span><span style=""font-style:italic; color:#acacac;"">delta/(delta*theta(l)ij) for every i, j, l</span>"
"For neural-network, the learning algorithm is basically splitted into these 4 steps:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"For neural-network, the learning algorithm is basically splitted into these 4 steps:<br /><span style=""font-weight:600; color:#0000ff;"">- set a(1) = x(i)</span><br /><span style=""font-weight:600; color:#0000ff;"">- forward propagate</span><br /><span style=""font-weight:600; color:#0000ff;"">- backward propagate</span><br /><span style=""font-weight:600; color:#0000ff;"">- compute the error function (delta), which is the partial derivative (or gradient)</span><br /><img src=""pastee7lr19.jpg"" /><br />"
"In neural networks, the back propagation algorithm is, simply put, the forward propagation in reversal: we compute <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"In neural networks, the back propagation algorithm is, simply put, the forward propagation in reversal: we compute <span style=""font-weight:600; color:#0000ff;"">the sum of the products of the theta (edges) and errors (delta)</span><br><span style=""font-weight:600; color:#0000ff;"">eg:</span><br><img src=""pastesfnay0.jpg"" />"
"Formally, delta(l)j = partial derivative of <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Formally, delta(l)j = partial derivative of <span style=""font-weight:600; color:#0000ff;"">cost(i) (for j&gt;=0)</span><br><img src=""paste4vhd38.jpg"" />"
"Consider the following neural network:<br><img src=""pastebcvdds.jpg"" /><br>What is associated to the red edges? <span style=""font-weight:600; color:#0000ff;"">[...theta...]</span>"	"<img src=""pastejpcqip.jpg"" />"
"Partial derivative of the cost function = <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Partial derivative of the cost function = <span style=""font-weight:600; color:#0000ff;"">gradient</span>"
"The <b>reshape</b> command enables one to <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The <b>reshape</b> command enables one to <span style=""font-weight:600; color:#0000ff;"">form back a matrix from a vector</span>"
"When you implement a back propagation algorithm, you should always implement a <span style=""font-weight:600; color:#0000ff;"">[...]</span> to verify that there's no bug that deviates the result"	"When you implement a back propagation algorithm, you should always implement a <span style=""font-weight:600; color:#0000ff;"">numerical gradient check</span> to verify that there's no bug that deviates the result"
"Numerical gradient checking is simply put <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Numerical gradient checking is simply put <span style=""font-weight:600; color:#0000ff;"">an approximation of the gradient by taking 2 points and calculating the line's coefficient, and then compare to the real derivation found by back propagation.</span><br><span style=""font-style:italic; color:#acacac;"">Alternative answer: a verification if one's implementation of back propagation is bug-free</span>"
"@neural-network: If you set initial_theta to a 0 filled vector, after each update, the produced parameters for every units will be <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"@neural-network: If you set initial_theta to a 0 filled vector, after each update, the produced parameters for every units will be <span style=""font-weight:600; color:#0000ff;"">identical </span><span style=""font-style:italic; color:#acacac;"">(hence why one must randomize the initial_theta vector)</span>"
"The two most common fixes to get a good neural network back propagation implementation are:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The two most common fixes to get a good neural network back propagation implementation are:<br /><span style=""font-weight:600; color:#0000ff;"">- randomized initial_theta </span><span style=""font-style:italic; color:#acacac;"">(so to avoid the symmetric weights problem, where each hidden unit gets the exact same function)</span><br /><span style=""font-weight:600; color:#0000ff;"">- numerical gradient checking</span> <span style=""font-style:italic; color:#acacac;"">(so that we can check that the gradient/partial derivative is OK and implementation of backprop is bug-free)</span>"
"In neural network's back propagation, the symmetric weights problem is when <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"In neural network's back propagation, the symmetric weights problem is when <span style=""font-weight:600; color:#0000ff;"">you get the exact same function for each hidden unit because of a non randomized initial_theta</span>"
"Neural network training algorithm<br /><span style=""font-weight:600; color:#0000ff;"">[...7 steps...]</span>"	"Neural network back propagation algorithm<br /><span style=""font-weight:600; color:#0000ff;"">- Pick a network architecture (connectivity pattern between neurons: how many hidden units in how many layers)<br />- Randomly initialize initial_theta</span><br /><span style=""font-weight:600; color:#0000ff;"">- Implement forward propagation to get h(x(i)) for any x(i) to compare with y(i)</span><br /><span style=""font-weight:600; color:#0000ff;"">- Implement cost function J(theta)<br />- Compute back propagation (error function) to compute partial derivatives<br />- Gradient checking<br />then disable gradient checking</span><br /><span style=""font-weight:600; color:#0000ff;"">- Minimize cost function J(theta) by using gradient descent or advanced optimization function </span><span style=""font-style:italic; color:#acacac;"">(using the partial derivative/gradient found by backprop)</span>"
"Gradient descent in neural networks is non-convex, which means that there are <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Gradient descent in neural networks is non-convex, which means that there are <span style=""font-weight:600; color:#0000ff;"">local optimums</span>"
"The intuition behind the neural network back propagation algorithm is as follows:<br>Given a training example (x(t);y(t)), we first run a <span style=""font-weight:600; color:#0000ff;"">[...]</span> to compute all the activations throughout the network, including the output value of the hypothesis h(x).<br>Then, for each node j in layer l, we back propagate the errors by computing the &quot;error term&quot; delta(l)j that measures how much that node was &quot;responsible&quot; for the errors in our output."	"The intuition behind the neural network back propagation algorithm is as follows:<br>Given a training example (x(t);y(t)), we first run a <span style=""font-weight:600; color:#0000ff;"">forward propagation</span> to compute all the activations throughout the network, including the output value of the hypothesis h(x).<br>Then, for each node j in layer l, we back propagate the errors by computing the &quot;error term&quot; delta(l)j that measures how much that node was &quot;responsible&quot; for the errors in our output."
"Gradient checking works for any function where you are computing the cost and the gradient, so it equally works for neural network, <span style=""font-weight:600; color:#0000ff;"">[...]</span> cost functions."	"Gradient checking works for any function where you are computing the cost and the gradient, so it equally works for neural network, <span style=""font-weight:600; color:#0000ff;"">logistic regression and linear regression</span> cost functions."
"In neural network backprop, Big delta is simply put <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"In neural network backprop, Big delta is simply put <span style=""font-weight:600; color:#0000ff;"">the error cost of the Theta (edges), alias theta_gradient</span><br><span style=""font-weight:600; color:#0000ff;"">(TODO: add image)</span>"
"Small deltas are, simply put, <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Small deltas are, simply put, <span style=""font-weight:600; color:#0000ff;"">the error costs for the units (neurons)</span><br><span style=""font-weight:600; color:#0000ff;"">(TODO: add image)</span>"
"What are the most common avenues to explore to fix big errors in a learning algorithm prediction:<br><span style=""font-weight:600; color:#0000ff;"">[...4 common fix...]</span>"	"What are the most common avenues to explore to fix big errors in a learning algorithm prediction:<br><span style=""font-weight:600; color:#0000ff;"">1. Add or reduce number of features</span><br><span style=""font-weight:600; color:#0000ff;"">2. Add artificial features (polynomial features, or Kernel trick)</span><br><span style=""font-weight:600; color:#0000ff;"">3. Get more training examples</span><br><span style=""font-weight:600; color:#0000ff;"">4. Increasing or decreasing the regularization parameter Lambda</span>"
"A Machine learning diagnostic is a <span style=""font-weight:600; color:#0000ff;"">[...definition...]</span>"	"A Machine learning diagnostic is a <span style=""font-weight:600; color:#0000ff;"">test checks what is/isn't working with a learning algorithm </span><span style=""font-style:italic; color:#acacac;"">(which will indicate what to do next to best improve performances)</span><br><span style=""font-style:italic; color:#acacac;"">Note: this can be time-consuming but is a very important practice, as it will show what is more likely, or unlikely, to improve performances significantly.</span>"
"Recommended approach when designing a machine learning system [no answer]:<br />- Start with a simple algorithm that you can implement as quickly as possible (in one or a few days <u>at most</u>). Implement it and test it on your cross-validation data. <span style=""font-style:italic; color:#acacac;"">This initial implementation of your algorithm is CRITICAL and a very powerful tool to know where to go further.</span><br />- Plot learning curves to decide if more data, more features, etc. are likely to help.<br />- Error analysis: Manually examine the examples (in cross-validation set) that your algorithm made errors on. See if you spot any systematic trend in what type of examples it is making errors on.<br /><br /><span style=""font-weight:600; color:#0000ff;""> (In summary: avoid premature optimization and prefer profiling on a quick and dirty implementation and then try and test quickly if a solution works)</span>"	
"When designing the enhancements to implement in a machine learning system, it is especially important to have a <span style=""font-weight:600; color:#0000ff;"">[...]</span> of the success of the solution"	"When designing the enhancements to implement in a machine learning system, it is especially important to have a <span style=""font-weight:600; color:#0000ff;"">single real number evaluation</span> of the success of the new solution <span style=""font-style:italic; color:#acacac;"">(eg: cross-validation set error rate, error metrics like accuracy, etc...)</span>"
"It is always recommended to do evaluation on the <span style=""font-weight:600; color:#0000ff;"">[...] set</span>, as this is more mathematically correct for error analysis."	"It is always recommended to do evaluation on the <span style=""font-weight:600; color:#0000ff;"">cross-validation set rather than on the test set</span>, as this is more mathematically correct for error analysis.<br /><br /><span style=""font-style:italic; color:#acacac;"">Note: because the system will be overly optimistic on the cross-validation set since we've done some tunings of some parameters over this set, so it's not objective anymore.</span>"
"The learning error rate is the opposite of the <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The learning error rate is the opposite of the <span style=""font-weight:600; color:#0000ff;"">accuracy</span>"
"Accuracy or learning error rate is not always a good error metric, particularly on <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Accuracy or learning error rate is not always a good error metric, particularly on <span style=""font-weight:600; color:#0000ff;"">skewed classes</span>"
"A skewed class is when <span style=""font-weight:600; color:#0000ff;"">[...definition...]</span>"	"A skewed class is when <span style=""font-weight:600; color:#0000ff;"">there are only a few rare positives compared to the negative class (or the opposite)</span><br /><span style=""font-style:italic; color:#acacac;"">ie: always predicting y = 0 gives a very good accuracy (like over 90%)</span><br /><br /><span style=""font-style:italic; color:#acacac;"">eg: Anomaly detection systems always have very skewed classes so we can't use accuracy.</span>"
"There are alternative error metrics for skewed classes like <span style=""font-weight:600; color:#0000ff;"">[...3 elements...]</span>"	"There are alternative error metrics for skewed classes like <span style=""font-weight:600; color:#0000ff;"">Precision or Recall or F1 score.</span><br><span style=""font-weight:600; color:#0000ff;""></span><br><span style=""font-style:italic; color:#acacac;"">eg: Anomaly detection systems always have very skewed classes so we can't use accuracy. For ADS, using these error metrics make much more sense.</span>"
"Precision is <span style=""font-weight:600; color:#0000ff;"">[...definition...]</span><br /><img src=""pasteqna87l.jpg"" />"	"Precision is <span style=""font-weight:600; color:#0000ff;"">the number of true positives over the total number of predicted positives (true positives + false positives):</span><br /><span style=""font-weight:600; color:#0000ff;"">Precision = true positives / #predicted positives</span><br /><span style=""font-weight:600; color:#0000ff;"">Precision = (true positives) / (true positives + false positives)</span><br /><img src=""paste0rbvpq.jpg"" />"
"Accuracy is <span style=""font-weight:600; color:#0000ff;"">[...definition...]</span><br /><img src=""pasteqna87l.jpg"" />"	"Accuracy is <span style=""font-weight:600; color:#0000ff;"">the opposite of the error rate:</span><br /><span style=""font-weight:600; color:#0000ff;"">Accuracy = (true positives + true negatives) / (total examples)</span><br /><span style=""font-style:italic; color:#acacac;"">eg: if error rate = 0.5% then accuracy = 99.5%</span><br><img src=""pastetfmpxx.jpg"" />"
"Recall is <span style=""font-weight:600; color:#0000ff;"">[...definition...]</span><br /><img src=""pasteqna87l.jpg"" />"	"Recall is <span style=""font-weight:600; color:#0000ff;"">of the actual positives (true positives + false negatives), how many did we detect?</span><br /><span style=""font-weight:600; color:#0000ff;"">Recall = true positives / #actual positives</span><br /><span style=""font-weight:600; color:#0000ff;"">Recall = (true positives) / (true positives + false negatives)</span><br><img src=""pastefwvzuf.jpg"" />"
"<b>Error metrics</b> are used to <span style=""font-weight:600; color:#0000ff;"">[...definition...]</span>"	"Error metrics are used to <span style=""font-weight:600; color:#0000ff;"">evaluate the performance of the system using a single real number representation of the performance (eg: Accuracy or Error Rate, Precision, etc...). Simply put, it tells you how well your classifier is doing. This is especially important to make decisions (and the right ones).</span>"
"Generally, it is preferred for error metrics to define y = <span style=""font-weight:600; color:#0000ff;"">[...]</span> for the rare class"	"Generally, it is preferred for error metrics to define y = <span style=""font-weight:600; color:#0000ff;"">1</span> for the rare class"
"Generally, there is a trade-off between precision and recall, so that if we set a high threshold for h_theta(x) we get <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Generally, there is a trade-off between precision and recall, so that if we set a high threshold for h_theta(x) we get <span style=""font-weight:600; color:#0000ff;"">a higher precision and a lower recall</span><br /><img src=""pasteffjn6q.jpg"" /><br><br><span style=""font-style:italic; color:#acacac;"">Note: concretely we have to retrain the system on the training set with the new threshold for h_theta(x) and then test the score (precision,recall,F1-score) on the cross-validation set.</span>"
"Generally, there is a trade-off between precision and recall, so that if we set a lower threshold for h_theta(x) we get <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Generally, there is a trade-off between precision and recall, so that if we set a lower threshold for h_theta(x) we get <span style=""font-weight:600; color:#0000ff;"">a higher recall and a lower precision</span><br /><img src=""pasteffjn6q.jpg"" /><br><br><span style=""font-style:italic; color:#acacac;"">Note: concretely we have to retrain the system on the training set with the new threshold for h_theta(x) and then test the score (precision,recall,F1-score) on the cross-validation set.</span>"
"The extremes in error metrics are very bad, and we can spot them easily by <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The extremes in error metrics are very bad, and we can spot them easily by <span style=""font-weight:600; color:#0000ff;"">seeing if one of the error metrics is particularly very low (near 0) or by computing the F1 score</span>"
"F1 score is just one of <span style=""font-weight:600; color:#0000ff;"">[...]</span> to combine Precision and Recall and is historically the most used in machine learning"	"F1 score is just one of <span style=""font-weight:600; color:#0000ff;"">many possible ways</span> to combine Precision and Recall and is historically the most used in machine learning"
"The F1 score is a way to <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The F1 score is a way to <span style=""font-weight:600; color:#0000ff;"">automatically choose the best threshold for h_theta(x) to get the best trade-off between precision and recall because it gives a single real number out of the combination of precision and recall:</span><br /><br><span style=""font-weight:600; color:#0000ff;"">F1 score = (2 * precision * recall) / (precision + recall)</span><br /><img src=""pasteohzbqb.jpg"" /><br><br><span style=""font-style:italic; color:#acacac;"">Note: concretely we have to retrain the system on the training set with the new threshold for h_theta(x) and then test the score (precision,recall,F1-score) on the cross-validation set.</span>"
"A <b>key test</b> to know if the features x contains enough informations to predict y is to ask: <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"A <b>key test</b> to know if the features x contains enough informations to predict y is to ask: <span style=""font-weight:600; color:#0000ff;"">&quot;given the input x, can a human expert confidently predict y?&quot;</span>"
"Large data rationale<br />Assuming that the features x contains enough informations to predict y and we have a large training set<br />-&gt; Jtrain(theta) will be small (with a low bias algorithm)<br />-&gt; Jtrain(theta) =~ Jtest(theta) (=~ means about equal)<br />(hopefully) imply that:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Large data rationale<br />Assuming that the features x contains enough informations to predict y and we have a large training set<br />-&gt; Jtrain(theta) will be small (with a low bias algorithm)<br />-&gt; Jtrain(theta) =~ Jtest(theta) (=~ means about equal)<br />(hopefully) imply that:<br /><span style=""font-weight:600; color:#0000ff;"">-&gt; Jtest (theta) will be small</span><br /><img src=""pasteix3k6q.jpg"" />"
"Support Vector Machine (SVM) is also called <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Support Vector Machine (SVM) is also called <span style=""font-weight:600; color:#0000ff;"">Large Margin Classifier </span><span style=""font-style:italic; color:#acacac;"">(because it will try to maximize the projection length p in order to suffice to the constraints theta' * x(i) &gt;= 1 or &lt;= 1 while minimizing the cost of the parameters theta):</span><br /><img src=""pastea_4iye.jpg"" /><br /><span style=""font-style:italic; color:#acacac;"">(notice the length of p in the left example, and its length in the right example)</span><br />"
"Polynomial kernel general formulation: <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Polynomial kernel general formulation:<br><img src=""pasteuvlfe8.jpg"" />"
"Having two vectors u and v, u'*v (matrix product of u transpose and v) is also called the <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Having two vectors u and v, u'*v (matrix product of u transpose and v) is also called the <span style=""font-weight:600; color:#0000ff;"">vector inner product</span>"
"||u|| is called the norm or length of the vector u, which is the <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"||u|| is called the norm or length of the vector u, which is the <span style=""font-weight:600; color:#0000ff;"">euclidian length of the vector u</span><br><img src=""paste3uchl7.jpg"" />"
"In a graphical view, the vector inner product of two vectors u and v (u' * v) is <span style=""font-weight:600; color:#0000ff;"">[...mathematical definition...]</span>"	"In a graphical view, the vector inner product of two vectors u and v (u' * v) is <span style=""font-weight:600; color:#0000ff;"">the orthogonal projection </span><span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">p</span><span style=""font-weight:600; color:#0000ff;""> of the vector v onto the vector u multiplied by the norm (or length) of the vector u:</span><br /><span style=""font-weight:600; color:#0000ff;"">u' * v = p * ||u|| = orthogonal_projection(v,u) * sqrt(u(1)² + u(2)²) = v' * u</span><br /><img src=""pasteeppqz1.jpg"" />"
"If the angle between the two vectors v and u is greater than 90°, what does p (the projection of u onto v or v onto u) looks like?<br /><img src=""pastekcpyc5.jpg"" />"	"<span style=""font-weight:600; color:#0000ff;"">p will be negative:</span><br><img src=""pastexx9trb.jpg"" />"
"SVM is also called large margin classifier because it will always try<span style=""color:#000000;""> to </span><span style=""font-weight:600; color:#0000ff;"">[...graphical explanation using orthogonal projection...]</span><br><span style=""font-style:italic; color:#acacac;""></span>"	"SVM is also called large margin classifier because it will always try<span style=""font-weight:600; color:#0000ff;""> </span><span style=""color:#000000;"">to </span><span style=""font-weight:600; color:#0000ff;"">maximize the projection length p in order to suffice to the constraints theta' * x(i) &gt;= 1 or &lt;= 1 while minimizing the cost of the parameters theta:</span><br><img src=""pastea_4iye.jpg"" /><br /><span style=""font-style:italic; color:#acacac;"">(notice the length of p in the left example, and its length in the right example)</span>"
"The projection p of a vector u is a <span style=""font-weight:600; color:#0000ff;"">[...signed,unsigned?...]</span> integer"	"The projection p of a vector v onto a vector u is a <span style=""font-weight:600; color:#0000ff;"">signed</span> integer <span style=""font-style:italic; color:#acacac;"">(negative or positive depending if the angle between u and v &gt; 90)</span>"
"K-means is an iterative algorithm that does two things:<br><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"K-means is an iterative algorithm that does two things:<br><span style=""font-weight:600; color:#0000ff;"">- Cluster assignment step</span><br><span style=""font-weight:600; color:#0000ff;"">- Move centroid step</span>"
Give the K-Means algorithm	"K-Means algorithm:<br /><img src=""pasteecud0l.jpg"" /><br /><span style=""font-style:italic; color:#acacac;"">(alternative formulation from ai-class:)</span><br /><span style=""font-weight:600; color:#0000ff;"">Initially: select randomly k cluster centers</span><br /><span style=""font-weight:600; color:#0000ff;"">repeat until no change</span><br /><span style=""font-weight:600; color:#0000ff;"">--- Correspond data points to their nearest clusters</span><br /><span style=""font-weight:600; color:#0000ff;"">--- Move each cluster center by mean of the corresponding data points</span><br /><span style=""font-weight:600; color:#0000ff;"">--- Empty cluster center : move randomly or eliminate</span>"
"Can K-Means be used to segment this population into 3 groups: small, medium and large (size of t-shirt)?<br><img src=""pasteds3rfq.jpg"" />"	"Yes, K-Means with a fixed number of clusters (here 3) to forcefully find a segmentation for the population.<br><img src=""pastewhsifw.jpg"" />"
"Every machine learning algorithm has an <span style=""font-weight:600; color:#0000ff;"">[...objective?...]</span>"	"Every machine learning algorithm has an <span style=""font-weight:600; color:#0000ff;"">optimization objective, which is a minimization of the cost function</span>"
"Knowing the optimization objective of a machine learning algorithm helps to <span style=""font-weight:600; color:#0000ff;"">[...2 items...]</span>"	"Knowing the optimization objective of a machine learning algorithm helps to <span style=""font-weight:600; color:#0000ff;"">debug the algorithm and make it efficient to avoid local optima</span>"
"The K-Means cost function is also called <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The K-Means cost function is also called <span style=""font-weight:600; color:#0000ff;"">the distortion cost function or distortion of the K-Means algorithm</span>"
"In a graphical representation, what does this represent?<br><img src=""pastetava7q.jpg"" />"	"<span style=""font-weight:600; color:#0000ff;"">This is the squared distance between x(i) and mu(c(i)):</span><br><img src=""pastesjarch.jpg"" /><br><span style=""font-style:italic; color:#acacac;"">Note: the squared of the distance is just a convention, we could use just the distance instead.</span>"
K-Means cost function?	"K-Means cost function (or optimization objective):<br /><img src=""pastelrnbio.jpg"" /><br><span style=""font-style:italic; color:#acacac;"">Note: the squared distance is a convention, one can just use the distance instead.</span><br><br><span style=""color:#000000;"">Detailed K-Means functionning with respect to the cost function:</span><br><img src=""pastevcyrfa.jpg"" />"
"Suppose you have implemented k-means and you plot the cost function J(c(1),...,c(m),mu(1),...,mu(k)) as a function of the number of iterations and your plot looks like this:<br /><img src=""pasteliim6e.jpg"" /><br />What do you conclude?"	"<span style=""font-weight:600; color:#0000ff;"">It is not possible for the cost function to sometimes increase. There must be a </span><span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">bug</span><span style=""font-weight:600; color:#0000ff;""> in the code.</span><br /><span style=""font-style:italic; color:#acacac;"">Note: there's no learning rate to tweak.</span>"
Give the recommended method to initialize k-means.	"Randomly initialize k clusters onto random k examples from the training set:<br /><img src=""pastexd0soc.jpg"" /><br /><br /><img src=""pasteksvvui.jpg"" /><br /><br />Eventually, if K is small (2 &lt;= K &lt;= 10) then we can run multiple random initialization:<br /><img src=""paste9lybio.jpg"" /><br />Because a lower value for the distortion/cost function implies a better clustering, so you should choose the clustering with the smallest value for the distortion function."
"Using a good initialization for K-Means (randomly initialized on k training examples) helps a lot to <span style=""font-weight:600; color:#0000ff;"">[...2 items...]</span>"	"Using a good initialization for K-Means (randomly initialized on k training examples) helps a lot to <span style=""font-weight:600; color:#0000ff;"">converge faster and to avoid local optimums</span>"
"The number of cluster K for K-Means is most often chosen manually by human, but it can be semi-automatically found with two methods:<br /><span style=""font-weight:600; color:#0000ff;"">[...2 items...]</span>"	"The number of cluster K for K-Means is most often chosen manually by human, but it can be semi-automatically found with two methods:<br /><span style=""font-weight:600; color:#0000ff;"">- Elbow method (give it a shot but most of the time it won't be useful):</span><br /><img src=""pastep3hmpy.jpg"" /><br /><span style=""font-weight:600; color:#0000ff;"">- Evaluate K-means based on a metric for how well it performs in respect to the later purpose (eg: T-shirt business)</span><br /><img src=""paste8w6mtq.jpg"" />"
"Dimensionality reduction's purpose is to <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Dimensionality reduction's purpose is to <span style=""font-weight:600; color:#0000ff;"">project the dataset {x(1), ..., x(m)} with x(i) in R^n onto a lesser dimensional dataset of {z(1), ..., z(m)} with z(i) is in R^k where k &lt;= n.</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">Alternative answer: to compress data by merging redundant or similar/</span><span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">correlated</span><span style=""font-weight:600; color:#0000ff;""> features in order to save memory space and computational time (so that the machine learning algorithm is much more quick and converge faster).</span><br /><span style=""font-weight:600; color:#0000ff;"">eg:</span><br /><img src=""pastesoabyl.jpg"" />"
"Data compression by dimensionality reduction is only an <span style=""font-weight:600; color:#0000ff;"">[...]</span> of the data"	"Data compression by dimensionality reduction is only an <span style=""font-weight:600; color:#0000ff;"">approximation (but a close one)</span> of the data"
"Dimensionality reduction can be used for two purposes:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Dimensionality reduction can be used for two purposes:<br /><span style=""font-weight:600; color:#0000ff;"">- Data compression (merging similar features)</span><br /><span style=""font-weight:600; color:#0000ff;"">&nbsp;&nbsp;* Speedup machine learning algorithm (converge and predict faster)</span><br /><span style=""font-weight:600; color:#0000ff;"">&nbsp;&nbsp;* Reduce memory/disk storage space needed</span><br /><span style=""font-weight:600; color:#0000ff;"">- Data visualization of high-dimensional data (to be able to plot a high dimensional chart into a lesser dimensional graphical representation 2D or 3D)</span><br /><span style=""font-weight:600; color:#0000ff;"">eg:</span><br /><img src=""pasteqybmog.jpg"" /><br /><img src=""pasteniy3pa.jpg"" /><br /><img src=""paste3b1_dq.jpg"" />"
"PCA is not linear regression, because <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"PCA is not linear regression, because <span style=""font-weight:600; color:#0000ff;"">there is no prediction of a special variable y, all variables x are treated equally, and we compute orthogonal projection rather than the prediction error:</span><br /><img src=""pastentq8_q.jpg"" /><br />(linear regression on the left, PCA on the right)"
"Principal Component Analysis (PCA)'s goal is to <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Principal Component Analysis (PCA)'s goal is to <span style=""font-weight:600;color:#0000ff"">find a lower dimensional surface (k vectors/directions) onto which to project the data while minimizing the squared projection error.</span><br /><img src=""pasteeefxiv.jpg"" /><br /><span style=""font-style:italic; color:#acacac;"">With Xapprox = z</span><br /><br /><span style=""color:#0000ff;"">Alternative answer: to find the eigenvectors (sub dimensioned subspaces) which keep the maximal variance of the original dataset.</span><br /><span style=""font-style:italic; color:#acacac;"">eg: vector with maximal variance</span><br /><img src=""pasten_uwtc.jpg"" /><br /><br /><span style=""font-style:italic; color:#acacac;"">bad vector: minimal variance</span><br /><img src=""pastesc8m_f.jpg"" />"
"The most common algorithm for automatic Dimensionality Reduction is called <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The most common algorithm for automatic Dimensionality Reduction is called <span style=""font-weight:600; color:#0000ff;"">Principal Component Analysis (PCA)</span>"
"Before using PCA, it is very important to procede to a <u>data preprocessing</u> by doing <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"Before using PCA, it is very important to procede to a <u>data preprocessing</u> by doing <span style=""font-weight:600; color:#0000ff;"">mean normalization (ensure every feature has zero mean) and feature scaling (ensure that every feature is in the same range of values)</span>."
"Using PCA, after calculating the svd of the covariance matrix, to reduce the data from n dimensions to k dimensions, we only need to <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Using PCA, after calculating the svd of the covariance matrix, to reduce the data from n dimensions to k dimensions, we only need to <span style=""font-weight:600; color:#0000ff;"">take the k first columns (or vectors) of the matrix U</span><br /><img src=""pasteybdamp.jpg"" />"
"Principal Component Analysis (PCA) (dimensionality reduction) algorithm:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Principal Component Analysis (dimensionality reduction) algorithm:<br /><span style=""font-weight:600; color:#0000ff;"">- Data preprocessing (mean normalization + feature scaling)<br />- Compute the covariance matrix Sigma<br />- Compute the eigenvectors matrix U<br />- Ureduce = Extract k vectors (columns) from U<br />- Z = Project X examples with Ureduce</span><br /><img src=""paster8qyc9.jpg"" /><br /><span style=""font-weight:600; font-style:italic; color:#acacac;"">Note: remember that there's no X0 = 1</span><br><span style=""font-weight:600; font-style:italic; color:#acacac;"">Note2: in a vectorized implementation, Z = X * Ureduce</span>"
"In principal component analysis (PCA), K is called the <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"In principal component analysis (PCA), K is called the <span style=""font-weight:600; color:#0000ff;"">number of principal components (we have retained)</span>"
Suppose you run k-means using k=3 and k=5 and you find that the cost function J is much higher for k=5 than for k=3. What can you conclude?	"<span style=""font-weight:600; color:#0000ff;"">For higher values of k, k-means should always get a lower optimum value (more clusters = smaller cost/average distance between clusters and examples).</span><br><span style=""font-weight:600; color:#0000ff;"">This means that for k=5, k-means got stuck in a bad local optimum, and you should try re-running k-means with multiple random initializations.</span>"
@pca Give the 2 methods to automatically choose the value for k (number of principal components)	"<span style=""font-weight:600; color:#0000ff;"">Automatically choosing the number of principal components k for PCA</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">- Run PCA, get Uk vectors and compute z^k, then compute the average variation on the projection over the average variation of the original dataset, and redo that for k = 1 to n until we have an acceptable variance (eg: &gt;= 99%):</span><br /><span style=""font-style:italic; color:#acacac;"">Note: we don't have to recompute the SVD only once, then we can compute several times Uk'*x</span><br /><img src=""pastetg6ozy.jpg"" /><br /><img src=""pasteol4p4d.jpg"" /><br /><span style=""font-weight:600; color:#0000ff;"">- Use the diagonal values of the S matrix given by SVD function, which represent the cumulative variation of the z^k dimensionally reduced dataset:</span><br /><span style=""font-style:italic; color:#acacac;"">Note: this method is more efficent than the other one.</span><br /><img src=""paste5wavpg.jpg"" /><br /><span style=""font-weight:600; color:#0000ff;"">Note: these methods can also be used for plotting to manually decide the best tradeoff</span>"
"PCA data compression: we can reconstruct a close approximation of the original dataset in the original dimension simply by <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"PCA data compression: we can reconstruct a close approximation of the original dataset in the original dimension simply by <span style=""font-weight:600; color:#0000ff;"">projecting Z onto the original dimension:</span><br /><span style=""font-weight:600; color:#0000ff;"">Xapprox(i) = Ureduce * Z(i) = Z * Ureduce'</span><br /><img src=""pasteju9j1v.jpg"" />"
"We can use dimensionality reduction to speedup supervised learning by simply <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"We can use dimensionality reduction to speedup supervised learning by simply <span style=""font-weight:600; color:#0000ff;"">applying PCA on the unlabeled dataset (X without Y) which give Z and recouple Z with Y.</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">Note: When we get a new example x(i) to add in the dataset, we can project it using our already computed vectors Ureduce.</span><br /><span style=""font-weight:600; color:#0000ff;"">Note2: Ureduce should only be computed on the training set (just like parameters theta), not the cv or test set (but we can then compute zcv and ztest using Ureduce and mean normalization+features scaling found before, see below)</span><br /><img src=""pasterrsyvo.jpg"" /><br /><span style=""font-style:italic; color:#acacac;"">Note: Mapping (computing Ureduce and mean normalization+feature scaling) x(i) -&gt; z(i) should be computed by running PCA </span><span style=""font-weight:600; font-style:italic; text-decoration: underline; color:#acacac;"">only on the training set</span><span style=""font-style:italic; color:#acacac;"">. This mapping can later be applied as well to the examples xcv(i) and xtest(i) in the cross validation and test sets or to new examples in the training set.</span>"
"3 bad use of PCA are:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"3 bad use of PCA are:<br /><span style=""font-weight:600; color:#0000ff;"">- To prevent overfitting by having fewer features </span><span style=""font-style:italic; color:#acacac;"">(use regularization parameter lambda instead because PCA doesn't use labels y so it may throw away valuable informations while cost function with regularization doesn't)</span><br /><span style=""font-weight:600; color:#0000ff;"">- Planning to use PCA from the start </span><span style=""font-style:italic; color:#acacac;"">(first try to process the raw data and then only if it doesn't work the intended way, try with PCA)</span><br><span style=""font-weight:600; color:#0000ff;"">- Clustering</span><span style=""font-style:italic; color:#acacac;""> (PCA does no clustering into coherent groups, but it can help later to find clusters with another clustering algorithm like K-Means)</span>"
"SVM (Support Vector Machine) cost function:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"SVM (Support Vector Machine) cost function:<br /><img src=""pasteh055vn.jpg"" /><br />where the functions cost0(z) and cost1(z) look like this:<br /><img src=""pastetd1gll.jpg"" />"
"In an SVM, we have:<br /><span style=""color:#000000;"">- for every example with y(i) = 0:</span><span style=""font-weight:600; color:#0000ff;""> theta' * x(i) [...]<br /></span><span style=""color:#000000;"">- for every example with y(i) = 1:</span><span style=""font-weight:600; color:#0000ff;""> theta' * x(i) [...]</span>"	"In an SVM, for every example with y(i) = 1, we have:<br /><span style=""font-weight:600; color:#0000ff;"">- </span><span style=""font-weight:600; color:#0000ff;"">for every example with y(i) = 0: </span><span style=""font-weight:600; color:#0000ff;"">theta' * x(i) &lt;= -1</span><span style=""font-weight:600; color:#0000ff;""><br /></span><span style=""font-weight:600; color:#0000ff;"">- </span><span style=""font-weight:600; color:#0000ff;"">for every example with y(i) = 1: </span><span style=""font-weight:600; color:#0000ff;"">theta' * x(i) &gt;= 1</span><br /><img src=""pastetd1gll.jpg"" />"
"In Anomaly Detection, we're given a set of <u>unlabeled</u> data, and the goal is to find <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"In Anomaly Detection, we're given a set of <u>unlabeled</u> data, and the goal is to find <span style=""font-weight:600; color:#0000ff;"">a gaussian model p(x) for this data so that for a given example xtest:</span><br /><span style=""font-weight:600; color:#0000ff;"">- if p(xtest) &lt; E -&gt; flag anomaly</span><br /><span style=""font-weight:600; color:#0000ff;"">- if p(xtest) &gt;= E -&gt; flag ok</span><br /><br /><span style=""font-style:italic; color:#acacac;"">Note: p(xtest) is the probability for the example xtest of being in the model (being &quot;normal&quot;).</span><br /><span style=""font-style:italic; color:#acacac;"">Note2: E is a constant threshold.</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">eg:</span><br /><img src=""pastefavdkl.jpg"" />"
"The best approach in Anomaly Detection is to modelize <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"The best approach in Anomaly Detection is to modelize <span style=""font-weight:600; color:#0000ff;"">the &quot;normality&quot;, so that if an example is outside of the normal behavior we flag it as an anomaly</span>.<br /><br />eg:<br /><img src=""pastefavdkl.jpg"" />"
"Cite some applications of Anomaly Detection:<br><span style=""font-weight:600; color:#0000ff;"">[...3 items...]</span>"	"Cite some applications of Anomaly Detection:<br><span style=""font-weight:600; color:#0000ff;"">- Fraud detection</span><br><span style=""color:#000000;"">&nbsp;&nbsp;* x(i) = features of user i's activities</span><br><span style=""color:#000000;"">&nbsp;&nbsp;* Model p(x) from data.</span><br><span style=""color:#000000;"">&nbsp;&nbsp;* Identify unusual users by checking which have p(x) &lt; E</span><br><span style=""color:#000000;"">&nbsp;&nbsp;* Then report to admin to ask for review and more details</span><br><span style=""font-style:italic; color:#acacac;"">eg: x1 = how often user login, x2 = number of transactions or webpages visited, x3 = number of posts in the forum, x4 = typing speed of the user in character/second, etc...</span><br><span style=""font-weight:600; color:#0000ff;""></span><br><span style=""font-weight:600; color:#0000ff;"">- Manufacturing</span><br><span style=""font-style:italic; color:#acacac;"">eg: aircraft engine quality with x1 = heat generated, x2 = vibration intensity, etc...</span><br><span style=""font-weight:600; color:#0000ff;""></span><br><span style=""font-weight:600; color:#0000ff;"">- Monitoring computers in a data center</span><br><span style=""color:#000000;"">&nbsp;&nbsp;* x(i) = features of machine i</span><br><span style=""color:#000000;"">&nbsp;&nbsp;* if p(xtest) &lt; E then the machine is anomalous and it means it may soon shutdown</span><br><span style=""font-style:italic; color:#acacac;"">eg: x1 = memory use, x2 = number of disk accesses/sec, x3 = CPU load, x4 = CPU load / network traffic, etc...</span>"
"A gaussian distribution is also called a <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"A gaussian distribution is also called a <span style=""font-weight:600; color:#0000ff;"">normal distribution</span>."
"A normal distribution is a <span style=""font-weight:600; color:#0000ff;"">[...parameters?...]</span>"	"A normal distribution is a <span style=""font-weight:600; color:#0000ff;"">distributed gaussian with mean mu, variance sigma^2, and is written:</span><br /><span style=""font-weight:600; color:#0000ff;"">x ~ N(mu, sigma^2)</span><br /><br /><span style=""font-style:italic; color:#acacac;"">Note: graphically, the mean mu represent the center of the gaussian, and the variance sigma^2 represent the width of the gaussian:</span><br /><br /><img src=""pasteud8ife.jpg"" /><br /><br />eg:<br /><img src=""pastet9aeps.jpg"" /><br />Note: the <span style=""font-style:italic; color:#acacac;"">(integral of the)</span> total density distribution must always be = 1 (because it's a sum of probabilities), that's why by changing sigma, the width change but the height too."
"One interpretation of the variance is that it is <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"One interpretation of the variance is that it is <span style=""font-weight:600; color:#0000ff;"">the average of the squared difference (values in the examples minus the mean):</span><br /><br /><img src=""pasteikxi16.jpg"" /><br><br><span style=""font-style:italic; color:#acacac;"">Note: these calculations are actually the maximum likelihood estimates of the parameters mu and sigma.</span>"
"The parameter estimation problem is the problem of <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The parameter estimation problem is the problem of <span style=""font-weight:600; color:#0000ff;"">finding the right parameters mu (mean) and sigma^2 (variance) for the gaussian distribution.</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">Alternative answer: finding the right parameters to modelize a normal distribution over the examples data {x(1),x(2),...,x(m)}</span><br /><br /><img src=""pasteommj6m.jpg"" /><br /><br />Note: in some notation we can find 1/(m-1) instead of 1/m, but both works pretty much the same for machine learning.<br /><img src=""pasteo7zcq1.jpg"" />"
"To estimate the parameters of a normal distribution, we can simply <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"To estimate the parameters of a normal distribution, we can simply <span style=""font-weight:600; color:#0000ff;"">compute an estimate of the mean mu and of the variance sigma^2:</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">mu = 1/m sum(X)</span><br /><span style=""font-weight:600; color:#0000ff;"">sigma^2 = 1/m sum(X - mu)^2</span><br /><br /><span style=""font-style:italic; color:#acacac;"">Note: X is a vector</span><br /><br /><img src=""pasteommj6m.jpg"" /><br /><br />Note: in some notation we can find 1/(m-1) instead of 1/m, but both works pretty much the same for machine learning.<br /><img src=""pasteo7zcq1.jpg"" /><br /><br />For each feature x^j, we should compute mu^j and sigma^j:<br /><img src=""pasterevnfg.jpg"" /><br />Vectorized implementation:<br /><img src=""pasteb2ph3l.jpg"" /><br />same for sigma^2."
"Give the formula for the (Univariate) Gaussian density:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"(Univariate) Gaussian density formula:<br /><img src=""pastepjdf1l.jpg"" /><br><br><span style=""font-style:italic; color:#acacac;"">Note: if X has n features, then we do the product of each p(xj):</span><br><img src=""pastea1nrxk.jpg"" />"
Describe the problem of <b>density estimation</b>	"Density estimation: given a set of examples (with each one containing a vector of n features), we must find the parameters mu^j and sigma^j of each one of these features:<br /><br />eg:<br /><img src=""pastean1qbw.jpg"" /><br /><span style=""font-style:italic; color:#acacac;"">Note: this example here does an independent assumption (the probabilities of each feature happening is independent, non correlated to any other in the set), but the algorithm we will use works just fine whether or not these are independent or not.</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">We would then estimate the parameters with these equations:</span><br /><img src=""pasterevnfg.jpg"" /><br><br>Vectorized implementation:<br><img src=""pasteb2ph3l.jpg"" /><br>same for sigma^2."
"Give the Anomaly Detection algorithm:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Anomaly Detection algorithm</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">1- Choose features x^i that you think might be indicative of anomalous examples.</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">2- Fit parameters mu1, ..., mun, sigma1^2, ..., sigman^2</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">3- Given new example x, compute p(x) (probability that x is normal).</span><br /><br /><img src=""paste0exkwe.jpg"" /><br /><br />eg:<br /><img src=""pastesx8rxu.jpg"" /><br /><span style=""font-style:italic; color:#acacac;"">Note: the purple region contains only anomalies, which is defined by the constant E (visually this defines a slice over the graph under which everything is considered anomalous).</span>"
"An anomaly detection system should be trained only on <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"An anomaly detection system should be trained only on <span style=""font-weight:600; color:#0000ff;"">normal examples </span><span style=""font-style:italic; color:#acacac;"">(a few anomalous examples can slip in, but not too much)</span><span style=""font-weight:600; color:#0000ff;"">. Then we can use a few anomalous examples in the cross-validation and test sets.</span><br /><br /><img src=""pastekq8udm.jpg"" /><br><br>eg:<br><img src=""pasterqc9ms.jpg"" />"
"The test set examples and the cross-validation set should <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The test set examples and the cross-validation set should <span style=""font-weight:600; color:#0000ff;"">never contain the same examples (even randomized). The sets should be </span><span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">completely</span><span style=""font-weight:600; color:#0000ff;""> different.</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">Alternative answer:</span> we should never reuse the same examples of the cross-validation set for the test set, as the system will be <span style=""font-weight:600; color:#0000ff;"">overly optimistic</span> over the examples used in the cv set <span style=""font-style:italic; color:#acacac;"">(the cv set is not objective anymore since we've tuned some parameters on it)</span>.<br /><br /><span style=""color:#ff0000;"">Note: this is very important!</span>"
"We can evaluate an Anomaly Detection System by using the <span style=""font-weight:600; color:#0000ff;"">[...]</span> but tuning the constant E instead of h_theta(x)."	"We can evaluate an Anomaly Detection System by using the <span style=""font-weight:600; color:#0000ff;"">same error metrics as for supervised learning (precision, recall, F1 score)</span> but tuning the constant E instead of h_theta(x)."
"We can evaluate an Anomaly Detection System by using the same error metrics as for supervised learning (precision, recall, F1 score) but <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"We can evaluate an Anomaly Detection System by using the same error metrics as for supervised learning (precision, recall, F1 score) but <span style=""font-weight:600; color:#0000ff;"">tuning the constant E instead of h_theta(x).</span>"
"Anomaly detection is preferable than using Supervised learning when <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Anomaly detection is preferable than using Supervised learning when <span style=""font-weight:600; color:#0000ff;"">we only have negative examples (or a very few positive examples).</span><br /><img src=""pasteuy7nk_.jpg"" /><br><br>eg:<br><img src=""pastehlm0ey.jpg"" />"
"Supervised learning is preferable than using Anomaly detection when <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Supervised learning is preferable than using Anomaly detection when <span style=""font-weight:600; color:#0000ff;"">we have enough positive examples (as many as negative examples).</span><br><img src=""pasteuy7nk_.jpg"" /><br><br>eg:<br><img src=""pastehlm0ey.jpg"" />"
"Concretely, anomaly detection and supervised learning can be both used for the same problems, the only difference are:<br><br><span style=""font-weight:600; color:#0000ff;"">- The constraint:</span><br>&nbsp;&nbsp;* very few positive examples (very skewed classes)? use Anomaly detection.<br>&nbsp;&nbsp;* as many positive as negative examples (normal classes)? use Supervised learning.<br><br><span style=""font-weight:600; color:#0000ff;"">- The intent:</span><br>&nbsp;&nbsp;* Detect a specific positive class? Use Supervised learning.<br>&nbsp;&nbsp;* Detect all anomalies (even future anomalies not expected at the time of training): use Anomaly detection<br>[...no answer...]"	
"The opposite of Anomaly detection <span style=""font-style:italic; color:#acacac;"">(huge negative examples, very few positive)</span> is called <span style=""font-weight:600; color:#0000ff;"">Misuse detection </span><span style=""font-style:italic; color:#acacac;"">(huge positive examples, very few negative)</span>.<br><br>Alternative answer: Anomaly detection detects the normality, while Misuse detection detects the anomalies."	
"<b>Choosing the right features</b> to use is not only important for any machine learning algorithm, but especially for <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<b>Choosing the right features</b> to use is not only important for any machine learning algorithm, but especially for <span style=""font-weight:600; color:#0000ff;"">Anomaly Detection systems.</span>"
"To check that a feature is good to use for an Anomaly Detection system, we can <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"To check that a feature is good to use for an Anomaly Detection system, we can <span style=""font-weight:600; color:#0000ff;"">plot the histogram and check that it's gaussian-like (bell-shaped curve)</span>.<br /><br /><span style=""font-style:italic; color:#acacac;"">Note: if it's not a gaussian, the algorithm should still work well, but we can also </span><span style=""font-weight:600; font-style:italic; text-decoration: underline; color:#acacac;"">transform</span><span style=""font-style:italic; color:#acacac;""> the x data so that it gets more gaussian-like (eg: log(x + c), x.^1/c, etc...).</span><br /><br /><img src=""pastevkvc0m.jpg"" />"
"If after checking the histogram, an x feature is not gaussian-like, we can <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"If after checking the histogram, an x feature is not gaussian-like, we can <span style=""font-weight:600; color:#0000ff;"">transform it (eg: log(x + c), x.^1/c, etc...).</span><br /><br /><img src=""pastevkvc0m.jpg"" />"
"The most common problem in choosing the features for anomaly detection is when <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"The most common problem in choosing the features for anomaly detection is when <span style=""font-weight:600; color:#0000ff;"">the features aren't enough to distinguish between normal examples and anomalies. We can then add a new feature.</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">Alternative answer:</span> p(x) is comparable (say, both large) for normal and anomalous examples.<br /><br /><img src=""pastezyewwu.jpg"" />"
"Error analysis for anomaly detection helps to <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Error analysis for anomaly detection helps to <span style=""font-weight:600; color:#0000ff;"">create new features based on checking how anomalies are distinguished with current features, using a plot.</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">Alternative answer: Error analysis for ADS consists in checking on the cross-validation set, and plotting the examples in function of the features, then highlight the anomalous examples to see if they are well separated from the normal examples. If not, we should add more features.</span><br /><br /><span style=""font-style:italic; color:#acacac;"">Note: this is pretty similar to error analysis for Supervised Learning where the algorithm is checked on the cross-validation set to see if we should add more features.</span><br /><br /><img src=""pastezyewwu.jpg"" /><br><br><span style=""font-weight:600; color:#0000ff;"">Note: alternatively, we can also use </span><span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Multi-variate</span><span style=""font-weight:600; color:#0000ff;""> gaussian distribution instead for correlated features:</span><br /><img src=""paste9om5qm.jpg"" />"
"For anomaly detection, we can create new features based on <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"For anomaly detection, we can create new features based on <span style=""font-weight:600; color:#0000ff;"">ratios of current features</span>.<br /><br /><span style=""font-style:italic; color:#acacac;"">Note: this is particularly appropriate when there are anomalies that correspond to an unusual </span><span style=""font-weight:600; font-style:italic; text-decoration: underline; color:#acacac;"">combination</span><span style=""font-style:italic; color:#acacac;""> of values of </span><span style=""font-weight:600; font-style:italic; text-decoration: underline; color:#acacac;"">multiple</span><span style=""font-style:italic; color:#acacac;""> features.</span><br /><br /><span style=""font-style:italic; color:#acacac;"">eg: Detecting when a webserver get in an infinite job loop (which produces high cpu load but very low network traffic)</span><br /><img src=""pastebsnft6.jpg"" /><br /><br /><span style=""font-weight:600; color:#0000ff;"">Note: alternatively, we can also use </span><span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Multi-variate</span><span style=""font-weight:600; color:#0000ff;""> gaussian distribution instead for correlated features:</span><br /><img src=""paste9om5qm.jpg"" />"
Suppose your anomaly detection algorithm is performing poorly and outputs a large value of p(x) for many normal examples and for many anomalous examples in your cross validation dataset.<br>Which of the following changes to your algorithm is most likely to help?<br><br>- Try using fewer features<br>- Try coming up with more features to distinguish between the normal and the anomalous examples<br>- Get a larger training set (of normal examples) with which to fit p(x)<br>- Try changing threshold Epsilon	"<span style=""font-weight:600; color:#0000ff;"">- Try coming up with more features to distinguish between the normal and the anomalous examples</span>"
"In a multivariate gaussian distribution, we don't model p(x1),p(x2),...,p(xn) separately but <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"In a multivariate gaussian distribution, we don't model p(x1),p(x2),...,p(xn) separately but <span style=""font-weight:600; color:#0000ff;"">we model p(x) all in one go</span>.<br /><br /><img src=""pastetiakwl.jpg"" />"
"Give the formula for the density estimation p(x) in a multivariate gaussian distribution:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Density estimation in Multivariate Gaussian (Normal) distribution</span><br /><br /><img src=""paste2sltda.jpg"" /><br /><br /><span style=""font-weight:600; text-decoration: underline;"">Additional informations:</span><br /><img src=""pastetiakwl.jpg"" /><br /><br />eg:<br /><img src=""pastefuewdk.jpg"" /><br /><img src=""pasteerki_h.jpg"" /><br /><img src=""pastepigpv1.jpg"" /><br /><img src=""pastemds8du.jpg"" /><br /><img src=""pastebqn4dt.jpg"" /><br /><img src=""paste9sb177.jpg"" />"
"Integral is simply put a <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Integral is simply put a <span style=""font-weight:600; color:#0000ff;"">sum over a </span><span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">continuous</span><span style=""font-weight:600; color:#0000ff;""> range of values for a variable x </span><span style=""font-style:italic; color:#acacac;"">(instead of just discrete values)</span><span style=""font-weight:600; color:#0000ff;"">.</span>"
"Multivariate gaussian distribution is particularly useful to model <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Multivariate gaussian distribution is particularly useful to model <span style=""font-weight:600; color:#0000ff;"">highly correlated features.</span><br /><br /><span style=""font-style:italic; color:#acacac;"">Note: alternatively we can create new features that are </span><span style=""font-style:italic; text-decoration: underline; color:#acacac;"">ratios</span><span style=""font-style:italic; color:#acacac;""> of current features.</span><br /><br /><span style=""font-style:italic; color:#acacac;"">eg:</span><br /><img src=""pasteygqw96.jpg"" /><br /><img src=""pastemds8du.jpg"" /><br /><img src=""pastebqn4dt.jpg"" /><br /><span style=""font-style:italic; color:#acacac;"">Note: the last example is an example of a negative correlation of the features x1 and x2.</span>"
"Give the formulas for the parameters estimation in multivariate gaussian distribution:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Parameters estimation for Multivariate Gaussian (Normal) distribution</span><br /><br /><img src=""pasteefwzyq.jpg"" /><br /><br /><span style=""font-style:italic; color:#acacac;"">Note: the computation of Sigma for MVGD is very similar to the computation of the Sigma for PCA.</span><br /><br /><span style=""color:#0000ff;"">Then, we can compute p(x):</span><br /><img src=""paste2sltda.jpg"" />"
"Give the algorithm for Anomaly detection using Multivariate gaussian distribution:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Anomaly detection using Multivariate gaussian distribution algorithm</span><br /><br /><img src=""pastevrod2q.jpg"" />"
"Multivariate gaussian model is a <span style=""font-weight:600; color:#0000ff;"">[...]</span> of the original (univariate) gaussian model where <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Multivariate gaussian model is a <span style=""font-weight:600; color:#0000ff;"">generalization</span> of the original (univariate) gaussian model where <span style=""font-weight:600; color:#0000ff;"">p(x) is constrained to the axes (where the matrix sigma is diagonal):</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">Alternative answer: where we can't model the correlated features.</span><br /><br /><img src=""pastej6rppp.jpg"" /><br /><br />eg: &quot;skewed&quot; graph of probabilities (correlated features) can't be modeled with univariate gaussian:<br /><img src=""pasterhi1na.jpg"" />"
"A good rule of thumb of when to use Multivariate gaussian model instead of univariate is when <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"A good rule of thumb of when to use Multivariate gaussian model instead of univariate is when <span style=""font-weight:600; color:#0000ff;"">m &gt;= 10n</span>"
"When a <b>matrix is invertible/singular</b> (eg: Sigma in Multivariate gaussian model), there are generally two reasons for that:<br><span style=""font-weight:600; color:#0000ff;"">[...2 items...]</span>"	"When a matrix is invertible (eg: Sigma in Multivariate gaussian model), there are generally two reasons for that:<br><span style=""font-weight:600; color:#0000ff;"">- does not satisfy m &gt; n (note that it must be strictly greater)</span><br><span style=""font-weight:600; color:#0000ff;"">- redundant features (not correlated but redundant! eg: x1 = x2 or x3 = x4 + x5)</span><br><span style=""font-weight:600; color:#0000ff;""></span><br><span style=""font-style:italic; color:#acacac;"">Note: the debugging proceduce is to manually check sequentially that these two conditions are met (first that m &gt; n and then check for redundant features).</span>"
"Formally speaking, <b>redundant features</b> are features that are <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Formally speaking, <b>redundant features</b> are features that are <span style=""font-weight:600; color:#0000ff;"">linearly dependent.</span>"
"Advantages and disadvantages of Multivariate gaussian model compared to original (univariate) gaussian model:<br><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<img src=""paste7sfqhz.jpg"" />"
"The multivariate Gaussian model can <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The multivariate Gaussian model can <span style=""font-weight:600; color:#0000ff;"">automatically capture correlations between different features in X.</span>"
"The original model <img src=""pasteiqumyk.jpg"" /> corresponds to a multivariate Gaussian where <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The original model <img src=""pasteiqumyk.jpg"" /> corresponds to a multivariate Gaussian where <span style=""font-weight:600; color:#0000ff;"">the contours of </span><img src=""pastew3jqqs.jpg"" /><span style=""font-weight:600; color:#0000ff;""> are axis-aligned.</span>"
"The original model can be more <span style=""font-weight:600; color:#0000ff;"">[...]</span> than the multivariate Gaussian model"	"The original model can be more <span style=""font-weight:600; color:#0000ff;"">computationally efficient</span> than the multivariate Gaussian model,<span style=""font-weight:600; color:#0000ff;""> and thus might scale better to very large values of n (number of features)</span>.<br><br><span style=""font-style:italic; color:#acacac;"">Note: this is similar to the pros and cons of normal equations vs gradient descent.</span>"
Suppose you have trained an anomaly detection system that flags anomalies when p(x) &lt;= E. In the CV set, it detects too many false positives (flagging too many things as anomalies). What should you do?	"<span style=""font-weight:600; color:#0000ff;"">Decrease E</span>"
"For anomaly detection it is very important, as for dimensionality reduction and other machine learning algorithms, to <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"For anomaly detection it is very important, as for dimensionality reduction and other machine learning algorithms, to <span style=""font-weight:600; color:#0000ff;"">preprocess the data (mean normalization and feature scaling)</span>.<br><br><span style=""font-style:italic; color:#acacac;"">Note: else, some features may have an artificially huge importance compared to the others, and the algorithm should decide this for himself (</span><span style=""font-style:italic; color:#acacac;"">objective feeding</span><span style=""font-style:italic; color:#acacac;"">).</span>"
"One of the big idea in machine learning, heavily applied in recommender systems, is the idea of <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"One of the big idea in machine learning, heavily applied in recommender systems, is the idea of <span style=""font-weight:600; color:#0000ff;"">automatically learning/choose what features to use (also called </span><span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">feature learning</span><span style=""font-weight:600; color:#0000ff;"">)</span>.<br /><br /><span style=""font-style:italic; color:#acacac;"">Note: the system does really choose the features for us. We simply give a number of features, then based on given theta (the preferences of the users), the system will learn what are the values of the features for each example (which effectively assign them a meaning, which is chosen automatically by the system).</span><br /><br /><span style=""font-style:italic; color:#acacac;"">eg: using collaborative filtering for recommender systems.</span>"
"Recommender systems problem: the goal is to <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"Recommender systems problem: the goal is to <span style=""font-weight:600; color:#0000ff;"">automatically fill in the missing ratings of a user based on its previous ratings.</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">Alternative: we try to predict what ratings the user would give to new products he didn't yet used (if high we recommend it)</span>.<br /><br />eg:<br /><img src=""pastewstrbz.jpg"" />"
"Notations in a recommender system:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Notations in a recommender system:</span><br /><br /><img src=""pasteyflozq.jpg"" /><br /><br /><span style=""font-style:italic; color:#acacac;"">Note: if we would compare with our previous machine learning algorithms: Nm = m, Nu = Yn (consider that Y is multidimensional, as in a multiclass problem) and size(x) = m x n matrix, and size(Y) = m x Yn matrix</span>"
"The bias unit (x0 = 1) is also called the <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"The bias unit (x0 = 1) is also called the <span style=""font-weight:600; color:#0000ff;"">interceptor</span>."
"The linear regression we studied uses the <span style=""font-weight:600; color:#0000ff;"">[...]</span> approach."	"The linear regression we studied uses the <span style=""font-weight:600; color:#0000ff;"">least squares</span> approach."
"Vectorization (vectorizing) consists in <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"Vectorization (vectorizing) consists in <span style=""font-weight:600; color:#0000ff;"">using matrix-specific and optimized functions (matrix multiplication, sum over rows/colums, etc...) in order to avoid using loops (which results in more computational efficiency)</span>.<br /><br /><span style=""font-style:italic; color:#acacac;"">Note: the term vectorization comes from the fact that in order to do that, most of the time you will have to convert the data to be stored in a vector/matrix.</span>"
"There are 2 approaches to the problem of recommender systems:<br /><span style=""font-weight:600; color:#0000ff;"">[...2 items...]</span>"	"There are 2 approaches to the problem of recommender systems:<br /><br /><span style=""font-weight:600; color:#0000ff;"">- Content based recommendations (we have a set of features defining each movie and we learn the parameters theta (preferences of the user) that predicts how a user will rate a now movie based on the features of this new movie)</span><br /><img src=""pasteavlfps.jpg"" /><br /><br /><span style=""font-weight:600; color:#0000ff;"">- Feature learning (given the preferences [theta] of the user and its rating of a movie, we try to find the value of the features for this rating)</span><br /><img src=""pasten0ftjy.jpg"" /><br /><br /><span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">-&gt; Content based recommendations + Features learning = Collaborative filtering (used in chain until it converges):</span><br /><br /><img src=""pastewsqzi0.jpg"" /><br />we guess theta randomly at first.<br /><br /><span style=""font-style:italic; color:#acacac;"">Note: this is only possible (to use both) because each user rates multiple movies and each movie is rated by multiple users.</span>"
"Cost function for recommender system using Content based recommendation (or optimization objective):<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Regularized Cost function for Content Based Recommender System</span><br /><img src=""paste2j6hpb.jpg"" /><br /><br /><span style=""font-weight:600; text-decoration: underline; color:#000000;"">Additional informations:</span><br /><img src=""pastebtmzux.jpg"" /><br /><span style=""font-style:italic; color:#acacac;"">Note: since m(j) is a constant, we can remove it without affecting the cost function.</span><br /><br /><img src=""pastej16s9z.jpg"" /><br /><br /><span style=""font-style:italic; color:#acacac;"">Note: this is essentially a variation of linear regression.</span><br /><br /><span style=""font-style:italic; color:#acacac;"">eg:</span><br /><img src=""pastebpxort.jpg"" />"
"Give the optimization algorithm (gradient descent) for Content Based recommender system:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Content Based Recommender System - Gradient Descent</span><br /><img src=""pastekyqhmg.jpg"" /><br /><br /><span style=""font-weight:600; text-decoration: underline; color:#000000;"">Additional informations:</span><br /><img src=""paste1shand.jpg"" /><br /><br /><span style=""font-style:italic; color:#acacac;"">Note: this is essentially a variation linear regression.</span>"
"Content Based Recommender System are solved by a variation of <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"Content Based Recommender System and feature learning are solved by a variation of <span style=""font-weight:600; color:#0000ff;"">linear regression </span><span style=""font-style:italic; color:#acacac;"">(but we can also use advanced optimization techniques like conjugate descent or L-BFGS)</span>."
"A convex function is a function that is <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"A convex function is a function that is <span style=""font-weight:600; color:#0000ff;"">local optima free.</span><br><span style=""font-weight:600; color:#0000ff;""></span><br><span style=""font-style:italic; color:#acacac;"">Note: a non convex function has multiple optima and is not appropriate for machine learning (although we can still use the algorithms, but they may get stuck in non-optimal solutions).</span>"
"Cost function for feature learning for Collaborative Filtering for Recommender systems:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Regularized Cost function for feature learning for Collaborative Filtering for Recommender systems</span><br /><br /><img src=""pasterc00id.jpg"" /><br /><span style=""font-style:italic; color:#acacac;"">Note: this is basically the same as Content Based recommendation's cost function but here we try to find the values for the features of X (notice that the regularization parameter here is on X instead of theta).</span><br /><br /><span style=""font-weight:600; text-decoration: underline;"">Additional informations:</span><br /><img src=""pastexxretm.jpg"" />"
"Gradient descent for feature learning for Collaborative filtering for Recommender system:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Regularized Gradient descent for feature learning for Collaborative filtering for Recommender system</span><br /><img src=""pastegnxbev.jpg"" />"
"Simply put, with <b>Content Based recommendations</b>, we are given&nbsp;&nbsp;<span style=""font-weight:600; color:#0000ff;"">[...]</span><span style=""color:#000000;""> and must find </span><span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"Simply put, with <b>Content Based recommendations</b>, we are given <span style=""font-weight:600; color:#0000ff;"">a set of features for movies (x) and we must then get the user's preferences (theta) based on their ratings (y).</span>"
"Simply put, with <b>Features learning</b>, we are given <span style=""font-weight:600; color:#0000ff;"">[...]</span><span style=""color:#000000;""> and must find </span><span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"Simply put, with <b>Features learning</b>, we are given <span style=""font-weight:600; color:#0000ff;"">a set of user's preferences (theta)</span><span style=""color:#000000;""> and must find </span><span style=""font-weight:600; color:#0000ff;"">the values of the feature (x) for each movie based on the ratings (y)</span>."
"Collaborative filtering = <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Collaborative filtering = <span style=""font-weight:600; color:#0000ff;"">Content based recommendations + Feature learning</span><br><span style=""font-weight:600; color:#0000ff;""></span><br><span style=""font-style:italic; color:#acacac;"">Note: the term &quot;collaborative filtering&quot; refers to the observation that the users are collaboratively contributing to make the system better and get better recommendations for everyone.</span>"
"Basically, what collaborative filtering algorithm does is to <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Basically, what collaborative filtering algorithm does is to <span style=""font-weight:600; color:#0000ff;"">randomly initialize preferences (theta) then compute products' features values (x) using Content based recommendations, then again preferences using Features learning, then again features values, then again preferences, etc... until it converges.</span><br><span style=""font-weight:600; color:#0000ff;""></span><br><img src=""pastewsqzi0.jpg"" /><br><br><span style=""font-style:italic; color:#acacac;"">Note: there is actually a more efficient algorithm that can compute both at the same time, but the principle works about the same.</span>"
"Cost function for Collaborative filtering (aka optimization objective):<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Regularized Cost function for Collaborative filtering</span><br /><img src=""pasteajsdzq.jpg"" /><br /><br /><span style=""font-style:italic; color:#acacac;"">Note: </span><span style=""font-weight:600; font-style:italic; color:#acacac;"">we should NOT use the interceptor/bias feature x0</span><span style=""font-style:italic; color:#acacac;""> in this cost function, contrary to the previous cost functions. We can do away with the interceptor because we are learning all the features and thetas at once now, so if the system wants an interceptor it now has the flexibility to create one by itself (eg: x1 = 1). This is more objective.</span><br /><br /><span style=""font-style:italic; color:#acacac;"">Note2: this is basically a combination of Content based recommendations cost function + Features learning cost function:</span><br /><br /><img src=""pastecvaohv.jpg"" /><br />Note: the highlighted parts are exactly equivalent. This shows how we combined the previous cost functions into a single one that computes theta and X at the same time.<br /><br />Optimization objective:<br /><img src=""pasteneo0dc.jpg"" />"
"Give the Collaborative filtering algorithm:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Collaborative filtering algorithm</span><br /><br /><img src=""pastewuzbz0.jpg"" /><br /><span style=""font-style:italic; color:#acacac;"">Note: there's no bias unit (no theta0 nor X0) so that's why there's no special gradient descente case for k=0.</span><br /><br /><span style=""font-style:italic; color:#acacac;"">Note2: we can see that the gradient descent for Collaborative filtering is simply the combination of gradient descents for Content based recommendations + Features learning.</span><br /><br /><span style=""font-style:italic; color:#acacac;"">Note3: we need to preprocess the data (mean normalization + features scaling) prior to do this algorithm (particularly if the dataset is a merge of several datasets from different sources with different ratings scales eg: 1-5 on one website merged with 1-100 on another).</span><br /><br /><span style=""font-style:italic; color:#acacac;"">Note4: the randomization of theta serves as a symmetry breaking (similar to the random initialization of a neural network's parameters) and ensures the algorithm learns features X that are different from each other.</span>"
"Give the gradient descent for Collaborative filtering:<br /><span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Regularized Gradient descent for Collaborative filtering</span><br /><br /><img src=""pasteq5vevo.jpg"" /><br /><br /><u>Alternative formulation:</u><br /><img src=""pastedg4u10.jpg"" /><br /><span style=""font-style:italic; color:#acacac;"">Note: there's no bias unit (no theta0 nor X0) so that's why there's no special gradient descente case for k=0.</span><br /><br /><span style=""font-style:italic; color:#acacac;"">Note2: we can see that the gradient descent for Collaborative filtering is simply the combination of gradient descents for Content based recommendations + Features learning.</span>"
"Collaborative filtering is also called <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Collaborative filtering is also called <span style=""font-weight:600; color:#0000ff;"">Low Rank Matrix Factorization</span>"
"A low rank matrix is a matrix that has <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"A low rank matrix is a matrix that has <span style=""font-weight:600; color:#0000ff;"">many linearly dependent colum vectors</span> <span style=""font-style:italic; color:#acacac;"">(eg: in a movie rating website, we assume that the ratings of the users are not independent of the ratings of the others, there are certain features that make them correlated)</span>."
"<span style=""font-weight:600; text-decoration: underline; color:#0000ff;"">Vectorized implementation of the prediction in Collaborative filtering:</span><br /><img src=""pasteyxdbep.jpg"" />"	"<img src=""pasteye09rg.jpg"" /><br /><br />eg:<br /><img src=""pastetwd3d_.jpg"" /><br /><img src=""pastef6q7c9.jpg"" />"
"To find related products, we simply have to <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"To find related products, we simply have to <span style=""font-weight:600; color:#0000ff;"">find the products which have the most similar set of values for the features (the smallest distance between the features of these different products):</span><br /><br /><span style=""font-weight:600; color:#0000ff;"">||x(i) - x(j)|| = sqrt((x1(i) - x1(j))^2) + sqrt((x2(i) - x2(j))^2) + ...</span><br /><br /><span style=""font-style:italic; color:#acacac;"">eg:</span><br /><img src=""pastem5ou11.jpg"" />"
"feature scaling = <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"feature scaling = <span style=""font-weight:600; color:#0000ff;"">max(X) - min(X)</span>"
"mean normalization = <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"mean normalization = <span style=""font-weight:600; color:#0000ff;"">X - mu</span><br><span style=""font-weight:600; color:#0000ff;"">where X is a vector (so in fact we compute x_j(i) - mu_j for each feature x_j) and mu_j = mean of all the values of feature x_j</span>"
"Without mean normalization, a user which has rated no product at all will get <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"Without mean normalization, a user which has rated no product at all will get <span style=""font-weight:600; color:#0000ff;"">a recommendation of 0 for all products.</span><br><span style=""font-weight:600; color:#0000ff;""></span><br><span style=""font-style:italic; color:#acacac;"">Note: this can be fixed by using mean normalization.</span>"
"In collaborative filtering, we can use <span style=""font-weight:600; color:#0000ff;"">[...]</span> to propose a recommendation for users who rated no product at all based on average ratings of all users."	"In collaborative filtering, we can use <span style=""font-weight:600; color:#0000ff;"">mean normalization</span> to propose a recommendation for users who rated no product at all based on average ratings of all users.<br /><br />eg: Users who have not rated any movies:<br /><img src=""paste95z8ul.jpg"" /><br /><img src=""paste6iarex.jpg"" /><br />The only thing that will be stay for the recommendations proposed to a user who didn't rate anything will be the mean mu (average rating for the movie)."
Even if each user has rated only a small fraction of all of your products (so r(i,j)=0 for the vast majority of (i,j) pairs), you can still build a recommender system by using collaborative filtering.<br>True or false?	"<span style=""font-weight:600; color:#0000ff;"">True</span>"
"Recall that the cost function for the content-based recommendation system is <img src=""pastem_jhay.jpg"" />.<br />Suppose there is only one user and he has rated every movie in the training set. This implies that nu=1 and r(i,j)=1 for every i,j. In this case, the cost function J(θ) is equivalent to the one used for regularized linear regression.<br />True or false?"	"<span style=""font-weight:600; color:#0000ff;"">True</span><br><span style=""font-weight:600; color:#0000ff;""></span><br><span style=""font-weight:600; color:#0000ff;"">In this case, the cost function is just a sum of squared differences between a prediction θTx and true vaue y; this is exactly linear regression.</span>"
Suppose you are writing a recommender system to predict a user's book preferences. In order to build such a system, you need that user to rate all the other books in your training set.<br>True or false?	"<span style=""font-weight:600; color:#0000ff;"">False</span>"
"Collaborative filtering is used when <span style=""font-weight:600; color:#0000ff;"">[...]</span>."	"Collaborative filtering is used when <span style=""font-weight:600; color:#0000ff;"">we must predict real-valued output (as in linear regression) but where the features and theta are missing as well as some values of the output Y, but with multiple users (which choices/output Y are not independent of each other)</span>."
"The threshold Epsilon (to detect an anomaly) can be automatically chosen by <span style=""font-weight:600; color:#0000ff;"">[...]</span>"	"The threshold Epsilon (to detect an anomaly) can be automatically chosen by <span style=""font-weight:600; color:#0000ff;"">using an automatic checking of the F1 score over the cross-validation set.</span>"
A common requirement for machine learning algorithm is that m &gt;= n (or even m &gt;&gt; n).<br>When we have m &lt; n (or even when m &gt;&gt; n does not hold), what does that mean?	"<span style=""font-weight:600; color:#0000ff;"">When m &lt; n, we don't have enough observations to adequately estimate the effects of all the features</span>"
What do you call a significance test in which the distribution of the test statistic under the null hypothesis is obtained by calculating all possible values of the test statistic under rearrangements of the data points?	a permutation test
In statistics, what do uppercase letters typically refer to?	random variables
What is the most standard way to compare data points from the same subject across different samples, which have different means and standard deviations?&nbsp;	normalize each data point to its sample mean and sample standard deviation (e.g., calculate t-statistics)
What does it mean for a summary statistic in a statistical model to be unstable with respect to different realizations of the random variables?	different realizations of random variables will yield highly different summary statistics
What summary statistic describes the probability of obtaining a test statistic at least as extreme as the one that was actually observed?	the p-value
Is the sum of two normally distributed random variables with the same mean normally distributed?	yes (http://en.wikipedia.org/wiki/Normal_distribution) 
Is the sum of two normally distributed random variables with different means normally distributed?	yes (http://en.wikipedia.org/wiki/Normal_distribution) 
Will a mixture density of two normal distributions with different means have one or two peaks?	two (provided that their means are far enough apart) (http://en.wikipedia.org/wiki/Normal_distribution) 
When a statistical population contains two or more sub-populations each with its own distribution, then what type of distribution arises naturally to describe them?	a mixture distribution (http://en.wikipedia.org/wiki/Mixture_distribution) 
If you are using models in order to make predictions, should you choose the best model first? 	"not usually (instead, you should average the probability predictions over models) (ripley, ""selecting amongst large classes of models"", http://www.stats.ox.ac.uk/~ripley/Nelder80.pdf)"
If the difference between A and C is statistically significant, and the difference between B and C is not statistically significant, must the difference between A and B be statistically significant?	a resounding no (http://www.stat.columbia.edu/~gelman/research/published/signif4.pdf; doi: 10.1198/000313006X152649)
In comparing two treatments, should you look at the statistical signiﬁcance of their difference or the difference between their signiﬁcance levels?	the statistical significance of their difference (http://www.stat.columbia.edu/~gelman/research/published/signif4.pdf; doi: 10.1198/000313006X152649)
In order to employ an ordinary least squares estimator in a regression model, do we need to assume that the residuals are independent? why or why not? 	no; trick q, because in fact residuals <i>cannot</i> be independent, since they must sum to 0<br>> (http://en.wikipedia.org/wiki/Errors_and_residuals_in_statistics)
Are matrices typically referred to using uppercase or lowercase letters? (statistics)	uppercase
Are vectors typically referred to using uppercase or lowercase letters? (statistics)	lowercase
For a continuous pdf, what property of the second derivative tells us whether that point is (locally or absolutely) a maximum? 	that it is less than zero (S&amp;S p 21) 
If a conclusion is statistically robust, does that mean that it is right?	no (e.g., the model could be wrong) (http://www.ft.com/intl/cms/s/2/9219969e-6a28-11e0-86e4-00144feab49a.html#axzz1KKnUH35Y) 
What does John Cook consider the key idea of Bayesian statistics?	to represent all uncertainty by probability distributions (http://www.johndcook.com/blog/2011/04/20/teaching-bayesian-stats-backward/) 
When reading a chart, do people compare distances or areas more accurately? 	distances (http://stats.stackexchange.com/questions/4810/how-to-use-cdf-and-pdf-statistics-for-analysis/4885#4885) 
What has a simpler non-parametric estimator, the cumulative distribution function or the probability density function?	the cumulative distribution function (estimated by the empirical distribution function) (for the pdf you have to choose arbitrary bin size or kernal shape) (http://stats.stackexchange.com/questions/4810/how-to-use-cdf-and-pdf-statistics-for-analysis/4891#4891) 
If there is synergy between two treatments for a condition, then how strong (on average) must their effects be in combination?	greater than additive (doi: 10.1158/0008-5472.CAN-09-1947)
What does it mean to say X ~ N(0,1)?	that the variable X follows a normal distribution with a mean of 0 and a variance of 1 (http://en.wikipedia.org/wiki/Normal_distribution) 
Let's say you perform many hypothesis tests simultaneously on correlated test statistics. How will your results be biased, relative to your prescribed error rate α, if you divide the α for each test by the total number of hypotheses? 	you'll have too many false negatives (unless your tests are independent, the Bonferroni correction will tend to be too conservative) (http://en.wikipedia.org/wiki/Multiple_comparisons#Methods) 
What is a statistic? 	a quantity calculated from a set of data (e.g., the sample mean)
Is &quot;the probability that a woman with a positive mammography has breast cancer&quot; usually the same thing as &quot;the probability that a woman with breast cancer has a positive mammography&quot;? 	no (http://yudkowsky.net/rational/bayes) 
In processes for which many independentfactors add together to generate a result, what type of distribution does the result follow? 	a normal distribution (http://en.wikipedia.org/wiki/Central_limit_theorem) 
In processes for which many independent factors multiply together to generate a result, what type of distribution does the result follow? 	a log normal distribution (http://en.wikipedia.org/wiki/Central_limit_theorem) 
What do you call the distribution of a statistic derived from a set of random samples of a particular size from a population?	the sampling distribution of that statistic
What does the word &quot;standard&quot; in standard deviation refer to?	&quot;standardized&quot; (the square root of the variance, to adjust for the fact that the variance squares the distances from the mean) 
For a normal distribution, around what percent of the data points will lie within two standard deviations of the mean? 	95% (http://en.wikipedia.org/wiki/68-95-99.7_rule) 
Even if our goal is merely to understand the relations between variables, how can prediction be useful? 	it tests our knowledge of relations (http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch01.pdf) 
What is a loss function?	a mapping of events onto numbers representing the associated cost
If E(Y|X=x) is constant for all values of x, does this mean that X and Y are independent?	"no (though that does tell you that they are uncorrelated; you cannot assume independence from uncorrelatedness; e.g., think of a case in which X changed Y's variance) (""they are independent, then the regression function is a constant, but turning this around is the logical fallacy of “afﬁrming the consequent”"") (http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch01.pdf) "
If X and Y are independent, does this mean that E(Y|X=x) is constant for all values of x?	yes (http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch01.pdf) 
If X takes on a relatively small and finite set of values, then what is a simple strategy to estimate the regression function E[Y|X=x]?	use the conditional sample means (1.4 http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ADAfaEPoV.pdf) 
When using least squares regression, do you implicitly assume a linear relationship between your variables? 	yes (http://www.annualreviews.org/doi/full/10.1146/annurev.soc.34.040507.134631)
If the window span in locally smoothed regression is very small, what effect will that have on the variance of the resulting best fit line? 	it will be too high (insufficient data will fall within each window and the line will shift too rapidly) (http://www.annualreviews.org/doi/full/10.1146/annurev.soc.34.040507.134631)
If the window span in locally smoothed regression is very large, what effect will that have on the variance of the resulting best fit line? 	it will be too low (the data will be oversmoothed, resulting in bias in the fitted curve) (http://www.annualreviews.org/doi/full/10.1146/annurev.soc.34.040507.134631)
You have access to planes that have returned from military missions and the distribution of the bullet &quot;wounds&quot; on the planes. Which areas should you recommend to have extra armor?	the areas with no damage (selection effects; those that fell likely suffered an attack in a place that was untouched on those that survived) (http://stats.stackexchange.com/questions/23779/most-interesting-statistical-paradoxes/23814#23814) 
What do you call a statistical test that does not assume a particular probability distribution? 	non-parametric (http://stats.stackexchange.com/a/7944/2073) 
What does it mean to center the columns of a matrix? 	to subtract the column mean from each entry of a column (http://stat.ethz.ch/R-manual/R-devel/library/base/html/scale.html) 
If two or more of your explanatory variables are collinear, then how many optimal parameter combinations will there be for a given loss function?	infinitely many (i.e., we can make the coefficients whatever we like, provided we make a corresponding adjustment to the other(s), and it will have no effect on our prediction) (http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ADAfaEPoV.pdf sxn 2.1) 
What is statistics? (acc'd to Shalizi; four words) 	inference from imperfect data (http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ADAfaEPoV.pdf sxn 5.1) 
When individual points are too close to one another in a chart to be able to distinguish them, what technique can you use to randomly move some of them apart? 	jittering (Wickham p 17) 
What is the phenomenon called in which there are so many points in a scatterplot that it is difficult to discern firm trends? 	overplotting (Wickham p 11) 
What problem does using semi-transparent data points in a chart help solve? 	overplotting (Wickham p 12) 
Is it possible to get a high value for [$]R^2[/$] in a regression even if the true model is not linear?	it is eminently so (Shalizi 2.2) 
If we add noise to our measurements of explanatory variables, what will that do to our ability to predict the response variable?	it will decrease it (in linear regression, it pushes the coefficient vector closer to zero than it would be if our measurements of the explanatory vectors were noiseless) (Shalizi 2.2) 
"What sign of skew does this distribution show?<br /><br /><img src=""Screen shot 2012-03-18 at 1.09.34 PM.png"" />"	negative (left) skew (http://upload.wikimedia.org/wikipedia/commons/b/b3/Skewness_Statistics.svg) 
"What sign of skew does this distribution show?<br /><br /><img src=""Screen shot 2012-03-18 at 1.10.39 PM.png"" />"	positive (right) skew (http://upload.wikimedia.org/wikipedia/commons/b/b3/Skewness_Statistics.svg) 
"What do you call this type of plot? (note x1, x2, ..., y on both axes) <br><br><img src=""Screen shot 2012-03-18 at 2.41.13 PM.png"" />"	a scatterplot matrix (with univariate histograms on the diagonals) (http://stats.stackexchange.com/a/24529/2073) 
What do you call the ability of a machine learning algorithm to perform accurately on new, unseen examples after training on a finite data set?	generalization (http://en.wikipedia.org/wiki/Machine_learning)
In sampling with replacement, when a ball of a particular color is randomly drawn from an urn, what is put back in?	the same ball (http://en.wikipedia.org/wiki/Polya_urn_model) 
What does a one-way ANOVA compare?	the means of three or more independent groups (http://en.wikipedia.org/wiki/One-way_ANOVA) 
What does a one-sample t-test compare?	a sample mean with a fixed value (e.g., a known population mean) (http://en.wikiversity.org/wiki/T-test) 
What does an independent samples t-test compare?	two means from independent groups (http://en.wikiversity.org/wiki/T-test) 
What does a one-way repeated measures ANOVA compare?	the means of three or more matched groups (e.g., in a longitudinal study where each group has its own level on some variable)&nbsp;&nbsp;(http://en.wikiversity.org/wiki/Analysis_of_variance)
When assessing the normal distribution assumption for a sample, is it more important that your particular sample is distributed normally, or that the population your sample was drawn from is distributed normally?	the population your sample was drawn from (is distributed normally) (so if you have data from previous experiments that measured the same variable, you can use that too) (http://www.graphpad.com/articles/interpret/anova/choosing_test.htm) 
Why do we want the errors of our model's predictions to be patternless?	because if there was a pattern to them, we should adjust for it, to make smaller mistakes (and thus our model could be easily improved) (Shalizi 3.2) 
If two random variables are independent, what is the relationship between their marginal and joint probability distributions? 	their joint probability distribution is the product of their marginal probability distributions (http://www.stat.cmu.edu/~cshalizi/uADA/12/reminders/uncorrelated-vs-independent.pdf) 
If X is uniformly distributed on the interval [-1,1], and Y is uniformly distributed on the interval [0,1], and X and Y are independent, then how must their joint distribution be distributed? 	uniformly on the rectangle [-1,1] x [0,1] (http://www.stat.cmu.edu/~cshalizi/uADA/12/reminders/uncorrelated-vs-independent.pdf) 
Even if you believe in some kind of ultimate physical determinism, why will the true, ideal statistical model of a phenomenon always have some non-zero predictive error? 	model inputs are never complete descriptions of the state of the universe, and this coarseness yields randomness (Shalizi 3.2) 
What is the origin of the bias term in the bias-variance decomposition of a model?	mis-specification of the model (e.g., we mess up on the functional form of the regression) (Shalizi 3.2) 
As we collect more data, does our choice of causal assumptions become more or less important?	neither, these remain substantial regardless of sample size (trick question) (Pearl p 101) 
If a stochastic process is stationary, what does that say about its joint probability distribution? 	that it is invariant to shifts (in time or space)
What case of letter is typically used to refer to probability density functions? 	lower (e.g., f(x)) (http://en.wikipedia.org/wiki/Notation_in_probability_and_statistics) 
What case of letter is typically used to refer to cumulative distribution functions? 	upper (e.g., F(x)) (http://en.wikipedia.org/wiki/Notation_in_probability_and_statistics) 
What does i.i.d. stand for? 	independent and identically distributed (http://en.wikipedia.org/wiki/Notation_in_probability_and_statistics) 
When is the expected value of a probability distribution not equal to the arithmetic mean? 	when the probabilities of all possible outcomes are not equal (Shalizi, chapter 1) 
What theorem says that the mean of a sufficiently large number of IID RVs, each with finite mean and variance, will be approximately normally distributed?	the central limit theorem (http://en.wikipedia.org/wiki/Normal_distribution)
What theorem says that the average of the results obtained from a large number of trials should be close to the expected value, and will tend to become closer as more trials are performed?	the law of large numbers (http://en.wikipedia.org/wiki/Law_of_large_numbers) 
Fitting a model to one randomly chosen half of the data set and then evaluating it on the other gives you an unbiased estimation of what?	the generalization error (of the model) (Shalizi 3.4) 
In k-fold cross validation, what does a &quot;fold&quot; refer to?	a randomly chosen, equally-sized subset of the data (Shalizi 3.4) 
What is it called if you do k-fold cross-validation with k = n, so that your testing sets consists of single points? 	leave-one-out cross-validation (LOOCV) (Shalizi 3.4) 
Because the amount of smoothing has opposite effects on the bias and variance of your model, what type of point will exist? 	an optimal amount of smoothing (where you can’t reduce one source of error without increasing the other) (Shalizi 4.1) 
As we collect more data, what tends to happen to the variance of our estimated models? 	it decreases (Shalizi 4.1) 
As we collect more data, in what way should we change the amount that we smooth our models? 	we should smooth less (because the estimator variance decreases and so contributes less to total error) (Shalizi 4.1) 
What happens to the relationship between two independent causes when a consequence common to them both is observed?	they are rendered dependent (Pearl p 106; http://en.wikipedia.org/wiki/Berkson's_paradox) 
If two events are known to be independent, is it possible for the observation of another event to render them dependent? classic example? 	yes; if you learn that exactly one of two flips of a coin is tails, their outcomes become dependent<br />&gt; Pearl p 106
What is the main way that the assumptions embodied in a structural equation model can confront the scrutiny of nonexperimental data? (according to Pearl) 	conditional independencies (induced by d-separation) (Pearl p 106) 
Asymptotically, does randomization neutralize either measured or unmeasured confounders? 	both (trick question) (http://bayes.cs.ucla.edu/BOOK-09/ch11-3-1-final.pdf p 340) 
Why is it not always a good idea to condition on as many pre-treatment measurements as possible? 	conditioning on some variables can increase bias (Pearl p 116) <div>&gt; e.g., Berkson's bias</div>
In Pearl's method of estimating causality, what qualitative judgements are required? 	cause-effect relationships between variables (Pearl p 118) 
Consider the causal model X → Z ← U → Y, where only U is unobserved. What would the relationship between X and Y be if Z were physically set to a constant?	they would remain independent (this would be equivalent to deleting all arrows entering Z) (Pearl p 133) 
Consider the causal model X → Z ← U → Y, where only U is unobserved. What would the relationship between X and Y be if you were to condition on Z?	you'd create a spurious association between X and Y (that might be construed as a direct effect) (this is &quot;conditioning on a collider&quot;) (Pearl p 133) 
What does Pearl think of the mantra &quot;no causation without manipulation&quot;?	that it must be rejected (because measuring variables is more fundamental to causality than changing) (Pearl p 136) 
If a probability distributing of waiting times T [...], then Pr(T &gt; 40 s|T &gt; 30 s) = Pr(T &gt; 10s). 	is memoryless (and therefore exponentially distributed, if continuous) (http://en.wikipedia.org/wiki/Exponential_distribution) 
According to Gelman, which are easier to interpret: standard deviations or variances?	standard deviations (http://andrewgelman.com/2012/05/comments-on-a-bayesian-approach-to-complex-clinical-diagnoses-a-case-study-in-child-abuse/) 
You live in a place with a constant probability of being struck by lightning throughout the year. Suppose that the strikes are random: every day the chance of a strike is the same, and the rate works out to one strike a month. Your house is hit by lightning on Monday afternoon. What is the most likely day for the next bolt to strike your house? 	Tuesday (the events are independent and this is a Poisson process) (Pinker BA, p 202) 
If a personality trait is polygenic, then during inheritance from one generation to the next, what statistical law will it obey? 	regression to the mean (Pinker BA, 233) 
If you are interested in inferring the mechanisms that underlie the formation and evolution of a data set, then is it likely to matter whether the distribution follows a power law as opposed to some other form? 	yes (http://arxiv.org/abs/0706.1062) 
If you are interested in predicting the future values of a data set over a relatively short time frame, is it likely to matter whether the distribution follows a power law as opposed to some other form? <br />	nope (in fact you would ideally be model averaging anyway) (http://arxiv.org/abs/0706.1062)
As you collect more i.i.d. observations, what will happen to your estimate of the standard deviation of a distribution? (in theory) 	it should not change (on average; this is a fixed parameter of a distribution. though actually, it will probably increase) (http://stats.stackexchange.com/questions/32318/difference-between-standard-error-and-standard-deviation#comment63459_32385)&nbsp;&nbsp;(http://en.wikipedia.org/wiki/Standard_error)
What is widely considered the most difficult topic to teach in intro statistics? 	the sampling distribution (e.g., of the mean) (http://stats.stackexchange.com/questions/34926/strategies-for-teaching-the-sampling-distribution) 
Imagine that your parents had rolled a six-sided die to decide how many children to have. What did they most likely roll? why?	a 6 (eg, this is more likely than them rolling a 1); because there's a higher chance of you existing in that case (there are more &quot;you's&quot; to observe it) (http://en.wikipedia.org/wiki/Self-Indication_Assumption) (http://lesswrong.com/r/discussion/lw/ef3/the_real_sia_doomsday/) 
In layman's terms, what does statistical power mean?	the chance of finding a significant effect if it's really there 
From a 3 dimensional data set (dimensions x, y, and z), how many unique covariance measures can you compute?	3 (cov(x,y), cov(x,z), and cov(y,z); combos = ((p)(p-1))/2) (Smith, PCA tutorial, 2002) <div>&gt; think of it in terms of the covariance matrix: non-diagonals, one half</div>
In PCA, what is the price we pay for the reduction in dimensions in terms of understanding the new directions?	the new axes will not (in general) map neatly to the original variables (instead, the new directions will correspond to linear combinations of the original variables) (Janetta p 335ish) 
"Sets: What do you call the shaded region in the Venn diagram of the two sets represented by circles below?<div><img src=""Screen shot 2013-02-03 at 5.59.21 PM.png"" /></div>"	the symmetric difference<div>&gt; i.e.,&nbsp;the union without the intersection;&nbsp;For example, the symmetric difference of the sets {1,2,3} and {3,4} is {1,2,4}</div><div>http://en.wikipedia.org/wiki/Symmetric_difference</div>
"<span style="" font-style: normal; font-weight: normal;"">If a probability distribution of waiting times T [...], then Pr(T &gt; 40 s|T &gt; 30 s) = Pr(T &gt; 40s).</span>"	"<span style="" font-style: normal; font-weight: normal;"">is known to be zero between T = 0 and 30 s&nbsp;</span><div><span style="" font-style: normal; font-weight: normal;"">(this is independence, not memorylessness, though)&nbsp;</span></div><div><span style="" font-style: normal; font-weight: normal;"">(http://en.wikipedia.org/wiki/Exponential_distribution)</span><div><span style="" font-style: normal; font-weight: normal;"">&gt; this card was a leech but remaking b/c it's important&nbsp;</span></div></div>"
What is the idea behind Efron's empirical Bayes?&nbsp;	experiments with many parallel situations allow estimation of their own prior&nbsp;<div>&gt;&nbsp;http://www.sciencemag.org/content/340/6137/1177.full?rss=1</div>
Give an algorithm for integer division without using multiplication or division operators. What issues might arise?	<div>\begin{itemize}</div>\item Implement long division as a bit-shifting algorithm.<div>\item Issues: buffer size (32 bit?), negative inputs.</div><div>\end{itemize}</div>
What is insertion sort?	\item Scan the array to be sorted from left to right<div>\item For each item, find it's place in the fragment of the array to it's left (so-far-sorted)</div>
Give the sort properties of insertion sort	\item Adaptive<div>\item Stable</div><div>\item In-place</div><div>\item Online</div>
Give best and worst case instances for insertion sort	\item Best: small arrays<div>\item Worst: reversed arrays</div>
Give the average and worst-case runtimes of insertion sort	Both $O(n^2)$
Describe selection sort	\item Iterate over the array from left to right<div>\item At each element, swap it for the smallest element in the fragment of the array to it's right.</div>
Give the benefits of selection sort	\item In-place<div>\item Low auxiliary memory use</div><div>\item Simple</div><div>\item Adaptive</div>
Give the average and worst-case runtimes of selection sort	Both $O(n^2)$
Describe a method of exponentiation faster than repeated squaring	\item Addition chain exponentiation<div>\item An addition chain is a sequence of integers, starting with 1, where each element is the sum of two previous elements.&nbsp;</div><div>\item An optimal addition chain for $n$ can be used to compute $a^n$ in an optimal manner</div><div>\item Finding addition chains is NP-complete.&nbsp;</div>
Give an algorithm to select $k$ elements from $n$ when $n$ is unknown	\item Select the first $k$ elements<div>\item For each remaining element, replace one of the current $k$ elements with probability $k/n$.&nbsp;</div>
What are the runtime properties of the Rabin-Karp algorithm?	\item Given a pattern of length $m$ and text of length $n$:<div>\item Expected runtime is $O(n+m)$</div><div>\item Worst case is $O(nm)$ if the hash collides often.&nbsp;</div>
Describe an algorithm to find the first unbalanced parentheses in a string of parentheses.	\item Loop over the string<div>\item Push to stack the index of locations with a `('</div><div>\item Pop from the stack when encountering a `)'. If the stack is empty, the `)' is unbalanced.</div><div>\item If the loop terminates, check the stack. If any indices remain in it, the corresponding `(' is unbalanced.</div><div>\\</div><div>\item Alternatively, count in from both ends.</div>
Give the Master Theorem	\item Let $T(n) = aT(n/b) + f(n)$<div>\item If $f(n) = o(n^{\log_b a})$ then $T(n) = \Theta(n^{\log_b a})$</div><div>\item If $f(n) = \Theta(n^{\log_b a})$ then $T(n) = \Theta(n^{\log_b a} \lg n)$</div><div>\item If $f(n) = \omega(n^{\log_b a})$ then $T(n) = \Theta(f(n))$</div>
Give an algorithm to find the majority element of an array in linear time	\item Mark the first element in the array, and initialise a counter to one<div>\item Move right. Increment the counter if the next element matches the marked element, else decrement it.</div><div>\item If the counter reaches zero, mark the element under consideration instead. Continue right.</div><div>\item When the end of the array is reached, assume the currently marked element is the majority element. Check this.&nbsp;</div>
Describe the Karp-Papadimitriou-Shenker algorithm for finding all elements that appear with at least frequency $\theta$ in an array.	\item Let $K$ be an initially empty set (implemented as a hash table).<div>\item Scan the array. For each element in turn:</div><div>\begin{itemize}</div><div>\item If the element is not in $K$, add it to $K$ with a counter set to 1.</div><div>\item If the element is in $K$, increment it's counter.</div><div>\item If $|K|&gt;1/\theta$, decrement the count of all elements in $K$, and delete any whose count reaches zero.</div><div>\end{itemize}</div><div>\item Make a second pass of the array to identify those items in $K$ which appear at least $\theta n$ times.</div>
Describe a linear-time algorithm for finding the median of an array	\item Divide the array into blocks of five elements (ignore leftovers).<div>\item Find the median of each block, and form an array from these medians (possibly in place).</div><div>\item Make a recursive call on the list of medians.&nbsp;</div>
Describe the operation of the mergesort algorithm.	<div>\item If the array is a singleton, return it.</div>\item Else, split the array into two subarrays of size $~n/2$ and call mergesort on each.&nbsp;<div>\item Merge the sorted subarrays by repeatedly popping the smallest element from the heads of the two subarrays.</div><div>\item Return the sorted array.</div>
Describe the properties of mergesort	\item Runs in $O(n \lg n)$ time, both worst- and average-case.<div>\item Requires $O(n)$ auxiliary space.<br /><div>\item Is stable.</div><div>\item Is easily parallizable<br /><div>\item Can be implemented as stable \&amp; in-place, but is more complicated. Easier on linked lists than arrays.</div></div></div>
Describe the implementation of the quicksort algorithm	\item If the array is a singleton, return it<div>\item Else, pick a pivot by some heuristic.</div><div>\item Partition the array into a subarray greater than the pivot, and a subarray less than it.</div><div>\item Call quicksort on the subarrays.</div>
Describe the properties of the quicksort algorithm.	\item $O(n^2)$ worst-case for arbitrary pivot, $O(n \lg n)$ for median pivots<div>\item Is \emph{not} stable</div><div>\item $O(n)$ auxiliary space naively; can be implemented in $O(\lg n)$ space by sorting the smaller subarray first then making a tail-call to the larger subarray.&nbsp;</div><div>\item Also makes it in-place.</div>
What is an adaptive sort?	\item A sorting algorithm that takes advantage of pre-existing order in the input
Give an algorithm for initializing and accessing an array both in constant time.	\item The array {\tt vec} stores data<div>\item The array {\tt to} lists the cells of {\tt vec} which are initialized.</div><div>\item The array \ttt{from} contains pointers to the cells of \ttt{to} that point to them</div><div>\item The pointer {\tt top} gives how many cells of {\tt to} have been initialised.</div><div>\item To access {\tt vec[i]}, check that {\tt from[i] &lt; top} and {\tt to[from[i]] = i}.&nbsp;</div>
Which data structure does BFS correspond to?	\item A queue&nbsp;
What are the three states a vertex can be in during a traversal?	\item Undiscovered<div>\item Discovered</div><div>\item Processed</div>
How can the shortest path from vertex $x$ to vertex $y$ be found?	\item Conduct a BFS from $x$, recording for each vertex $j$ the {\tt parent} vertex $i$ that discovered it.<div>\item Follow the chain of {\tt parent}s from $y$ back to $x$</div>
At what three sets of points in a graph search are actions usually carried out?	\item Before any of a vertices' edges are processed<div>\item After all of a vertices' edges are processed</div><div>\item During the processing of a vertex's edge.</div>
What is the runtime of BFS on an adjacency list of $n$ vertexes and $m$ edges?	\item $O(n+m)$
How can the components of an undirected graph be identified?&nbsp;	\item Pick any vertex and run a BFS to completion on it.<div>\item Mark all discovered vertices.</div><div>\item Repeat.</div>
How can we test whether a graph is bipartite?	<div>\item Colour each vertex alternately, then check each edge for violations.</div>
What data structure is associated with a DFS?	\item A stack, although it is more cleanly implemented as a recursion.&nbsp;
What three properties does a DFS w/ timesteps record about the vertices of the graph?&nbsp;	\item State - undiscovered, discovered, or processed<div>\item Entry time - the number of steps into the algorithm at which a vertex is set to discovered</div><div>\item Exit time - the number of steps into the algorithm at which a vertex is set to processed</div>
How can a DFS w/ timesteps be used to identify ancestors of a vertex $x$ in a DFS tree?&nbsp;	\item The entry-exit time interval of the ancestor contains the entry-exit time interval of $x$.
How can the trace of a DFS with timesteps be used to count the descendents of a vertex $v$?&nbsp;	\item Difference between entry and exit times is twice the number of descendents.
What are tree edges and back edges wrt a DFS?	\item Tree edges are traversed by the DFS<div>\item Back edges are edges pointing to earlier in the search tree</div>
How can cycles be found in an undirected graph?	\item Conduct a DFS from any vertex.<div>\item If an edge is found from a discovered vertex to a discovered one that isn't it's parent (a back edge), the graph has a cycle.</div>
How can articulation vertices be identified in a graph?	\item Conduct a DFS, recording for each vertex it's parent, it's DFS-tree outdegree, and the earliest ancestor reachable through it's children.&nbsp;<div>\item After processing each vertex, check whether it is an articulation vertex using the information recorded.</div><div>\item Back-propogate earliest-ancestor information at the conclusion of processing.</div>
What kinds of edge can be encountered during a DFS on a directed graph?	\item Tree edges, involved in the algorithm.<div>\item Forward edges, linking an earlier vertex to a later one which isn't it's DFS-child.</div><div>\item Back edges, linking a later vertex to a DFS-ancestor.</div><div>\item Cross edges, linking edges which are neither DFS-ancestor nor DFS-child.</div>
On what graphs is a topological sort guaranteed to exist?	\item Directed acyclic graphs
How can a topological sort of a DAG be generated?	\item Conduct a DFS and push vertices into a stack in the order that they are marked processed.<div>\item Pop the stack to retrieve the topological order.</div>
How can you tell whether a graph is a DAG?	\item A DFS won't find any back edges.
In a DFS, how can back edges be identified?	\item They will link two discovered-but-unprocessed vertices together.
How can strongly connected components be identified in a directed graph?	\item Run a DFS.<div>\item If a back-edge is found, shrink the corresponding cycle down to a single vertex.</div><div>\item Repeat.</div>
Euler's characteristic formula is	\item $V - E + F = 2$ for spherical polyhedra and connected planar graphs&nbsp;<br />
Give a linear-time algorithm for finding the diameter of a tree.	\item Pick an arbitrary vertex and run a BFS to identify the most distant vertex, $u$.<div>\item Then, find the vertex $v$ most distant from $u$. This is the diameter of the tree.</div>
What is an arboresence of a digraph?	\item A rooted tree subgraph such that there is a path from the root to every node.
What is a mother vertex in a digraph?	\item A vertex from which all others can be reached.<div><br /></div>
Give an algorithm to identify whether a graph has a mother vertex.	\item Compute the strongly connected components<div>\item Represent each component as a vertex. The resulting graph is a DAG.</div><div>\item If more than one vertex in the derived graph has in-degree 0, the original graph doesn't have a mother vertex.</div>
In the DFS algorithm for finding a graph's strongly connected components, what happens when a vertex is first discovered?	\item It is pushed into the active stack<br />
In the DFS algorithm for finding strongly connected components, what happens during the processing of an edge $(x, y)$?	\item If it's a back edge, update $x$'s earliest reachable vertex to be the older one of $x$ and $y$'s reachable vertices<div>\item If it's a cross edge and $y$ does not yet have a component, do the same.&nbsp;</div>
In the DFS algorithm for finding strongly connected components, what happens after a vertex $v$ has been processed?	\item If the earliest reachable vertex of $v$ is $v$, pop vertices from the stack until $v$ is found, marking each as belonging to $v$'s component.<div>\item Update the earliest reachable vertex of the parent of $v$ to be the earliest of $v$'s and it's own. &nbsp;</div>
Give the three types of articulation vertex relevent to the DFS algorithm to find them.	<div><div>\item If $v$ has no parents (is the root) but more than one child, it is an articulation vertex.</div><div>\item If the oldest ancestor reachable from $v$ is $v$, it is an articulation vertex.</div></div><div>\item If the oldest ancestor reachable from $v$ is the parent of $v$, the parent is an articulation vertex.</div>
Describe Prim's algorithm for finding a minimum spanning tree	\item Pick any vertex<div>\item While the tree is incomplete, add the lowest-weight edge adjacent to it.</div>
What is the runtime of Prim's algorithm?	\item $O(n^2)$ naively<div>\item $O(m + n\lg n)$ with a Fibonacci heap</div>
Describe Kruskal's algorithm to find a minimum spanning tree	\item Repeatedly pick the cheapest edge between any two disconnected components.
What is the runtime of Kruskal's algorithm?	\item $O(mn)$ naively<div>\item $O(m \lg m)$ on a union-find data structure with the shorter-tree heuristic</div><div>\item $O(m \alpha (n))$ amortized on a disjoint-set data structure with shorter-tree and path compression heuristics.</div>
Describe the union-find datastructure and it's various heuristics.	\item A forest of `reversed' trees, with each element pointing to its parent.<div>\item {\tt find(x)} returns the representative element of $x$'s set by walking up the tree</div><div>\item {\tt union(x,y)} merges the sets containing $x$ and $y$ by pointing the root of one tree at the root of the other.</div><div>\item The shorter tree heuristic keeps track of tree heights and merges the smaller tree into the larger.</div><div>\item The path compression heuristic points each traversed node to the root during {\tt find} operations</div>
Give the runtimes of the union-find data structure's methods	\item $O(\lg n)$ for both find and union with the shorter-tree heuristic<div>\item $O(\alpha (n))$ amortized for both find and union with shorter-tree and path compression heuristics&nbsp;</div>
Describe Dijkstra's algorithm for finding shortest paths in weighted graphs.	\item Initialise the origin vertex $s$ as `current' and all other vertices as `unvisited'.<div>\item For each $(s,v)$, set ${\tt dist[v]} = w(s,v)$.<br /></div><div>\item While there are still unvisited vertices:</div><div>\item Set the unvisited vertex $v$ minimizing {\tt dist[v]} to be current</div><div>\item For each $(v,x)$, update {\tt dist[v]} to be the distance to $s$ through $x$ if it's shorter</div><div>\item Remove $v$ from the unvisited set.</div>
What is the runtime of Dijkstra's algorithm?	\item $O(n^2)$ naively<div>\item $O(m + n\lg n)$ on a priority queue over a Fibonacci heap</div>
Give a class of graphs on which Dijkstra's fails.	\item Graphs with negative weight edges.
Give a class of graphs on which Floyd's algorithm fails.	\item Graphs with negative-weight cycles.
Describe Floyd's algorithm for the all-pairs shortest path problem	<div>\item Initialise the weight matrix $[w_{ij}]$, with infinite values for non-adjacency</div><div>\item Initialise the parent matrix $[p_{ij}]$</div>\item For $i, j, k \in [0, n]^3$, $k$ in increasing order:<div>\item If $w_{ik} + w_{kj}$ is less than $w_{ij}$, update the latter, and store $k$ in $p_{ij}$</div>
What is the runtime of Floyd's algorithm?	\item $O(n^3)$.
What is Floyd's algorithm used for?	\item Calculating the shortest paths between all pairs of vertices in a graph.
Describe the basic Ford-Fulkerson algorithm for max network flow.	\item Initialise all flows to zero.<div>\item Find a path from source to sink with a positive remaining capacity.</div><div>\item Augment the flows with this path. Remember to subtract the flow going the other way.</div>
Describe the Karp-Edmonds algorithm for maximum network flows	\item Ford-Fulkerson where the augmenting paths are identified with a BFS from the source.&nbsp;
What is the runtime of the Edmonds-Karp algorithm?	\item $O(nm^2)$
List a standard set of seven questions to ask when stuck on an algorithmic problem	<div>\item Does brute force work?</div><div>\item Does it have an ordering?</div><div>\item Would sorting help?</div><div>\item Is approximation easier?</div><div>\item Does it have subproblems?</div><div>\item How does trivializing/ignoring parameters simplify things?</div><div>\item Have you followed Polya?</div>
What is a DAO?	\item Data Access Object
What is a ORM?	\item Object-relational mapping, which allows database tables to be treated as objects.
What is the MVC?	\item The model-view-controller software architecture<div>\item It separates the information in a program (the model) from the user.</div><div>\item The view component displays the model to the user; the controller allows the user to modify the model</div>
In large multi-project Maven builds, what can be done to clean up dependencies?	\item Pull any dependency that's declared more than once in a subtree up to the dependencyManagement section of the root POM.<div>\item Use {\tt \$\{project.version\}} and&nbsp;{\tt \$\{project.groupId\}} when referring to a sibling POM.</div>
In large Maven projects, how can the plugins of a POM be cleaned up?	\item Consolidate version numbers in {\tt property}s in a top-level POM<div>\item Consolidate configurations into {\tt dependencyManagement} in a top-level POM</div>
What is the difference between an option type and a nullable type?	\item Nullable types allow the variable to be set to null.<div>\item Option types allow the variable not to be set at all.</div>
What is the semipredicate problem?	\item That a function might fail, but signalling the failure requires a useful return value to be used.&nbsp;
What are the heaps created by .NET?	\item The code heap, which stores instructions after they've been JITed.<div>\item The small object heap (SOH), for objects $&lt; 85K$.</div><div>\item The large object heap (LOH), for objects $&gt; 85K$ (with some exceptions)</div><div>\item The process heap.</div>
In .NET, how does the stack work?	\item When a method is called, a container (a stack frame) is created which holds everything needed to complete the call.<div>\item The frame is put on top of the stack.</div><div>\item When the method completes, the frame is removed.</div><div>\item The frame at the top of the stack is always the one in use by the currently executing method.</div>
In NET, what information does a stack frame hold?	\item Parameters of the method<div>\item Local variables</div><div>\item Address of the code to exit to.</div>
In NET, how do stacks interact with threads?	\item Each thread has its own stack.
In NET, what is boxing and unboxing?	\item Boxing is a value type being assigned to a reference type variable, causing it to be copied onto the heap.&nbsp;<div>\item \ttt{int stackVar = 10; object boxedObject = stackVar;}<div>\item Unboxing is a reference type being assigned to a value type variable, causing it to be copied onto the stack.&nbsp;</div><div>\item \ttt{int unboxedVar = (int) boxedObject;}</div></div>
Which of .NET's heaps are managed?	\item The SOH and LOH
In NET, what are the five sources of root references?&nbsp;	\item Stack references<div>\item Global or static references</div><div>\item CPU registers</div><div>\item Object finalization references</div><div>\item Interop references (NET objects passed to COM/API calls)</div>
In NET, what does COM stand for?	\item Component Object Model<div>\item It is Microsoft interface standard for interprocess communication and object creation</div>
In NET, where are arrays of doubles stored?	\item If the array has 999 items or less, on the SOH<div>\item Otherwise, on the LOH.</div><div>\item Yes, this is an exception to the 85K rule</div>
Describe a constant space, linear time algorithm for merging two sorted lists of total length $n$.	\item Gather the $O(\sqrt{n})$ largest elements in the list on the far left. Call these the buffer.<div>\item Break each sublist - other than the buffer (``block 1'') - into blocks of $\sqrt{n}$ elements.</div><div>\item Sort the blocks from smallest-to-largest by the size of their tailmost element.</div><div>\item Let block $i$ be the first block such that the tail element of block $i \geq 2$ is larger than the head element of block $i+1$.</div><div>\item Merge the elements in blocks 2 through $i$ with block $i+1$ by repeatedly comparing the leftmost elements in each series of elements, and swapping the smaller of the two with the leftmost buffer element.</div><div>\item Identify the next two series of elements to merge in the same way.</div>
What is the Yale format?	\item A way to store two-dimensional sparse matricies.<div>\item Uses three arrays: $A$ contains all non-zero elements,&nbsp;</div><div>\item $IA$ contains the indices in $A$ of the first nonzero element of each row,&nbsp;</div><div>\item $JA$ contains the column indices of each nonzero element in $A$&nbsp;</div>
What is bandwidth minimization?	\item Minimizing the number of nonzero diagonals in a matrix by reordering the rows and columns.&nbsp;
What is the upper bandwidth of a matrix?	\item The smallest $p$ such that every element $a_{ij}$ is zero for $i &lt; j - p$.
What's a chain datastructure?	\item A singly-linked list with a null pointer at the end.
What is a generalized list?	\item A list in which each element is either atomic or another generalized list.
How can a queue be efficiently implemented on an array?	\item Implement it on a circular array and use modular arithmetic
What is a threaded binary tree?	\item A binary tree where each null left child points to the inorder predecessor of the node<div>\item and each null right child points to the inorder successor</div>
What is a tournament tree?	\item A complete binary tree in which each node contains the smaller (larger) of its two children.
How can a tournament tree be used for sorting?	\item When combining $k$ sorted lists, populate a tournament tree with the heads of each list.<div>\item The root is then the first item in the merged list. Pop it then repopulate the tree with $\lg(k)$ comparisons.</div>
How can sets be implemented by a bit vector?	\item Set the $i$th bit to 1 if the $i$th object is in the set.&nbsp;
What are the drawbacks of a bit vector set implementation?	\item Space is linear in the size of the universe<div>\item Listing set elements is linear in the size of the universe</div>
How do Bloom filters work?	\item On inserting an item $x$ into a set $S$, evaluate hash functions $H_1(x), \dotsc, H_k(x)$ and set the corresponding memory locations to 1.<div>\item To check whether $x$ is in $S$, hash it and check the corresponding memory locations.</div><div>\item False positives possible</div><div>\item Elements can't be removed</div><div>\item Can estimate number of elements in S</div>
How do counting filters work?	\item Bloom filter with a counter at each memory location. Insertion increments counters, removal decrements them.<div>\item A `full' counter should no longer be incremented or decremented.</div>
What is the false positive rate in a Bloom filter?	\item $p \approx \left( 1 - e^{-kn/m} \right)^k$<div>\item on $n$ elements, $m$ bits and $k$ hash functions</div>
What is a generalized bit vector?	\item Used for representing partitions<div>\item $i$th cell contains the name of the subset containing the $i$th element</div>
How do generalized bit vectors perform?	\item Set identification is constant time<div>\item Single-element modification is constant time</div><div>\item Union is proportional to the size of the universe</div>
What is a k-d tree?	\item A binary tree in which every node is a k-dimensional point.<div>\item Left children have a smaller value than the parent along the axis associated with the parent, right children have a larger value.&nbsp;</div><div>\item Non-leaf nodes implicitly generate a hyperplane perpendicular to the axis associated with the node.</div>
What is a quadtree?	\item A variant of a k-d tree for partitioning the plane.<div>\item Each node has four children, corresponding to the four quadrants around the node.</div>
What is a BSP tree?	\item A binary space partition tree<div>\item A variant of a k-d tree where each internal node has a generalized (not axis-parallel) plane associated with it.&nbsp;</div>
What is an R-tree?	\item A rectangle tree&nbsp;<div>\item A variant on k-d trees where each internal node represents a minimum bounding rectangle of its children</div>
What are k-d trees commonly used for?	\item Point location<div>\item Nearest neighbour search</div><div>\item Range search</div><div>\item Partial key search</div>
What is the end-to-end principle?	<div>\item It's far easier to obtain a necessary standard of reliability by altering the end hosts in a network rather than the machines in between.</div>
What are the standard defenses against MITM attacks?	<div>\item Third-party authentication</div><div>\item Session checksums</div><div>\item Shared secrets</div>
What is the standard example of a race condition attack?	\item A program verifying a file&nbsp;then reading it in seperate operations<div>\item An attacker can substitute the file for a malicious one after the verification has been done.</div>
What is the standard defense against race condition attacks?	\item Avoid non-atomic operations unless you're confident there're no security implications<div>\item If you don't know that an operation is atomic, assume it isn't.</div>
What are the standard defenses against replay attacks?	\item Session tokens<div>\item Timestamping</div><div>\item Nonces</div>
How do session tokens work?	\item Alice generates a token and sends it to Bob<div>\item who mutates the shared secret with it</div><div>\item and sends the result back to Alice</div>
How do cryptographic nonces work?	\item Alice requests a nonce from Bob<div>\item and then uses it to salt the rest of the exchange.</div><div>\item This prevents replay attacks</div>
How are parsing error attacks best defended against?	\item Use specialist libraries for user input processing<div>\item Check input against whitelists of safe tokens</div>
What are the three factors at work against secure coding?	\item Technical - the complexity of the task<div>\item Psychological - mental models ill-adapted for spotting flaws</div><div>\item Real-world - economic and social pressures</div>
What are the four classic stages of information security?	\item Protect<div>\item Deter</div><div>\item Detect</div><div>\item React</div>
In a hard disk, what is a cylinder?	\item The vertically aligned set of tracks, one on each platter, which correspond to the same head position.
In a hard disk, what is a track?	\item A circle traced out by a stationary head
In most hard disks, how many tracks can be read simultaneously?	\item Usually one.
In a hard disk, what is a sector?	\item A subdivision of a track holding a fixed amount of data (4kB nowadays)<div>\item plus a header and ECC</div>
How long does it typically take a read head to move from one cylinder to another?	\item 3-10ms
What is the rotational latency of a hard disk?	\item The time it takes for the platter to make half a revolution<div>\item which is 3-10ms</div>
What are the main parameters of the parallel disk model?	\item N, the problem size<div>\item M, the internal memory size</div><div>\item B, the block transfer size</div><div>\item D, the number of disks</div><div>\item P, the number of CPUs</div>
What are the parameters of the parallel disk model specific to queries?	\item Q, the number of queries in a batch problem<div>\item Z, the answer size</div>
What are the normalized parameters of the parallel disk model?	\item $n = N/B$, the problem size in terms of disk blocks<div>\item $m = M/B$, the internal memory size in terms of disk blocks</div><div>\item $q = Q/B$, the query specification size in terms of disk blocks</div><div>\item $z = Z/B$, &nbsp;the answer size in terms of disk blocks</div>
What is assumed about the processor interconnect network of the parallel disk model?	\item That items in the collective internal memories of the processors can be sorted in optimal $O((M/P) \lg M)$ time
What restriction is there on the input and output of data in the parallel disk model?	\item It should be striped across the $D$ disks
In the parallel data model, how long does it take to read/write striped data?	\item $O(N/DB)$ I/O ops
When is a type constructor covariant?	\item When it preserves the ordering of types.
When is a type constructor contravariant?	\item When it inverts the ordering of types.
What is an inner join?	\item \ttt{employee INNER JOIN department} will return all \ttt{(employee, department)} pairs.&nbsp;
What is a left outer join?	\item \ttt{employee LEFT OUTER JOIN department} will return a pair \ttt{(employee, department)} for every employee in the database.<div>\item In some pairs, \ttt{department} might be null.</div><div>\item The same employee might appear multiple times.</div>
What is a full outer join?	\item \ttt{employee FULL OUTER JOIN department} will return a pair \ttt{(employee, department)} for every employee and department.<div>\item In some pairs, \ttt{employee} or \ttt{department} might be null.</div>
What is preemption?	<div>\item It's the system of thread management where a thread manager switches context without the thread's approval.</div>
What is a time slice?	\item The time between thread scheduler interventions<div>\item AKA a quantum</div>
What is a quantum?	\item The time between thread scheduler interventions<div>\item AKA a time slice</div>
How does a semaphore work?	\item \ttt{wait()} decrements the semaphore by 1. If it becomes negative, the thread executing \ttt{wait()} will block and is added to the queue.<div>\item \ttt{signal()} increments the semaphore by 1. If the pre-increment value was negative, a thread is &nbsp;released from the queue.</div>
How do you write to the console in Unity3D?	\item \ttt{Debug.Log(message)}
What is the standard unit testing library for VS2012?	\item \ttt{Microsoft.VisualStudio.TestTools.UnitTesting}
What is a test harness?	\item The code used to test a piece of software (test scripts), \item along with the code that runs those tests (test execution engine)
What are the two qualities of a good unit test?	\item It runs fast ( $&lt;&lt;$100ms)<div>\item It localizes failures.</div>
What is the legacy code change algorithm?	\item Identify change points<div>\item Find test points</div><div>\item Break dependencies</div><div>\item Write tests</div><div>\item Make changes and refactor</div>
What are the two reasons to break dependencies in code?	\item Sensing: when otherwise you couldn't access what our code computes.<div>\item Separation: when otherwise you couldn't get the code to run in a test harness</div>
What is a fake object?	\item An object that impersonates a collaborator of the class under test.
What is the dominant method of breaking dependencies for sensing purposes?	\item&nbsp;Faking a collaborator, and querying the fake as to what data it recieved.
What is a mock object?	\item A fake object which performs assertions internally.
As far as legacy code goes, what is a seam?	\item A place where you can alter the behaviour of your program without doing any editing at that location.
How can you suppress calls to \ttt{\#include}d static functions?	<div>\item Using an object seam, ie</div>\item By creating a subclass and overriding the function<div>\item and using the override to either pass the call on to the intended recepient or redirect it.</div>
How can you intercept calls to global functions?	<div>\item Using an object seam, ie</div>\item By creating a subclass and overriding the function<div>\item and using the override to either pass the call on to the intended recepient or redirect it.</div>
What is an object seam?	\item A place where you can modify behaviour by replacing one object with another.<div>\item Usually by creating a subclass that overrides various methods.</div>
What feature specific to C++ and C (and a few other languages) can be used for sensing?	\item The preprocessor
How can a language's preprocessor be used for sensing?	\item By \ttt{\#include}ing a file which, conditional on \ttt{\#ifdef TESTING}<div>\item will \ttt{\#define} fake versions of the functions you want to intercept</div>
What is an enabling point?	\item The place associated with each seam<div>\item where you can make the decision for a seam to use one behaviour or another</div>
Give an example of an enabling point.	\item In a preprocessor seam, the enabling point is the \ttt{def TESTING}
What is an effective way to break many dependencies with a third party library?	\item By using a linker seam<div>\item and (dynamic linking) adding a fake library of the same name earlier in the \ttt{classpath}</div><div>\item or (static linked) by creating a fake library and altering the test environment's compilation scripts to link against the fake library instead of the real one</div>
What is a linker seam?	\item A call to an external library<div>\item which can be intercepted by creating a fake library of the same name and changing the classpath of the linker (dynamic linking)</div><div>\item or by creating a fake library and changing the test environment's build script to link against it.</div>
What is a danger in using a link seam?	\item The enabling point is outside the program's text<div>\item so it can easily be missed if it's not made obvious.</div>
How can calls to a \ttt{private static} method easily be intercepted?	\item By relaxing it to \ttt{protected} and overriding it in a subclass.
What's the enabling point of a object seam?	\item The place where you choose between creating a fake object or a real one
What are the problems with preprocessing seams?	\item They're not as explicit as object seams<div>\item Tests depending on them can be hard to maintain</div>
What are the problems with linker seams?	\item They're not as explicit as object seams<div>\item Tests depending on them can be hard to maintain</div>
What is refactoring?	\item Changing the structure of software with the purpose of making it easier to understand and cheaper to modify<div>\item without changing its behaviour.</div>
Give a general outline of how xUnit and its ilk work internally.	\item Given a test class containing a setup method, some test methods, and a teardown method<div>\item xUnit uses reflection to identify the test methods</div><div>\item For each test method, it creates a standard test class containing any variables declared in the class, the setup method, the test method in question, and the teardown method.</div><div>\item The test class runs the setup method, then the test method, then the tear down method.</div>
What is the FIT test harness?	\item The Framework for Integrated Tests<div>\item Each test function is associated with a HTML table<br /><div>\item that describes inputs to and the expected outputs of the test function.</div><div>\item Running FIT returns a table saying if expected cases were satisfied.&nbsp;</div></div>
What is FitNesse?	\item A wiki front-end for FIT, a HTML-table based testing harness.
When is the sprout method appropriate?	\item When a change can be implemented as a single sequence of statements at one place in a method.
How is the sprout method carried out?	\item Insert a call at the required place to the new method, but comment it out.<div>\item Identify the local variables needed for the new method it do its job, and make those the arguments. Add them to the commented-out method.</div><div>\item Determine whether a return is needed, and add the assignment to the commented-out method.</div><div>\item Implement the method using TDD.</div><div>\item Remove the comment.</div>
How can you apply the sprout method to a class with heavy initialization dependencies?	\item Make it a public static method and pass in any necessary instance variables.&nbsp;<div>\item Can then write the tests for it without instantiating the class.</div>
If you're applying the sprout method many times to a class with heavy initialization dependencies, what can be done to simplify matters?	\item If the public static sprouted methods share many arguments,&nbsp;<div>\item they can be farmed off to a new class and the arguments can be passed via the new class's constructor.</div>
What are the advantages of the sprout method?	\item There's a clean interface between new, under-test code and old code.
What are the disadvantages of the sprout method?	\item You're effectively giving up on getting the whole class under test.<div>\item It might not be clear to the next dev why that code's farmed off to it's own function.</div>
Describe test-driven development.	<div>\item ASSUMING THE CLASS IS ALREADY UNDER TEST:</div>\item Write a test case that describes desired behaviour. Let it fail.<div>\item Get it to compile.</div><div>\item Write the code neccessary to make it pass.</div><div>\item Remove duplication.</div><div>\item Repeat.</div>
What is the use case for a sprout class?	\item When it isn't possible to initialize a class in a test harness so that a method can be sprouted.
Describe the sprout class process.	\item Insert the class instantiation into the required place in the code, along with the method call. Comment both out.<div>\item Determine the local variables the method will need, and make them arguments to the class constructor.</div><div>\item Determine whether a value will need to be returned, and add a (commented out) assignment to do that if necessary.</div><div>\item Write the sprout class using TDD</div><div>\item Uncomment the class instantiation and method calls.</div>
What are the disadvantages of sprouting classes?	\item Conceptual complexity. It makes it harder for subsequent devs to work out how classes fit together.
When is a wrap method appropriate?	\item When new functionality needs to be added to a method simply because it needs to run at the same time as that method. No logic need be shared.
Describe the process of implementing a wrap method.	\item Identify the method that needs to change.<div>\item Rename the method, and create a new wrap method with the original name and signature.</div><div>\item Call the old method from within the wrap method.</div><div>\item Develop a method for the new feature, then call it from the wrap method too.</div>
When is a wrap class appropriate?	\item When the behaviour that needs adding to a class is independent of the current contents of the class
What is the decorator pattern?	\item Given a class \ttt{Component},<br /><div>\item create a decorator class \ttt{Decorator} which extends \ttt{Component}</div><div>\item and which as a \ttt{Component} field internally.</div><div>\item Forward any calls to \ttt{Component}'s methods to it's internally-held \ttt{Component}.</div><div>\item Then create a subclass \ttt{ConcreteDecorator} of \ttt{Decorator} to add functionality, possibly still forwarding calls to the internal \ttt{Component}s.</div>
What is a wrap class?	\item A subclass that holds an instance of its parent class internally<div>\item and which forwards calls to it's own methods to the parent instance's methods.</div>
What is programming by difference?	\item Create a failing test for a new feature of a class \ttt{parent}.<div>\item Derive a new class \ttt{child}&nbsp;</div><div>\item Make the test instantiate an instance of \ttt{child} rather than \ttt{parent}. It should still fail.</div><div>\item Implement the new feature in \ttt{child}, overriding whatever methods are needed.</div><div>\item When the test passes, can refactor \ttt{child} back into \ttt{parent} until everything in \ttt{child} can be commented out. If the test fails, you broke something.</div><div>\item When \ttt{child} is fully commented out, delete it and switch the test back to instantiating \ttt{parent}.</div>
What's the difference between method hiding and method overriding?	\item If you instantiate a subclass and cast it to the parent class, calls to the instance&nbsp;<div>\item will make use of overrides (\ttt{override}) in the subclass.<div>\item will not make use of hidden (\ttt{new}) methods in the subclass.</div></div>
What is the single responsibility principle?	\item A class should have a single responsibility:&nbsp;<div>\item it should have a single purpose in the system,</div><div>\item and there should only be one reason to change it.</div>
What is the Liskov substitution principle?	\item Subclasses should be able to substituted for their parents throughout the code without causing problems.
What are the rules of thumb for avoiding LSP violations?	\item Don't override concrete methods.<div>\item And if you must, try to call the base method from inside the derived method.</div>
What's a nomalized class hierarchy?	\item One where no class overrides a concrete method of it's superclasses
What's the advantage of having a normalized class hierarchy?	\item You can divine which implementation of a method a class is using by just looking in the class.<div>\item because either it's defined an overriding implementation itself,&nbsp;</div><div>\item or it hasn't and it's using the same implementation all of it's ancestors are using.</div>
What are the four most common problems with getting a class into a test harness?	\item Objects of the class can't be created easily<div>\item The test harness won't easily build with the class in it.</div><div>\item The constructor has bad side effects</div><div>\item The constructor does a lot of work and you need to sense it.</div>
What's an easy way to work out which&nbsp;arguments&nbsp;a&nbsp;constructor call in a test case requires?	\item Pass \ttt{null} as each constructor argument and see what complains.<div>\item DON'T DO THIS IN UNMANAGED MEMORY (C, C++)</div>
What is the null object pattern?	\item A way to avoid using \ttt{null}.<div>\item If a request usually returns an \ttt{Object}, create a subclass \ttt{NullObject} with empty methods and fields.</div>
What're the problems with the null object pattern?	\item Null objects still exist as objects - counting the number of \ttt{Objects} in a collection without filtering out \ttt{NullObjects} first could return an inaccurate count.
Describe three ways of dealing with irritating parameters when trying to get a class under test.	\item Extract an interface and pass a fake object to the constructor.<div>\item Pass \ttt{null} to the parameter if it's unneeded by the code under test (ONLY in pointer-safe code).</div><div>\item Subclass the irritating parameter's type and override the parts of it that make it irritating.</div>
When putting a class under test, what is an irritating parameter?	\item A parameter to the constructor or setup methods that is difficult to instantiate in a test environment.
What is parameterizing a constructor?	\item If an object is being created in a constructor, create a test version by passing it as an argument to the constructor instead.
When is it useful to parameterize a constructor?	\item When you want to sense through a item initialized inside the constructor
Describe the process of parameterizing a constructor.	\item Make a copy of the constructor<div>\item Add the required parameter</div><div>\item Rewrite the original constructor to forward it's calls to the new constructor, with the additional parameter `filled in'</div>
What are the disadvantages of parameterizing a constructor?	\item Anyone else can use the constructor too. This isn't usually much of a problem though.
What is superseding an instance variable?	\item If an instance variable \ttt{XXX} that needs to be replace is created in a constructor<div>\item add a method \ttt{supersede{XXX}(parameter)} that destroys (!!!) the old variable's contents and replaces it with \ttt{parameter}</div>
When is it appropriate to supersede an instance variable?	\item When it's awkward to parameterize the constructor<div>\item When virtual methods can't be called from the constructor, stopping you from extracting \&amp; overriding a factory method</div>
What are the disadvantages of superseding instance variables?	\item It breaks encapsulation. Someone else might use it.<div>\item Fortunately \ttt{supercedeXXX} is an unusual enough name that it's easy to recognise</div><div>\item Destroying reference types can cause trouble if the destructor does much work.</div>
What's the best way to deal with hard-coded initialization work in a constructor you're trying to sense?	\item Extract it to a virtual factory method<div>\item and then override it in a testing subclass.</div>
What're the problems with extracting \&amp; overriding factory methods?	\item It requires the language allow calls to virtual methods from constructors<div>\item It can cause problems if someone else decides to override the virtual method in production</div>
How can you sense a variable initializated in the constructor in C++?	<div>\item By extracting and overriding the getter for it.</div>
What're better alternatives to extracting \&amp; overriding a getter?	\item Extracting \&amp; overriding a factory method if the language allows it<div>\item Extracting \&amp; overriding a call if it's just one method using the object that's problematic</div>
What're the problems with extracting and overriding a getter?	\item You have to be careful to destroy the test instance in the same way production code destroys the instance<div>\item Someone might try to access the extracted variable before it's initialized.</div>
How do you extract and override a getter?	<div>\item Create a lazy getter for the constructor-initialized variable which creates the neccessary object on first call.<div>\item Then replace all uses of the variable with uses of the getter.</div><div>\item and initialize the reference that holds the object to null in all constructors.</div><div>\item Then subclass and override the getter.</div></div>
What is the singleton pattern?	\item A pattern used to ensure there's only ever one instance of a class.<div>\item It has private constructors.</div><div>\item and a static variable that holds the only instance of the class,</div><div>\item and static methods with names like \ttt{instance} are used to provide access to the class.</div>
How do you deal with singleton dependencies when trying to get a class under test, assuming they have accessible constructors?	<div>\item Add a \ttt{setTestingInstance(newInstance)} static method that allows the test to replace the singleton's instance</div><div>\item or add a \ttt{resetForTesting()} method that sets the singleton's instance to null (preferred if there is a easy way of setting the instance up in a suitable state)</div>
How do you deal with singleton dependencies when trying to get a class under test if they don't have accessible constructors?	\item Either: add a static setter, make the constructor protected, then subclass the singleton and create a fake<div>\item or extract an interface, swap all references to the singleton out with interface references, then pass in a fake.</div>
How do you extract the implementer of a class?	\item Make a copy of \ttt{Object}'s source called \ttt{ProductionObject}.<div>\item Turn the source class into an abstract interface.</div><div>\item Remove any now-unneccessary imports and includes.</div><div>\item Make \ttt{ProductionObject} implement \ttt{Object}</div><div>\item Replace any instantiations of \ttt{Objects} in the rest of the system with instantiations of \ttt{ProductionObjects}.</div>
How can you sense on an object a method constructs internally?	\item Parameterize the method and pass in a fake.
How do you parameterize a method?	\item Make a copy of the method.<div>\item Add a parameter to the method for the object you want to sense.</div><div>\item Replace the body of the original method with the original construction of the object, and then forward calls to the parameterized method.</div>
What's the problem with parameterizing a method?	\item It breaks encapsulation. This can be minimized by picking a suitably \ttt{test}-y name.
What's an alternative to parameterizing a method if it's not too much work?	\item Extract and override a factory method instead.
How can you deal with a large dependency graph when developing tests for C++?	<div>\item Create a header \ttt{Fakes.h} which contains a collection of overrides for methods that'd otherwise require many \ttt{\#include}s.</div><div>\item Then create a separate compilation script to avoid any issues with the same function being defined more than once.</div>
What's the problem with using \ttt{Fakes.h} file in C++?	\item The duplicate definitions have to be maintained along with the rest of the program<div>\item It doesn't help break dependencies in the main program.</div>
What is the total pressure gradient force on an infinitesimal parcel of air?	$$\mathbf{F} = -\frac{m}{\rho} \nabla p$$
What does $\mu$ represent in meteorology?	The dynamic viscosity coefficient
What is the dynamic viscosity coefficient?	If a fluid with dynamic viscosity $\mu$ is placed between two plates with seperation $d$,&nbsp;<div>and one plate is pushed sideways with a shear stress of 1Pa,&nbsp;the top plate moves a distance $\mu d$ in one second.</div>
What is the shearing stress in the direction of $x$ across an infinitesimal layer $\delta z$?	$$\tau_{zx} = \mu \frac{\partial u}{\partial z}$$
What is the kinematic viscosity coefficient?	$$\nu = \frac{\mu}{\rho}$$
In meteorology, what is the molecular viscosity of a fluid?	$$\mbf{F}_{r} = \nu (\Delta u, \Delta v, \Delta w)$$
What does $\nu$ represent in meterology?	\item The kinematic viscosity coefficient, $\nu = \mu / \rho$
What is the formula for centripetal acceleration?	$$\frac{D\mathbf{V}}{Dt} = -\omega^2 \mbf{r}$$
What's the length of a sidereal day?	\item 23hrs, 56m, 4s
In meterology, what is apparant gravity?	\item The sum of gravity and centrifugal force,<div>\item defined as $\mathbf{g} = -g \mathbf{k} \equiv \mathbf{g}^* + \Omega^2 \mathbf{R}$&nbsp;</div><div>\item where $\mbf{k}$ is parallel to vertical.</div><div>\item This leads to $g = 9.81m/s$ everywhere thanks to the oblate shape of the Earth</div>
In meteorology, what is $\Phi(z)$?	\item The work needed to raise a unit mass to height $z$ from sea level.&nbsp;
Give the formula for the Coriolis effect.	$$\frac{D\mbf{V}}{Dt} = -2\Omega \times \mbf{V}$$
What is the Coriolis parameter?	$$f = 2 \omega \sin \phi$$
Give the horizontally-restricted Coriolis effect in terms of the Coriolis parameter.	$$\frac{D\mbf{V}}{Dt} = -f\mbf{k} \times \mbf{V}$$
What is the qualitative result of the Coriolis effect?	Trajectories are deflected right in the northern hemisphere&nbsp;and left in the southern
What does $\alpha$ denote in meteorology?	Specific volume, the reciprocal of density
What is the equation of state for dry air?	$$p = \rho R T$$
What is the gas constant for dry air?	$$R = 287\,J\cdot kg^{-1} K^{-1}$$
What is the equation of hydrostatic balance?	$$\frac{dp}{dz} = -\rho g$$
What is the hypsometric equation?	$$\Phi(z_1) - \Phi(z_2) = R\int^{p_1}_{p_2} T d \ln p$$
What is the geopotential height?	$Z = \frac{1}{g_0} \Phi(z)$,&nbsp;where $g_0$ is the global average of gravity as mean sea level
What's the transliteration of ``hypsometric''?	``Height measure''
What is the scale height in meteorology?	The distance over which the atmospheric pressure changes by a factor of $e$
What is the thickness of an atmospheric layer between two pressure surfaces $p_1, p_2$ in terms of the layer mean scale height?	$$Z_T = H \ln(p_1/p_2)$$
What is the layer mean scale height?	$$H = \frac{1}{g_0} R \langle T \rangle$$
How is the layer mean temperature between two pressure surfaces $p_1, p_2$ calculated?	$$\langle T \rangle = \int^{p_1}_{p_2} T d \ln p \left[&nbsp;\int^{p_1}_{p_2}&nbsp;d \ln p \right]^{-1}$$&nbsp;
How does the derivative of pressure along the $x$ axis correspond to the derivative of pressure along the $z$ axis?	$$\left(\frac{\partial p}{\partial x}\right)_z = -\left(\frac{\partial p}{\partial z}\right)_x\left(\frac{\partial z}{\partial x}\right)_p$$
How is the horizontal pressure gradient measured in an isobaric coordinate system?	<div>\item By the gradient of the geopotential at constant pressure:</div>\item $-\frac{1}{\rho} \left(\frac{\partial p}{\partial x}\right)_z = -\left(\frac{\partial \Phi}{\partial x}\right)_p$<div>\item&nbsp;$-\frac{1}{\rho} \left(\frac{\partial p}{\partial y}\right)_z = -\left(\frac{\partial \Phi}{\partial y}\right)_p$</div>
What is the $\sigma$ coordinate system?	\item A vertical axis parameterized as multiples of the pressure at the ground
Given a vertical coordinate $s$ that's a monotonic function of height, how can the change in pressure along the $x$ axis at a surface of constant $s$ be calculated?	$$\left(\frac{\partial p}{\partial x}\right)_s = \frac{\partial p}{\partial z}&nbsp;\left(\frac{\partial z}{\partial x}\right)_s +&nbsp;\left(\frac{\partial p}{\partial x}\right)_z$$
What's the difference between the total and the local derivative?	<div>\begin{itemize}</div>\item The total derivative is the rate of change of a field variable when you follow the motion of the fluid<div>\item The local derivative is the rate of change of a field variable at a fixed point.</div><div>\end{itemize}</div>
What's the difference between a Eularian and Lagrangian frame of reference?	\item In a Eularian frame, the control volume is a parallelpiped whose position is fixed relative to the coord axes<div>\item In a Lagrangian frame, the control volume consists of an infinitesimal mass of ``tagged'' fluid particles.</div>
For the field variable $T$, what is the relation between the total and local derivatives?	$$\frac{DT}{D t} = \frac{\partial T}{\partial t} + \mbf{U} \cdot \nabla T$$
What are other names for the total derivative?	The substantial derivative or the material derivative
What is the advection term for a field variable $T$?	$$- \mbf{U} \cdot \nabla T$$
In fluid dynamics, what does it mean to say that a field variable is conserved?	That the total derivative of the variable is zero; the local change is entirely due to advection.
What is the relationship between the total derivative of a vector in an inertial frame and one in a rotating frame?	$\frac{D_a \mbf{A}}{D t} =&nbsp;\frac{D \mbf{A}}{D t} + \mbf{\Omega} \times \mbf{A}$, where &nbsp;$D_a$ is the derivative with respect to the inertial frame.
What is the relationship between a velocity vector in an inertial frame and one in a rotating reference frame?	$\frac{D_a \mbf{U_a}}{D t} =&nbsp;\frac{D \mbf{U}}{D t} + 2 \mbf{\Omega} \times \mbf{U} - \Omega^2 \mbf{R}$, where $\mbf{R}$ is the vector perpendicular to the axis and with magnitude equal to the distance to the axis of rotation
What is the vector momentum equation when applied to the pressure gradient, gravitation and friction acting on a parcel of the atmosphere? Use a rotating reference frame.	$$\frac{D \mbf{U}}{D t} = - 2 \mbf{\Omega} \times \mbf{U} - \frac{1}{\rho} \nabla p + \mbf{g} + \mbf{F}_r$$
What is the equation for the total derivative of $u$ when treated in a spherical rotating coordinate system?&nbsp;	\item $\frac{D u}{D t} -\frac{uv \tan \phi}{a} + \frac{uw}{a} = - \frac{1}{\rho} \frac{\partial p}{\partial x} + 2\Omega (v \sin \phi - w \cos \phi) + F_{rx}$<br />
What is the geostrophic relationship?	\item $-fv&nbsp;&nbsp;\approx&nbsp;-\frac{1}{\rho} \frac{\partial p}{\partial x}$<div>\item&nbsp;$fu &nbsp;\approx&nbsp;-\frac{1}{\rho} \frac{\partial p}{\partial y}$</div>
Qualitatively, what is the geostrophic wind?	\item The horizontal velocity field that satisfies the geostrophic relationship exactly
Give the formula for the geostrophic wind.	$$\mbf{V}_g \equiv \mbf{k} \times \frac{1}{\rho f} \nabla p$$
Under what conditions should the geostrophic wind be used as an approximation?	Only for large-scale motions away from the equator.
How is the geostrophic relationship obtained?	By ignoring all but the pressure gradient and Coriolis terms of the&nbsp;horizontal&nbsp;equations of momentum.&nbsp;
What are the predictive equations derived under the geostrophic approximation?	\item $\frac{Du}{Dt} = fv - \frac{1}{\rho} \frac{\partial p}{\partial x}$<div>\item $\frac{Dv}{Dt} = -fu - \frac{1}{\rho} \frac{\partial p}{\partial y}$</div>
What's the problem with using the predictive equations derived from the geostrophic approximation for actual prediction?	\item Their RHSs are taking the difference between two acceleration terms with very similar values, resulting in a LHS that's about an order of magnitude smaller than them both. Slight errors in initialization can lead to dramatically different results.
What is the Rossby number?	The ratio of the characteristic scale of the acceleration, $v \cdot \nabla v \sim U^2/L$&nbsp;to the characteristic scale of the Coriolis force, $\Omega v \sim f U$.
What are the characteristic scales for synoptic motions?	\item $U \sim 10m/s$, the horizontal velocity scale<div>\item $W \sim 1cm/s$, &nbsp;the vertical velocity scale</div><div>\item $L\sim 1,000km$, the length scale</div><div>\item $H \sim 10km$, the depth scale</div><div>\item $\delta P / \rho \sim 1,000m^2s^{-2}$, the horizontal pressure fluctuation scale</div><div>\item $L/U \sim 1 \mbox{day}$, the time scale</div>
What are some features of interest in synoptic scale meteorlogy?	\item Extratropical cyclones,<div>\item Baroclinic troughs and ridges,</div><div>\item Frontal zones,</div><div>\item Jet streams</div>
What is the troposphere?	\item The lowest part of the atmosphere,&nbsp;<div>\item containing about 80\% of its mass</div><div>\item and is about $\sim$17km thick at the mid-latitudes</div>
What can be assumed about the vertical component of synoptic-scale motion?	That it can be very well approximated by a pressure field in hydrostatic equilibrium.
What is the mass divergence form of the continuity equation?	$$\frac{\partial \rho}{\partial t} + \mbf{\nabla \cdot} (\rho \mbf{U}) = 0$$
What is the velocity divergence form of the continuity equation?	$$\frac{1}{\rho} \frac{D\rho}{D t} + \nabla \cdot \mbf{U} = 0$$
Qualitatively, what is the continuity equation?	The expression of conservation of mass for a fluid.
How can the vertical structure of the troposphere be characterized when under hydrostatic equilibrium?	By $\frac{1}{\rho_0} \frac{d p_0}{dz} \equiv -g$, where $p_0(z)$ and $\rho_0(z)$ are the average pressure and density at each height
At the synoptic scale, how can the continuity equation be approximated?	$$\nabla \cdot (\rho_0 \mbf{U}) = 0$$
What is an adiabatic process?	A transfer of energy as work without a transfer of heat between the system and its surroundings.
What is the mechanical energy equation?	$$\rho \frac{D}{Dt} \left( \frac{1}{2} \mbf{U \cdot U} + \Phi \right) = - \mbf{U \cdot \nabla} p$$
What is the thermodynamic energy equation?	$c_\nu \frac{D T}{D t} + p \frac{D \alpha }{D t} = J$, where $c_\nu$ is the specific heat at constant volume of air, and $J$ is the rate of heating per unit mass
Where in the equations of atmospheric dynamics does solar heating contribute energy to the system?	Via the $p \frac{D \alpha}{D t}$ term of the thermodynamic energy equation, which represents the rate of working of the fluid system per unit mass.
What is Poisson's equation?	$\theta = T (p_s/p)^{R/c_p}$, where $p_s$ is a standard pressure and $c_p$ is the specific heat at constant pressure of dry air.
What does $\theta$ represent in meterology?	The potential temperature, the temperature a parcel of dry air would have if it were adiabatically expanded/compressed to a standard pressure $p_s$.
What is the restriction on the movement of a parcel of fluid that conserves entropy?	It must move along an isentropic (constant $\theta$) surface.
What is the entropy form of the first law of thermodynamics?	$$c_p \frac{D \ln T}{Dt} - R \frac{D \ln p}{D t} = \frac{J}{T} = \frac{Ds}{Dt}$$<div><br /></div><div><br /></div><div><br /></div><div>where $c_p$ is the specific heat of the fluid at constant pressure, $J$ is the rate of external heating, and $s$ is the entropy of the parcel of fluid in question</div>
How is the change in potential temperature related to the change in entropy of a parcel of fluid?	$$c_p \frac{D \ln \theta}{D t} = \frac{Ds}{Dt}$$
What is the dry adiabatic lapse rate of temperature?	The expected rate of decrease in temperature with respect to height when potential temperature is constant with respect to height.<div><br /></div><div>$$\Gamma_d \equiv \frac{g}{c_p} = -\frac{dT}{dz}$$</div>
What is the stability criterion for dry air?	\item If $\frac{d\theta_0}{dz} &gt;0$, a parcel is statically stable and will oscillate around it's level.<div>\item If $\frac{d\theta_0}{dz} =0$, a parcel is statically neutral</div><div>\item If $\frac{d\theta_0}{dz} &lt;0$, a parcel is statically unstable and displacement will increase exponentially with time.</div>
How is the environmental potential temperature defined?	$$\left( \frac{\rho_0 - \rho}{\rho} \right) = \frac{\theta}{\theta_0}$$
How is the first law of thermodynamics estimated if a parcel of fluid is not undergoing strong diabetic heating?	$$\left( \frac{d\theta}{dt} + u&nbsp;\frac{d\theta}{dx} + v&nbsp;\frac{d\theta}{dy} \right) \approx - w&nbsp;\frac{d\theta_0}{dw}$$
What does the gas constant represent?	It relates the energy scale to the temperature scale when one mol of ideal gas is being considered.
<div>What is the equation for the total derivative of $v$ when treated in a spherical rotating coordinate system?&nbsp;</div>	<div>$$\frac{D v}{D t} + \frac{u^2 \tan \phi}{a} + \frac{vw}{a} = - \frac{1}{\rho} \frac{\partial p}{\partial y} - 2\Omega u \sin \phi + F_{rz}$$</div><div><br /></div>
<div>What is the equation for the total derivative of $w$ when treated in a spherical rotating coordinate system?&nbsp;</div>	$$\frac{D w}{D t} - \frac{u^2 + v^2}{a} \qquad \quad = - \frac{1}{\rho} \frac{\partial p}{\partial z} - g + 2\Omega u \cos \phi + F_{rz}$$
What is the Courant number of a simulation?	$$\frac{U\Delta t}{\Delta x}$$<div><br /></div><div>where $U$ is the fastest wave on the grid and $\Delta t, \Delta x$ are the resolutions.&nbsp;</div>
What is the Courant-Friedrich-Lewis criterion?	A neccesary condition for the advection term in a Eulerian framework to be stable is that the Courant number is less than 1.&nbsp;
How many gridpoints are needed to reasonably resolve a wave?	Approximately 10 per wavelength.
What is the optimal relationship between vertical grid increments and horizontal grid increments in an atmospheric model?&nbsp;	$$\Delta z_{opt} = s\Delta y$$<div><br /></div><div>where $s$ is the frontal slope</div>
What are the six visibility notations available for a class member in UML?	\item $+$, public<div>\item $-$, private</div><div>\item $\#$, protected</div><div>\item $/$, derived</div><div>\item $\_$, static</div><div>\item $\sim$, package</div>
How is scope indicated on a UML class diagram?	\item Classifier members (static members) are underlined<div>\item Instance members are not</div>
How are the various instance-level links in UML indicated?	\item Bi-directional/uni-directional/reflexive Association (plain line)<div>\item Aggregation (hollow diamond on the containing class)</div><div>\item Composition aggregation (solid diamond on the containing class)</div>
What is the difference between a composition and an aggregation link in UML?	\item Aggregation represents a `has a' association<div>\item Composition represents a `owns a' association. Destroying the owner should destroy the owned instances.</div>
How are the various class-level relationships denoted in UML?	\item Generalization (hollow arrow on solid line)<div>\item Realization (hollow arrow on dotted line)</div>
What is the difference between generalization and realization in UML?	\item Generalization represents a `is a' relationship<div>\item Realization represents a `implements' relationship</div>
Describe three high-level perspectives to consider object oriented code from&nbsp;	\item The conceptual level - what the responsibilities of an object are<div>\item The specification level - what the object looks like from the outside</div><div>\item The implementation level - how the object is implemented</div>
What are the three rules given by the Gang of Four?	\item Design to interfaces<div>\item Favour composition over inheritance</div><div>\item Find what varies and encapsulate it.</div>
In short, what is the intent of the Facade pattern?	\item To simplify the use of an existing system.
What are the consequences of the Facade design pattern?	\item It simplifies the use of a system,<div>\item but may hide some functionality in doing so.</div>
What's the relationship between the conceptual and specification perspectives of OO design?	\item Commonality: the specification identifies the interface needed to capture all the cases of a concept
What's the relationship between the specification and implementation perspectives on OO design?	\item Variation: the implementation identifies the various cases of the specified interface
What is the problem solved by the Bridge pattern?	\item The derivations of an abstract class must use multiple implementations without causing an explosion in the number of classes.
What are the participants and collaborators of the Bridge pattern?	\item Abstraction: defines the interface for the objects being implemented<div>\item Implementor: defines the interface for specific implementation classes</div><div>\item Classes derived from Abstraction use classes derived from Implementor without knowing which ConcreteImplementor is being used</div>
How are case statements a code smell?	\item They might indicate misplaced responsibilities that could be factored out in favour of polymorphism
What is the problem that the Abstract Factory pattern solves?	\item Families of related objects need to be instantiated
What are the participants and collaborators of the AbstractFactory?	\item AbstractFactory: the collection of interfaces for how to create each member of the family of objects required.<div>\item ConcreteFactory: the implemented factory for a family of objects</div>
What are the rules for design pattern application?	\item Apply one at a time<div>\item Context first, ie top-down</div>
What is the open-closed principle?	\item That software components should be open for extension, but closed for modification
"What's a better alternative to the question ""Which implementation is better?"""	"\item ""Under what circumstances would each of the possible alternatives be optimal?""<div>\item ""Which of those circumstances is most like my problem domain?""</div>"
What is the problem solved by the Strategy pattern?	\item The algorithm to be applied is dependent on which client is making the request or what data is being acted on
What are the participants and collaborators of the Strategy pattern?	\item Strategy: the interface to the various algorithms<div>\item ConcreteStrategy: the implementations of the various algorithms, implementing Strategy.</div><div>\item Context: holds a reference of type Strategy and interprets calls from the client into calls to the strategy.</div><div>\item Client: makes calls to the context</div>
What's the problem solved by the Decorator pattern?	\item When you have an object which fulfills some basic functionality, but it needs to be extended in a variety of ways.
What are the participants of the Decorator pattern?	<div>\item Component: the abstract class from which ConcreteComponent and Decorator derive from. Has an Operation() method.</div>\item ConcreteComponent: the class being decorated<div>\item Decorator: the abstract class from which ConcreteDecorators derive. Holds a reference to a Component.</div><div>\item ConcreteDecorator: a subclass of Decorator which conducts some work, makes a call to the Operation() of Component it holds, then does some more work.</div>
What problem does the Singleton pattern solve?	\item Several different clients refer to the same object, and you want to ensure it is only instantiated once.
How is the Singleton pattern implemented?	\item Add a static property to the class that holds an instance of the class.<div>\item Add a public method that checks whether the property is null, and if it is instantiates a new object and stores it there.</div><div>\item Set the constructor to private.</div>
What is the Double-Checked Locking pattern?	\item A variation on the Singleton for use in multithreaded applications.&nbsp;
What problem does the Double-Checked Locking pattern solve?	\item The race condition that can emerge when two threads instantiate a singleton.
What are the Gang of Four's three categories of patterns?	\item Structural<div>\item Behavioural</div><div>\item Creational</div>
What are the Gang of Four's five creational patterns?	\item Abstract Factory<div>\item Builder</div><div>\item Factory Method</div><div>\item Prototype</div><div>\item Singleton</div>
What are the Gang of Four's seven structural patterns?	\item Adapter<div>\item Bridge</div><div>\item Composite</div><div>\item Decorator</div><div>\item Facade</div><div>\item Flyweight</div><div>\item Proxy</div>
What are the Gang of Four's eleven structural patterns?	\item Chain of responsibility<div>\item Command</div><div>\item Interpreter</div><div>\item Iterator</div><div>\item Mediator</div><div>\item Memento</div><div>\item Observer</div><div>\item State</div><div>\item Strategy</div><div>\item Template method</div><div>\item Visitor</div>
What does SOLID stand for?	\item Single responsibility<div>\item Open/closed<br />\item Liskov substitution</div><div>\item Interface segregation</div><div>\item Dependency inversion</div>
What is the problem solved by the Observer pattern?	\item You want to notify a varying list of objects of an event.
What are the participants in the Observer pattern?	\item Subject: abstract class with methods to let an observer register, deregister, and a Notify() method that calls the Update() methods of each registered observer<div>\item ConcreteSubject: implementation of Subject</div><div>\item Observer: abstract class with an Update() method.</div><div>\item ConcreteObserver: implementation of observer</div>
How can preexisting objects be added as observers in the Observer pattern?	\item By using an Adapter.
Which party should filter extraneous notifications in the Observer pattern?	\item The subject.
How can extraneous notifications be filtered in the Observer pattern?	\item Using the Strategy pattern<div>\item When added, each observer passes to the Subject a strategy on how to filter notifications to them.</div>
How can the information passed to an observer in the Observer pattern be specialised?	\item Using the Strategy pattern.<div>\item Each observer passes to the Subject a strategy concerning which information to pass to it.</div>
What's the difference between a Template Method and a collection of Strategies?	\item The processes in the Template Method are conceptually similar
What is the problem solved by the Template Method pattern?	\item There is a procedure that is consistant at one level of detail, but individual steps vary between implementations at a lower level of detail.
What are the participants in the Template Method pattern?	\item AbstractClass: might not actually be abstract, contains a skeleton of the algorithm with calls to virtual methods in the same class.<div>\item ConcreteClass: derives from AbstractClass, overrides the virtual methods to produce different behaviour&nbsp;</div>
What's the problem solved by the Factory Method pattern?	\item A class needs to instantiate an interface, but the implementation varies.
What're the participants in the Factory Method pattern?	\item Product: the interface to be instantiated<div>\item ConcreteProduct: an implementation of Product<br /><div>\item Creator: the interface containing a virtual FactoryMethod()</div></div><div>\item ConcreteCreator: an implementation of Creator that overrides FactoryMethod() to return a ConcreteProduct</div>
How is Shalloway's Analysis Matrix structured?	<div>\item Each row describes a rule</div>\item Each column describes a case
What does DCI stand for?	\item Data, context and interaction
In what seven ways does lean architecture differ from classic software architecture?	\item Defers engineering<div>\item Accomodates change</div><div>\item Defers implementation</div><div>\item Lightweight documentation</div><div>\item People-focused</div><div>\item Collective planning</div><div>\item End-user mental model</div>
What are the values of the Agile Manifesto?	\item Individuals and interactions over processes and tools<div>\item Working software over comprehensive documentation</div><div>\item Customer collaboration over contract negotiation</div><div>\item Responding to change over following a plan</div>
What's the value chain?	\item The chain of activities a firm performs in order to transform its inputs into a valuable product
What situations are Agile approaches maladapted for?	\item Those where there's little valuable user feedback&nbsp;<div>\item ie when developing a protocol to a formal specification</div><div>\item or building a library, where there's no short feedback loop</div>
What's the difference between a complicated and a complex system?	\item Complicated systems: only known unknowns, can rely on fact-based management<div>\item Complex systems: have unknown unknowns, no predictable path from current state to better state</div>
What situations are lean architectures maladapted for?	\item Simple systems with no unknowns, for which lean architecture is overkill<div>\item Chaotic systems without (m)any patterns enough to make assumptions off of</div>
What're the fundamental mismatches between lean and agile methodologies?	\item Lean emphasizes throughput over latency<div>\item Lean emphasizes processes; agile emphasizes people.&nbsp;<br /><div>\item Lean emphasizes bringing decisions forward; agile emphasizes deferring them</div></div>
What's the Lean architecture rule of thumb?	\item Everybody, all together, early on
What are the two purposes of documentation?	\item As a tutorial for people who weren't there when a decision was made<div>\item As a reminder for those who were</div>
Fundamentally, what is Scrum?	\item An Agile framework for the management side of development
Give a good definition of `problem'.	\item The difference between the current state and the desired state
What binary division of a system does Lean Architecture propose?	\item What the system is: the system architecture; the stable structures of the business over time; how the users think<div>\item What the system does: the system's functionality; what the users do</div>
Who are the five key stakeholders in the development of software?	\item End users<div>\item the business</div><div>\item customers</div><div>\item domain experts</div><div>\item developers</div>
What metric do end users evaluate software against?	\item Whether it does what they expect it to
What is the end user cognitive model?	\item The end user's perception of the system's form.
What does DFT stand for in the context of software?	\item Design for Testability
What's an autopoeietic system?	\item A self-organizing system.
What does a bug discovered in the field cost to fix vs one in requirements review?	\item 70 times more
What are the five properties of a good problem definition?	\item It is written down and shared<div>\item It is a difference between a current state and a desired state of an organization</div><div>\item Its achievement is measurable at some mutually understood point in time.</div><div>\item It is one or two sentances in simple language</div><div>\item It is internally consistent.</div>
What're the properties of a wicked problem?	\item The problem is not understood until after the formulation of a solution<div>\item They don't have a stopping rule</div><div>\item Solutions are not right or wrong</div><div>\item Every wicked problem is novel and unique</div><div>\item Every solution is a one-shot</div><div>\item There are no alternative solutions</div>
In Agile methodology, what's the difference between an objective and a goal?	\item An objective is a waypoint that must be met. Failure is indication that the process needs to be improved.<div>\item A goal is the desired endpoint in the best of all possible worlds.</div>
With respect to software architecture, what is form?	\item Form is the essence of structure, without the structure itself.
Why does top-down design break down for complex systems?	\item Because complex systems have many tops
What is the usual dividing line between code that is stable and code that changes frequently?	\item Stable code: what the system is<div>\item Unstable code: what the system does</div>
How should expected fluctuation in code affect architecture?	\item The components of an architecture should be seperated by their different rates of change
When designing a system architecture, what interpretation should be focused on?	\item The essence of the system form, ie what the system \emph{is}<div>\item Don't worry about what the system \emph{does}&nbsp;</div>
How should a system's form be partitioned when developing an architecture?	\item In whichever way leads to subsystems that are as autonomous as possible
What should drive the choice of architectural partitions of a system's form?	\item Human considerations. Software engineering considerations are secondary.
With respect to software architecture, what is a domain?	\item A business area of focus/interest/study/specialization.<div>\item An area for which a body of knowledge (possibly tacit) exists.</div>
How are domains of interest to the partitioning of a system's form?	"\item Each domain forms a ""top"" of the system and shouldn't be split across architectual units,<div>\item and certainly not across geographic locations.</div>"
How do domains influence software product variants?	\item They commonly designate sets of closely related products in a way that supports code reuse
What's Conway's Law?	\item That software architecture tends to reflect the organizational structure of the team that built it.
How are user's mental model of the form of a system reflected in architecture?	\item Through modules, which are the partitions of the subsystems&nbsp;
What are the most important considerations when establishing the modules in a partition?	\item They correspond to the end-user's cognitive model<div>\item Each module is as independent as possible</div><div>\item Each module should be cohesive</div><div>\item Each module should correspond to a specific domain (expert)</div>
Which is the most important consideration in the module partitioning of an architecture?&nbsp;	\item Domain knowledge.<div>\item Domain experts have acquired a knowledge of what stays constant and what varies</div>
In the absence of domain knowledge, what's the most important consideration when creating the module partitioning of an architecture?	\item That they follow the end user's cognitive model.
What does commonality mean in the context of software architecture?	\item The invariant properties across concurrent options and also over time
What's the difference between generalization and abstraction in describing a software architecture?	\item Abstraction ignores certain attributes in favour of others<div>\item Generalization ignores the attributes that can be inferred from context</div>
What are the five commonality categories of software components in Von Neumann languages?	\item Behaviours (like move or rotate)<div>\item Algorithms (like the alg for moving or rotating)</div><div>\item State</div><div>\item Data structure</div><div>\item Type (in the programming sense)</div>
What's a Von Neumann programming language?	\item One which at a high level is isomorphic to a von Neumann architecture
What are common examples of a von Neumann language?	\item Most every procedural or OO language.
How is software architecture best represented?	\item In the most compressed, generalized form possible given the context and domain dictionaries at hand<div>\item but nothing should be abstracted, which might throw away important information</div>
How should the programming paradigm for implementing an architecture be selected?	\item Choose the one whose commonality and variation best matches that of the domain model/end user model
When is the object-oriented paradigm best suited for implementing an architecture?	\item When variation of the system over time will likely require changes to algorithms, while the data structures stay constant.&nbsp;
What are the families within a domain of a system's architecture?	\item A set of elements in the domain which have some properties in common and some parameters that characterize how they vary.
How are object-shaped domains of a system architecture usually represented?	\item As an abstract base class, with a small set of supporting types or constants
When constructing the domain classes associated with a system's form, how much logic should they contain?	\item Very little. They should be as dumb as possible.
How are procedural domains of a system architecture usually represented?	\item With procedure declarations
How are generative domains of a system architecture usually represented?	\item With template or generic declarations
In the concrete base classes of the architecture of a system's form, how can the intent of the API be effectively communicated?	\item With assertions&nbsp;<div>\item Or (even better) compile-time assertions</div>
What's architectural testing?	\item Imagining ways in which the architecture might have to change over time, and evaluating how painful implementing those changes would be
What's a rule of thumb for evaluating the cost of a change?	\item Count the number of architectural interfaces that'll have to change to accomodate it
When does architectural testing indicate the architecture needs to change?	\item When it identifies a large set of expensive changes that would be considered easy from a business or end user perspective
How many use cases can single system handle?	\item At most $\sim$240
What're the responsibilities of the model in MVC?	\item Updates data at the request of commands from the controller<div>\item Notifies appropriate views when its state changes</div><div>\item Can be asked to register/de-register views</div>
What are the responsibilities of a view in MVC?	\item Presents a particular representation of the data<div>\item Can ask the model for the current value of the data</div><div>\item Can handle its own input</div><div>\item Together with the controller, handles selection</div>
What are the responsibilities of the controler in MVC?	\item Creates and manages views<div>\item Handles selection across views</div><div>\item Passes commands to the model</div><div>\item Handles commands that apply to the entire system</div>
What are the four components of DCI's representation of a system?	\item Domain classes<div>\item Objects</div><div>\item Methodful roles</div><div>\item Methodless roles (identifiers)</div>
Which parts of the DCI architecture represent a system's behaviour?	\item Methodful and methodless roles
Which parts of the DCI architecture represent a system's form?	\item Classes and objects
What part of a use case do methodless roles follow from?	\item Habits
In DCI, what's a trait?	\item A holder of stateless methods
How are DCI's contexts derived from use cases?	\item Each use case has a corresponding context
What is the job of the Context in DCI?	\item To bind its identifiers to matching objects, then to call the first method of the first object role
What are the responsibilities of a&nbsp;DCI&nbsp;Context in the execution of a use case?	\item To identify the objects involved in a use case invocation<div>\item To associate these objects with their appropriate object roles</div><div>\item To start enactment when the trigger is called</div><div>\item To publish interface bindings for the methodful object roles&nbsp;</div>
In MVC, where do DCI's domain objects reside?	\item In the model
In MVC, where do DCI's contexts reside?	\item Mostly in the controller
In DCI, what's an environment?	\item The code that initiates the enactment of a use case
In DCI, what's the job of the context accessor?	\item To stack execution contexts&nbsp;
What are the five rules to writing context objects in DCI?	\item Create a new Context class for each use case<div>\item Context classes should have a parameterless constructor</div><div>\item Context classes should have a run method, or have a convention that calling the constructor runs the use case</div><div>\item Context classes should publish identifiers (pointers) for all object roles involved in the use case</div><div>\item Identifiers should be typed as methodless object role types</div>
What are the four ways to pass around Contexts in DCI?	\item Pass the individual object role bindings to the methods in the methodful object roles<div>\item Pass the context to the methodful role interface of each domain object</div><div>\item Pass the Context object as an argument to each method in the methodful object roles</div><div>\item Let methodful object roles access a global Context object which manages accesses to other roles</div>
What's the best algorithm for the longest common subsequence between two permutations?	\item The Robinson-Schensted-Knuth algorithm
Given a 0-1 array $A$, what's the best way to identify whether there's a integer $k$ such that the $k$th row is all zero, and the $k$th column is all 1 (except for $A[k,k]$?	\item Start with a list $1, 2, \cdots, n$ and at each step pull the first two elements out (say $i, j$) and test whether $A[i, j]$ is 1.&nbsp;<div>\item If it is, delete $i$, if it isn't, delete $j$.</div>
How do you generate uniformly random points on a sphere?	\item By remembering that the area of a slice of a sphere between two parallel planes is dependent only on the distance between the planes.
What is the Stout-Warren algorithm?	\item An in-place linear-time algorithm for balancing a binary tree
What's the best way to balance a binary tree?	\item The Stout-Warren algorithm
How would the fact ``John likes Mary`` be written in Prolog?	\item \ttt{likes(john, mary).}
In the Prolog fact \ttt{likes(john, mary).}, what are the names of the components?	\item \ttt{likes} is a predicate<div>\item with two objects, \ttt{john, mary} as its arguments</div>
What's a database in Prolog?	\item A collection of facts and rules for a particular problem
How might the question ``Does Mary own the book?'' be phrased in Prolog?	\item \ttt{?- owns(mary, book).}
What does it mean for a fact in Prolog to unify a question?	\item The fact has the same predicate and arguments as the question
When will a Prolog question return \ttt{yes}?	\item When there is a unifying fact in database for that question.
What's the naming rule for Prolog variables?	\item A variable must begin with a capital letter.
What is an instantiated Prolog variable?	\item A variable is instantiated when there's an object the variable stands for
How does Prolog instantiate a variable in a question?	\item It searches the database for the first unifying fact (in input order)<div>\item and then pattern-matches the variable against the fact's arguments</div><div>\item and marks its place in the database.</div>
In interactive mode, how can you request Prolog move to the next instantiation of a variable?	\item Colon, then enter.
In interactive Prolog, how can you indicate you're satisfied with the current instantiation of variables?	\item Hit enter.
How is a conjunction described in Prolog?	\item With a comma: \ttt{?- likes(john, mary), likes(mary, john)}
How does Prolog attempt to satisfy conjunctions	\item By backtracking: it finds the first unifying fact for the first goal of the question,<div>\item then continues its search from that point if the second goal isnt also satisfied, etc.</div>
How might the rule ``John likes anyone who likes wine`` be written in Prolog?	\item \ttt{likes(john, X) :- likes(X, wine).}
What are the components of a Prolog rule?	\item The head, which comes before the \ttt{:-}, describes what the rule is intended to define.<div>\item The body, which comes after the \ttt{:-}, describes the conjunction of goals that must be satisfied in order for the head to be true.</div>
What's the naming style for compund names in Prolog?&nbsp;	\item Use underscores and lower case.
What's a clause in Prolog?	\item Either a fact or a rule.
How are comments written in Prolog?	\item With \ttt{/*...*/}
What are the four `primative' types supported by JSON?	\item Strings<div>\item Numbers</div><div>\item Booleans</div><div>\item null</div>
What are the two compound types supported by JSON?	\item Array, an ordered sequence of values<div>\item Object, an unordered collection of name/value pairs.</div>
What type are the names of an object in JSON?	\item Strings.
What is globbing?	\item The type of pattern matching traditionally used by the Unix shell
What are the five features common to most glob syntaxes?	\item \ttt{?}, matching a single unknown character<div>\item \ttt{*}, matching any number of unknown characters</div><div>\item \ttt{[abc]}, matching any contained character</div><div>\item \ttt{[!a]} matching all but the contained character</div><div>\item \ttt{\textbackslash *}, matching the escaped character&nbsp;</div>
How is the program \ttt{egrep} usually invoked?	\item \ttt{egrep 'pattern' filename}
What is \ttt{egrep}?	\item The \ttt{grep} patternmatcher invoked with the \ttt{-E} switch to enable extended regular expressions
How can the beginning of a line be denoted in egrep?	\item \ttt{\^{}cat}
How can the end of a line be denoted in an egrep pattern?	\item \ttt{cat\$}
What does egrep use to match exactly one of a class of characters?	\item \ttt{[ea]}
How can a range of possible matching characters be denoted in an egrep pattern?	\item \ttt{[a-c]}
How can multiple ranges of possible character matches be denoted in an egrep pattern?	\item \ttt{[1-5b-f]}
How can you denote a set of characters that shouldn't be matched in an egrep pattern?	\item \ttt{[\^{}ea]}
What does \ttt{[\^{}ea]} mean in an egrep pattern?	\item That a character OTHER THAN \ttt{e, a} should be matched.<div>\item This is different from ``don't match e or a''</div>
What's different about metacharacters inside and outside a character class in an egrep pattern?	\item Almost everything.&nbsp;<div>\item It's best to think as regexs inside and outside a character class as different languages.</div>
How can you match any single character in an egrep regex?	\item \ttt{.}
When is a dash in a character class in an egrep regex not considered a metacharacter?	\item When it appears first in the class, immediately after \ttt{[} or \ttt{[\^{}}
How does egrep pattern match against newline characters it encounters?	\item It doesn't - it strips them out and considers the lines in isolation.<div>\item This is a peculiarity of grep though, it isn't standard across all such tools.</div>
How can you match regexs over multiple lines in Linux?	\item Using \ttt{pcregrep -M}.<div>\item In contrast, \ttt{grep} considers lines in isolation.</div>
How can you match one of multiple possible subpatterns in an egrep regex?	\item \ttt{(pattern1|pattern2)}
How can you make egrep do a case-insensitive match?	\item Use the \ttt{-i} switch.
How can you match against word boundaries in some versions of egrep?	\item \ttt{\textbackslash &lt;cat\textbackslash&gt;}&nbsp;
How can you mark a character as optional in an egrep regex?	\item \ttt{colou?r} marks \ttt{u} as optional
How can you match one or more of a character in a egrep regex?	\item \ttt{a+}
How can you match zero or more of a character in a egrep regex?	\item \ttt{a*}
What are the quantifer metacharacters in a egrep regex?	\item \ttt{+}<div>\item \ttt{*}</div><div>\item \ttt{?}</div>
How can you match against a range of repetitions of a character in some versions of egrep?	\item \ttt{a\{1, 5\}}
How does backreferencing work in egrep versions that support it?	\item Text matching the $i$th parenthesised pattern in a regex&nbsp;can be matched against later with \ttt{\textbackslash i}&nbsp;<div>\item Parenthesised expressions are counted by opening parentheses from the left</div>
How can you escape a metacharacter in an egrep regex?	\item If it's outside a character class, prefix it with \ttt{\textbackslash}<div>\item If it's inside, you can't escape it, though this is specific to egrep.</div>
How are the subexpressions alternated by a \ttt{|} in an egrep regex delimited?	\item By the end of the string or by enclosing parentheses.&nbsp;
What's a network coordinate system?	\item An assignation of coordinates to servers such that the distance between pairs of coordinates reflects the latency (or some other useful metric) between each pair of servers
What's the standard way of identifying the same client over a sequence of interactions?	\item By giving the client a cookie during the first interaction&nbsp;
What's NAT?	"\item Network address translation, usually used to ""hide"" many client IP addresses behind a single gateway address"
How can a distributed system localize a client's request to the nearest server?	\item Ask the client to execute a network coordinate algorithm to find its `distance' from a set of `landmark' servers<div>\item then use the reported information to calculate the client's coordinates and `nearest' server.</div><div>\item and have the DNS cache its IP for some period (shorter = finer control)</div>
What's DNS?	\item Domain name system<div>\item Associates domain names with various information, most importantly IP addresses</div>
Sketch how domain name resolution works.	\item Each network host has a hints file of addresses of root name servers.<div>\item A name query is first made to a root name server; it will return the address of another name server which deals with the appropriate top-level domain</div><div>\item A name query is then made to that name server; it will return the address of another name server which deals with the appropriate second-level domain</div><div>\item etc until you get the IP address sought.&nbsp;</div>
How is the load on high-level name servers disappated?	\item Through the use of caching name servers, which will cache fetched DNS records for a period of time.
What are the four layers of the IP suite?	\item Application layer (DNS, HTTP, etc)<div>\item Transport layer (TCP, UDP, etc)</div><div>\item Internet layer (IPv4, IPv6, etc)</div><div>\item Link layer (ARP, NDP, etc)</div>
What's the purpose of TCP?	\item To provide reliable, ordered, error-checked delivery of a stream of octets.
What's the purpose of UDP?	\item To send simple messages (datagrams) quickly.
What is the Internet Protocol responsible for?	\item Addressing hosts and routing datagrams
What does TCP stand for?	\item Transmission Control Protocol
What does UDP stand for?	\item User Datagram Protocol
Give twelve interpretations of the idea of reliability in the context of distributed systems.	\item Fault tolerance<div>\item High availability</div><div>\item Continuous availability</div><div>\item Recoverability</div><div>\item Consistency</div><div>\item Scalability</div><div>\item Security</div><div>\item Privary</div><div>\item Correct specification</div><div>\item Correct implementation</div><div>\item Predictable performance</div><div>\item Timeliness</div>
Give eight kinds of common failure in distributed systems	\item Halting failures (process times out)<div>\item Fail-stop failures (process reports it's failed)</div><div>\item Send-omission failures</div><div>\item Receive-omission failures</div><div>\item Network failures (between specific pairs of processes)</div><div>\item Network partitioning failures</div><div>\item Timing failures</div><div>\item Byzantine failures (arbitrary failures)</div>
How is reliability of distributed systems best judged?	\item By the experience of the end user
What does ACID stand for in the context of distributed systems?	\item A set of properties that guarantee that database transactions will be processed reliably&nbsp;<div>\item Atomicity - each transaction is all or nothing<div><div>\item Consistency - any transaction will take the system from one valid state to another</div><div>\item Isolation - applying transactions concurrently will achive the same result as applying them serially</div><div>\item Durability - once a transaction is committed, it will remain so.</div></div></div>
What does BASE stand for in the context of distributed computing?	\item Basically Available Soft-state Services with Eventual consistency<div>\item ie, a highly-available first-tier with some background services to clean up consistency</div>
What is the CAP theorem?	\item That no system can simultaneously be<div>\item Consistent - all nodes see the same data at the same time</div><div>\item Available - every request recieves a response</div><div>\item Partition-tolerant - the system functions despite arbitrary message loss</div>
What's important to remember when comparing CAP and ACID in distributed systems?&nbsp;	<div>\item ACID consistency means that a transaction preserves all database rules</div>\item CAP consistency means that all nodes see the same data (single-copy consistency), which is a strict subset of ACID consistency
How does TCP open a connection?	\item Alice sends a SYN, with a segment sequence number $A$<div>\item Bob responds with a SYN-ACK, with acknowledgement number $A+1$ and sequence number $B$</div><div>\item Alice responds with an ACK with sequence number $A+1$ and acknowledgement number $B+1$.</div>
How does TCP close a connection?	\item Alice sends a FIN<div>\item Bob sends an ACK</div><div>\item Bob sends a FIN</div><div>\item Alice sends an ACK.</div><div>\item Usually compressed to a three-way handshake with a FIN/ACK.</div>
What's TCP's flow control protocol?	\item A sliding window: the reciever specifies in each segment the recieve window field, the amount of additional data it's willing to buffer.<div>\item A recieve window of zero means the sender will stop transmitting data until recieving a new window or the persist timer runs out.</div><div>\item If the persist timer runs out, the sender asks for a new recieve window.</div>
What are the phases of TCP's standard congestion avoidance algorithm?	\item Slow start (exponential increase in window size until losses occur)<div>\item Congestion avoidance (additive increase, multiplicative decrease each time losses occur)</div>
Sketch how SOAP works.	\item A remote procedure call is encoded in HTML&nbsp;and sent to the server<div>\item which decodes it, executes the call, and returns another SOAP-formatted HTML page<br /><div><br /></div></div>
What is SOAP in the context of web services?	\item Simple Object Access Protocol, an alternative to RPC
How can a connection be maintained with a device with a changing IP address?	\item By making the connection through a tunnel which maintains the illusion of a static IP
How do you calculate the area of a planar triangle?	\item $A = \| (v_2 - v_0) \times (v_1 - v_0) \|/2$
What does the body tag represent in HTML?	\item That everything contained in its element should be displayed in the browser window
What does the head element represent in HTML?	\item That its element is information about the page (like the title)
What does the title tag specify in HTML?	\item The text that should be displayed in the browser bar/tab
How is an attribute stored in a HTML tag?	"\item \ttt{&lt;p lang=""fr""&gt;} has the attribute \ttt{lang} with value \ttt{fr}"
What's the paragraph tag in HTML?	\item \ttt{&lt;p&gt;}
How do you declare text to be a heading in HTML?	\item Using \ttt{&lt;h1&gt;, &lt;h2&gt;} etc, from most important (1) to least important (6).
What's the top-level tag of a HTML document?	\item \ttt{&lt;html&gt;}
In web design, what's a CMS?	\item A content management system,&nbsp;<div>\item which usually exist to allow the user to edit components of a website efficiently&nbsp;</div>
What's structural and semantic markup in HTML?	\item Structural markup denotes how the page should be laid out<div>\item Semantic markup adds information like where emphasis should be placed in a sentance</div>
How are bold and italics indicated in HTML?	\item \ttt{&lt;b&gt;}<div>\item \ttt{&lt;i&gt;}</div>
How are superscript and subscript denoted in HTML?	\item \ttt{&lt;sup&gt;}<div>\item \ttt{&lt;sub&gt;}</div>
What's whitespace collapsing in HTML?	\item Any whitespace character in the code is treated as a space (including linebreaks!)<br /><div>\item Two or more sequential whitespace characters will be collapsed to a single space.</div>
How can you insert a linebreak in HTML?	\item \ttt{&lt;br /&gt;}
What's an empty element in HTML?	\item An opening tag which is it's own closing tag, like \ttt{&lt;br /&gt;}
How is a horizontal linebreak inserted into a HTML document?	\item \ttt{&lt;hr /&gt;}
When is a horizontal linebreak suitable in a HTML document?	\item When there's a change in the themes or topic treated in the text
What are the standard emphasis tags in HTML?	\item \ttt{&lt;strong&gt;}, usually interpreted as bold<div>\item \ttt{&lt;em&gt;}, usually interpreted as italics</div>
What's the tag for quoting a paragraph in HTML?	\item \ttt{&lt;blockquote&gt;}
What's the tag for an inline quote in HTML?	\item \ttt{&lt;q&gt;}
How can you cite a quote in HTML?	\item Using the \ttt{cite} attribute, with a URL to the source as its value&nbsp;
How can you embed an abbrivation in HTML?	"\item \ttt{&lt;abbr title=""Professor""&gt;Prof&lt;/abbr&gt;}<div>\item will usually display Professor on mouseover</div>"
What should be used for denoting acronyms in HTML5?	\item The abbr tag, as the acronym tag is deprecated
How should citations be marked up in HTML?	\item With the \ttt{&lt;cite&gt;} tag
How should a defining term (the first use of a term in the text) be marked up in HTML?	\item \ttt{&lt;dfn&gt;}
Where should the contact information for the author of a HTML page go?	\item In the \ttt{&lt;address&gt;} element
What's hCard?	\item A microformat for publishing contact details
How can you highlight newly inserted and deleted text in HTML?	\item \ttt{&lt;ins&gt;}<div>\item \ttt{&lt;del&gt;}</div>
Why shouldn't you use the \ttt{&lt;u&gt;} tag in HTML?	\item Because underlining text like that is deprecated and should be done with styles instead (like span or em)
What are the three types of list supported by HTML?	\item Ordered lists (\ttt{&lt;ol&gt;} to open, \ttt{&lt;li&gt;} for each item)<div>\item Unordered lists (\ttt{&lt;ul&gt;} to open, \ttt{&lt;li&gt;} for each item)</div><div>\item Definition lists (\ttt{&lt;dl&gt;} to open, \ttt{&lt;dt&gt;} for the term, \ttt{&lt;dd&gt;} for the definition)</div>
How are links denoted in HTML?	\item With a \ttt{&lt;a&gt;} tag<div>\item which has a \ttt{href} attribute that has the URL as its value</div>
When a URL to a folder is passed, what do browsers usually do?	\item Try to return the contents of the index.html file in that folder&nbsp;
How do you mark up an email link in HTML?	"\item \ttt{&lt;a href=""mailto:aaa@bbb.com""&gt;}"
How can you indicate a link should be opened in a new window in HTML?	"\item Use the \ttt{target=""\_blank""} attribute in the link tag."
What should come with any link that opens a page in a new window?	\item Text notifying the user the page will be opened in a new window
How can you link between points in the same HTML document?	"\item Mark the destination tag with the attribute \ttt{id=""name""}<div>\item Tag the link with \ttt{href=""\#name""}&nbsp;</div>"
How can you link to a specific tag in another page in HTML?	"\item Mark the destination with the \ttt{id=""name""} attribute<div>\item Append \ttt{\#name} to the link to the page.</div>"
Where should images in a webpage come from?	\item Places that give away/sell copyright to them, idiot.
What five guidelines should you follow when picking images for a website?	\item They should be relevant<div>\item They should convey some information</div><div>\item They should convey the right mood</div><div>\item They should be instantly recognisable</div><div>\item They should fit the colour palette</div>
What tag do you use to mark up images in HTML?	\item \ttt{&lt;img&gt;}
What are the three most common attributes of HTML's \ttt{img} tag?	\item \ttt{src}, which gives the image file's location<div>\item \ttt{alt}, which is the text to be displayed if the image can't be loaded</div><div>\item \ttt{title}, which gives the mouseover text</div>
What should go in the \ttt{alt} attribute of an image in HTML?	\item An accurate description of the image<div>\item unless the image has no information content (such as a dividing line), in which case it should be the empty string</div>
How do you indicate the size of an image in HTML?	\item Using the \ttt{height, width} attributes in the \ttt{img} tag,&nbsp;<div>\item with measurements given in pixels</div>
Why shouldn't you use the \ttt{height, width} attributes in an image tag?&nbsp;	<div>\item Because this role is being taken over by CSS</div>
What're the rules about newlines and block elements vs inline elements in HTML?	\item Block elements always start a new line<div>\item Inline elements inside a block element do not start a new line</div>
Why shouldn't you use the \ttt{align} tag in HTML?	\item Because it's been deprecated in HTML5 in favour of CSS
What are the three rules regarding adapting images for websites?	\item Use a web format (jpeg, gif or png)&nbsp;<div>\item Use the height and width the img tag specifies</div><div>\item Use the resolution you want them to be displayed at</div>
When should you use GIF vs PNG vs JPEG?	\item Use JPEG when there are many colours in the image, or when smooth gradients are important (ie photos)<div>\item Use GIF or PNG when there are few colours, or large areas with the exact same colour (ie diagrams and drawings)</div>
What's the target pixel density for most websites?	\item 72ppi
When's the SVG format appropriate?	\item Vector graphics and fairly modern browsers.
What web formats support transparency?&nbsp;	\item PNG, SVG<div>\item and only on modern browsers (post-IE6)</div>
How can you attach a caption to an image in HTML?	\item With HTML's \ttt{&lt;figure&gt;} tag<div>\item containing one or more \ttt{&lt;img&gt;}s and a \ttt{&lt;figcaption&gt;}</div>
How do older browsers treat HTML5 tags?	\item They ignore them and simply display the content.
What are the three fundamental tags of a HTML table?&nbsp;	\item \ttt{&lt;table&gt;}, used to create a table<div>\item \ttt{&lt;tr&gt;}, used to start a row</div><div>\item \ttt{&lt;td&gt;}, used to add a cell (a \emph{d}ata) to the row</div>
How do you add a heading to a row or column of a HTML table?	"\item \ttt{&lt;th scope=""col""&gt;} tag<div>\item \ttt{&lt;th scope=""row""&gt;} tag</div>"
How can you get a cell to span more than one column in a HTML table?	"\item \ttt{&lt;td colspan=""2""&gt;}"
How can you get a cell to span more than one row in a HTML table?	"\item \ttt{&lt;td rowspan=""2""&gt;}"
How can you distinguish the first and last rows of a table in HTML?	\item Using the \ttt{&lt;thead&gt;}, \ttt{&lt;tbody&gt;} and \ttt{&lt;tfoot&gt;} tags around the relevent rows
Why shouldn't you specify the width or spacing of a table in HTML?	\item Because these attributes have been replaed by CSS
Why shouldn't you specify the border or background of a table in HTML?	\item Because these roles have been taken over by CSS
What are generally the elements of HTML4 that have become deprecated?	\item The presentational ones - alignment, font appearance, strikethrough, etc
What's XHTML?	\item HTML reformulated to follow the rules of XML (every open tag must have a closing tag, nesting is correct, etc)<br />
How can you declare which version of HTML your page uses?	\item With a \ttt{&lt;!DOCTYPE&gt;} tag at the top of the page.&nbsp;<br />
How can you declare that your page uses HTML5?	\item With a \ttt{&lt;!DOCTYPE html&gt;} tag at the top of the page.
How are comments denoted in HTML?	\item \ttt{&lt;!-- comment --&gt;}
Where can the \ttt{id} attribute be used in HTML?	\item In any tag. It's a global attribute.
How can you reference a set of elements in a HTML page?&nbsp;	\item Using the \ttt{class} attribute, whose value is a space-separated list of identifiers of classes the tag belongs to
Where can HTML's \ttt{class} attribute be used?	\item In any tag. It's a global attribute.
What are block elements in HTML?	\item Elements that will always appear to start on a new line
How can you group HTML elements together in a single block-level box?	\item Using the \ttt{&lt;div&gt;} tag.
How can you group a set of inline HTML elements or text into one inline element?	\item Using the \ttt{&lt;span&gt;} tag
How would you embed something like a Google map into a HTML page?	\item Using an \ttt{&lt;iframe&gt;}
What are the attributes usually associated with a HTML \ttt{iframe}?	\item \ttt{src}, which contains the URL of the page to display in the iframe<div>\item \ttt{height} and \ttt{width}, which gives the iframe's size.</div>
How can you display or avoid displaying scrollbars on a HTML \ttt{iframe}?	"\item With the HTML5 \ttt{seamless} attribute, which suppresses the scrollbars.<div>\item It doesn't need a value, but often people will use \ttt{seamless=""seamless""} for consistency's sake.</div>"
What attributes of an \ttt{iframe} have been deprecated in HTML5?	\item \ttt{scrolling} and \ttt{frameborder}
Where do you usually keep information about a HTML page that'd only be relevent to machines?	\item A \ttt{&lt;meta&gt;} tag in the \ttt{head}<div>\item which carries any data in its attributes.</div>
What six values of \ttt{name} often appear in a \ttt{meta} tag?	"\item \ttt{description}, a 155-character description of the page. Often displayed in search engine results.<div>\item \ttt{keywords}, a comma-separated list of keywords that appear on the page. Largely deprecated nowadays.</div><div>\item \ttt{robots} with \ttt{content=""noindex""} or \ttt{content=""nofollow""}</div><div>\item \ttt{author}</div><div>\item \ttt{pragma} with \ttt{content=""no-cache""}&nbsp;</div><div>\item \ttt{expires} with the expiration date in \ttt{content}</div>"
How are escape characters represented in HTML?	\item With an \ttt{\&amp;} followed by the escape code
What're the preferred alternatives to Flash nowadays?	\item Javascript&nbsp;<div>\item HTML5 \ttt{&lt;video&gt;} and \ttt{&lt;audio&gt;} tags.</div>
What formats are supported by different browsers for HTML5 \ttt{video} tags?	\item Safari and IE: h264<div>\item Opera, Firefox, Chrome: WebM and h264</div>
In what four ways can you control the loading and playing of a HTML video?	<div>\item The \ttt{src} attribute gives the path to the video</div>\item The \ttt{preload} attribute can be \ttt{none, auto, metadata}<div>\item The \ttt{autoplay} attribute</div><div>\item The \ttt{loop} attribute</div>
In what four ways can you specify the appearance of a HTML5 video?	\item The \ttt{poster} attribute gives the image to display while the video is loading<div>\item The \ttt{height, width} attributes define the size of the player</div><div>\item The \ttt{controls} attribute indicates whether the browser should supply its own controls</div>
How can you indicate a HTML5 video is available in multiple formats?	\item By omitting the \ttt{src} attribute in the \ttt{video} tag in favour of multiple \ttt{&lt;source&gt;} tags inside the video environment.
What two attributes often appear in a HTML5 video \ttt{source} tag?	"\item \ttt{src}, specifying the path to the file<div>\item \ttt{type}, indicating the format of the video. The codec is listed in its value after a semicolon using&nbsp;\ttt{codecs}.</div><div>\item Example: \ttt{type='video/webm;codecs=""vp8, vorbis""'}</div>"
What's the preferred method for embedding audio in HTML?	\item \ttt{&lt;audio&gt;}
What's a railroad diagram?	\item A syntax diagram, a way to illustrate the grammar of a language
How can you insert comments in JS?	\item \ttt{//}<div>\item Don't use \ttt{/* */} because \ttt{*/} can occur in JS code</div>
What are JS's number types?	\item There is only one: the double.
How can you check whether an arithmetic operation has failed in JS?	\item \ttt{isNaN(number)}<div>\item \ttt{NaN} is not equal to anything (even itself!) so dont try to use equality</div>
What're JS's textual types?	\item There's only one: strings.<div>\item Characters are just single-element strings.</div>
Are strings mutable in JS?	\item No, they're immutable
How does a railroad diagram denote whether whitespace can be inserted between its tokens?	\item A vertical single bar on the LH and RH terminals.<div>\item A vertical double bar forbids extra whitespace</div>
What distinguishes JS blocks from blocks in most other languages?	\item JS blocks do not create a new scope
Where should variables be defined in JS functions?	\item At the top of the function, as blocks don't create new scope.
What are the six `falsy' values in JS?	\item false<div>\item null</div><div>\item undefined</div><div>\item Empty string&nbsp;</div><div>\item 0</div><div>\item NaN</div>
"What are the ""truthy"" values of JS?"	\item All but the six falsey values.
What conditional statements are available in JS?	\item if<div>\item switch</div>
What are the three looping statements available in JS?	\item while<div>\item for</div><div>\item do</div>
What disruptive statements are available in JS?	\item break<div>\item return</div><div>\item throw</div>
What decides whether a JS \ttt{if} statement will be activated?	\item Whether its expression evaluates to a truthy value or a falsy value
What forms of \ttt{for} are used in JS?	\item \ttt{for (initialization expression; condition expression; increment expression)}<div>\item \ttt{for (variable name in object expression)}</div>
What does the \ttt{for in} statement in JS do?	\item Iterates over the property names (keys) of an object.
What's the equality operator in JS?	\item \ttt{===}
How can you write an in-line if expression in JS?	\item \ttt{? conditional : option : alternative}
What's the not operator in Javascript?	\item \ttt{!a}
How do you define a function in JS?	\item \ttt{function [name] parameters body}
What are the six types in JS?	\item Numbers<div>\item Strings</div><div>\item Booleans</div><div>\item null</div><div>\item undefined</div><div>\item Object</div>
What's an object in JS?	\item A container of properties (name value pairs)
What values can object properties in JS take on?	\item Anything but \ttt{undefined}
What's an object literal in JS?	"\item \ttt{\{ ""propertyName1"" : value1, ""propertyName2"" : value2 \}}<div>\item Don't need the quotation marks if the string is a legal JS name</div>"
How can you access the values of the properties of a JS object?	"\item \ttt{objectName.propertyName}<div>\item \ttt{objectName[""propertyName""]}, if the name isn't a legal JS name</div>"
What happens if you try to retrieve a non-existant property of an object in JS?	\item It returns \ttt{undefined}
How can you guard against \ttt{undefined} being returned when you access a property in JS?	\item \ttt{var variableName = objectName.propertyName || defaultValue }
What happens if you try to retrieve a property's value from an undefined object in JS?	\item You get a \ttt{TypeError} exception.
How can you guard against errors thrown from accessing the properties on undefined objects in JS?	\item \ttt{undefinedVariable \&amp;\&amp; undefinedVariable.propertyName} will return \ttt{undefined} rather than throwing a \ttt{TypeError}
What happens in JS when you assign to a property that doesn't exist on an object?	\item The object is augmented with that property.
How are objects passed around in JS?	\item Always by reference.
How do prototypes interact with retrieval in JS?	\item Through delegation. If a property can't be found on an object, it'll look for it in the object's prototype.<div>\item Undefined will be returned if a property can't be found anywhere in the retrieval chain.</div>
How do you set the prototype of an object in JS?	\item \ttt{objectName.prototype = prototypeName}
How can you set the prototype of an object at creation in JS?	\item Either use an object literal and set it there<div>\item Or create a function that takes an object returns an empty object with the argument as its prototype.</div>
How can you test whether a specific object has a property in JS?	"\item \ttt{objectName.hasOwnProperty(""propertyName"")}<div>\item Ignores the prototype chain.</div>"
How can you test whether some object in a prototype chain has a property in JS?	\item Check whether \ttt{typeof objectName.propertyName} is undefined
What order will the properties of an object be iterated through by the \ttt{for in} JS statement?	\item The order's not defined.
What should you be careful to do when iterating through the data fields of an object with JS's \ttt{for in}?	\item Exclude the properties fetched from the object's prototype<div>\item Exclude properties of the type \ttt{function}</div>
How can you iterate over the properties of a JS object in a particular order?	\item By creating an array of the property names and iterating over that
How can you remove a property from an JS object?	\item \ttt{delete object\_name.property\_name}<br />\item This will not touch the prototype.
How can you suppress many of the problems with global variables in JS?	\item Create a single global \ttt{MYAPP} object in which all the top-level variables are stored.&nbsp;
What's the hidden prototype of functions in JS?	\item \ttt{Function.prototype}
What's the hidden prototype for objects in JS?	\item \ttt{Object.prototype}
What're the hidden properties of a function object in JS?	\item A link to \ttt{Function.prototype}<div>\item A link to its closure</div><div>\item A link to the code that implements the function</div>
What's a function literal in JS?	\item \ttt{function [name] (args) body}
What are the four invocation patterns in JS?	\item method invocation<div>\item function invocation</div><div>\item constructor invocation</div><div>\item apply invocation</div>
What's the invocation operator in JS? What does it do?	\item An \ttt{()} (possibly non-empty) following a function name.<div>\item It tries to assign each expression in it to one of the parameters of the function</div>
What happens if JS's invocation operator is supplied with fewer expressions than the function has parameters?	\item The trailing parameters will be left \ttt{undefined}
What happens if JS's invocation operator is supplied with more expressions than the function has parameters?	\item The trailing expressions will be discarded.
What's the method invocation pattern in JS?	\item If a function is stored in an object<div>\item then calling that function through a refinement of the object</div><div>\item will set the \ttt{this} variable in the function to be the object through which it was called.</div><div>\item Example: \ttt{object\_name.function\_name()}</div>
What's a refinement in JS?	"\item A \ttt{.} dot expression or \ttt{[""subscript""]} expression that retrieves the value of some property of an object."
In the method invocation pattern in JS, when is \ttt{this} bound to the containing object?	\item At invocation time.
What's the function invocation pattern in JS?	\item \ttt{Example: function\_name()}<div>\item Sets \ttt{this} to be the global object.</div><div>\item which was a bad idea on the designers' part.</div>
What's the \ttt{that} idiom in JS?	\item Because \ttt{this} is set to the global object in the function invocation pattern, a method can't employ an inner function to do work on the methods' \ttt{this}.<div>\item The work around is to define \ttt{var that = this;} in the method.</div><div>\item The inner function will then have access to \ttt{that} through it's closure.</div>
What's the constructor invocation pattern in JS?	<div>\item Example: \ttt{var variable\_name = new Function();}</div>\item If a function is called with \ttt{new}, a new object will be created with a hidden link to the value of the function's protoype member.<div>\item and \ttt{this} in the function will be bound to the new object.</div><div>\item This is generally a shitfest. Avoid it.</div>
What distinguishes functions intended for constructor invocation in JS?&nbsp;	\item A capitalized name.<div>\item A constructor function called without \ttt{new} can be a shitfest, so this is important.</div>
What's the apply invocation pattern in JS?	\item Example: \ttt{function\_name.apply(name\_of\_this, array\_of\_arguments)}<div>\item Apply invokes the function with a specified value of \ttt{this} and the specified arguments.</div>
How can you retrieve arguments that overflowed the number of parameters a function has in JS?	\item Using the \ttt{arugments} variable, which returns an array of all the arguments that were supplied.
What should you be careful about when using JS's \ttt{arguments} variable?	\item It's not actually an array. It has a length property, but none of the other methods you'd expect of an array.
What defines the return of a function in JS?	\item If there's a \ttt{return} statement, it'll return the value of the statement's expression.<div>\item Otherwise, it'll return undefined</div><div>\item unless it was invoked with \ttt{new} in which case it'll return \ttt{this}</div>
How do you throw an exception in JS?	"\item \ttt{throw \{ name: ""ErrorName"", message: ""ErrorMessage \} }<div>\item More properties can be added.</div>"
How does exception catching work in JS?	\item Any exception thrown in a \ttt{try} block will be dealt with in \ttt{catch (e)}'s block.&nbsp;<div>\item If there are a variety of errors that need handling, the catch code should inspect \ttt{e.name}</div>
When adding methods to basic JS types, what should be done?	\item Add it conditionally: make the assignment only if some method with that name doesn't already exist on the object.
Does JS have tail call optimization?	\item Nope.
What variables won't be captured by a function's closure in JS?	\item The containing function's \ttt{this} and \ttt{arguments}
What's the module pattern in JS?	\item Creating a function which holds private variables and private functions<div>\item which then returns the functions it wishes to be public (or stores them in a public place).</div>
What's cascading in JS?	\item Having state-modifying methods return \ttt{this} so other state-modifying methods can be called on the same object.
What's the \ttt{create} method Crockford recommends to encapsulate \ttt{new}?	\item Object.create = function (obj) \{<div>\item var F = function () \{\};</div><div>\item F.prototype = obj;</div><div>\item return new F();</div><div>\item \}</div>
What's the method \ttt{method} Crockford recommends defining?&nbsp;	\item Function.prototype.method = function (name, func) \{<div>\item this.prototype[name] = func;</div><div>\item return this;</div><div>\item \};</div>
What's the \ttt{inherits} method Crockford recommends to help encapsulate \ttt{new}?	\item Function.method('inherits', function (Parent) \{<div>\item this.prototype = new Parent();</div><div>\item return this;</div><div>\item \})</div>
What happens if you forget a \ttt{new} statement when calling a constructor function in JS?	\item \ttt{this} won't be bound to a new object, but instead to the global object.<div>\item so all your shiny new properties will be clobbering the global namespace.</div>
What's the best way to avoid issues with constructors in JS?	\item Don't use constructors.
What's the best way to deal with constructors with large parameter lists in JS?	\item Have them instead accept a single object with the parameters as its properties<div>\item and then loop over the properties in the argument and copy them into a similar default parameters object (which allows some arguments to be omitted from the initializing object)</div>
When does a name need to be specified in quotation marks in JS?	\item When it's not a legal JS name.
How do you emulate private variables in JS?	\item Using the module pattern.
How do you construct a module using JS?	\item Make a function that does the following:<div>\item It creates a new object (using an object literal or \ttt{new})</div><div>\item It defines what will be the private variables and functions of the object as variables of an object called \ttt{my}</div><div>\item It augments the new object with its public variables and functions</div><div>\item It returns the new object.&nbsp;</div>
How can you emulate an inheritance chain in JS's module pattern?	\item Have each constructor take a \ttt{spec} object, containing the specifications for constructing the object<div>\item and an optional \ttt{my} object, which will be instantiated to a blank object if it isn't passed.</div><div>\item Then \ttt{my} can be used to pass information among constructors.</div>
How can you decompose the functionality of an object in JS?	\item Use parts: a part is a function that takes an object and attaches methods to it whose state is stored in a \ttt{my} object
What's an array literal in JS?	\item \ttt{[item1, item2]}
What's important to remember about JS arrays?	\item They're not regular contiguous-memory arrays<div>\item instead the subscripts are converted to strings and used as properties</div>
What's the hidden prototype of JS arrays?	\item \ttt{Array.prototype}
What's the length property of JS arrays?	\item The largest integer property name in the array, plus one.<div>\item It's not an upper bound.</div>
How can you index into an element in a JS array?	\item \ttt{array\_name[3]}<div>\item The \ttt{[]} operator converts its argument to a string using the arguments' \ttt{toString} and retrieves the value at that propety&nbsp;</div>
What happens if you change the value of a JS array's \ttt{length}?	\item Increasing it does nothing.<div>\item Decreasing it deletes all properties with a equal or larger index than the new length.</div>
How does the JS array method \ttt{splice} work?	\item \ttt{array\_name.splice(index, delete\_count, new\_element1, new\_element2)}<div>\item will delete the specified number of elements at the given index, decrementing any higher entries</div><div>\item then insert the specified new elements at the same location</div>
What's important to remember about JS's \ttt{typeof} operator?	\item It can't recognise arrays or \ttt{null} - it'll report them as an object.
What five things do you need to check when testing whether an object is a JS array?	"\item Verify it's truthy<div>\item Verify \ttt{typeof obj === ""object""}</div><div>\item Verify \ttt{typeof obj.length === ""number""}</div><div>\item Verify \ttt{typeof obj.splice === ""function""}</div><div>\item Verify \ttt{!(obj.propertyIsEnumerable(""length""))}</div>"
How is a regular expression constructed in JS?	\item Either with a regex literal, enclosed in \ttt{/.. ../}<div>\item Or with the \ttt{RegExp} constructor, which takes a string.</div>
What should you be careful of with regexp literals in JS?	\item The regex objects they produce all share the same instance!
What are the five properties of a RegExp object in JS?	\item \ttt{global}, which is true if the \ttt{g} flag was used<div>\item \ttt{ignoreCase}, which is true if the \ttt{i} flag was used</div><div>\item \ttt{lastIndex}, which indicates the index to start the next \ttt{exec} match at<br /></div><div>\item \ttt{multiline}, which is true if the \ttt{m} flag was used</div><div>\item \ttt{source}, which is the source text of the regexp.</div>
How are flags used on JS regexp literals?	\item Append them to a regexp literal<div>\item or provide them as a second argument to a RegExp constructor.</div>
What flags are there for JS regexps?	\item \ttt{g} is the global flag, which makes the regexp match multiple times, storing the last match in \ttt{lastIndex}<div>\item \ttt{i} is the case sensitivity flag</div><div>\item \ttt{m} is the multiline flag</div>
What ten methods are available on JS arrays?	\item .concat(item...) (with individual items or another array)<div>\item .join(separator) (convert to string, interleaving with the separator)</div><div>\item .pop() (removes \&amp; returns last element)</div><div>\item .push(item... ) (pushes at back)</div><div>\item .reverse() (reverses array, returns it)</div><div>\item .shift() (removes first element and returns it)</div><div>\item .slice(start, end) (copies portion of array)</div><div>\item .sort(comparefn) (sorts in place)</div><div>\item .splice(start, deleteCount, item...) (deletes and/or inserts at index)</div><div>\item .unshift(item...) (pushes at front)</div>
What's important to remember about the JS array's \ttt{sort} function?	\item By default, it converts to a string and then sorts lexicographically. Even on an array of numbers.
What four methods are available on JS numbers?	\item \ttt{.toExponential(numberOfSF)} converts it to a string<div>\item \ttt{.toFixed(numberOfDP)} converts it to a string</div><div>\item \ttt{.toPrecision(numberOfSF)} converts it to a string</div><div>\item \ttt{.toString(radix)} converts it to a string in the given base</div>
What method is called by \ttt{String(obj)} in JS?	\item The \ttt{toString} method, if \ttt{obj} has one.
What two methods are available on JS regexes?	\item \ttt{.exec(string)} searches for the regex in the string and returns an array of the results (without \ttt{g} flag), or sets \ttt{lastIndex} to the the index of the next match (with \ttt{g} flag.<div>\item \ttt{.test(string)} is much faster than \ttt{.exec}, but only returns \ttt{true} or \ttt{false}. Don't use \ttt{g} with this.&nbsp;</div>
What methods are available on JS strings?	\item do this later, there're a lot of them :(
What brace style should be used with JS?	\item K\&amp;R opening-brace-on-same-line-as-control-statement<div>\item because Allman style (ie, C\# style) can break return statements.</div>
Why is Allman style bracing a problem in JS?	\item Because if the brace is on the next line from say a return statement, JS will automatically insert a semicolon at the end of the \ttt{return}.<div>\item Good lord that's stupid.</div>
What should you be careful with when using switch statements in JS?	\item Break at the end of each case, because falling through the options produces some hard-to-spot bugs.
What's the name of the global object in JS?	\item In browsers, it's usually \ttt{window}
What's an implied global in JS?	\item Using a variable without declaring it:&nbsp;\ttt{foo = value}<div>\item This'll create a \ttt{foo} object in the global namespace.</div>
How do you test for \ttt{null} in JS?	\item \ttt{variable\_name === null}
How can you test whether something is an object in JS?	"\item Verify it's truthy (excluding \ttt{null})<div>\item Verify \ttt{typeof variable\_name === ""object""}</div>"
What's a common issue with JS's \ttt{+} operator?	\item It can both sum and concatenate.<div>\item So make sure that the arguments are both numbers if you want to sum them</div><div>\item otherwise it'll convert them both to strings and concatenate them</div>
What's a common issue with JS's \ttt{parseInt} function?	\item If you don't supply a radix as the second argument, it'll try and deduce it from the string<div>\item returning a value in base 8 if the number starts with a zero.</div>
What're the issues with JS's \ttt{eval} operator?	\item It's incredibly tricky and hard to understand. Don't use it.
How do you establish a Vagrantfile?	\item vagrant init
How do you add a new box to Vagrant?	\item vagrant box add boxName boxURL
How do you configure a Vagrantfile to use a specific box?	"\item Add the line<div>\item \ttt{config.vm.box = ""boxName""}</div><div>\item to the vagrantfile</div>"
How do you boot a Vagrant instance?	\item \ttt{vagrant up}
In what three ways can you tear down a Vagrant instance?	\item \ttt{vagrant destroy} removes all traces of the machine from your hard disk<div>\item \ttt{vagrant suspend} will save the current state and stop it</div><div>\item \ttt{vagrant halt} will gracefully shut it down</div>
What folder is shared by default by Vagrant?	\item The folder containing the vagrantfile is shared as \ttt{/vagrant}
What's a shebang?	\item \ttt{\#!}, followed by the name of the interpreter to load the script into.<div>\item Example: \ttt{\#!/bin/sh} loads it into the Bourne shell.</div>
What's Unix's \ttt{ln} command?	\item A command used to create links.
What're the most common switches for Unix's \ttt{ln}?	\item \ttt{-f} removes existing destination files<div>\item \ttt{-s} creates symbolic links rather than hard links.</div>
How do you provision a Vagrant instance with auxilliary programs?	"\item Add to the Vagrantfile the line<div>\item \ttt{config.vm.provision :shell, :path =&gt; ""scriptName.sh""}</div><div>\item where the script is in the same directory and details what shell commands to run.</div>"
How do you re-provision a Vagrant machine?	\item \ttt{vagrant reload --provision}
What's the smallest free number problem?	\item Find the smallest natural number not in a finite set \ttt{X}
What's the trick to solving the smallest free number problem?	\item At least one number in $\{0, 1, .., |X|\}$ must not be in $X$
What are the two main options when seeking a $O(n)$ algorithm for processing a list of $n$ elements?	\item Either $n$ operations each taking (amortized) constant time.<div>\item Or a recursive process where each of the $k$ subproblems is of size at most $n/k$, and the processing takes $o(n)$ time.</div>
What's the surpasser count of an array element?	\item The number of elements to the right which are larger than the element.
What's the optimal runtime for computing the maximum surpasser count of an array?	\item $O(n \lg n)$
What's the optimal runtime for solving the minimum free number problem?	\item $O(n)$
What's a good heuristic for identifying whether a divide \&amp; conquer algorithm will work for a problem?	\item Look at the information present in the solutions to the subproblems. Is there enough there to compute a solution to the whole problem?<div>\item If not, is there a more general problem where it is?</div>
What does an $O(n \lg n)$ runtime suggest about how an algorithm works?&nbsp;	\item Divide and conquer, with $k$ subproblems of size $1/k$ and a linear amount of work at each step.<div>\item Probably some sorting too.</div>
What does SQL's notion of a table correspond to in the relational model?	\item a relation
What does SQL's notion of a row correspond to in the relational model?	\item a tuple
What does SQL's notion of a column correspond to in the relational model?	\item an attribute
What's another name for a relational type?	\item a domain
What's a relational type?	\item A named, finite pool from which values can be drawn
What's a candidate key in relational theory?	\item A set of attributes which will uniquely identify any tuple in a *relvar*.<br /><div>\item and such that no subset has the uniqueness property</div>
What's a primary key in relational theory?	\item A candidate key that's been singled out for special treatment.<div>\item The distinction is mainly syntactic; the theory doesn't care much for primary vs candidate keys.</div>
What's a foreign key in relational theory?	\item A set of attributes in one relvar that're required to match the values of some candidate key in the same or another relvar.
What's an integrity constraint in relational theory?	\item A boolean expression which must evaluate to true on every tuple in a relvar
What are the two generic integrity constraints that apply to every relational database?	\item Entity integrity: primary key attributes can't be null.<div>\item Referential integrity: there can't be unmatched foreign key values.</div>
What's a null in relational theory?	\item A marker representing an unknown value.<div>\item It's not a value itself!</div>
What are the eight original operators of relational theory?	\item Restrict<div>\item Project</div><div>\item Product</div><div>\item Intersect</div><div>\item Union</div><div>\item Difference</div><div>\item Join</div><div>\item Divide</div>
What's the restrict operator in relational theory?	\item Returns a relation containing all tuples from a specified relation that satisfy a specified condition.
What's the project operator in relational theory?	\item Returns a relation containing all tuples that remain in a specified relation after all but specified attributes have been removed.
What's the product operator in relational theory?	\item Returns a relation containing all possible tuples that are a combination of two tuples, one from each of two specified relations.
What's the intersect operator in relational theory?	\item Returns a relation containing all tuples that appear in both of two specified relations.
What's the union operator in relational theory?	\item Returns a relation containing all tuples that appear in either or both of two specified relations.
What's the difference operator in relational theory?	\item Returns a relation containing all tuples that appear in the first but not the second of two specified relations.
What's the join operator in relational theory?	\item Returns a relation containing all possible tuples that are a combination of two tuples, one from each of two specified relations, such that the two tuples contributing to any given result tuple have a common value for the common attributes of the two relations.<div>\item (and the common value appears just once, not twice, in the result tuple)</div>
What's the divide operator in relational theory?	\item Takes two relations, one binary and one unary, and returns a relation consisting of all values of one attribute of the binary relation that match (in the other attribute) any value in the unary relation.
What's the difference between relational algebra and relational calculus?	\item Relational algebra provides a procedural way to describe database queries<div>\item Relational calculus provides a declarative way to describe database queries.</div><div>\item They're logically equivalent though: a query described in one can be translated to the other.</div>
What's a data model in relational theory?	\item First sense: The abstract, self-contained, logical definition of the data structures, data operators, etc that make up the abstract machine with which users interact. The interface.&nbsp;<div>\item Second sense: a model of the persistant data of some system. A database design.</div>
What's data independence in relational theory?	\item It means that the way the data is stored and accessed can be changed without having to make changes to the way the data is percieved by the user.
What's a relation in relational theory?	\item A heading: a set of attributes<div>\item A body: a set of tuples that conform to the heading</div>
What's an attribute in relational theory?	\item An attribute-name:type-name pair.
What's the degree of a relation in relational theory?	\item The number of attributes in the heading.
What's the cardinality of a relation in relational theory?	\item The number of tuples in the body.
What're two important implications of the definitions of a head and a body of a relation in relational theory?	\item The body is a *set* of tuples.&nbsp;<div>\item So no duplicates.</div><div>\item And they're unordered.</div>
What's first normal form in relational theory?	\item Every tuple in a relation contains a single value corresponding to each attribute.<div>\item Each value is atomic with respect to the DBMS.</div>
What're base and derived relations in relational theory?	\item Base relations are defined ex nihilo.<div>\item Derived relations are derived from base relations through a combination of relational operators.</div>
What's a relvar in relational theory?	\item A relational variable, which is to relations (relational values) as an \ttt{int i} is to an integer value.
When can values be tested for equality in relational theory?	\item When they have the same type.
What's a DCO in relational theory?	\item A domain check override. It says to ignore the types of values when performing an operation.
How are DCOs implemented in most relational database systems?	\item They aren't. They'll generally be willing to compare values from across types.
What's a selector operator in relational theory?	\item An operator associated with every type, which allows us to retrieve an arbitrary value of the type in question.&nbsp;<div>\item Ex: \ttt{TYPE\_NAME('VALUE')}</div>
What's coercion in relational theory?	\item An implicit type conversion.
What's a \ttt{THE\_} operator in relational theory?	\item The operator defined on every type which converts a given value of the type to the form used to represent it physically.<div>\item ie \ttt{THE\_CHAR}</div>
What's atomicity with respect to relational theory?	\item A value is atomic if it can't be decomposed into smaller pieces by the DBMS.
What's an RVA in relational theory?	\item A relation-valued attribute. ie, value which is also a relation.
What's a tuple in relational theory?	\item A set of attribute:value pairs.
When are two tuples equal in relational theory?	\item When their headings are equal and for each attribute in the heading, the values in each tuple are equal.
How is the primary key of a relational database usually depicted pictorially?	\item By double-underlining the appropriate attribute.
What are the two variations of \ttt{SELECT} in SQL?	\item \ttt{SELECT DISTINCT} returns only distinct tuples.&nbsp;<div>\item \ttt{SELECT} aka \ttt{SELECT ALL} returns all tuples.&nbsp;</div>
What're the advantages and issues of preferring \ttt{SELECT DISTINCT} over \ttt{SELECT} in SQL?	\item \ttt{SELECT DISTINCT} is closer to the relational theory and makes operations a lot more predictable.<div>\item but it's also not the default and can be much slower.</div>
What's the main advantage of prohibiting duplicate tuples in relational databases?	\item It clarifies the result of queries: there are many queries that, without this restriction, could plausibly produce different multiplicities of a tuple<div>\item and so allows much more effective query optimization.</div>
What's 3VL in relational theory?	\item Three-valued logic: there is TRUE, FALSE and NULL/UNKNOWN
What's the main advantage of disallowing nulls in a database?	\item Because SQL queries only return tuples which cause the query to evaluate to TRUE, there are many queries whose results can change under obvious optimizations.<div>\item ex: \ttt{SELECT .. WHERE P.CITY = P.CITY} when \ttt{P.CITY} is always null.</div>
What are the relations of degree zero?	\item The empty relation<div>\item The relation containing the empty tuple.</div>
What's \ttt{TABLE\_DUM} in relational theory?	\item The zero-degree empty table.<br />
What's \ttt{TABLE\_DEE} in relational theory?	\item The zero-degree table containing only the empty tuple.
What's the logical value of \ttt{TABLE\_DUM} in relational theory?	\item \ttt{FALSE}
What's the logical value of \ttt{TABLE\_DEE} in relational theory?	\item \ttt{TRUE}
Why is the distinction between relvars and relations important in relational theory?	\item Relations are immutable, relvars aren't!
What's the idea underlying foreign keys in relational theory?	\item They're not fundamental; they're just shorthand for certain integrity constraints that are commonly required in practice.
What's another name for a virtual relvar in relational theory?	\item A view.
What's a virtual relvar in relational theory?	\item A relvar whose value is the result of evaluating a relational expression.
What's a materialized view in database theory?	\item A query evaluated at a fixed time, saved, and possibly refreshed at periodic intervals.<div>\item Not, in fact, a view.<br /><div>\item Aka a `snapshot'.</div></div>
What's another name for the intension of a relvar?	<div>\item The relvar predicate</div>
What's the relvar predicate?	\item The predicate which instantiates true propositions for exactly the tuples in the relvar.
What's the extension of a relvar predicate or intension?	\item The body of the value of that relvar at a given point in time.
What's the intension of a relvar?	\item The predicate that describes how the relation should be interpreted.<div>\item ie, \ttt{Supplier SNO has name SNAME and is in city CITY}</div>
What's the difference between a predicate and a proposition?	\item A proposition is an unconditional predicate
What's the logic interpretation of relational databases?	\item Tuples are axioms (true propositions)<div>\item Queries are proofs, deriving new truths from given ones.</div>
How do you implement the relational restrict operator in SQL?	\item \ttt{SELECT S.*}<div>\item \ttt{FROM S}</div><div>\item \ttt{WHERE S.CITY = 'Paris'}</div>
How do you implement the project relational operator in SQL?	\item \ttt{SELECT DISTINCT S.SNAME, S.CITY}<div>\item \ttt{FROM S}</div>
How do you implement the relational join operator in SQL?	\item \ttt{SELECT *}<br /><div>\item \ttt{FROM P NATURAL JOIN S}</div><div>\item Not implemented in all SQL products, but is in the standard.</div>
What's the relational semijoin operator?	\item Join \ttt{r} and \ttt{s}, then project the result back onto the attributes of \ttt{r}.
How do you implement the relational semijoin operator in SQL?	\item \ttt{SELECT DISTINCT S.*}<div>\item \ttt{FROM S, P}</div><div>\item \ttt{WHERE S.SNO = P.SNO}</div>
What's the result of the join of no relations in relational theory?	\item \ttt{JOIN\{\}} is \ttt{TABLE\_DEE}
What's the join on a single relation in relational theory?	\item \ttt{JOIN\{r\}} is just \ttt{r}
What's the relationship between \ttt{TABLE\_DEE} and \ttt{JOIN} in relational theory?	\item It's the identity element.
How do you implement the relational intersect operator in SQL?&nbsp;	\item \ttt{SELECT DISTINCT S.CITY}<div>\item \ttt{FROM S}</div><div>\item \ttt{INTERSECT}</div><div>\item \ttt{SELECT DISTINCT P.CITY}</div><div><div>\item \ttt{FROM P}</div></div>
How do you implement the relational union operator in SQL?	\item \ttt{SELECT DISTINCT S.CITY}<div>\item \ttt{FROM S}</div><div>\item \ttt{UNION DISTINCT}</div><div>\item \ttt{SELECT DISTINCT P.CITY}</div><div>\item \ttt{FROM P}</div>
What are the variants of the UNION operator available in SQL?	\item \ttt{UNION, UNION DISTINCT} suppresses duplicates<div>\item \ttt{UNION ALL} allows duplicates.</div>
How do you implement the relational difference operator in SQL?	\item \ttt{SELECT S.CITY}<div>\item \ttt{FROM S}</div><div>\item \ttt{EXCEPT}</div><div>\item \ttt{SELECT P.CITY}</div><div>\item \ttt{FROM P}</div>
Why is the relational divide operator named as it is?	\item Because if \ttt{r} and \ttt{s} have disjoint headings, then \ttt{(r TIMES s) DIVIDE s} is \ttt{r}, assuming \ttt{s} isn't empty.
What's the relational semidifference operator?	\item \ttt{r} except \ttt{r SEMIJOIN s}&nbsp;
How do you express a relational semidifference in SQL?	\item \ttt{SELECT S.*}<div>\item \ttt{FROM S}</div><div>\item \ttt{EXCEPT}</div><div>\item \ttt{SELECT S.*}<div>\item \ttt{FROM S, P}</div></div><div>\item \ttt{WHERE S.CITY = P.CITY}</div>
What's one possible set of primative relational operators?	\item Restrict, project, join, union and semidifference.
What relational operation does a SQL \ttt{SELECT-FROM-WHERE} query roughly correspond to?	\item A projection (using the SELECT clause)<div>\item of a restriction (using the WHERE clause)</div><div>\item of a Cartesian product (using the FROM clause)</div>
How do you represent a Cartesian product in SQL?	\item \ttt{SELECT *}<div>\item \ttt{FROM P, S}</div>
What's the extend relational operator?	\item \ttt{EXTEND r ADD (exp AS X)} returns a relation matching \ttt{r} except the heading is extended with a new attribute \ttt{X}, and each tuple has a new value which is \ttt{exp} evaluated on that tuple
What's the relational summarize operator?	\item \ttt{SUMMARIZE r PER ( s ) ADD (summary AS X)}<div>\item is a relation with a heading of \ttt{s} extended with \ttt{X}</div><div>\item and a body of all tuples \ttt{t} such that \ttt{t} is a tuple of \ttt{r} extended with a value for \ttt{X}</div><div>\item and this value is computed by evaluating \ttt{summary} over all tuples \ttt{r} that match \ttt{t} on \ttt{s}</div>
What are some common SQL operators that can be interpreted as relational summarize operators?&nbsp;	\item COUNT<div>\item SUM</div><div>\item AVG</div><div>\item MAX</div><div>\item AND</div><div>\item etc</div>
What's the difference between the summarize relational operator and an SQL aggregate operator?	\item Summarize returns a relation<div>\item The aggregate operator will return some kind of scalar</div>
Which relational operators deal with RVAs?	\item GROUP and UNGROUP<div>\item SQL has no facility for this unfortunately.</div>
What's another name for relational query optimization?	\item Query rewriting.
What does a relational restrict distribute over?	\item Intersect<div>\item Union</div><div>\item Difference</div><div>\item Join if the restriction is at its most complex an AND of two separate conditions, one for each of the join operands.</div>
What does relational project usually distribute over?	\item Intersect<div>\item Union</div><div>\item Join if all the joining attributes are included in the projection.</div>
Which relational operators are commutative?	\item Intersect<div>\item Union</div><div>\item Join (though it isn't in SQL!)</div>
Which relational operators are associative?	\item Intersect<div>\item Union</div><div>\item Join</div>
What are the four ways in which the building blocks of a distributed system vary?&nbsp;	\item What the communicating entities are<div>\item The communication paradigm</div><div>\item The roles \&amp; responsibilities the entities have in the architecture</div><div>\item The placement of the entities</div>
What's `placement' in the context of distributed systems?	\item How software entities are mapped onto the infrastructure.
From a systems perspective, what're the usual entities communicating in a distributed system?	<div>\item Processes running on threads in most cases.</div>\item In primative environments without a process abstraction, nodes.
From a programming perspective, what are the three kinds of common communicating entities in a distributed system?	\item Objects, which define interfaces<div>\item Components, which define interfaces and define the assumptions they make about other components</div><div>\item Web services, which are intrinsically integrated into the web (identified by a URI, described in XML or JSON, etc)</div>
What are the three types of communication paradigm for a distributed system?	\item Interprocess communication (message passing, socket programming, etc)<div>\item Remote invocation</div><div>\item Indirect communication</div>
What are three common remote invocation paradigms in distributed systems?	\item Request-reply<div>\item Remote procedure calls</div><div>\item Remote method invocation</div>
What's the request-reply communication paradigm?	\item A pattern imposed on top of a message-passing service.&nbsp;<div>\item A message is sent with an encoding of the operation for the receiver to carry out and the bytearray to use as an argument.</div><div>\item And the receiver returns any results as another bytearray.</div><div>\item Primative, efficient.</div>
What's the remote procedure call communication paradigm in distributed systems?	\item Procedures in processes on remote computers can be called as if they were procedures in the local address space.&nbsp;<div>\item Built on top of (and hides) a request-reply paradigm.</div>
What's the remote method invocation communication paradigm in distributed systems?	\item RPC adapted to distributed objects, possibly with added support for passing around object identifiers as parameters.
What are the four main challenges in handling failures in distributed systems?	\item How to detect them.<div>\item How to mask them.</div><div>\item How to tolerate them.</div><div>\item How to recover from them.</div>
What's transparancy in the context of distributed systems?	\item The concealment from the client of the separation of the components in a distributed system<div>\item so it appears as a whole rather than a collection of components.</div>
What are the eight key forms of transparancy in distributed systems?	\item Access transparancy<div>\item Location transparancy</div><div>\item Concurrency transparancy</div><div>\item Replication transparancy</div><div>\item Failure transparancy</div><div>\item Mobility transparancy</div><div>\item Performance transparancy</div><div>\item Scaling transparance</div>
What's access transparancy in the context of distributed systems?	\item Local and remote resources can be accessed using identical operatiosn
What's location transparancy in the context of distributed systems?	\item Resources can be accessed without knowledge of their physical or network location
What's concurrency transparancy in the context of distributed systems?	\item Processes can operate concurrently on shared resources without requiring knowledge of the others.
What's replication transparancy in the context of distributed systems?	\item Multiple instances of a resource can be used to improve performance without the knowledge of the client
What's failure transparancy in the context of distributed systems?	\item Clients can complete their tasks ignorant of failures in the system's components.
What's mobility transparancy in the context of distributed systems?	\item Resources and clients can move about within a system without impeding the clients' tasks.
What's performance transparancy in the context of distributed systems?	\item The load on a system doesn't affect clients.
What's scaling transparancy in the context of distributed systems?	\item The system can be vastly expanded without affecting clients.
What's network transparancy in the context of distributed systems?	\item The combination of access and location transparancy.
What're the general goals of indirect communication paradigms in distributed systems?	\item Spatial decoupling (senders don't need to know who they're sending to)<div>\item Temporal decoupling (senders and recievers don't need to exist at the same time)</div>
What are five indirect communication techniques in distributed computing?	\item Group communcation<div>\item Publish-subscribe</div><div>\item Message queues</div><div>\item Tuple spaces</div><div>\item Distributed shared memory</div>
What's the group communication technique in distributed systems?	\item Recipients join a group and recieve all messages sent to it<div>\item Senders send messages to the group identifier.</div>
What's the key use case for publish-subscribe models in distributed systems?	\item A large number of producers want to distribute information to a large number of consumers.<div>\item Publish-subscribe models provide an intermediary that allows for efficient dissemination.</div>
What's a tuple space in the context of distributed systems?	\item Processes can place arbitrary items of structured data (tuples) into a persistant tuple space.<div>\item Other processes can then read or remove the tuples by specifying patterns of interest.</div>
What's distributed shared memory in the context of distributed systems?	\item A system by which clients can read from or write to shared data structures as if they resided in their local address space.
What are the two general architectures for a distributed system?	\item Client-server<div>\item Peer to peer</div>
What are the four main placement architectures for distributed systems?	\item Mapping services to multiple servers<div>\item Caching</div><div>\item Mobile code</div><div>\item Mobile agents.</div>
What are some common architectural patterns in distributed computing to assist with segregation of services?	\item Layering<div>\item Tiers</div>
What's layering with respect to distributed systems?	\item A system is partitioned into layers, with each layer making use of the services provided by the layers below
What's the name of the lowest level layer in a distributed system?	\item The platform layers, which include the OS and hardware
What's middleware in the context of distributed systems?	\item A layer whose purpose is to mask heterogeneity in the lower layers, providing as convenient a programming model as possible.
What's tiering in the context of distributed systems?	\item A way to organize functionality within a layer and place those functions onto appropriate servers.
What's a common three-tier decomposition of a software layer in distributed systems?	\item Presentation logic tier<div>\item Application logic tier</div><div>\item and data logic tier</div>
What's a common two-tier decomposition of a software layer in distributed systems?	\item User view, controls and manipulation in the client tier<div>\item Application and data management in the server tier.</div>
What's AJAX?	\item Asynchronous Javascript and XML
What's a MIME type?	\item An internet media type, a standard identifier to indicate the type of data a file contains.
What's VNC in the context of distributed computing?	\item Virtual network computing, a way to support remote desktopping etc
What's the brokerage pattern in distributed systems?	\item A service provider<div>\item a service requester</div><div>\item and a service broker which matches providers to requesters.</div>
What's jitter in the context of distributed systems?	\item Variation in the time taken to deliver a series of messages.
How long does a L1 cache reference take?	\item approx 500ps
How long does a branch mispredict take?	\item approx 5ns
How long does a L2 cache reference take?	\item approx 7ns
How long does a mutex take to lock or unlock?	\item approx 25ns
How long does reading 1MB from memory take?	\item approx 250us
How long does a roundtrip on a local network take?	\item Approx 500us
How long does reading 1MB from a SSD take?	\item approx 1ms
How long does a hard drive disk seek take?	\item approx 10ms
How long does reading 1MB sequentially from a hard disk take?	\item approx 20ms
How long does a main memory reference take?	\item approx 100ns
How long does a random read for a SSD take?	\item approx 150us
How large is a Haswell L1 cache?	\item 64KB per core
How large is a L2 Haswell cache?	\item 256KB per core
How large is a L3 Haswell cache?	\item 2MB-8MB shared
What's frame relay switching in the context of distributed systems?	\item Transmitting small packets called frames<div>\item and switching them based on their first few bits.&nbsp;</div><div>\item Frames as a whole aren't stored by nodes but pass through them as a short stream of bits.</div>
How fast is frame relay switching?&nbsp;	\item Crossing a large network takes $&lt;100$us
What are the four types of switching used in computer networking?	\item Broadcast<div>\item Circuit swithing (ie POTS)</div><div>\item Packet switching</div><div>\item Frame switching</div>
What's POTS in the context of computer networks?	\item Plain Old Telephone System
What's ISO OSI in the context of computer networking?	\item The ISO Open Systems Interconnection protocol model<div>\item which provides a framework for the definition of protocols</div>
What're the seven layers of the ISO OSI protocol model?	\item Application<div>\item Presentation</div><div>\item Session</div><div>\item Transport</div><div>\item Network</div><div>\item Data link</div><div>\item Physical</div>
What's the application layer of the ISO OSI protocol model?&nbsp;	\item Application layer protocols are designed to the communication requirements of specific applications.<div>\item Often defines the interface to a service.</div>
What's the presentation layer of the ISO OSI protocol model?&nbsp;	\item Protocols at this level transmit data in a network representation that's independent of the representations used in individual computers.<div>\item Handles encryption.</div>
What's the session layer of the ISO OSI protocol model?&nbsp;	\item Protocols at this level deal with reliability and adaptation.<div>\item Does failure detection and automatic recovery.</div>
What's the transport layer of the ISO OSI protocol model?&nbsp;	<div>\item Protocols at this layer are concerned with reliable delivery of messages.</div>\item The lowest layer dealing with messages (rather than packets).
What's the network layer of the ISO OSI protocol model?&nbsp;	\item Protocols at this layer route packets between endpoints within a network.
What's the data link layer of the ISO OSI protocol model?&nbsp;	\item Protocols at this layer deal with transmission of packets between physically connected nodes.
What's the physical layer of the ISO OSI protocol model?&nbsp;	\item Protocols at this layer deal with transmitting binary data by analogue signalling.
What's the disadvantage of using a tall protocol stack?	\item Control has to be transferred from each layer to the next layer, which can reduce transfer rates.
What's the MTU in the context of computer networking?	\item Maximum transfer unit
What's the maximum transfer unit in the context of computer networking?	\item The maximum size of a packet that can be transmitted over the connection in question.
What's the MTU for the IP suite?	\item 64KB, though 8KB is often used.
What's a port in the context of computer networking?	\item A software-defined destination point at a host computer.<div>\item They're attached to processes to allow that process to recieve data.</div>
What's a contact port number in the context of computer networking?	\item A port number assigned to an internet service (like HTTP)<div>\item To access a service on a host, a request is sent to the service's contact port.</div>
What's the contact port for HTTP?	\item Port 80.
How is the range of ports available on a computer partitioned?	\item 0-1023: well-known ports<div>\item 1024-49151: registered ports</div><div>\item 49152-65535: dynamic ports</div>
What're well known ports in the context of computer networking?	\item Ports restricted to priviledged processes on most OSes, used for network services.
What're registered ports in the context of computer networking?	\item Port numbers registered with the IANA for specific applications<div>\item (they can be used by ordinary users too for any old thing, but it'll prevent the registered service from connecting)</div>
What are the two approaches to packet delivery that can be taken in computer networking?	\item Datagram delivery<div>\item Virtual circuit delivery</div>
What's datagram packet delivery in the context of computer networking?	\item Each packet is a `one-shot' whose delivery requires no set up and for which the network retains no information.<div>\item As such, every packet contains the routing information needed to get it to its destination or back to its origin.</div>
What's virtul circuit packet delivery in the context of computer networking?	\item A route is established from source to destination, with entries stored in the intermediates' routing tables.&nbsp;<div>\item `Dumb' packets without routing information are then transmitted over the route.</div>
What's ATM in the context of computer networking?	\item Asynchronous Transfer Mode
What's asynchronous transfer mode in the context of computer networking?	\item A protocol developed for unifying telecommunication and computer networks.<div>\item Nowadays being phased out in favour of all IP</div>
What's the biggest example of a virtual circuit packet delivery protocol?	\item ATM
What's a RIP in the context of computer networking?	\item Router information protocol, a way to update routing tables.&nbsp;
What's the vector distance routing algorithm?	\item Each node holds a table which gives, for each other node, the link to take to travel towards that node and the cost of the journey.<div>\item When a local link is modified, a node updates its own routing table then sends a copy to each of its neighbours.</div><div>\item When a table is received from a node's neighbour, if the neighbour offers a cheaper route than is currently known, update that entry in the node's own routing table.</div>
What's a high-level way of looking at vector distance routing algorithms?	\item They're a distributed implementation of the Bellman-Ford shortest-path-in-a-graph algorithm.
What are link state routing algorithms?	\item Algorithms where the only information propagated is about connectivity.<div>\item Every node builds its own map of the network, and shares with its neighbours who its own neighbours are.</div>
What's the rule of thumb as to when congestion starts to become a problem for packet-switched networks?	\item When load reaches 80\% of capacity, throughput tends to drop as a result of packet loss.&nbsp;
What's ARP in the context of computer networking?	\item Address resolution protocol<br />
What does the address resolution protocol do?	\item Converts Internet addresses to network addresses for the specific underlying network.<div>\item How it does this is dependent on the network technology being used.</div>
How does ARP work on ethernets?	\item Each host has a IP address to Ethernet address cache.<div>\item When trying to send a packet to an IP address, ARP checks the cache. If the address is there, great!</div><div>\item Otherwise, a broadcast is sent out asking that the machine which controls that IP address respond.</div><div>\item Each listening machine checks to see if it has that IP, and the one that does responds with it's ethernet address.</div><div>\item The responding machine's address is added to the cache.</div>
What two methods have been used to control the expansion of router table size in the internet?	\item Topological grouping of IP&nbsp;addresses.<div>\item Default entries</div>
How do default entries help control the size of routing tables?	\item The accuracy of routing information can be relaxed for most routers, as long as a few key routers (close to backbone links) have reasonably complete tables.<div>\item So most routers forward packets destined for unknown addresses onwards to one of these key routers, and let them sort it out.</div>
What's CIDR in the context of computer networking?	\item Classless interdomain routing.
What's the purpose of CIDR in the context of computer networking?	\item To alleviate address shortages by batching Class C addresses together to form a Class B address.
How does CIDR work in the context of computer networking?	\item It added a mask field to router tables.<div>\item The mask is a bit pattern that is used to select the portion of the address to be compared with the routing table entry.</div><div>\item This allows the host/subnet address to be any portion of the IP address.</div>
What's the difference between a Class C and a Class B IPv4 address?	\item Class B has a 16 bit network ID and so can support $2^{16}$ computers in the subnet<div>\item Class C has a 24 bit network ID and so can support $2^8$ computers in the subnet</div>
What's DHCP in the context of computer networking?	\item Dynamic Host Configuration Protocol, which assigns IP addresses to computers in the network.
How does NAT work in the context of computer networking?	\item When a computer sends a packet to a computer outside the network<div>\item the router saves the source IP and port number in a slot in its address translation table,&nbsp;</div><div>\item then substitutes the IP in the packet for its own and the port for a virtual port number that indexes the slot in the table holding the source's address and port.</div>
What's the main disadvantage of network address translation?	\item Computers behind a NAT have to initiate connections<div>\item unless some port in the router is specifically forwarded.</div>
What's datagram fragmentation in computer networking?	\item When a packet is larger than the next router's MTU, it's broken up by the current router into smaller packets.
What are the seven main advantages of IPv6?	\item Larger address space<div>\item Faster routing speed (no header checksum, no fragmentation)</div><div>\item Traffic class header field (ie priority, transmit promptly vs drop)</div><div>\item Flow label header field (resource reservation)</div><div>\item `Next' header field (enables optional header fields in packet)</div><div>\item Multicast and anycast</div><div>\item IP-level authentication \&amp; encryption</div>
What are three aims of a firewall?	\item Service control<div>\item Behavioural control</div><div>\item Access control</div>
In what three ways does a firewall commonly filter traffic?	\item IP packet filtering<div>\item TCP gateway&nbsp;</div><div>\item Application level gateway</div>
What the purpose of an application-level gateway?	\item To proxy an application process<div>\item Example: user telnetting through an application-level gateway could be captured by a TCP gateway and prompt the creation of a telnet proxy.</div><div>\item The user then forms a connection with the proxy and the proxy with the destination.&nbsp;</div>
What's the purpose of a TCP gateway?	\item To validate TCP connection requests and segment transmissions.&nbsp;<div>\item Can be used to suppress malformed segments and to route connections through an application-level gateway</div>
What's a bastion in the context of computer networking?	\item A computer inside the firewall which conducts gateway processes.&nbsp;
What's a MAC address in the context of computer networking?	\item A medium access control address, intended for use by the Ethernet protocol.<div>\item (but also used by other protocols because they're ubiquitous and unique)</div>
How does collision detection work in the Ethernet protocol?	\item If a station hears a different signal on the carrier than its transmitting<div>\item it transmits a jamming signal</div><div>\item and then backs off for a random (but bounded) length of time.&nbsp;</div><div>\item If, on retransmit, another collision occurs, the backoff time is doubled.</div>
How does collision detection work in WiFi?	\item Slot reservation: the sender transmits a request-to-send (RTS) frame containing a duration<div>\item and the receiver replies with a clear-to-send (CTS) frame.</div><div>\item As such all stations within range of the sender or receiver will hear at least one of the RTS or CTS frames, and refrain from transmitting during that period.</div><div>\item If a collision occurs, or a RTS doesn't get a CTS back, there's an exponentially-increasing random backoff period.</div>
define p-hacking	trying multiple statistical tests until you get your desired low p-value<div>&gt;&nbsp;http://www.nature.com/news/scientific-method-statistical-errors-1.14700</div>
What is it called when a scientists tries multiple hypothesis tests using different approaches until she gets the result she wants?&nbsp;	p-hacking<div>&gt; http://www.nature.com/news/scientific-method-statistical-errors-1.14700</div>
If you want to show the world that you planned on doing a hypothesis test prior to actually doing it, how can you do this?&nbsp;	<div>preregister it at the open science framework or at another pre-registration website</div>&gt; can distinguish btwn exploratory and confirmatory, too; https://osf.io/getting-started/&nbsp;
What abstraction does the API for UDP present?	\item A message passing abstraction
What abstraction does the API for TCP present?	\item A two-way stream between processes.
What's the difference between synchronous and asynchronous communication?	\item In synchronous communication, sending and receiving processes sync at every message: the \ttt{send} operation blocks its process until a \ttt{receive} operation is issued by the other process and vice versa.<div>\item In asynchronous operation, \ttt{send} is non-blocking and \ttt{receive} will be either blocking or non-blocking. In the non-blocking case, the receiving process will provide a buffer to be filled in the background.</div>
Do most modern systems prefer synchronous or asynchronous communication?	\item Asynchronous, with a blocking \ttt{receive} operation.
How many senders and receivers can a port have?	\item Any number of sending processes<div>\item but exactly one receiving process.</div>
What's a socket address in computer networking?	\item An IP address and port number.
What's a socket in the context of computer networking?	\item A software abstraction of an internet address, composed of an IP and a port.
What determines the size of UDP messages?	\item The receiving process specifies the size&nbsp;<div>\item and it's limited by IP's 64KB restriction, though it's usually further limited to 8KB</div>
What failures are UDP datagrams subject to?	\item Omission (by failed checksum or buffer overflow)<div>\item Ordering&nbsp;</div>
What are some popular services that use UDP?	\item DNS<div>\item VoIP</div>
How does TCP recognize when a message has been lost?	\item On receiving a packet, the receiver responds with a packet containing the highest contiguous sequence number so far *accepted*.&nbsp;<div>\item On a successful accept, this shifts the transmit window along.</div>
When do processes block when using TCP?	\item They can block on receive if there's no data in the receive buffer<div>\item They can block on send if the transmit window is closed.</div>
How is the fact that receive operations are often blocking usually dealt with in programs?	\item If threads are available, monitoring a socket is delegated to its own thread<div>\item Otherwise you simply have to test as to whether there's data available before trying to read.</div>
What's marshalling in the context of computer networking?	\item Converting data into a format ameniable to transmission in a message&nbsp;
What's an external data representation in computer networking?	\item An agreed standard for the representation of data structures and primative values.
What's unmarshalling in the context of computer networking?	\item Converting marshalled data back into usable formats.
What are five of the most common external data representations in use?	\item CORBA CDR<div>\item Language-specific serialization formats, like Java object serialization</div><div>\item XML</div><div>\item Protocol buffers</div><div>\item JSON</div>
What's CORBA?	\item Common Object Request Broker Architecture
What's CORBA CDR stand for?&nbsp;	\item CORBA Common Data Representation
How does the CORBA CDR format data?	\item Fixed-length types (bools, longs, floats, arrays, etc) are encoded as-is<br /><div>\item Variable length types are given as a length followed by its fixed-length individual elements (usually in the format of possibly-padded unsigned longs)</div>
How does CORBA CDR encode type information?	\item It doesn't. It assumes the sender and receiver have common knowledge of the order and types of the items in a message.
How does Java serialize references to other objects?	<div>\item Each serialized object is given a handle.</div>\item and references to the object are serialized as that handle.
What type information does Java serialize?	\item The name of the serialized class and a version number (either set manually or computed from a hash of the class's contents)
What's a remote object reference in the context of computer networking?	\item An identifier for an object that is valid throughout a distributed system.
What's a simple way to create a remote object reference?	\item Concatenate the IP of the host and port of the process with the current time and the current value of a local objects-created counter.
At a high-level, how does IPv4 multicast work?	\item An UDP datagram is sent to a Class D IP address<div>\item Any computer with a socket registered with that IP address will receive a copy of the datagram.</div>
What's a Class D IP address?	\item A multicast IP, whose first four bits are 1110
What are some common uses of multicast protocols?	\item Fault tolerance through replicated services<div>\item Service discovery</div><div>\item Data replication</div><div>\item Event notification propagation.</div>
What's reliable multicast?	\item A protocol type where either all subscribers receive messages or none of them do.
What're IP multicast's failure modes?	\item Omission (can be partial, where only some recipients miss the message)<div>\item Ordering (again, can be partial)</div>
What's an overlay network?	\item A network of nodes and virtual links that sits on top of another network, and offers something that is not otherwise provided.
What are some examples of overlay networks?	\item Distributed hash tables<div>\item Peer-to-peer file sharing</div><div>\item Content distribution networks</div>
What's MPI in the context of computer networking?	\item The Message Passing Interface standard, developed in high-performance computing.
What's the general structure of a request-reply message?	\item \ttt{messageType} int (either 0 for request or 1 for reply)<div>\item \ttt{requestId} int (unique wrt sender)</div><div>\item \ttt{remoteReference} int (usually address of the sender)</div><div>\item \ttt{operationId} int</div><div>\item \ttt{arguments} byte array</div>
What's an idempotent operation with respect to computer networking?	\item An operation that can be performed repeatedly with the same effect had it been executed once.
How are timeouts dealt with in request-reply protocols?	\item Typically, the request is resubmitted a number of times before a failure.<div>\item which means the operation either has to be idempotent or the receiver needs to recognize duplicates using a history.</div>
What's the structure of a request-reply protocol?	\item A client will execute \ttt{doOperation(RemoteRef s, int operationId, byte[] args)}, which sends a message to the server \ttt{s} containing the procedure and argument to execute.<div>\item Upon receiving the request, the server's \ttt{getRequest()} procedure will execute the requested operation and call \ttt{sendReply(byte[] result, RemoteRef c)} to reply to client \ttt{c} with the result.</div><div>\item Upon receiving the reply, \ttt{doOperation} will return.</div>
What are the R, RR and RRA protocols?	\item Request protocol (used when no reply is needed)<div>\item Request-reply protocol</div><div>\item Request-reply-acknowledge protocol</div>
What's an example of a request reply protocol?	\item HTTP
What are the seven most common HTTP methods?	\item GET&nbsp;<div>\item HEAD</div><div>\item POST</div><div>\item PUT</div><div>\item DELETE</div><div>\item OPTIONS</div><div>\item TRACE</div>
What does the GET HTTP method do?	\item Requests a resource at a specific URL.<div>\item If the resource is data, the data is returned.</div><div>\item If it's a program, the program is run with the supplied parameters and the result is returned.</div><div>\item Can also be configured to be conditional on the date the data was last modified, and to return only parts of the data.</div>
What's the HTTP HEAD method?	\item Same as GET, but returns statistics about the resource (size, type, last modified, etc)
What's the HTTP POST method?	\item Specifies the URL of a resource that can deal with the data supplied in the body of the request.
What's the HTTP PUT method?	\item Requests that the body of the request is stored with the specified URL as its identifier.
What's the HTTP OPTIONS method?	\item Fetches the list of operations that can be applied to the &nbsp;specified URL.
What does the HTTP TRACE method do?	\item The server replies with the request message. Diagnostic.
What's the contents of a HTTP request message?	\item Name of the method (GET, POST, etc)<div>\item URL</div><div>\item HTTP version</div><div>\item Headers</div><div>\item Body</div>
What's usually held in the header of a HTTP request?	\item Request modifiers (like conditions on the latest date of modification)<div>\item Client information (like its DNS name and what datatypes it can handle)</div><div>\item Credentials</div>
What's the structure of a HTTP reply message?	\item HTTP version<div>\item Status code (404, etc)</div><div>\item Reason (Not Found, etc)</div><div>\item Headers</div><div>\item Body</div>
What's an IDL in the context of computer networking?	\item An interface definition language.
What are the possible choices of call semantics for remote procedure call protocols?	\item Maybe semantics<div>\item At-least-once semantics</div><div>\item At-most-once semantics</div>
What are `maybe' call semantics in distributed systems?	\item The remote procedure call is executed either once or not at all.<div>\item Arises when no fault tolerance measures are applied.</div>
What are `at-least-once' call semantics in distributed systems?	\item The invoker of the remote procedure call will receive either a result, or an exception saying no result was received.<div>\item Arises when requests are retransmitted.</div><div>\item Requires idempotent operations to avoid errors.</div>
What are `at-most-once' call semantics in distributed systems?	\item Invoker of the remote procedure call receives either a result or an error saying that no result was received, which means either the operation was carried out once or not at all.<div>\item Arises with message retransmission, duplicate filtering and reply retransmission.&nbsp;</div>
How are RPC protocols implemented?	\item Each procedure in the service interface has a corresponding stub procedure in the client, which marshalls the arguments and sends the request to the server.<div>\item Each procedure in the service interface has a corresponding stub procedure in the server, which unmarshalls the arguments and calls the service procedure. The result of the service procedure is then marshalled and returned by the server stub procedure.</div><div>\item The client stub procedure unmarshalls the result and returns to the caller.</div>
What are the core concepts of the distributed object model?	\item Remote object references<div>\item Remote interfaces</div><div>\item A process with a remote object reference can invoke the methods listed in its remote interface.</div>
How does Java implement remote interfaces?	\item Remote interfaces are simply interfaces derived from \ttt{Remote}
What are the server components of an RMI protocol implementation?	\item Communication module<div>\item Remote reference module</div><div>\item Servants</div><div>\item Dispatchers</div><div>\item Skeletons</div>
What are the client components of an RMI protocol implementation?	\item Communication module<div>\item Remote reference module</div><div>\item Proxies</div>
What does the communication module of an RMI protocol implementation do?	\item Conducts all communication between client and server.<div>\item At the client end, is passed a call to the proxy, replaces proxy with the corresponding remote reference, and sends the request to the server.</div><div><div>\item At the server end, gets the local object reference from the remote reference via the remote reference module, then passes the local reference to the relevant dispatcher.</div></div>
What does the remote reference module of an RMI protocol implementation do?	\item Keeps a remote reference table, containing all the remote objects held by the process and all local proxies.<div>\item Creates remote references for objects that are about to be passed remotely for the first time</div><div>\item Converts remote references to local references, possibly creating a proxy if the remote reference refers to a non-local object</div>
What does the servant in an RMI protocol implementation do?	\item It's the instance of a class that provides the body of a remote object.<div>\item Handles the remote requests passed on by the corresponding skeleton</div>
What do the proxies of an RMI protocol implementation do?	\item Makes RMI transparant to clients by behaving like a local object to the invoker.<div>\item One created for each remote reference the object holds, and implements all the methods in the remote object's remote interface.</div><div>\item Calls to these methods are forwarded to the communication module</div>
What does the dispatchers of an RMI protocol implementation do?	<div>\item One for each class of object for which a remote reference has been given out.</div>\item Receives request messages from the communication module, along with the local reference for the corresponding obejct.<div>\item Selects the relevant method from the skeleton and passes on the request method.</div>
What do the skeletons of an RMI protocol implementation do?	\item One for each class of object for which a remote reference has been handed out.<div>\item Unmarshalls the arguments in a request method and invokes the corresponding method in the servant for which a local reference has been given.</div><div>\item When the servant returns, it marshalls the result into a reply message and returns it to the dispatcher.</div>
How do RMI protocol implementations accomodate objects whose interfaces weren't known at compile time?	\item Dynamic invocation: instead of proxies, a generic \ttt{doOperation} procedure is available that takes a remote object reference, a method name and arguments.<div>\item Requires dynamic skeletons if the objects are also unknown to the server at compile time.</div>
What's a binder in a RMI protocol implementation?	\item A service that maintains a mapping of textual names to remote object references
What's an activator in an RMI protocol implementation?	\item Recreates passive objects from saved state, possibly booting up new server processes to run them<div>\item Keeps a registry of passive objects available for activation.</div>
What's activation in a RMI protocol implementation?	\item Objects can be `passivated' into passive objects to save resources if they're not accessed for a while.<div>\item Their state will be saved and they can be spun back up at a later date by an activator if needed.</div>
What's a persistant object store in a RMI protocol implementation?	\item A way to preserve objects between activations and deactivations of processes.<div>\item Transparantly returns active objects on request.</div>
What's a location service in a RMI protocol implementation?	\item A database that maps remote object references into their probable current locations.<div>\item Also manages locating objects if they've moved from their last recorded location.</div>
How does distributed garbage collection usually work in RMI protocol implementations?	\item Reference counting.<br /><div>\item When a client tries to instantiate a proxy, it'll try and add itself to the server's reference list first. If the addition fails, the proxy won't be created.</div><div>\item The server considers the proxy to be leased: the client must request a lease renewal periodically in order to avoid being removed from the reference list.</div><div>\item A temporary entry is added to the reference list between a remote reference being handed out and the server being informed of the new proxy. This stops the object being destroyed &nbsp;before the client can register.</div>
What's spatial coupling in the context of distributed systems?	\item The sender has to know the identity of the receiver to send a message to them.
What's temporal coupling in the context of distributed systems?	\item The sender has to be alive at the same time as the receiver.
What are the two main types of group communication?	\item Process groups<div>\item Object groups</div>
What's a process group in the context of distributed systems?	\item Communicating entities are processes<div>\item Messages are delivered to processes</div><div>\item Messages are typically unstructured byte arrays.</div>
How object groups invoked in the context of distributed systems?	\item Client objects invoke operations on a proxy object<div>\item which uses a group communication system to send the invocations to each object in the group.&nbsp;</div>
What's the difference between a closed and open group communication protocol in the context of distributed systems?	\item In closed groups, only members of the group can multicast to it<div>\item In open groups, anyone can multicast to the group.</div>
What's the difference between an overlapping and non-overlapping group protocols in the context of distributed systems?	\item In overlapping group protocols, an entity can be a member of many groups.<div>\item In non-overlapping group protocols, an entity can be a member of at most one group.</div>
What's integrity in the context of distributed systems?	\item The guarantee that a received message&nbsp;will be the same as the one sent, and that it will only be received once.
What's validity in the context of distributed systems?	\item The guarantee that any message sent will eventually be delivered.
What's agreement in the context of distributed systems?	\item The guarantee that in a multicast protocol, if one process receives a message, all the processes in the group will receive the message.
What ordering properties can a group communication protocol enforce?	\item FIFO ordering: the messages from a particular sender will be delivered in the same order they're sent<div>\item Causal ordering: if one message is sent before another, it'll be delivered before the other.</div><div>\item Total ordering: if one message arrives before another at one process, that message will arrive before the other at all processes.</div>
What are the main responsibilities of the membership management service in a group communication protocol?	\item Provide an interface for group membership changes<div>\item Failure detection</div><div>\item Notifying the rest of the group of membership changes</div><div>\item Performing address expansion, from the group identifier to the current group membership list</div>
What's another name for publish-subscribe communication protocols?	\item Distributed event-based systems.
What are the two main characteristics of publish-subscribe protocols?	\item Heterogeneity: subscribers only need to provide a notification interface<div>\item Asynchronicity: publishers push notifications out asynchronously</div>
What are the common filter types for publish-subscribe protocols?	\item Channel-based filters: publishing and subscription is done to named channels<div>\item Topic-based filters: publishing and subscription is done with respect to a (possibly hierarchical) topic field</div><div>\item Content-based filters: subscription is done with expressions that are evaluated over each notification</div><div>\item Type-based filters: when notifications are objects, subscription can be done by type of object that's desired.</div><div>\item Context-based filters: notifications are propagated on the basis of the phase of the moon</div>
What's CBR in the context of distributed systems?	\item Content-based routing, a problem in distributed publish-subscribe protocols.
What are the various architectural options for content-based routing in publish-subscribe protocols?	<div>\item Centralized</div>\item Distributed flooding<div>\item Distributed filtering</div><div>\item Distributed filtering w/ advertisements</div><div>\item Distributed rendezvous</div><div>\item Distributed informed gossip</div>
What's flooding in the context of distributed publish-subscribe protocols?	\item Sending an event notification to every subscriber in the network, and letting them figure out if it matches the selection criteria.
How can a flooding protocol be optimized&nbsp;in the context of distributed publish-subscribe protocols?	<div>\item Use multicast protocols if they're available</div>\item Structure brokers as an acyclic graph
What's filtering based routing&nbsp;in the context of distributed publish-subscribe protocols?	\item Subscription information is propagated backwards to all potential publishers, and then event notifications are only propagated along routes which contain interested subscribers.<div>\item Requires that all brokers hold a routing table as well as a matching implementation.</div>
What are advertisements&nbsp;in the context of distributed publish-subscribe protocols?	\item Filtering-based routing can generate a lot of traffic due to propagation of subscriptions<div>\item If publishers have an idea as to the kind of notifications they'll be pushing, they can `advertise' this.</div><div>\item Adverts are then propagated towards subscribers, while subscriptions are propagated backwards.</div>
What's rendezvous routing in the context of distributed publish-subscribe protocols?	\item The space of possible notifications is partitioned among brokers.<div>\item Two functions are defined: one which takes a subscription and returns the list of brokers whose partitions intersect it (who subscribers can then subscribe to),&nbsp;</div><div>\item and one which takes a notification and does the same.</div><div>\item Then when an event is published, it's evaluated against the function and pushed to the relevant brokers, which then distribute it to their subscriber list.</div>
What's informed gossip in the context of distributed publish-subscribe protocols?	\item A gossip protocol that takes into account local information when deciding how to propagate the gossip.
What's the obvious implementation for rendezvous routing in the context of distributed publish-subscribe systems?	\item A distributed hash table.<div>\item Requires intelligent selection of a hash function though.</div>
What's another name for message queues?	\item Message oriented middleware.
What are the styles of receive commonly supported in a message queue protocol?	\item Blocking receive, which will wait until there's a message available to return with<div>\item Non-blocking receive, which will return a message if there is one or a not available notification otherwise</div><div>\item Notify, which issues an event notification when a message becomes available</div>
What's the usual content of a message in a message queue?	\item A destination queue<div>\item Metadata about the message which can be used for selection</div><div>\item An opaque body which the message must be dequeued to view.</div>
What's a message broker in the context of a message queue protocol?	\item The service that manages the transformations to be applied to arriving messages.&nbsp;
What's the difference between message passing protocols and message queues?	\item In message passing, the queues are implicitly attached to their receiving process, making it a temporally coupled protocol.<div>\item In message queues, the queues are hosted by a third party.</div>
What're the differences between message passing and distributed shared memory?	\item DSM doesn't require marshalling<div>\item Message passing syncs via a lock server; DSM uses locks, semaphores, etc</div><div>\item DSM can be made persistant and temporally decoupled.</div><div>\item DSM performance can fall off dramatically with large numbers of computers accessing a small number of items.</div><div>\item DSM hides communication; message passing is explicit about it</div>
What are the standard operations on a tuple space?	\item write<div>\item read</div><div>\item take</div>
How are tuples found in a tuple space?	\item Via associative addressing<div>\item a tuple specification is given, and all matching tuples are returned.</div>
What's the structure of a tuple in a tuple space?	"\item \ttt{&lt;""string"", 2, 'c'&gt;}"
Are tuples in tuple spaces immutable?	\item Yep
How can tuple spaces be broken up?	\item By creating named tuple spaces, possibly dynamically.
What are some up-and-coming variants of tuple spaces?	\item Using sets instead of tuples, so that tuples and tuple spaces are self-similar.<div>\item Using objects instead of tuples to form object spaces&nbsp;</div>
What's the state machine approach to tuple spaces?	\item When using replicated tuple spaces, the replicas can be kept consistent if<div>\item every replica must start in the same (empty) state</div><div>\item every replica must execute events in the same order (assured by a totally ordered multicast)</div><div>\item replicas must react deterministically to events</div>
What's the `hashing' approach to tuple space replication?	\item Tuples are hashed to a replica and placed only in that replica.<div>\item The hashing algorithm is picked so that read or take operations can calculate a small set of possible servers where the desired tuple could reside.</div>
What's variable hoisting in JS?	\item If a variable is initialized somewhere in a function, the *declaration* will be moved to the top of the scope by the compiler, but the initialization won't be.<div>\item Which will leave an \ttt{undefined} variable in an unexpected place.</div>
How large is a 2014 harddrive's write cache?	\item 8MB or larger
How would you define a 2D point type in SQL?	\item \ttt{CREATE TYPE POINT AS (X NUMERIC, Y NUMERIC);}
How would you create a type synonym for an integer in SQL?	\item \ttt{CREATE TYPE QTY AS INTEGER;}
How do you create subtypes in SQL?	\item Parent type must have been declared with \ttt{NOT FINAL}<div>\item Subtype is then \ttt{CREATE TYPE SubtypeName UNDER ParentName;}</div>
How would you assert that all \ttt{VAL} values in a SQL table \ttt{S} were greater than 0?	\item \ttt{CREATE ASSERTION AssertionName CHECK}<div>\item \ttt{(NOT EXISTS}</div><div>\item \ttt{(SELECT S.* FROM S}</div><div>\item \ttt{ WHERE S.VAL &lt;= 0 ))}</div>
How would you assert that all \ttt{VAL} values in a SQL table \ttt{S} were unique?	\item \ttt{CREATE ASSERTION AssertionName CHECK}<div>\item \ttt{(UNIQUE}</div><div>\item \ttt{(SELECT S.VAL FROM S ))}</div>
What's problematic about SQL's \ttt{UNIQUE} operator from a relational perspective?	\item It's meaningless in relational theory because every tuple in a relation is already unique!
What's the equality operator in SQL?	\item \ttt{(=)}
When are database constraints applied?	\item In relational theory, immediately - they're applied whenever the relation is updated<div>\item SQL deviates from relational theory by supporting deferred updates too though.</div>
How can you update multiple tables in SQL simultaneously?	\item \ttt{START TRANSACTION;}<div>\item \ttt{UPDATE S SET CITY = 'Paris' WHERE SNO = SNO('S1');}</div><div>\item \ttt{UPDATE P SET CITY = 'Paris'&nbsp;WHERE PNO = PNO('S1');}</div><div>\item \ttt{COMMIT;}</div>
Conventionally in SQL, where are integrity constraints enforced?	\item At the boundaries of transactions.
What's it mean to say that a database is correct?	<div>\item A correct database faithfully reflects the true state of affairs in the real world.</div>\item Slightly more formally, in a correct relvar, every tuple satisfies the relvar predicate.
What's it mean to say that a database is consistent?	\item Every tuple satisfies the database constraint
How do correctness and consistency relate with respect to databases?	\item Correctness *implies* consistency
What's the total relvar constraint?	\item The conjunction of all the constraints enforced on the relvar.
What's The Golden Rule of databases?	\item No update operation must ever violate the total database constraint
What's the total database constraint?	\item The conjunction of the relvar constraints of that database
What should happen when a constraint is applied to a database that doesn't satisfy it?	\item The constraint should be rejected.
What's a transition constraint in database theory?	\item A constraint that restricts the legal transitions that relvars can make from one value to another.
What's the class naming convention in Java?	\item Nouns with Pascal case.
What's the Java convention for interface names?	\item Adjectives in Pascal case that end with `ible' or `able'.
What's the Java naming convention for methods \&amp; variables?	\item Camel cased.
What's the Java naming convention for package names?	\item Lowercase and underscore.
How do you write a comment in Java?	\item \ttt{//} (preferred)<div>\item \ttt{/*..*/}</div>
How do you write a Javadoc comment in Java?	\item \ttt{/** .. */}
What's the type comparison operator in Java?	\item \ttt{instanceof}
How do you concatenate strings in Java?	"\item \ttt{""a"" + ""b"";}"
How do you give a hex literal in Java?	\item \ttt{int i = 0x3a;}
How do you enter binary literals in Java?	\item \ttt{int i = 0b011101;}
Does Java intern strings?	\item Yeah, it interns string literals.
How do you enter a double in scientific notation in Java?	\item \ttt{double a = 10.1e4;}
What type is a Java numeric literal which contains a decimal point?	<div>\item Float if it's got a \ttt{f} or \ttt{F}</div>\item Double if it's \ttt{d} or \ttt{D} or doesn't have one
What're Java's unsigned types?	\item \ttt{char} is the only one
What're Java's special floating point entities?	\item \ttt{Double.POSITIVE\_INFINITY}<div>\item \ttt{Double.NEGATIVE\_INFINITY}</div><div>\item \ttt{Double.NaN}</div><div>\item There's also a \ttt{-0.0} entity, but it doesn't have a constant.</div>
How do you test if a Java double is infinite?	\item \ttt{Double.isInfinite(x)}
How do you test if a Java double is NaN?	\item \ttt{Double.isNaN(x)}<br />
What's the difference between \ttt{boolean} and \ttt{Boolean} in Java?	\item \ttt{boolean} is a primative type<div>\item \ttt{Boolean} is a reference type</div><div>\item Same for all the primative types.</div>
What's autoboxing in Java?	\item Implicitly converting a primative type to its reference type when necessary.
What's the best way to unbox a primative's reference type in Java?	\item If it's not done automatically, \ttt{valueOfIntegerType.intValue()} and similarly for other types.
What are Java's value types?	\item The boolean and numeric types (aka the primative types)<br />
How does Java initialize variables by default?	\item Instance variables are initialized to null<div>\item Local variables aren't initialized. Accessing them is an error.</div>
How do you declare an array in Java?	\item \ttt{int[] array;} (preferred)<div>\item \ttt{int array[];}&nbsp;</div>
How do you declare a multidimensional array in Java?	\item \ttt{int[][] array;}<div>\item \ttt{int array[][];}</div>
How do you write a multidimensional array literal in Java?	\item \ttt{int[][] array = \{\{1, 2\}, \{3, 4\}\};}
How do you create an anonymous array in Java?	\item \ttt{int[] array = new int[] \{7, 3, 4\};}
Does Java pass by reference or value?	\item Value&nbsp;<div>\item (but it's the reference to an object that's passed, not the object itself)<br /></div>
What's the default implementation of equality for reference types in Java?	\item Reference equality.
How is string equality testing implemented in Java?	\item \ttt{equals()} tests for equality character by character<div>\item \ttt{==} tests for reference equality!</div>
What're Java's mutable string types?	\item \ttt{StringBuffer}<div>\item \ttt{StringBuilder}</div>
What's cloning in Java?	\item Copying an object rather than just the reference to the object.
How do you create shallow clones of objects in Java?	\item Implement \ttt{Cloneable}<div>\item and call the \ttt{(type) clone()} method</div><div>\item Cast is needed as it returns an \ttt{object} by default.</div>
What's the preferred way to conduct deep cloning in Java?	\item Copy constructors.<div>\item People often use serialization though.</div>
How do you create a subclass in Java?	\item \ttt{class SubclassName extends SuperclassName}&nbsp;
How do you implement an interface in Java?	\item \ttt{class ImplementorName implements Interface1, Interface2}
Which methods can be overridden in Java?	\item Ones that aren't \ttt{final, static, private}
What're the rules about overrides and errors in Java?	\item The override can't throw checked exceptions other than those declared by the function it's overriding.
How do you instantiate a Java class?	\item \ttt{TypeName variableName = new ConstructorName()}
What are getters and setters known as in Java?	\item Accessor and mutator functions.
How can a subclass refer to it's parent in Java?	\item \ttt{super}
How do you delegate to the parent class's constructor in Java?	\item The first statement in the constructor should be \ttt{super()}
How do you refer to the containing object in Java?	\item \ttt{this}
How do you implement variable-length argument lists in Java?	\item \ttt{void functionName(String... argList)}<div>\item and \ttt{argList} can be accessed as an array.</div>
How do you denote an abstract class in Java?	\item \ttt{abstract class ClassName \{ \}}
How do you denote an abstract method in Java?	\item \ttt{abstract void functionName()}
How do you give a class member static duration in Java?	\item \ttt{static int i;}
What's a static initializer in Java?	\item \ttt{static \{ classVariable1 = initialValue1; classVariable2 = initialValue2; \}}<div>\item Any number of static initializers are allowed \&amp; they'll be executed in order.</div>
How do you create an enum in Java?	\item \begin{verbatim}<div>enum EnumName {<div>&nbsp; VALUE_1 (arg1, arg2),</div><div>&nbsp; VALUE_2 (arg1, arg2);&nbsp;</div><div><br /></div><div>&nbsp; EnumName(type1 param1, type2 param2) {..}</div><div>}</div></div><div>\end{verbatim}</div>
How do you iterate over an enum in Java?	\item \ttt{for (EnumName v : EnumName.values())}
What privacy modifications are available in Java?	\item \ttt{public} (class, package, subclass, world)<div>\item \ttt{protected} (class, package, subclass)</div><div>\item no modifier (class, package)</div><div>\item \ttt{private} (class)</div>
What are Java annotations?	\item \ttt{@AnnotationName}<div>\item Provides a way to associate metadata with classes or methods.&nbsp;</div>
What're Java's built-in annotations?	\item \ttt{@Override}<div>\item \ttt{@Deprecated}</div><div>\item \ttt{@SuppressWarnings}</div>
What's a marker in Java?	\item An annotation with no parameters.
How do you define custom annotations in Java?	\item \ttt{public @interface AnnotationName \{ }<div>\item \ttt{keyType keyName1() default defaultValue \} }</div>
What restrictions are there on custom annotations in Java?	<div><div>\item Methods can't have any parameters or a throws clause</div><div>\item and can only return specific types</div></div>
How do you use a multivalue annotation in Java?	\item \ttt{@AnnotationName(keyName1 = value1, keyName2 = value2)}
How do you implement annotations in Java that'll be read at runtime?	\item Annotate the annotation's defintion with<div>\item \ttt{@Retention(RetentionPolicy.RUNTIME)}</div>
How do you use a single value annotation in Java?	\item \ttt{@AnnotationName(value)}
How do you restrict where a Java annotation can appear?	\item Decorate it with \ttt{@Target(\{ElementType.METHOD\})}
Do Java switch statements fall through?	\item Yup.
How do you implement a foreach loop in Java?	\item \ttt{for (TypeName a : as)}<div>\item where \ttt{as} is an \ttt{Iterable} or an array.</div>
How are assertions implemented in Java?	\item \ttt{assert boolean\_expression : error\_string\_expression;}<div>\item In debug mode, if the boolean expression evaluates to false, the error string is displayed and the program terminates.</div>
What does the \ttt{final} modifier do in Java?	\item On classes, it prevents subclassing.<div>\item On methods, it prevents overriding</div><div>\item On variables, it prevents modification.</div>
How do you denote the package of a Java class?	\item \ttt{package com.oreilly.tutorial;}
How do you import packages into a Java class?	\item \ttt{import java.util.GregorianCalendar}
What packages are imported by default in Java?	\item \ttt{java.lang}
How do you define finalizers in Java?	\item Override \ttt{finalize()}<div>\item Try not to though, because it's a poor way to clean up resources.</div>
What six types can Java annotation keys return?	\item Primatives<div>\item Strings</div><div>\item Types</div><div>\item Enums</div><div>\item Annotations</div><div>\item Arrays of the aforementioned.</div>
What are the basic navigation keys in vim?	\item h (left)<div>\item j (down)</div><div>\item k (up)</div><div>\item l (right)</div>
How do you return to Normal mode in vim?	\item Esc<div>\item Ctrl-c</div>
How do you exit vim and discard changes?	\item :q!
How do you delete single characters in vim?	\item In normal mode, \ttt{x}
How do you insert text in vim?	\item From normal mode, enter insert mode with \ttt{i}
How do you append text to a line in vim?	\item \ttt{A} in normal mode
How do you quit and save changes in vim?	\item \ttt{:wq}
What's the end-of-the-line motion in vim?	\item \ttt{\$}
What's the end-of-the-current-word motion in vim?	\item \ttt{e}&nbsp;
What's the before-the-start-of-the-next-word motion in vim?	\item \ttt{w}
What's the delete operator in vim?	\item \ttt{d}
How do you repeat a motion in vim?	\item Operator then number then motion.&nbsp;<div>\item ie \ttt{d3w} deletes the next three words</div>
How do you move to the start of the line in vim?	\item \ttt{0} in normal mode
How do you delete a whole line in vim?	\item \ttt{dd} in normal mode
How do you undo all edits to a particular line in vim?	\item \ttt{U} in normal mode
How do you undo a command in vim?	\item \ttt{u} in normal mode
How do you undo an undo in vim?	\item \ttt{Ctrl-r}
How do you `put' a line in vim?	\item \ttt{p} in normal mode
How do you cut and paste a line in vim?	<div>\item in normal mode</div>\item \ttt{dd} to cut it<div>\item \ttt{p} to paste it</div><div><br /></div>
How do you replace a single character in vim?	\item \ttt{rx} in normal mode, where \ttt{x} is the substitute character
What does the change operator do in vim?	\item Deletes a portion of text and puts you in insert mode so you can replace it
What's the change operator in vim?	\item \ttt{c} in normal mode
How do you find your current location in a file in vim?	\item \ttt{Ctrl-g}
How do you move to the end of the file in vim?	\item \ttt{G} in normal mode
How do you move to the start of the file in vim?	\item \ttt{gg} in normal mode
How do you move to a specific line number in vim?	\item In normal mode, \ttt{45G} will move you to line 45.
How do you conduct a forward&nbsp;search&nbsp;in vim?&nbsp;	\item \ttt{/searchphrase} in normal mode<div>\item then \ttt{n} to move forward, \ttt{N} to move back</div>
How can you skip between a search result and the origin of the search in vim?	<div>\item \ttt{Ctrl-o} to skip back to the start of the search&nbsp;</div><div>\item and \ttt{Ctrl-i} to skip to where you skipped back from.</div>
How do you find a parentheses' partner in vim?	\item \ttt{\%} in normal mode.
How do you substitute for the first occurance of a phrase in a line in vim?	\item \ttt{:s/oldphrase/newphrase} to replace the first occurance of oldphrase with newphrase
How do you substitute for the first occurance of a phrase in a file in vim?	\item \ttt{:\%s/oldphrase/newphrase} to replace the first occurance of oldphrase with newphrase
How do you substitute for the first occurance of a phrase in a specific range of lines in vim?	\item \ttt{:3,7s/oldphrase/newphrase} to replace the first occurance of oldphrase between lines 3 and 7 with newphrase
What are some common switches for vim's substitute command?	\item \ttt{oldphrase/newphrase/g} causes it to replace every instance of oldphrase in its range<div>\item \ttt{oldphrase/newphrase/gc} causes it to replace every instance of oldphrase in its range, giving a prompt each time</div>
How do you execute a shell command in vim?	\item \ttt{:!command} in vim
When must a vim normal mode command be terminated with \ttt{ENTER}?	\item When it starts with \ttt{:}
What's the Linux command to get the current directory?&nbsp;	\item \ttt{pwd}
How do you save a file under a new name in vim?	\item \ttt{:w filename}
How do you select text in vim?	\item \ttt{v} in normal mode
How do you copy the contents of a file into the current file in vim?	\item \ttt{:r filename} in normal mode
How do you copy the result of a command into the current file in vim?	\item \ttt{:r !command}
How do you insert a line below the cursor in vim?	\item \ttt{o} in normal mode
How do you insert a line above the cursor in vim?	\item \ttt{O} in normal mode
How do you insert text after the cursor in vim?	\item \ttt{a} in normal mode
How do you enter replace mode in vim?	\item \ttt{R} in normal mode
What's the copy operator in vim?	\item \ttt{y} in normal mode
How do you ignore case in a vim search?	\item \ttt{/searchpattern\textbackslash c}
How do you enable and disable options in vim?	\item \ttt{:set optionname}<div>\item \ttt{:set nooptionname}&nbsp;</div>
How do you open a file for editing in vim?	\item \ttt{:e filename} in normal mode
What are the autocompletion commands in vim?	\item \ttt{Ctrl-d} to get a list of commands matching the characters entered so far<div>\item \ttt{Tab} to complete</div>
How do you access help in vim?	\item \ttt{:help}
How do you instantiate a Maven archetype?	\item \ttt{mvn archetype:generate}
What's a Maven archetype?	\item A skeleton for a project.
What's the structure of a Maven command?	\item \ttt{mvn [plugin:]goal -keyName=keyValue}
What are Maven coordinates?	<div>\item Four elements of the POM:</div>\item \ttt{groupId}<div>\item \ttt{artifactId}</div><div>\item \ttt{packaging}</div><div>\item \ttt{version}</div><div>\item that uniquely identify a project.</div>
How do Maven POMs work?	\item The POM in a directory extends a parent POM (which extends its parent, etc)<div>\item and together they describe what Maven should do with a project</div>
How can you view the total POM of a Maven project?	\item \ttt{mvn help:effective-pom}
What are the basic phases of the default Maven lifecycle?	\item validate<div>\item compile<br /><div>\item test</div><div>\item package</div><div>\item integration-test</div><div>\item verify</div><div>\item install</div><div>\item deploy</div></div>
What's a Maven lifecycle phase?	\item An ordered list of zero or more goals.
What happens when you execute a Maven goal?	\item All phases and goals up to and including that goal will be executed in order.
What's POM in Maven?	\item Project object model, a declarative description of a project.
Which parts of a Maven POM are meant for human consumption?	\item \ttt{name}<div>\item \ttt{url}</div>
How do you add a dependency to a Maven project?	\item In the \ttt{dependencies} environment of the POM<div>\item add a \ttt{dependency} environment</div><div>\item which has the \ttt{groupID}, \ttt{artifactID} and \ttt{version} of the dependency.</div>
How do you find the Maven coordinates of a dependency?	\item Use \ttt{repository.sonatype.org}
How do you move to the first non-blank character in a line in vim?	\item \ttt{\^{}}
What are Java's standard streams?	\item System.in<div>\item System.out</div><div>\item System.err</div>
How do you interact with the console in Java?	\item Through the \ttt{Console} class
What are the four basic components of Java's IO class hierarchy?	\item \ttt{Reader}s<div>\item \ttt{Writer}s</div><div>\item \ttt{InputStream}s</div><div>\item \ttt{OutputStream}s</div>
How do you read a line of character text from a file in Java?	"\item Create a \ttt{FileReader(""filename"")}<div>\item then use it to create a \ttt{BufferedReader(fileReader)}</div><div>\item and call \ttt{bReader.readLine()} while it's not null.</div><div>\item then close it with \ttt{bReader.close()}.</div>"
How do you read binary data from a file in Java?	"\item Create a \ttt{FileInputStream(""filename"")}<div>\item and use it to create a \ttt{DataInputStream(fileStream)}</div><div>\item then call \ttt{inStream.read()}</div>"
How do you write character data to file in Java?	"\item Create a \ttt{FileWriter(""filename"")}&nbsp;<div>\item and use it to create a \ttt{PrintWriter(fileWriter)}</div><div>\item then call \ttt{printWriter.println(str)}</div>"
How do you write binary data to a file in Java?	"\item Create a \ttt{File(""filename"")} object<div>\item and use it to create a \ttt{FileOutputStream(file)}<br /></div><div>\item and use that to create a \ttt{DataOutputStream(fileOutputStream)}</div><div>\item then call \ttt{outStream.writeInt(i)} or similar</div>"
When reading or writing a large amount of binary data in Java, what should you do?	\item Use a \ttt{BufferedInputStream} or \ttt{BufferedOutputStream} rather than a filestream
How do you get the input stream of a socket in Java?	"\item Create a \ttt{Socket(""IP"", portNum)}<div>\item Call \ttt{socket.getInputStream()}</div>"
How do you exclude a data member in Java from serialization?	\item Mark it \ttt{transient}
How do you serialize an object in Java?	"\item Create a \ttt{FileOutputStream(""filename"")}<div>\item and use it to create an \ttt{ObjectOutputStream(fileStream)}</div><div>\item The use \ttt{objectStream.writeObject(objName)}</div>"
How do you deserialize an object in Java?	"\item Create a \ttt{FileInputStream(""filename"")}<div>\item and use that to create an \ttt{ObjectInputStream(fileStream)}</div><div>\item then call \ttt{(Type) objectStream.readObject()}</div>"
What's the old way of interacting with directories and files in Java?	\item Using the \ttt{File} class.&nbsp;<div>\item \ttt{delete()}, \ttt{exists()}, \ttt{list()}, etc</div>
How do you get random access to a file in Java?	"<div>\item Create a \ttt{File(""filename"")}</div>\item Use it to create a \ttt{RandomAccessFile(file, ""rw"")}"
What's the new way of interacting with the filesystem in Java?	<div>\item NIO 2.0 (new input/output)</div>\item \ttt{java.nio.file}
What are the main classes of NIO2.0 in Java?	\item \ttt{Path} interface and \ttt{Paths} class (an upgraded version of \ttt{java.io.File})<div>\item \ttt{Files}, a static set of methods on paths.</div>
How do you create threads in Java?	\item Extend \ttt{Thread} and override \ttt{run()}<div>\item or implement \ttt{Runnable} and define \ttt{run()}</div>
How do you start a Java thread?	\item \ttt{thread.start()}
How do you pause and resume a Java thread?	\item Using \ttt{wait()} and \ttt{notify()}
What's the simplest implementation of a mutex in Java?	\item Marking a block with \ttt{synchronized (syncObject) \{..\}}<div>\item Decorating a method with \ttt{synchronized}, which uses \ttt{this} as the sync object</div>
How can you create a thread pool in Java?	\item Using the factory methods in the class \ttt{Executors} to make an \ttt{ExecutorService}
How do you use thread pools in Java?	\item Given a threadpool \ttt{ExecutorService}<div>\item and a \ttt{Runnable} object \ttt{task}</div><div>\item call \ttt{executorService.execute(task)}</div>
What are the common interfaces of the Java collections framework?	\item \ttt{Collection}<div>\item \ttt{List}</div><div>\item \ttt{Map}</div><div>\item \ttt{Queue}</div><div>\item \ttt{Set}</div>
What are the common implementations of Java's \ttt{List} interface?	\item ArrayList<div>\item LinkedList</div>
What are the common implementations of Java's \ttt{Map} interface?	\item HashMap<br /><div>\item LinkedHash</div><div>\item TreeMap</div>
What's Java's \ttt{LinkedHash} datatype?	\item A hashtable which is also a linked list, allowing ordered access
What are the common implementations of Java's \ttt{Set} interface?	\item \ttt{HashSet}<div>\item \ttt{LinkedHashSet}</div><div>\item \ttt{TreeSet}</div>
What're the common implementations of Java's \ttt{Queue} interface?	\item \ttt{PriorityQueue}
Where are Java's methods on the \ttt{Collection} interface stored?	\item In the \ttt{Collections} class
How do you order items in Java collections?	\item Implement \ttt{Comparator} and override its \ttt{compare} function, then pass it to the collection constructor.
What's the diamond operator in Java?	\item When initializing a generic type, the initializer can use \ttt{GenericType&lt;&gt;} rather than the full type<div>\item ie \ttt{List&lt;Integer&gt; list = new ArrayList&lt;&gt;();}</div>
How do you constrain a type parameter to implement multiple interfaces in Java?	\item \ttt{&lt;T extends P \&amp; S&gt;} where \ttt{S} and possibly \ttt{P} is an interface
How do you constrain a type parameter in Java to derive a subclass?	\item \ttt{&lt;T super P&gt;}&nbsp;
What's a generic wildcard in Java?	\item \ttt{&lt;? extends P&gt;} or similar<div>\item used when you don't need to know the specific type</div>
When should \ttt{&lt;? extends P&gt;} and \ttt{&lt;? super P&gt;} be used in Java?&nbsp;	\item&nbsp;&nbsp;\ttt{&lt;? extends P&gt;}&nbsp;when you only *get* items out of a structure (covariant)<div>\item \ttt{&lt;? super P&gt;} when you only *put* items into a structure (contravariant)</div>
How do you declare a generic Java method in a nongeneric class?	\item Precede the return type with a generic parameter, and precede the call with one too<div>\item ie \ttt{public &lt;T&gt; T func(T t)}</div><div>\item \ttt{&lt;Integer&gt;func(i)}</div>
What's the underlying implementation of generics in Java?&nbsp;	\item Type erasure<div>\item At compile time, the generic parameter is replaced with \ttt{Object} and any casts necessary are introduced.</div>
What're the problems with Java's implementation of generics?	<div>\item Can't access type information at runtime.</div>\item Can't overload methods with only generic parameters, as they'll all be erased to \ttt{Object}<div>\item Casts to generic types are unchecked.</div>
What's reification in the context of Java?	\item Refining the Java generics framework to retain type information at runtime.
How do you write lambdas in Java 8?	\item \ttt{(int i) -&gt; f(x)}<br />
How do you reference static methods in Java 8?	\item \ttt{TypeName::methodName}
How do you reference methods in Java 8?	\item \ttt{objectName::methodName}
How does Java double brace initialization work?	\item \ttt{List&lt;Integer&gt;() \{\{ add(1); \}\} }<div>\item Outer set of braces declare an anonymous inner subclass</div><div>\item Inner set of braces define an instance initializer.</div>
What are the restrictions on Java's double brace initialization?	\item Can't be used on \ttt{final} classes<div>\item Can't be used with the diamond generics operator.</div>
What's Java's boolean type?	\item \ttt{boolean}
What're the steps in Johnson's algorithm?	<div>\item Start with a single node. Then:</div>\item Add a node $q$ to the graph and connect it with weight 0 edges to every other vertex.<div>\item Use Bellman-Ford to find the minimum weight $h_q(u)$ path from $q$ to each node $u$ in the graph.&nbsp;</div><div>\item Negative-weight cycles might be detected here, in which case terminate.</div><div>\item Reweight all edges $uv$ from $w_{uv}$ to $w_{uv} + h_q(u) - h_q(v)$&nbsp;</div><div>\item Edges are now all positive weight, so run Dijkstra's on each vertex.</div>
What's the runtime of Johnson's algorithm?	\item $O(n(m +&nbsp;n \lg n))$
Which algorithm solves the all-pairs shortest path problem on graphs with negative weight edges?	\item Johnson's algorithm.
What're the steps in the Bellman-Ford algorithm?	\item Initially assume the distance from the source to each vertex $d(v)$ is infinite.<div>\item Repeat $n$ times:</div><div>\item For each edge $uv$, set $d(v) = \min(d(v), d(u) + w_{uv})$.</div><div>\item Having updated all edges, if $d(v) &gt; d(u) + w_{uv}$, then the graph contains a negative weight cycle. Abort.</div>
What algorithm would you use to solve the single-source shortest path problem when there are negative weight edges?	\item Bellman-Ford.
What's the runtime of Bellman-Ford?	\item $O(nm)$
What algorithm can you use to detect negative-weight cycles in a graph?	\item Bellman-Ford
What's a Harvard computer architecture?	\item One where data and instructions have separate paths
What's a modified Harvard architecture?	\item One where data and instructions are backed by the same storage, but have separate paths to the processor<div>\item By far the most common architecture nowadays</div>
What's a static import in Java?	\item \ttt{import static packageName;}<div>\item which allows you to reference static methods without qualifying them</div>
How do you build a regex in Java?	"\item Call \ttt{Pattern.compile(""patternString"")} to get a Pattern object<div>\item then call \ttt{pattern.matcher(""targetString"")} to get a matcher object</div><div>\item which you can then call different regex operations from</div>"
What are the core components of TypeScript?	\item The compiler<div>\item The TS Language Service, a VS plugin</div><div>\item The declaration files&nbsp;</div>
What's TypeScript?	\item A superset of JS that compiles to idiomatic JS
How can you get split-screen editing for TS in VS?	\item Install Web Essentials extension&nbsp;
How do you declare a variable in TS?	\item \ttt{var variableName: variableType = value;}
What's a TS declaration file?&nbsp;	\item A file containing variables and types of variables, to provide support to the TSLS
How do you import another file in TS?	"\item Add a declaration file for the library to the project and reference it with \ttt{/// &lt;reference path=""defFilePathName.d.ts""/&gt;} at the top of the file"
How do you declare a class in TS?	\item \ttt{class ClassName \{ .. \}}
How do you declare static methods in TS?	\item In a class, define \ttt{static MethodName(): returnType \{ ... \}}
What's the difference between regular methods and static methods in TS?	\item Regular methods have to be accessed through an instantiated copy of a class<div>\item Static methods can be accessed from the class itself.</div>
How is a module declared in TS?	\item \ttt{module Module.Name \{ export class ClassName \{ .. \} \}}<br />
How are classes in other modules referenced in TS?	\item By the fully qualified name; there's no \ttt{import} keyword
What type is an untyped variable in TS?	\item \ttt{Any}
How do you declare an array type in TS?	\item \ttt{var arrayName: any[] = new Array();}
What's the difference between indexing into an array with a number vs a string in TS?	\item Indexing into an array with a number will give a typed result<div>\item Indexing into an array with a string will give a \ttt{any} type</div>
How do you cast a variable in TS?	\item \ttt{var variableName: int = &lt;int&gt;anotherVariable;}
What's an ambient declaration in TS?	\item \ttt{declare var variableName;}, which is a standin for a variable that'll be provided by the script's environment
What are the three types of function in TS?	\item Global functions, defined outside of any class or module<div>\item Class methods</div><div>\item Anonymous functions</div>
How do you give a function declaration in TS?	\item \ttt{functionName(argName:&nbsp;argType) =&gt; returnType \{ ... \}}
What's the type of a function in TS?	\item \ttt{(argName: argType) =&gt; returnType}
How do you mark a parameter as optional in TS?	\item \ttt{function functionName(argName?: argType = defaultValue): returnType}
How do you declare a varargs parameter in TS?	\item \ttt{function functionName(...paramName: paramType[]): returnType}
How do you test whether a variable is without a value in TS?	\item \ttt{variableName === null || variableName === undefined}
What's the difference between looping over an array with \ttt{for in} and with \ttt{for} in TS?	\item \ttt{for in} will convert each value to a string<div>\item \ttt{for} will preserve the type</div>
How do you overload functions in TS?	\item \ttt{function functionName(paramName: childType1): returnType;}<div>\item \ttt{function functionName(paramName: childType2): returnType; }</div><div>\item \ttt{function functionName(paramName: parentType): returnType;}</div><div>\item \ttt{ if (paramName instanceof childType1) \{ .. \}}</div><div>\item \ttt{ if (paramName instanceof childType2) \{ .. \}}</div><div>\item \ttt{\}}</div>
How do you define getters and setters in TS?	\item \ttt{class ClassName \{}<div>\item \ttt{ &nbsp;private fieldName: typeName; }</div><div>\item \ttt{ &nbsp;get FieldName: typeName \{ return this.fieldName; \}}</div><div>\item \ttt{ &nbsp;set FieldName(value: typeName) \{ this.fieldName = value; \}}<br />\item \ttt{\}}</div>
How do you access an instance field in the same object in TS?	\item \ttt{this.fieldName}<div>\item Have to use \ttt{this}!</div>
What's an arrow function in TS?	\item \ttt{argName =&gt; \{ .. \}} is like \ttt{function(argName) \{ ..\}} but \ttt{this} will inherit its definition from its lexical scope rather than being set to global
How do you declare a constructor in TS?	\item \ttt{constructor (paramName: paramType) \{ .. \}}
How do you declare a class event in TS?	\item \ttt{class className \{ eventName?: (ev: Event) =&gt; any; \}}
How do you reference static methods from elsewhere in a class in TS?	\item \ttt{className.methodName}. No \ttt{this} required.
How do you create an anonymous type in TS?	\item \ttt{var anon = \{ fieldName1: value1, fieldName2: value2 \}}<br /><div>\item Types will be inferred by the TSLS.</div>
How do you create a subtype in TS?	<div>\item \ttt{class ClassName extends ParentClassName \{ .. \} }</div>
How do you reference a parent type's constructor in TS?	<div>\item \ttt{super(args)}</div>
How do you override a method in TS?	\item Just give a method with the same type signature in the child class.
How can you alias a function's type in TS?	\item \ttt{interface IAliasName \{}<div>\item \ttt{ &nbsp;(paramName: paramType): returnType;}</div><div>\item \ttt{\}}&nbsp;</div>
How do you declare an interface in TS?	\item \ttt{interface IInterfaceName \{ ... \}}<div>\item with the body being a list of signatures</div>
How can you alias an import in TS?	"\item \ttt{///&lt;reference path=""ImportedFile.ts""/&gt;}<div>\item \ttt{import aliasName = importedFileClassFullName;}</div>"
What are the three main types of machine learning?	\item Predictive learning<div>\item Descriptive learning</div><div>\item Reinforcement learning</div>
What's supervised learning?	\item Another name for predictive learning
What's unsupervised learning?	\item Another name for descriptive learning
What's the general outline of a predictive learning problem?	\item Given a training set of input-output pairs $D = \{(x_i, y_i)\}$<div>\item then given some other $x$, predict its associated $y$.</div>
What are two other names for features in predictive learning?	<div>\item attributes</div><div>\item covariates</div>
What's the name for the output variable $y$ from a predictive learning algorithm?	\item The response variable
What's the difference between the classification problem and the regression problem in machine learning?	\item Classification problems have a categorical response variable<div>\item Regression problems have a response variable with an ordering</div>
What's another name for classification problems in machine learning?	\item Pattern recognition problems
What's a knowledge discovery problem in machine learning?	\item Another name for descriptive learning
What's the outline of a descriptive learning problem?	\item Given a set of inputs $D = \{x_i\}$<div>\item find some interesting patterns in the data</div>
What's reinforcement learning?	\item Teaching a system how to behave through reward and punishment signals
What's the difference between multiclass and multilabel classification?	\item In multiclass, each input can be assigned to one of many classes<div>\item In multilabel, each input can be assigned to any number of labels</div>
What does $p(y|x, D)$ denote in machine learning?	\item The probability distribution of response $y$ given input vector $x$ and training set $D$
What's the MAP estimate in machine learning?	\item Maximum a posteriori estimate<div>\item ie assign to $x$ the mode of $p(y|x, D)$</div>
What's density estimation in machine learning?	\item Reconstructing a probability distribution from observed data
What's a latent variable in machine learning?	\item A variable that doesn't appear in the dataset.
What's another name for a latent variable?	\item A hidden variable
What's PCA stand for in machine learning?	\item Principal component analysis
What's the use of principal component analysis?	\item A machine learning approach to dimensionality reduction: given a set of high-dimensional $x$, deduce the latent low-dimensional $z$ that inferrs them
What's another name for imputation in machine learning?&nbsp;	\item Matrix completion
What's imputation in machine learning?	\item Inferring the value of missing data from the data you do have
What's the main problem in K-nearest neighbour algorithms?	\item Dimensionality. In high-dimensional data, there's a looong way between datapoints.
What's the interpretation of the posterior distribution?	\item The probability of an event given evidence
What's the prior distribution?	\item The probability of an event before taking some piece of evidence into account
What's the likelihood in Bayesian statistics?	\item The probability of the evidence given some event
How are the posterior, prior and likelihood distributions related?	\item $posterior \propto likelihood \times prior$
What's inductive bias in machine learning?	\item The set of assumptions made by the learner in order to make predictions
How is a linear response often written in machine learning?	\item By defining the feature vector to be $x^\prime = (1, x)$, a linear equation with a constant term can be written as $w^T x^\prime$
What's the sigmoid function?	\item $sigm(\eta) = \frac{1}{1+e^{-\eta}}$
What's another name for the sigmoid function?	<div>\item Logistic</div>
What distribution is used in logistic regression?	\item $p(y|x, w) = \text{Ber}(y|\text{sigm}(w^T x))$<div>\item though it's actually a form of classification, not regression&nbsp;</div>
What does $\text{Ber}(y|\mu(x))$ represent in machine learning?	\item The Bernouilli distribution with mean $\mu(x)$
What's a validation set in machine learning?	\item A set of inputs against which a model can be tested<div>\item Often generated by splitting off part of the data intended for training</div>
What's the generalization error in machine learning?	\item The expected value of the error on future data&nbsp;
What's the relationship between the training, validation and test sets in machine learning?	\item A set of models should be trained on the training set<div>\item and the one with the lowest error on the validation set should be evaluated against the test set.</div>
What's the usual size of the validation set in machine learning?	\item 1/4 of the size of the training set
What's cross validation in machine learning?	\item Split the training data into $K$ `folds'<div>\item Train on all but the $k$th and then test on the $k$th for each $k$.</div><div>\item The test error is then approximated as the average of the errors on each of the folds</div>
What's LOOCV in machine learning?	\item Leave-one-out cross validation, where there are as many folds as datapoints
How many folds are typically used in cross validation?	\item 5
What's the no free lunch theorem in ML?	\item Any two optimization algorithms are equivalent when their performance is averaged across all possible problems
What's Knuth's shuffle algorithm?	\item Given a string $s$ of length $n$<div>\item for $0 \leq i &lt; n$</div><div>\item swap $s_i$ with $s_k$, where $k \in_R \{i, .., n-1\}$<br /></div>
What's the standard algorithm for randomly permuting a string?&nbsp;	\item Knuth's shuffle algorithm
What's a common problem with initializing static variables in C++?	\item If the initialization depends on other static variables, the C++ spec doesn't lay out in what order the variables will be initialized
What's another name for a Merkle tree?	\item A hash tree
What does $X \perp Y$ represent in machine learning?	\item Unconditional independence; $p(X, Y) = p(X)p(Y)$
What does $X \perp Y | Z$ represent in machine learning?	\item Conditional independence; $p(X, Y | Z) = p(X|Z)p(Y|Z)$
What's marginal independence another name for?	\item Unconditional independence
What's the pdf of the categorical distribution in machine learning?	\item $\text{Cat}(x|\theta) = \prod \theta^{\mathbb{I}(x_j = 1)}_j$
What's another name for the categorical distribution in machine learning?	\item The multinouilli distribution
What's the empirical distribution of $D = \{x_1, \dotsc x_n\}$?	\item $p_{emp}(A) = \frac{1}{N} \sum \delta_{x_i}(A)$<div>\item where $\delta$ is the Dirac measure</div>
What's the Dirac measure?	\item $\delta_x(A) = 1$ iff $x \in A$ else 0
What's the precision of a Gaussian distribution?	\item $\lambda = 1/\sigma^2$
What's the fundamental reason that the Gaussian distribution is so popular?	\item It makes the least number of assumptions in the sense that it's the distribution with maximal entropy when constrained to a specific mean and variance
What's the sifting property of a delta function?	\item $\int^\infty_{-\infty} f(x) \delta(x - \mu)dx = f(\mu)$
What's a Cauchy distribution?	\item A Student distribution with a single degree of freedom
What's a Lorentz distribution another name for?	\item A Cauchy distribution
What's notable about the Cauchy distribution?	\item The tails are so heavy that the integral for the mean doesn't converge
What do various degrees of freedom get you from a Student's distribution?	\item $\nu = 1$ is a Cauchy distribution<div>\item $\nu = 2$ is the minimum required to get finite variance</div><div>\item $\nu = 4$ is the usual setting that'll give good performance in a range of problems</div><div>\item $\nu &gt; 5$ rapidly approaches a Gaussian</div>
In machine learning, what's generally the advantage in using a Student's distribution over a Gaussian?	\item Heavier tails mean it's less sensitive to outliers
What's the advantage of the Laplace distribution over the Gaussian?	\item Heavier tails and a higher density at the origin, which is useful for encouraging sparsity in a model<br />
What's the pdf of the Laplace distribution?	\item $Lap(x|\mu, b) = \frac{1}{2b}exp(-\frac{|x-\mu|}{b})$
What are the common special cases of the Gamma distribution?	\item Exponential, $Exp(x|\lambda) = Ga(x|1, \lambda)$<div>\item Erlang, $Erl(x|k, \lambda) = Ga(x|k,\lambda)$</div><div>\item Chi-squared, $\chi^2(x|\nu) = Ga(x|\frac{\nu}{2}, \frac{1}{2})$</div>
What does the inverse Gamma distribution describe?	\item If $X \sim Ga(a, b)$ then $\frac{1}{X} \sim IG(a, b)$
How do different parameters affect the Beta distribution?	<div>\item If $a \leq 0$ or $b \leq 0$ then it's non-integrable&nbsp;</div>\item If $a, b = 1$ you get the uniform distribution<br /><div>\item If $a, b &lt; 1$ you get a bimodal distribution with spikes at $0, 1$</div><div>\item If $a, b &gt; 1$ you get a unimodal distribution</div>
What's the Pareto distribution usually used for?	\item Modelling quantities with very heavy tails
What's Zipf's Law?	\item That the frequency of words follows a power law
What's the pmf of the Poisson distribution?	\item $\text{Poi}(x|\lambda) = e^{-\lambda}\frac{\lambda^x}{x!}$
What's the support of the Poisson distribution?	\item Nonnegative integers
What's the usual use of the Poisson distribution?	\item Modeeling the counts of rare events (like nuclear decays)
What's the pdf of the Gaussian distribution?	\item $N(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp(-\frac{(x-\mu)^2}{2\sigma^2})$
What's the error function in probability?	\item $\text{erf}(x) = \frac{2}{\sqrt{\pi}}\int^x_0 e^{-t^2}dt$
How do you define the cdf of the Gaussian in terms of the error function?	\item $\Phi(x; \mu, \sigma) = \frac{1}{2} + \frac{1}{2}\text{erf}(\frac{x-\mu}{\sqrt{2}\sigma})$
What's the pdf of the Student $t$ distribution?	\item $T(x|\mu, \sigma^2, \nu) \propto \left[ 1 + \frac{1}{\nu} \left(\frac{x-\mu}{\sigma}\right)^2 \right]^{-\frac{\nu+1}{2}}$
What're the mean and variance of Student's t distribution?	\item Mean is $\mu$<div>\item Variance is $\frac{\nu}{\nu - 2}&nbsp;\sigma^2$</div>
What's the mean and variance of the Laplace distribution?	\item Mean is $\mu$<div>\item Variance is $2b^2$</div>
What are the names of the gamma distribution's parameters?	\item Either shape ($a$) and rate ($b$)<div>\item Or shape ($a$) and scale ($1/b$)&nbsp;</div>
What's the pdf of the Gamma distribution?	<div>\item With the shape and rate parameterization:</div>\item $\text{Ga}(x|a, b) = \frac{b^a}{\Gamma(a)}x^{a-1}e^{-bx}$
What's the definition of the Gamma function?	\item $\Gamma(x) = \int^\infty_0 u^{x-1} e^{-u} du$
What're the mean and variance of the gamma distribution?	<div>\item Using the shape and rate parameterization</div>\item Mean is $a/b$<div>\item Variance is $a/b^2$</div>
What's the mode of the gamma distribution?	\item With the shape and rate parameterization<div>\item the mode is $\frac{a-1}{b}$</div>
What's the pdf of the beta distribution?	\item $Beta(x|a,b) = \frac{1}{B(a,b)}x^{a-1}(1-x)^{b-1}$
What's the definition of the beta function?	\item $B(a, b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}$
What's the mean and variance of the beta distribution?	\item Mean is $\frac{a}{a+b}$<div>\item Variance is $\frac{ab}{(a+b)^2(a+b+1)}$</div>
What's the mode of the beta distribution?	\item $\frac{a-1}{a+b-2}$
What's the pdf of the Pareto distribution?	\item $\text{Pareto}(x|k, m) = \frac{km^k}{x^{k+1}}\mathbb{I}(x \geq m)$
How do the parameters to the Pareto distribution control its shape?	\item $m$ controls the minimum nonzero value<div>\item $k$ controls the falloff above that value; as $k \rightarrow \infty$, the distribution converges on $\delta(x-m)$</div>
What form does the Pareto distribution take when plotted on a log-log scale?	\item A straight line.
What's the mean of the Pareto distribution?	\item $\frac{k}{k-1}m$ if $k &gt; 1$
What's the definition of the Pearson correlation coefficient?	\item $\text{corr}(X, Y) = \frac{\text{cov}(X, Y)}{\sqrt{\text{var}(X)\text{var}(Y)}}$
What's the definition of the covariance?	\item $cov(x, y) = E[(x-E[x])(y-E[y])^T]$
What're the structural properties of a covariance matrix?	\item Symmetric<div>\item Positive definite</div>
What's the concentration matrix in statistics?	\item Inverse of the covariance matrix
What's another name for the precision matrix in statistics?	\item The concentration matrix
What's it mean for a covariance matrix to be isotropic?	\item It's got the form $\sigma^2 \mathbb{I}$, giving it one free parameter
Which distribution is most commonly used which has a support of the probability simplex?	\item The Dirichlet distribution
What's the multivariate generalization of the Beta distribution?	\item The Dirichlet distribution.
What's the covariance matrix of $Ax+b$?	\item $\text{cov}(Ax+b) = A \text{cov}(x) A^T$
What's the entropy of a distribution?	\item $H(X) = E_x[\ln p(x)]$
What's the binary entropy function?	\item $H(\theta) = - \theta \ln \theta - (1-\theta)\ln(1-\theta)$
What's relative entropy another name for?	\item The Kullback-Leibler divergence
How does the Kullback-Leibler divergence relate to the entropy for discrete distributions?	\item $KL(p\|q) = -H(p)+H(p,q)$
What's the definition of the cross entropy for discrete distributions?	\item $H(p, q) = -\sum p_k \ln q_k$
What's the intuitive interpretation of the cross entropy?	\item It's the average number of bits needed to encode data coming from a source with distribution $p$ when model $q$ is used to define the codebook
What's the intuitive interpretation of the KL divergence?	\item It's the average number of extra bits needed to encode a source with distribution $p$ using a codebook defined by a model $q$<div>\item compared to using a codebook defined by a model with distribution $p$</div>
What's Laplace's principle of insufficient reason?	\item If you've got a set of indistinguishable, mutually exclusive and collectively exhaustive events,<div>\item then you should use the uniform distribution to model them</div>
What's the definition of the conditional entropy?	\item $H(Y|X) = \sum p(x) H(Y|X = x)$
What's the fundamental definition of mutual information?	\item $\mbb{I}(X;Y) = \sum_{x, y} p(x,y) \ln \frac{p(x, y)}{p(x)p(y)}$
What's the definition of mutual information in terms of the KL divergence?	\item $\mbb{I}(X;Y) = KL(p(X, Y)|| p(X)p(Y))$
What's the definition of mutual information in terms of conditional entropy?&nbsp;	\item $\mbb{I}(X;Y) = H(X) - H(X|Y) = H(Y) - H(Y|X)$<div>\item ie it's the reduction in uncertainty about one variable you get from observing the other</div>
What's the intuitive interpretation of the mutual information?	\item It tells you how much knowledge one variable gives you about the other - like a more general correlation coefficient
What's the defintion of the pointwise mutual entropy?	\item $\text{PMI}(x, y) = \lg \frac{p(x,y)}{p(x)p(y)}$
What's the intuitive interpretation of the pointwise mutual information?	<div>\item It's the amount learnt by updating the prior $p(x)$ into the posterior $p(x|y)$</div>
How does the mutual information and the pointwise mutual information relate?	\item PMI is MI on a single event<div>\item MI is the expected value of the PMI</div>
How is the mutual information of an empirical distribution usually calculated?	\item By discretizing the data into bins and using that to calculate the MI
What's the use of the maximal information coefficient?	\item When discretizing a distribution so you can calculate the MI, the choice of bin grid can affect the results.<div>\item The MIC is calculated over all possible grids and a value of 0 represents no relationship; 1 represents a noise-free relationship *of any form*</div>
What's the defintion of the maximal information coefficient?	\item Let $m(i, j) = \frac{1}{\log \min(i, j)} \max_G I(X(G), Y(G))$<div>\item where $G$ is a 2D grid of dimensions $x \times y$ used to discretize the variables</div><div>\item Then $MIC = \max_{i, j : ij &lt; B} m(i, j)$, where $B$ is some upper bound on the number of bins.</div>
What's the typical number of bins used in calculating the MIC of a distribution?	\item $B = N^{0.6}$
What's a version space in machine learning?&nbsp;	\item It's the subset of the hypothesis space that's consistent with the data
What's the extension of a concept in machine learning?	\item The set of datapoints that'd be consistent with the concept
What's the size principle in machine learning?	\item A formalization of Occam's razor: you should favour the hypothesis in the version space with the smallest extension.
"How do you generally deal with ""unnatural"" hypotheses in a generative classifier?"	\item By suppressing them in the prior.
What's the relationship between the MAP and MLE estimates in statistics?	\item Under certain regularity conditions, the MLE converges to the MAP as the amount of data increases and overwhelms the prior.<br />
What's the MLE in statistics?	\item Maximum likelihood estimate
What does it mean for a hypothesis space to be identifiable in the limit?	\item That given infinite data, the true hypothesis could be recovered
What's the analogue of the observers belief state in Bayesian statistics?	\item The posterior distribution
What's Bayes model averaging?	\item Constructing a predictive density by summing over all possible hypotheses, weighted by their posterior probability<div>\item ie $p(\tilde x | D) = \sum p(\tilde x | h)p(h | D)$</div>
What's the plug-in approximation in machine learning?	\item The predictive distribution attained by assuming a posterior distribution entirely concentrated at the MAP estimate<div>\item ie $p(\tilde x \in C|D) = p(\tilde x | \hat h)$</div>
What's usually the problem with the plug-in approximation to the predictive density?	\item It drastically overestimates our confidence
What's the main contrast in how plug-in approximation-based predictive systems learn compared to how BMA-based predictive systems systems learn?	\item Plug-in based systems will start with a very narrow predictive distribution and gradually widen it as they receive data<div>\item BMA based systems will start with a very broad predictive distribution and gradually narrow it as they receive data</div>
What's a sufficient statistic for a data?	\item $s(D)$ is sufficient iff $p(\theta|D) = p(\theta|s(D))$
What're hyperparameters in statistics?	\item The parameters of the prior distribution
What are the assumptions of the naive Bayes classifier?	\item That the features are conditionally independent given the class label.&nbsp;
What's stemming in machine learning?	"\item Stripping common suffixes and prefixes off words to get them in their ""base form"""
What's the log-sum-exp trick in machine learning?	\item In order to avoid numeric underflow when working with very small probabilities, its best to apply Bayes rule using logarithms<div>\item However this can require taking the log of a sum, which obviously can't be broken down.</div><div>\item Solution is to factor the largest term out of the sum and take that outside the logarithm.</div><div>\item ie $\log \sum e^{b_c} = \log\left(\sum e^{b_c - B}\right) + B$</div><div>\item where $B = \max b_c$</div>
What's feature selection in machine learning?	\item Removing `irrelevant' features from a dataset to both accelerate any methods applied and to reduce the effect of overfitting
What're the three simplest approaches to document classification in machine learning?	\item Bernouilli product model: considers whether each word appears in a document<div>\item Multinomial model: considers number of times each word appears</div><div>\item Dirichlet compound multinomial: considers number of times and accounts for `burstiness'</div>
What's the burstiness problem in machine classification?	\item Most words don't appear in most documents, but when they do appear they appear a lot!
What's the simplest solution to the burstiness problem in machine learning?	\item Encountering one occurance of a word updates the posterior count on that word, making another occurance more likely.<div>\item This is the Dirichlet Compound Model.<br /><div>\item Also equivalent to a Polya urn, where on drawing a ball you replace it along with an additional copy.</div></div>
What's the problem with the Dirichlet Compound Multinomial model for document classification?	\item Fitting it is hard.
What's the pdf of the Dirichlet Compound Multinomial model?	<div>\item $p(\mathbf{x}|y = c, \mathbf{\alpha}) =&nbsp;\frac{N!}{\prod_j x_j!} \frac{B(\mathbf{x} +&nbsp;\mathbf{\alpha_c})}{B(\mathbf{\alpha_c})}$</div>
How does Student's t distribution arise?	\item It's the distribution of the sample mean of a $\nu+1$ item sample drawn from a Gaussian distribution<br />
How does a chi squared distribution arise?	\item It's the distribution of the sum of squares of $k$ independent standard normal variables
How does a Laplace distribution arise?	\item It's the distribution of the difference between two exponentially distributed random variables.
How does an Erlang distribution arise?	\item As the sum of $k$ exponentially distributed variables
What's the pdf of the Dirichlet distribution?	\item $Dir(x|\alpha) = \frac{&nbsp;\mathbb{I}(x \in S_K)}{B(\alpha)}\prod x_k^{\alpha_k - 1}$<div>\item where $S_K$ is the probability simplex on $K$ variables</div>
How is the beta function defined on $K$ variables?	\item $B(\alpha) = \frac{\prod_1^K \Gamma(\alpha_k)}{\Gamma(\alpha_0)}$<div>\item where $\alpha_0 = \sum_1^K \alpha_k$</div>
What's the usual mental model for a Dirichlet distribution?	\item It's the distribution of ball colors in a Polya urn - each time a ball is drawn, the ball is replaced along with one of the same color.
What're the mean and variance of a Dirichlet distribution?	\item Mean of variable $x_k$ is $\frac{\alpha_k}{\alpha_0}$<div>\item Variance of $x_k$ is $\frac{\alpha_k(\alpha_0 - \alpha_k)}{\alpha_0^2(\alpha_0 + 1)}$</div><div>\item where $\alpha_0 = \sum_1^K \alpha_k$</div>
What's the mode of the Dirichlet distribution?	\item For variable $x_k$ it's $\frac{\alpha_k - 1}{\alpha_0 - K}$<div>\item where $\alpha_0 = \sum_1^K \alpha_k$</div>
What are the categories of commands in SQL?	\item Schema statements, used to create tables/indexes/constraints/etc<div>\item Data statements, used to create/manipulate/retrieve data</div><div>\item Transaction statements, used to begin/end/rollback transactions</div>
What's a surrogate key in database systems?	\item An attribute generated by the DBMS, not derived from the data, whose only significance is to act as a key
How do you write a comment in SQL?	\item \ttt{/*..*/}
How do you log into MySQL as root from the commandline?	\item \ttt{mysql -u root -p}
How do you create a new empty database in SQL?	\item \ttt{create database databaseName}
How do you add a local user with full privileges to a MySQL database?	\item \ttt{grant all privileges on databaseName.* to 'username'@'localhost' identified by 'password';}
How do you attach to a database in MySQL?	\item \ttt{use databaseName;}
How do you load a \ttt{.sql} file into MySQL?	\item \ttt{source filename}
How do you fetch the current date and time in MySQL?	\item \ttt{SELECT now();}
What's the difference between char and varchar types in SQL?	\item \ttt{char(n)} values must be exactly \ttt{n} characters long (if the provided value is shorter, it'll be right-padded wtih spaces (these spaces will be stripped when the string is retrieved))<div>\item \ttt{varchar(n)} values can be less than \ttt{n} characters</div>
How can you set the character set of a attribute in MySQL?	\item \ttt{varchar(20) character set utf 8}
What SQL type should be used for long tracts of text?	\item \ttt{text} or one of it's variants (\ttt{mediumtext, longtext})
How are \ttt{text} values compared in MySQL?	\item On the first \~{}1024 bytes, though this can be increased
What're the MySQL numeric types?	\item \ttt{int} and its variants<div>\item \ttt{int unsigned} and its variants<br /><div>\item \ttt{float, double} and their variants</div></div>
What's MySQL's boolean type?	\item Doesn't have one - just aliases for \ttt{tinyint}, with 0 considered false and non-zero values considered to be true.
What're MySQL's main temporal types?&nbsp;	\item Date<div>\item Datetime</div><div>\item Time</div>
How do you create a SQL table?	\item \ttt{CREATE TABLE table\_name(attribute\_name type\_name, CONSTRAINT constraint\_name constraint);}
How do you constrain the values that an attribute can take in SQL?	\item \ttt{CREATE TABLE table\_name(attribute\_name type\_name CHECK (attribute\_name IN (value1, value2, value3)));}
How do you get a description of a table in MySQL?	\item \ttt{DESC tableName;}<br />
How do you define a foreign key constraint in SQL?	\item \ttt{CONSTRAINT fk\_name FOREIGN KEY (key\_in\_this\_table) REFERENCES other\_table (key\_in\_other\_table)}
How do you constrain an attribute to be non-null in SQL?	\item \ttt{CREATE TABLE table\_name(attribute\_name type\_name not null);}
How do you designate a primary key in SQL?	\item \ttt{CONSTRAINT pk\_constraint\_name PRIMARY KEY (key\_attr\_1,&nbsp;key\_attr\_2)}
What are the four SQL data statements?	\item \ttt{insert}<div>\item \ttt{update}</div><div>\item \ttt{delete}</div><div>\item \ttt{select}</div>
How do you automatically generate a primary key in PSQL?	\item \ttt{attr\_name INT UNSIGNED AUTO\_INCREMENT;}
How do you modify the definition of a SQL table?	\item \ttt{ALTER TABLE table\_name MODIFY component\_name /* new defn */}
How do you insert data into an SQL table?	\item \ttt{INSERT INTO table\_name (attr\_name\_1, attr\_name\_2) VALUES (value\_A1, value\_A2),&nbsp;&nbsp;(value\_B1, value\_B2);}<div>\item Values for attributes not specified are assumed to be null</div>
How do you order data returned by an SQL query?	\item \ttt{SELECT * FROM table\_name ORDER BY attr\_name}
How do you update a row in a table in SQL?	\item \ttt{UPDATE table\_name SET attr\_name\_1 = val\_1, attr\_name\_2 = val\_2 WHERE expr;}
How do you delete rows from a table in SQL?	\item \ttt{DELETE FROM table\_name WHERE expr}
How do you set temporal data in MySQL?	\item \ttt{attr\_name = str\_to\_date('JAN-1-2010', '\%b-\%d-\%y')}
How do you list the tables in a SQL database?	\item \ttt{SHOW TABLES;}
How do you remove a table from an SQL database?	\item \ttt{DROP TABLE table\_name;}
At a high level, how is a query processed by a SQL database?	\item Permissions are checked<div>\item Syntax is checked</div><div>\item Query optimizer generates an execution plan</div><div>\item Result set is returned to the calling application</div>
What are the six standard clauses possible in an SQL select statement?	\item Select<div>\item From</div><div>\item Where</div><div>\item Group by</div><div>\item Having</div><div>\item Order by</div>
What does the \ttt{HAVING} clause do in SQL?	\item Filters groups according to some predicate
How do you select all columns in an SQL query?	\item \ttt{SELECT *}
How can you transform the result of a SQL select query?	<div>\item With a literal: \ttt{SELECT 'string\_literal'}</div>\item With an expression: \ttt{SELECT col\_name * 2}<div>\item With a function call: \ttt{SELECT UPPER(col\_name)}</div>
How do you alias the columns headings returned by a SQL select query?&nbsp;	\item \ttt{SELECT col\_name alias\_name}<div>\item \ttt{SELECT col\_name AS alias\_name}</div>
How do you remove duplicates from the result set of a SQL query?	\item \ttt{SELECT DISTINCT col\_name}
How do you include duplicates in the result set of an SQL query?	\item \ttt{SELECT ALL col\_name}<div>\item This is the default though</div>
How do you create a subquery in SQL?	\item \ttt{... FROM (/* query */) AS alias\_name;}
How do you create a view in SQL?	\item \ttt{CREATE VIEW a (x, y, z) AS /* query */;}
What's a view in SQL?	\item A table defined in terms of other tables by way of a query statement
What're the standard boolean operations in SQL?	\item AND<div>\item OR</div><div>\item NOT</div>
How do you order results in specifically ascending or descending order in SQL?	\item \ttt{ORDER BY expr DESC;}<div>\item \ttt{ORDER BY expr ASC;} (default)</div>
How do you sort results by multiple attributes in SQL?&nbsp;	\item \ttt{ORDER BY expr\_1,&nbsp;expr\_2}
What's the inequality operator in SQL?	\item \ttt{&lt;&gt;}<div>\item Sometimes \ttt{!=} too</div>
What's the shorthand for a range-filtered query in SQL?	\item \ttt{WHERE exrp BETWEEN lower\_bound AND upper\_bound}<div>\item Will expand to a pair of \ttt{&gt;=, &lt;=} restrictions</div>
How do you test set membership in SQL?	\item \ttt{expr IN ('member1', 'member2', 'member3')}
How do you match strings against a simple pattern in SQL?&nbsp;	\item \ttt{expr LIKE 'pattern'}
What're the wildcards available for use in SQL's \ttt{LIKE} operator?	\item \ttt{\%} (zero or more characters)<div>\item \ttt{\_} (any single character)</div><div>\item \ttt{[charlist]} (single character from the class)</div><div>\item \ttt{[\^{}charlist]} (single character not from the class)</div>
How do you match against a range of characters with SQL's LIKE operator?	\item \ttt{expr LIKE '[a-c]'}
How do you match against regular expressions in MySQL?	\item \ttt{expr REGEXP 'pattern'}
What're the rules with null and equality in SQL?	\item While values can be null, they're never equal to null, nor are they not equal to null!<div>\item And null is not equal to itself, nor is it not equal to itself!</div><div>\item tl;dr 3VL</div>
How do you test whether a value is null in SQL?	\item \ttt{expr IS NULL}
How do you test whether a value is not null in SQL?	\item \ttt{expr IS NOT NULL}
What're the two main kinds of join available in SQL?	\item \ttt{INNER JOIN} (default for \ttt{JOIN})<div>\item \ttt{OUTER JOIN}</div>
What's a cross join in SQL?	\item The query \ttt{x CROSS JOIN y} that constructs a Cartesian product<div>\item Also the default of \ttt{x JOIN y}</div>
What's the difference between an inner join and an outer join in SQL?	\item Inner joins will only return rows for which the \ttt{ON} clause is true<div>\item Outer joins will return rows for which the \ttt{ON} clause is true, and rows for which there's no matching row in the other table (in which case the data is filled in with null)</div>
What's implicit join syntax in SQL?	\item It's the pre-SQL92 syntax for specifying joins<div>\item \ttt{FROM a, b WHERE a.x = b.y} is implicitly equivalent to the SQL92 \ttt{FROM a INNER JOIN b ON a.x = b.y}</div>
How do you join on three tables in SQL?	\item \ttt{FROM a INNER JOIN b \\<div>ON a.x = b.y \\&nbsp;</div><div>INNER JOIN c \\</div><div>ON a.x = c.z}</div>
Does the order in which tables are given in an SQL join matter?	\item Not usually. The query optimizer will pick the table to use as the `driving table' unless you hint that it shouldn't.
How do you use the same table twice in an SQL query?	\item Give it two different aliases;<div>\item \ttt{FROM abc AS a INNER JOIN abc AS b}</div>
What's an equi-join in SQL?	\item A join whose condition uses only equality comparisons
What's the shorthand for equi-joins in SQL?	\item \ttt{a INNER JOIN b USING (x, y)}<div>\item where \ttt{x, y} are the columns to join on</div>
What's a natural join in SQL?	\item A join on all columns with matching names, returning a table with one column for each matching pair of columns.
What's the problem with natural joins in SQL?	\item They're sensitive to schema changes; adding a new column to one table could change the result
What's a left outer join in SQL?	\item An join that returns rows satisfying its condition, but also rows from the left table with no matching row in the right table
How do you perform a natural join in SQL?	\item \ttt{a NATURAL JOIN b}
How do you perform a left outer join in SQL?	\item \ttt{a LEFT OUTER JOIN b}
What's the set operator precedence in SQL?	\item Intersect has highest precedence<div>\item and the rest is determined top-to-bottom&nbsp;</div>
How do you escape apostraphes in SQL?	\item With another apostraphe: \ttt{'don''t'}
What should you always do when passing string data in SQL?	\item Wrap the strings in a function like MySQL's \ttt{quote()} to automatically escape them
How do you count the number of rows in each group in a SQL query?	\item \ttt{SELECT COUNT(*) \\<div>FROM a \\</div><div>GROUP BY x}</div>
What're the five most common SQL aggregate functions?	\item \ttt{MAX()}<div>\item \ttt{MIN()}</div><div>\item \ttt{AVG()}</div><div>\item \ttt{SUM()}</div><div>\item \ttt{COUNT()}</div>
What's implicit grouping in SQL?	\item In the query<div>\item \ttt{SELECT x, MAX(x) \\ FROM a;}</div><div>\item the result set is implicitly gathered into a single group over which \ttt{MAX} is taken.&nbsp;</div><div>\item This only works though if the attribute things are being grouped by (\ttt{x}) has its own column &nbsp;in the results set.</div>
How do you count only distinct members of a group in SQL?	\item \ttt{COUNT(DISTINCT x)}
How does \ttt{COUNT()} interact with nulls in SQL?	\item It ignores them unless \ttt{COUNT(*)} is used
How would you get the year part of a date in SQL?	\item \ttt{EXTRACT(YEAR FROM date)}
When aggregating data over groups defined by multiple expressions in SQL, how can you automatically generate summaries for the subgroupings?	\item \ttt{GROUP BY a, b WITH ROLLUP;} which will generate groupings on \ttt{(), (a), (a, b)}<div>\item \ttt{GROUP BY a, b, c WITH CUBE;} which will generate groupings on \ttt{(), (a), (b), (a, b)}</div>
What're correlated and noncorrelated subqueries in SQL?	<div>\item Correlated subqueries reference columns from the containing query</div>\item Noncorrelated subqueries are standalone
What's a scalar subquery in SQL?	\item A subquery that returns a table with a single row and column
What's special about scalar subqueries in SQL?	\item They can be used in equality and comparison operators
When can a subquery be used as a set in SQL?	\item When it returns a single column.
How are the \ttt{ANY} and \ttt{ALL} operators used in SQL?	\item \ttt{expr = ALL set} tests whether expr is equal to all elements of set&nbsp;<div>\item \ttt{expr &lt;&gt; ANY set} tests whether expr is not equal to any one of the elements of set&nbsp;</div><div>\item etc for the other comparison operators</div>
What's a common mistake when using \ttt{IN} and \ttt{ALL} in SQL?	\item If the set being used contains \ttt{null}, you need to consider the query in the context of 3VL
How do you use subqueries that return multiple columns in SQL?	\item Use an alias<br /><div>\item Use a parenthesized expression containing the same column names in the same order as the result set of the subquery. Example:</div><div>\item \ttt{WHERE (x, y) IN (SELECT x y FROM a)}</div>
Why is the distinction between correlated and uncorrelated subqueries important?	\item Uncorrelated subqueries execute once<div>\item Correlated subqueries execute once for each candidate row</div>
What's SQL's \ttt{EXISTS} operator?	\item It returns true if its argument (usually a subquery) is nonempty.
When should you use a plain \ttt{JOIN} in SQL?	\item You shouldn't. When you intend to use a cross join, specify \ttt{CROSS JOIN} explicitly
How are switch statements implemented in SQL?	\item \ttt{CASE \\<div>WHEN expr1 THEN result1 \\</div><div>WHEN expr2 THEN result2 \\</div><div>ELSE result3 \\</div><div>END}</div><div>\item \ttt{CASE expr \\<div>WHEN val1 THEN result1 \\</div><div>WHEN val2 THEN result2 \\</div><div>ELSE result3 \\</div><div>END}</div></div>
Do SQL \ttt{CASE} expressions fall through?	\item Nope.
What are the granularities of locks available in SQL?	\item Table locks<div>\item Memory page locks</div><div>\item Row locks</div>
What are the common concurrency strategies implemented in SQL servers?	\item Read locks \&amp; write locks<div>\item Write locks \&amp; versioning to preserve read consistency</div>
What's a transaction in SQL?	\item A group of queries that are either all executed, or none of them are.
What are the two most common transaction creation strategies in SQL implementations?	\item Transactions are equivalent to database sessions<div>\item Users are in auto-commit mode until they explicitly start a transaction</div>
What should you always do when logging into an SQL database?	\item Disable auto-commit mode!
In what six scenarios are transactions commonly terminated by most SQL servers?	<div>\item On \ttt{commit}</div><div>\item On \ttt{rollback}</div>\item On shutdown (causing a rollback on restart)<div>\item On schema changes (causing a commit)</div><div>\item On creation of a new transaction (causing a commit)</div><div>\item On deadlock detection (causing a rollback)</div>
Why do schema changes end a transactions in most SQL implementations?	\item Because they can't be rolled back.
What's a storage engine in SQL?	\item The program responsible for low-level database activities like retrieving a particular row or issuing locks
How can you create a savepoint in a transaction in SQL?	\item \ttt{SAVEPOINT savepoint\_name;}
How do you return to a savepoint in SQL?	\item \ttt{ROLLBACK TO SAVEPOINT savepoint\_name;}
How do you start a transaction in MySQL?	\item \ttt{START TRANSACTION;}
How are rows ordered in an SQL table?	\item In no particular order; new rows will be inserted into the first free space.
How do you create an index for a column in SQL?	\item \ttt{CREATE INDEX a\_x\_idx&nbsp;ON a (x);}
How do you get a list of the indexes for a table in SQL?	\item \ttt{SHOW INDEX FROM a;}
When are indexes are automatically created in SQL?&nbsp;	\item In most implementations, a unique index \ttt{PRIMARY} on the primary key (if specified)<div>\item Foreign key and uniqueness constraints can create indexes in some implementations, but not others</div>
What's the default datastructure underlying an SQL index?	\item A b-tree
How do you remove an index from a table in SQL?	\item \ttt{DROP INDEX index\_name;}
How do you create a unique index in SQL?	\item \ttt{CREATE UNIQUE INDEX a\_x\_idx \\<div>ON a (x)}</div>
What's the effect of a unique index in SQL compared to a regular index?	\item It enforces a uniqueness constraint
What's important about the ordering of columns in a compound index in SQL?	\item The index will only be useful for lookups using the heads of the column list<div>\item So if you build an index on \ttt{(x, y, z)}, it's useful for looking up \ttt{(x), (x, y), (x, y, z)}</div>
What index datastructures are commonly available in SQL?	\item B-tree indexes<div>\item Bitmap indexes</div><div>\item Hash indexes</div><div>\item Text indexes</div>
When should you use each of the SQL index datastructures?	\item B tree indexes in general<div>\item Bitmap indexes when there are only a few possible values for the column (low-cardinality data)</div><div>\item Text indexes when the data is comprised of documents</div>
How do you create a bitmap index in SQL?	\item \ttt{CREATE BITMAP INDEX a\_x\_idx ON a (x);}
How do you view the execution plan for a query in MySQL?	\item \ttt{EXPLAIN /* query */}
What're the problems with SQL indexes?	\item Every time a table is modified, indexes on it will be modified too.<div>\item They take up disk space</div><div>\item They entail extra maintenance time</div>
What's the standard strategy as to which columns to index in SQL?	\item Primary keys<div>\item Columns referenced as foreign keys</div><div>\item Columns that'll be frequently used to fetch data (such as dates)</div>
What are the four most common kinds of constraints in SQL?	\item Primary key&nbsp;constraints<div>\item Foreign key&nbsp;constraints</div><div>\item Uniqueness constraints</div><div>\item Check constraints</div>
How do you remove a primary key constraint from a table in SQL?	\item \ttt{ALTER TABLE a \\<div>DROP PRIMARY KEY;}</div>
How do you remove a foreign key constraint from a table in SQL?	\item \ttt{ALTER TABLE a \\<div>DROP FOREIGN KEY fk\_a\_name;}</div>
What's a cascading update in SQL?	\item One that propagates through foreign key constraints rather than throwing an error
How do you create a cascading update constraint in SQL?	\item \ttt{ALTER TABLE a \\<div>ADD CONSTRAINT fk\_a\_x FOREIGN KEY (x) \\</div><div>REFERENCES a (x)</div><div>ON UPDATE CASCADE;}&nbsp;</div>
How do you create a cascading deletion constraint in SQL?	\item \ttt{ALTER TABLE a \\<div>ADD CONSTRAINT fk\_a\_x FOREIGN KEY (x) \\</div><div>REFERENCES a (x)</div><div>ON DELETE CASCADE;}&nbsp;</div>
What's the main use of cascading constraints?	\item When using self-referential foreign key constraints<div>\item since you won't be able to insert a row otherwise</div>
What are the four main reasons to use views in SQL?	\item Data security<div>\item Data aggregation</div><div>\item Hiding complexity</div><div>\item Joining partitioned data</div>
How can views help with data security in SQL?&nbsp;	\item By granting users \ttt{SELECT} permissions on certain views but not on the underlying tables, you can conceal sensitive data.<div>\item This doesn't sound like a very solid strategy.</div>
Are views updateable in SQL?	\item They can be, but the conditions under which they are are complex and implementation-dependent&nbsp;<br />
How can you access metadata about a database in SQL?	\item By querying the \ttt{information\_schema} table
How can you generate database components automatically in SQL?	\item You can do it using SQL alone, but it's a pain.&nbsp;<div>\item Better to use a procedural language (PL/SQL, Transact-SQL, Java, etc)&nbsp;</div>
What're PL/SQL and Transact-SQL?	\item PL/SQL is an extension of SQL for Oracle products<div>\item Transact-SQL is an extension of SQL for Microsoft products</div>
What's a cache-oblivious algorithm?	\item One that's able to take advantage of a memory hierarchy without knowing the sizes of the levels
What are the five common implementations of a priority queue?	\item Sorted array or list<div>\item Binary heaps</div><div>\item Bounded height pqueue</div><div>\item Binary search trees</div><div>\item Fibonacci/pairing heaps</div>
What's the bounded height implementation of a priority queue?	\item Create an array of linked lists, one for each possible key value<br /><div>\item Keep a pointer to the least non-empty cell.</div>
When is the bounded height priority queue implementation optimal?	\item When there's only a small, discrete range of possible keys
When are Fibonacci or pairing heaps appropriate for a pqueue implementation?	\item When decrease-key operations need to be speeded up.
What's the structure of a pairing heap?	\item A pairing heap is either an empty heap, or a pair consisting of an element and a possibly empty list of pairing heaps.<div>\item In the latter case, the element is no larger than the roots in the list</div>
Describe the \ttt{merge-pairs(l)} operation on a pairing heap.	\item If \ttt{l} is an empty list, return an empty heap<br /><div>\item If \ttt{l} has one element, return it</div><div>\item if \ttt{l} has more than one element, return \ttt{merge(merge(l[0], l[1]), merge-pairs(l[2..]))}</div>
Describe the \ttt{merge(g, h)} operation of a pairing heap	\item If one of the heaps is empty, return the other<div>\item Else append the one with the smaller root element to the list of subheaps of the larger one</div>
What're the nontrivial operations on pairing heaps, and how do they work?	\item \ttt{delete-min} and works by returning \ttt{merge-pairs(heap.subheaps)} if the heap isn't empty<div>\item \ttt{decrease-key} changes the key of a node, and if necessary cutting it out of the parent node's list and then re-merging it.</div>
What're the advantages of the pairing heap?	\item It's very simple<br /><div>\item In practice, despite having worse bounds on \ttt{decrease-key} than a Fibonacci heap (log vs constant), it's faster</div>
What's a vEB tree?	\item A van Emde Boas tree, a tree that implements an associative array on $m$ bit keys<div>\item All operations run in $O(\lg m)$ time (so $O(\lg \lg n)$ time in the size of the largest key), including next/previous</div>
In practice, what's usually the optimal implementation of a priority queue?	\item A binary heap over an array. It's competitive with pairing heaps up to a large number of elements.
What's a suffix tree?	\item A radix tree of all the suffixes of a string.
What's the difference between a trie and a radix tree?	\item Tries can only have one letter per node<div>\item Radix trees can have substrings in each node</div>
How much space does a suffix tree take?	\item $O(n)$ in the size of the source string
How do you construct a suffix tree in linear time?	\item Using Ukkonnen's algorithm or one of its successors. Highly nontrivial.
What are the two most popular uses of suffix trees?	\item Finding substrings<div>\item Finding longest common substrings</div>
What's a suffix array?	\item An array of integers providing the starting positions of suffixes of $S$, sorted in lexicographic order
What're the advantages of suffix arrays over suffix trees?	\item They use less memory<div>\item Linear-time construction of sarrays is much simpler than strees</div><div>\item They exploit cache locality</div><div>\item Any algorithm using suffix trees can be adapted to use a suffix array and (if necessary) a LCP array while maintaining their time bounds</div>
What's a LCP array?	\item A longest common prefix array, an auxilliary structure to a suffix array<div>\item It stores the lengths of the longest common prefixes between consecutive elements of the suffix array</div>
What's a compressed suffix array?	\item A variant of the suffix array that uses $O(n \lg |\Sigma|)$ space rather than sarrays' $O(n \lg n)$ space.<div>\item Uses wavelet trees to carry out the compression.</div>
What's the BWT algorithm?	\item The Burrows-Wheeler Transform, which is a reversible rearrangement of a string into runs of similar characters<div>\item The rearranged string can then be more efficiently compressed&nbsp;</div>
What're the usual data structures for representing hypergraphs?	\item Incidence matricies, with \ttt{M[i, j] == 1} if vertex $i$ appears in edge $j$<div>\item Incidence lists, which contain the element $(i,j)$ if vertex $i$ appears in edge $j$&nbsp;</div>
What's a static graph representation?	\item A data structure for graphs which won't be modified during the course of an algorithm<div>\item Ex: using a 2d array to implement an adjacency list.</div>
How are extremely large graphs commonly implemented?	\item As hierarchies, with subgraphs represented as nodes in a parent graph<div>\item A natural/domain-specific partitioning is preferred to a naive heuristic</div>
What are dynamic graph algorithms?	\item Algorithms that can efficiently recompute some property of a graph after insertion or deletion of some edges
What's sparsification in the context of graph algorithms?	\item A general approach to designing dynamic graph algorithms.
What are the usual representations of sets?	<div>\item Arbitrary containers</div>\item Bit vectors<div>\item Hash sets<br /><div>\item Bloom filters</div></div>
What're the common implementations of a set partition datatype?	\item Collection of arbitrary containers<div>\item Generalized bit vector</div><div>\item Dictionary onto a set ID attribute</div><div>\item Union-find&nbsp;</div>
How are KD trees usually constructed?	\item Recursively partition a set of points into the points less than and the points greater than the median along a selected axis
How is the axis to partition points by in a KD tree node usually selected?	\item Either by cycling through the dimensions<div>\item Or by selecting the dimension with the greatest range, which encourages cube-shaped boxes</div>
What range of dimensions are KD trees best in?	\item 2-20.<div>\item Above that the number of neighbours gets too high</div>
How is bandwidth minimization relevant to storing graphs?	\item By picking a bandwidth-minimized permutation of the graph's vertices, locality of access can be improved
Roughly how large does a matrix have to be before Strassen's beats naive multiplication?	\item About $100 \times 100$
What's Strassen's algorithm?	\item A $O(n^{2.81})$ algorithm for matrix muliplication
What's the Cooley-Tukey algorithm?	\item The most common algorithm for calculating the FFT, which uses divide-and-conquer and the roots of unity.
What's a common optimization in chained matrix multiplications?	\item Matrix multiplication is associative, so use a DP algorithm to order the multiplications
What's the polytime algorithm for computing the determinant?	\item Calculate the LU factorization and take the product of the diagonal elements
What's a linear congruential generator?	<div>\item A very simple and (with the right constants) reasonably good PRNG:</div>\item $R_n = (aR_{n-1} + c) \mod m$
What's the main problem with linear congruential generators?	\item Low period. A 32-bit LCG can repeat inside a few minutes on modern machines.
What's the simplest way to approximate arbitrary random number distributions?	\item Accept-reject methods: pick a value of $x$ uniformly, then a $y \in [0, 1]$ uniformly.&nbsp;<div>\item If $f(x) &lt; y$, accept it, else reject and try again.</div>
What's Karatsuba's Algorithm?	\item A $O(n^{1.6})$ algorithm for multiplication
When does Karatsuba's Algorithm beat out the naive approach?	\item Somewhere under 100 digits
When does bucket sort make sense?	\item When the input is known to be uniformly distributed
What's the worst-case runtime of a radix sort?	\item $O(kn)$ on $k$-character keys and $n$ items
How does a radix sort work?	\item For each digit, going from least to most significant,&nbsp;group the input by the digit's value, making sure to preserve the order within a group.<div>\item A bucket or counting sort can be used for the grouping stage.</div>
What's the functional difference between a LSB-first and MSB-first radix sort?	\item LSB is stable; MSB isn't.<div>\item MSB will stop rearranging a key after reaching its unique prefix</div>
How does a counting sort work?	\item If the maximum key is $m$, create an array of length $m$.<div>\item Sweep the input, counting how many of each key there is</div><div>\item Calculate the partial sums of the array</div><div>\item Insert the input into the output array using the partial sums, incrementing a sum each time a value is inserted into the range following it</div>
What's the best way to sort a small range of distinct integers?	\item Create a bit vector the size of the range<div>\item Sweep the input, flipping the corresponding bit.</div><div>\item Sweep the bit vector to get the sorted output.</div>
What's an optimal binary search tree?	\item A binary search tree that's been adjusted to represent the access distribution
At a high level, how is an optimal binary search tree constructed?	\item By dynamic programming and by observing that each possible root node partitions the space of keys into two smaller ranges, and that each subrange should be represented by its own optimal binary search tree.
At a high level, how does the Stout-Warren algorithm work?	<div>\item Create a pseudo-root with the real root as it's right child.</div>\item Conduct tree rotations until the tree forms a right chain, then rotate it back into a balanced tree.
What's the best algorithm for finding the $k$th order statistic?	\item Recursively use median of medians to partition the input and select the partition in which the $k$th order statistic lies.<div>\item By the Master Theorem, this is linear time.</div>
What's the lower bound on the runtime of any algorithm for computing the mode?	\item $O(n \lg n)$, as element uniqueness reduces to it
What are ranking and unranking functions in the context of permutation generation?	\item Given a permutation generation scheme,<div>\item $\text{Rank(p)}$ gives the position of permutation $p$ in the generation order</div><div>\item $\text{Unrank(m, n)}$ gives the permutation in position $m$ in the generation order when permuting $n$ elements</div>
What's the use of ranking \&amp; unranking function in generating permutations?	\item Once they're defined, several useful operations can be performed:<div>\item Finding the permutation after a given permutation</div><div>\item Generating a random permutation</div><div>\item Keeping track of a set of permutations&nbsp;</div>
What are the two general approaches to generating permutations?	\item For small $n$, define ranking \&amp; unranking functions<div>\item For larger $n$, define previous \&amp; next functions&nbsp;</div>
What're the steps in the Johnson-Trotter algorithm?	\item For each element, define a direction: $-, 0, +$.<div>\item Initialize the first element with direction $0$, and the others with $-$.</div><div>\item At each step, find the largest element with a nonzero direction and swap it in that direction.</div><div>\item If this causes the element to reach the end of the permutation, or if the next element in the same direction is larger than the chosen element, set the direction of the chosen element to $0$.</div><div>\item Now set the directions of all elements larger than the chosen element to $+$ if they're to the left of it and $-$ if they're right of it.</div>
What's the best algorithm for generating permutations in sequence?	\item Johnson-Trotter<div>\item aka change ringing</div>
What are the three main approaches to generating all subsets of a set?	\item Lexicographic order (hard)<div>\item Gray code</div><div>\item Binary counting</div>
What's the best way to generate subsets containing exactly $k$ elements?	\item Lexicographic order.
What's an efficient way of generating Gray codewords in sequence?	\item Start with the all zero codeword.<div>\item At step $i$, find the position $j$ of the least significant $1$ in the binary representation of $i$</div><div>\item and flip bit $i$ in the codeword.</div>
What's the best way to generate all integer partitions of a number?	\item Use lexicographically decreasing order<div>\item Start with the integer to be partitioned,&nbsp;$n$</div><div>\item Subtract 1 from the smallest part that is $&gt;1$</div><div>\item then gather all the 1s so as to match the new smallest part $&gt;1$</div>
How can you generate integer partitions uniformly at random?	\item The partition function $P_{n,k}$, the number of partitions of $n$ with largest part at most $k$, has a simple recursive form.<br /><div>\item This can be used recursively to select the largest part of a random partition with the correct probabilities</div>
What's a restricted growth string in the context of set partition generation?	\item A sequence $a_1, \dotsc, a_n$<div>\item such that $a_i \leq 1+\max(a_1, \dotsc, a_{i-1})$</div>
How do restricted growth strings correspond to set partitions?	\item Each distinct number in the string corresponds to a block of the partition<div>\item So $0, 1, 1$ corresponds to $\{\{0\}, \{1, 2\}\}$&nbsp;</div>
How do you generate a set partition uniformly at random?	\item Stirling numbers of the second kind ${n \brace k}$ count the number of partitions of an $n$ element set with $k$ blocks.<div>\item This can be used in a recursive manner to generate partitions uniformly at random.</div>
What are integer compositions?	\item A representation of the possible assignments of $n$ indistinguishable balls to $k$ boxes
What are the three strategies commonly used to generate random graphs?	\item Including edges with a specified probability<div>\item Including $m$ random edges</div><div>\item Selecting neighbours for each node in proportion to how many neighbours the targets currently have (power law graphs)</div>
What's a Prufer code?	\item They're a way to rank \&amp; unrank labelled trees by bijecting each tree onto a $n-2$ length string $s$ on the alphabet $\{1, \dotsc, n\}$
How do you generate the Prufer code associated with a tree?	\item For $i \in \{1, \dotsc, n\}$, pick the vertex $v$ incident on the leaf with the lowest label. Set $s_i = \text{label}(v)$ and remove the leaf.
How do you generate the tree associated with a Prufer code?	\item Given a code $s$, the lowest-labelled leaf will be the smallest integer $u$ missing from $s$.&nbsp;<div>\item The first edge will be from $u$ to the vertex $v$ corresponding to $s_1$.</div><div>\item Proceed recursively from this.&nbsp;</div>
How can you generate a graph corresponding to a specific degree sequence?	\item Given degree sequence $\{p_1, \dotsc, p_n\}$ going from highest to lowest<div>\item Connect vertex $v_1$ to $v_2, \dotsc, v_{p_1+1}$</div><div>\item Reduce the degree counts and repeat.</div><div>\item If any degree count becomes negative, no graph corresponds to this degree sequence (there's a simpler condition to test this)</div>
At a high level, what needs to be done to implement calendrical calculations?	\item Pick an epoch to count from.<div>\item Create a function that converts a count since epoch to a date in your given calendar system.</div><div>\item Create a function that converts a date in your given calendar system into a count since epoch.</div><div>\item Don't actually do this</div>
What're the steps in Kosaraju's algorithm?	\item Given a digraph $G$ and an empty stack $S$<div>\item While $S$ doesn't contain all vertices:</div><div>\item Pick an arbitrary vertex $v \not \in S$ and perform a DFS from $v$. When a vertex $u$ has been processed and its children all DFSd, push $u$ into $S$</div><div>\item Reverse the directions of all arcs to get the transpose graph.</div><div>\item While $S$ is nonempty:</div><div>\item Pop the top vertex $v$ and perform a DFS from it. Record all visited vertices - this is the strongly connected component of $v$. Remove all these vertices from the graph and stack.</div>
What's the best algorithm for finding strongly connected components in a digraph?	\item Kosaraju's algorithm. It's easier to program than Tarjan's.
What's a feedback arc set in graph theory?	\item A set of edges that can be removed from a graph in order to convert it to a DAG.<br />
What's a linear extension in graph theory?	\item Another name for a topological sort of a graph.
What's an easy way to generate a linear extension of a graph uniformly at random?	\item Take any topological sort and try to swap a pair of vertices.&nbsp;<div>\item If the resulting permutation is still a topological sort, this is a random linear extension.</div><div>\item A large number of iterations will converge on a uniform distribution over the linear extensions of the graph.</div>
What's the fastest (reasonably simple) algorithm for calculating MSTs in practice?	\item Prim's over an array heap.
What's a particularly fast randomized algorithm for minimum cuts?	\item Karger's algorithm: repeatedly pick an edge at random and contract it until there're only two vertices left. The number of edges between these vertices is the candidate minimum cut.<div>\item Repeat this a whole pile of times and take the minimum.</div>
What are the two main classes of algorithm for network flow problems?	\item Augmenting path methods (Ford-Fulkerson, etc)<div>\item Preflow-push methods&nbsp;</div>
How do preflow-push methods work in the solution of network flow problems?&nbsp;	\item Flows are pushed from one vertex to its neighbours, ignoring the zero-sum-flow-at-nodes constraint.<br />
How do preflow push methods compare to augmenting path methods in the solution of network flow problems?	<div>\item Preflow push methods are generally faster than augmenting path methods</div>
What's the best known runtime for graph planarity testing problem?&nbsp;	\item Linear, though the algorithms used are complicated.
What's the pdf for a multivariate Gaussian?	\item $N(x|x, \Sigma) =\exp&nbsp;\frac{1}{\sqrt{(2\pi)^D |\Sigma|}}&nbsp;&nbsp;\left[-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right]$
What're the isoclines of a multivariate Gaussian distribution?	\item They're ellipses with axes $u_1, u_2$, coefficients $\sqrt{\lambda_1},&nbsp;\sqrt{\lambda_2}$ and center $\mu$.<div>\item where $u_i$ are the eigenvectors of $\Sigma$ and $\lambda_1$ are the eigenvalues</div>
What's the definition of the Mahalanobis distance?	\item $d(x, y) = \sqrt{(x-y)^T S^{-1} (x-y)}$
What's the use of the Mahalanobis distance?	\item It's a statistic intended to gauge similarity between two samples
What distinguishes the Mahalanobis distance from the Euclidean distance?	\item Takes into account correlations in the data<div>\item Is scale-invariant</div>
What're the two possible estimators for a normal distribution's variance, and what're the advantages of each?	\item $s^2 = \frac{1}{n-1} \sum(x_i - \bar x)^2$ is unbiased.<div>\item $\hat \sigma^2 = \frac{1}{n} \sum(x_i - \bar x)^2$ is biased (underestimates $\sigma^2$) but has slightly lower MSE.</div>
What's Bessel's correction in statistics?	\item Using $n-1$ rather than $n$ in estimators for the sample variance and sample standard deviation
What're the caveats attached to Bessel's correction?	\item It gives an unbiased estimator of the variance but not of the standard deviation<div>\item It generally increases the mean square error</div>
Why does Bessel's correction still yield a biased estimator for the standard deviation?	\item Because square root is a concave function.&nbsp;
What's the trace trick in linear algebra?	\item $x^T A x = \text{tr}(x^T A x) = \text{tr}(Axx^T)$
What's the MLE for the mean of a multivariate Gaussian?	\item The sample mean
What's the MLE for the variance of a multivariate Gaussian?	\item The sample variance
What does GDA stand for in machine learning?	\item Gaussian discriminant analysis
What's GDA equivalent to when the covariance matrix is the identity?	\item Naive Bayes classification.
What's GDA equivalent to under the Mahalanobis distance?	\item A nearest centroid classifier
What's the difference between a generative and a discriminative model in machine learning?	\item Generative models can generate datapoints from some joint distribution (typically with hidden parameters)<div>\item Discriminative models must work with a supplied dataset only</div>
What's QDA stand for in machine learning?	\item Quadratic discriminant analysis
What's quadratic discriminant analysis?	\item Assume the prior probability for a class label $c$ is $\pi_c$<div>\item and assume $p(x|y=c, \theta)$ is a multivariate Gaussian distribution&nbsp;</div><div>\item Then use Bayes to construct the class posterior $p(y = c|x, \theta)$</div><div>\item Thresholding the resultant formula yields quadratic discriminant analysis</div>
What's LDA stand for in machine learning?	\item Linear discriminant analysis<div>\item Latent Dirichlet allocation</div>
What's linear discriminant analysis?	\item Take QDA and assume $\Sigma_c = \Sigma$ for all $c$.&nbsp;<div>\item Then in the exponent&nbsp;</div><div>\begin{itemize}</div><div>\item throw away the quadratic term in $x$ (because it's independent of $c$)</div><div>\item define $\beta_c$ to be the linear coefficient of $x$</div><div>\item define $\gamma_c$ to be the constant.</div><div>\end{itemize}</div><div>\item Then let $\eta&nbsp;= [\beta^T_1 x + \gamma_1, \dotsc, \beta^T_C x + \gamma_C]$</div><div>\item and we can write $p(y=c|x, \theta) = \mathcal{S}(\eta)_c$ using the softmax function</div>
What's the definition of the softmax function?	\item $\mathcal{S}(\eta)_c = &nbsp;\frac{e^{\eta_c}}{\sum_{c^\prime} e^{\eta_{c^\prime}}}$
What's the asymptotic behavior of the softmax function?	\item $\mathcal{S}(\eta/T)_c$ concentrates on $\text{argmax}_{c^\prime} \eta_{c^\prime}$ with value 1 as $T \rightarrow 0$
What's another function very similar to the softmax function?	\item The Boltzmann distribution
What does LDA degenerate to in the case of two classes?	\item $p(y=1|x, \theta) = \text{sigm}(w^Tx + x_0)$<div>\item for some $w$, $x_0$ that can be derived from $\Sigma, \mu_0, \mu_1$ and $\pi$</div>
What's the definition of d-prime in machine learning?	\item $d^\prime = \frac{\mu_1 - \mu_0}{\sigma}$
What does the d-prime of a pair of distributions represent in machine learning?	\item Discriminability of a signal from background noise<div>\item Large $d^\prime$, easier to discriminate</div>
How do you fit a GDA model using the MLE?	\item Factor the log-likelihood into a class priors term and $C$ log-Gaussian, one for each class $c$<div>\item Estimate the class prior $\pi_c$ as $N_c / N$</div><div>\item Partition the data according to class label and estimate &nbsp;$\mu_c, \Sigma_c$ for each class independently using the sample mean and variance</div>
What's the definition of the sample variance for a multivariate distribution?	\item $\hat \Sigma = \frac{1}{N} \sum (x_i - \hat \mu)(x_i - \hat \mu)^T$
When will the MLE for a full covariance matrix be singular?	\item When the number of datapoints is less than the dimension<div>\item It can be ill-conditioned even when there are more datapoints than the dimension though!</div>
What does it mean for a matrix to be ill-conditioned in machine learning?	\item Means its close to singular.
What are six strategies to use when overfitting occurs with the MLE in GDA?	\item Use a diagonal covariance matrix<div>\item Share the covariance matrix across classes (ie LDA)</div><div>\item Use a diagonal, shared covariance matrix (ie diagonal covariance LDA)</div><div>\item Impose a prior then integrate it out (ie Bayesian naive Bayes)</div><div>\item Fit a full or diagonal covariance matrix using MAP estimation instead</div><div>\item Project onto a lower dimension</div>
What's regularized discriminant analysis?	\item It's LDA with a IW prior enforced on the covariance matrix and integrated out<br />
What's the definition of the pooled empirical variance?	\item $s^2 = \frac{1}{N-C} \sum_c \sum_{i : y_i = c} (x_i - \bar x_{c})^2$
What's done in diagonal LDA?	\item Take LDA and enforce a diagonal covariance matrix<div>\item and take the variance to be the pooled empirical variance of the set</div>
What's the idea in nearest shrunken centroids classification?	\item Write $\mu_{cj} = m_j + \Delta_{cj}$<div>\item and put a sparsity-promoting prior (like a Laplace prior) on the $\Delta_{cj}$</div><div>\item Compute a MAP estimate.&nbsp;</div><div>\item If for some feature $j$ all $\Delta_{cj} = 0$, that feature is not discriminative and will be automatically ignored.</div>
Given a Gaussian joint distribution $p(x, y)$, what're the marginals?	\item $x \sim \mathcal{N}(\mu_x, \Sigma_{xx})$<div>\item $y \sim \mathcal{N}(\mu_y, \Sigma_{yy})$</div>
Given a Gaussian joint distribution $p(x, y)$, what's the precision-mean of $p(x|y)$?	\item $\Lambda_{x|y}\mu_{x|y} = \Lambda_{xx}\mu_x - \Lambda_{xy}(y - \mu_y)$
Given a Gaussian joint distribution $p(x, y)$, what's the precision matrix of $p(x|y)$?	\item $\Lambda_{x|y} = \Lambda_{xx}$<br />
Given a Gaussian joint distribution $p(x, y)$, what's the distribution of $p(x|y)$?	\item $x|y \sim \mathcal{N}(\mu_{x|y}, \Sigma_{x|y})$<div>\item Can be used when $x_1, x_2$ are vectors, as can the other, similar results</div>
What're the moment parameters of a Gaussian distribution?	\item $\mu$<div>\item $\Sigma$</div>
What're the canonical parameters of a Gaussian distribution?	\item $\Lambda = \Sigma^{-1}$<div>\item $\xi = \Sigma^{-1}\mu$</div>
What's another name for the natural parameters of a Gaussian distribution?	\item The canonical parameters
What're the advantages of the canonical parameterization of the Gaussian?	<div>\item Conditional distributions,</div><div>\item and product distributions</div><div>\item have a much simpler form than they do in the moment parameterization</div>
What are two key mathematical tools for use in inverting partitioned matricies?	\item Schur complements<div>\item Sherman-Morrison-Woodbury formula</div>
What's a linear Gaussian system?	\item A system with the form<div>\item $p(x) = \mathcal{N}(x|\mu_x, \Sigma_x)$</div>\item $p(y|x) = \mathcal{N}(y|Ax+b, \Sigma_y)$
Given a linear Gaussian system with conditional $p(y|x)$, what's the distribution of $p(x|y)$?	<div>\item $p(x|y) = \mathcal{N}(x|\mu_{x|y}, \Sigma_{x|y})$</div>
Given a linear Gaussian system with conditional $p(y|x)$, how is &nbsp;the $\Lambda_{x|y}\mu_{x|y}$ of $p(x|y)$ defined?	\item $\Lambda_{x|y}\mu_{x|y} = \Lambda_x\mu_x + A^T\Lambda_y(y-b)$
Given a linear Gaussian system with conditional $p(y|x)$, how is &nbsp;the precision of $p(x|y)$ defined?	\item $\Lambda_{x|y} = \Lambda_x + A^T\Lambda_y A$
Given a linear Gaussian system with conditional $p(y|x)$, what's the distribution of $p(y)$?	\item $p(y) = \mathcal{N}(y|A\mu_x + b, \Sigma_y + A\Sigma_x A^T)$
What's sensor fusion in machine learning?	\item Using readings from multiple noisy sensors to predict a parameter
How do you revert all unsaved changes to a file in vim?	\item \ttt{:e!}
How do you overwrite a file in vim?	\item \ttt{:w!}
How do you get vim to automatically insert newlines?	\item \ttt{:set wrapmargin=10} will insert them ten characters before the right border<br />
How do you enable line numbers in Vim?	\item \ttt{:set number}
How do you move back a word in vim?	\item \ttt{b}
What's the difference between change and replace in vim?	\item Change will delete a portion of text then stick you in insert mode to replace it<div>\item Replace mode will let you overwrite the text as you go</div>
What's the general form of a vim command?	\item \ttt{(command)(number)(object)}<div>\item Command is optional; without it you just get a movement</div><div>\item Number is optional; unspecified, it defaults to 1</div><div>\item Object is optional for some commands</div>
How do you change a whole line in vim?	\item \ttt{cc}<div>\item Shorthand for \ttt{c\_}</div>
What's the whole-line movement in vim?	\item \ttt{\_}
How do you change up to the end of the line in Vim?	\item \ttt{C}<div>\item shorthand for \ttt{c\$}</div>
How do you delete until the end of the line in vim?	\item \ttt{D}<div>\item shorthand for \ttt{d\$}</div>
How do you give repeat counts to vim commands that have single-character effects, like \ttt{c}?	\item \ttt{(number)(command)(object)}
How do you change the case of a character in vim?	\item \ttt{\~{}} will toggle between uppercase and lower case
How do the default deletion buffers work in vim?	"\item The last 9 whole deleted lines are stored in numbered buffers, and can be recalled with \ttt{""3p} or similar<div>\item Words and characters are stored in a temporary buffer that'll be overwritten with the next change/delete/yank/etc command</div>"
How do you transpose two letters in vim?	\item \ttt{xp}&nbsp;<div>\item (\ttt{x} deletes the character and stuffs it in the buffer, \ttt{p} pastes it after the new character under the cursor)</div>
How do you repeat your previous command in vim?	\item \ttt{.}
How do you enter insert mode at the beginning of a line in vim?	\item \ttt{I}
How can you join two consecutive lines in vim?	\item \ttt{J} while in the first line
How do you scroll down by a half-screen in vim?&nbsp;	\item \ttt{Ctrl-D}
How do you scroll up by a half-screen in vim?	\item \ttt{Ctrl-U}
How do you move the current line to the top of the screen in vim?	\item \ttt{z}
How do you move the current line to the center of the screen in vim?	\item \ttt{z.}
How do you move the current line to the bottom of the screen in vim?	\item \ttt{z-}
How do you move a specific line number to the top of the screen in vim?	\item \ttt{200z}
How do you move the cursor to the top of the screen in vim?	\item \ttt{H} (for home)
How do you move the cursor to the middle of the screen in vim?	\item \ttt{M}
How do you move the cursor to the bottom of the screen in vim?	\item \ttt{L}
How do you move the cursor to the 5th line down the screen in vim?	\item \ttt{5H}
How do you move to the first character of the next line in vim?	\item Enter.
How do you move to the first character of the previous line in vim?	\item \ttt{-}
How do you move to the 50th column in vim?	\item \ttt{50|}
How do you move to the end of the word, ignoring punctuation in vim?	\item \ttt{E}
How do you move to the ends of a sentence in vim?	\item \ttt{(} and \ttt{)}
How do you move to the ends of a paragraph in vim?	\item \ttt{\{} and \ttt{\}}
How do you move to the ends of a code block in vim?	\item \ttt{[\{} and \ttt{]\}}
How do you move to the ends of a parenthesized expression in vim?	\item \ttt{[(} and \ttt{])}
How do you search backwards in vim?	\item \ttt{?pattern}
How can you repeat the previous forward search in vim?	\item \ttt{/}
How do you delete text up to and including a specific word in vim?	\item \ttt{d/pattern}
How do you move the cursor to the first occurance of \ttt{z} in a line?	\item \ttt{fz}<div>\item (\ttt{f} for find)</div>
How do you move the cursor to one before the character \ttt{z} in a line in vim?&nbsp;	\item \ttt{tz}
How can you repeat a find command in vim?	\item \ttt{;}
How can you repeat a find command in vim, but in the other direction?	\item \ttt{,}
How do you find the previous occurance of the character \tt{z} in vim?	\item \ttt{Fz}
How do you return the cursor to a position it was in when you issued a command in vim?	\item \ttt{``}
How do you return the cursor to the start of the line it was in when you issued a command in vim?	\item \ttt{''}
From the commandline, how do you open a file in read-only mode in vim?	\item \ttt{vim -R filename}
How do you get a list of autosaved files from vim?	\item \ttt{vim -r}
How do you recover an autosaved copy of a file in vim?	\item \ttt{vim -r filename}
How can you search through the numbered yank buffers in vim?	"\item \ttt{""1p}<div>\item Then \ttt{u} and \ttt{.} to auto-increment and put the previous buffer</div>"
How do you yank a line into a named buffer in vim?	"\item \ttt{""kyy} will yank into buffer \ttt{k}&nbsp;"
How do you put before the cursor in vim?	\item \ttt{P}
How do you yank a whole line in vim?	\item \ttt{yy}
How do you append a line to a named buffer in vim?	"\item \ttt{""Kyy} will append to the k buffer"
How do you set a named bookmark in vim?&nbsp;	\item \ttt{mk} will set a bookmark called k
How do you move to the line containing a named bookmark in vim?	\item \ttt{'k} will move to bookmark k
How do you move to a named bookmark in vim?	\item \ttt{`k} will move to bookmark k
What's \ttt{ex} in Unix?	\item The line editor that \ttt{vi} is built on
Which vim commands start with a colon?	\item The ones that're actually commands to the underlying \ttt{ex} line editor
How do you invoke \ttt{ex} from vim?	\item \ttt{Q}
How do you get from \ttt{ex} in vim back to vim?	\item Give the command \ttt{vi}
In \ttt{ex} commands, how can you refer to the current line number?	\item \ttt{.}
In \ttt{ex} commands, how can you refer to number of the last line of the file?	\item \ttt{\$}
In \ttt{ex} commands, how can you refer to all lines?	\item \ttt{\%}
In \ttt{ex} commands, how can you refer to the number of the 20th line after the current line?	\item \ttt{.+20}<div>\item \ttt{+20}</div>
In \ttt{ex} commands, how can you refer to the number of the line 20 lines before the current line?	\item \ttt{.-20}<div>\item \ttt{-20}</div>
In \ttt{ex} commands, how can you refer to the before-the-first line in a file?	\item \ttt{0}
When addressing ranges of lines in \ttt{ex}, how can you give the second line number relative to the first?	\item \ttt{:100;+5}
How do you combine commands in \ttt{ex}?	\item \ttt{command1|command2}
What's the difference between \ttt{wq} and \ttt{x} in vim?	\item \ttt{x} will only write to the file if it's been modified.&nbsp;<div>\item Useful with make, which rebuilds files if the last modified time has changed</div>
How do you refer to the current filename in vim?	\item \ttt{\%}
How do you refer to the filename of the previous file in vim?	\item \ttt{\#}
How do you switch to the previous file in vim?&nbsp;	\item \ttt{Ctrl+\^{}}
How do you repeat the last substitute command in vim?	\item \ttt{:s}
How do you apply a command to every line in a range in \ttt{ex}?	\item \ttt{:143,256g} followed by the command<div>\item Before each execution of the command, \ttt{.} will be set to the current line</div>
What's the problem with ranges like \ttt{[a-z]} in regex patterns?	\item They don't localize well: é isn't matched for example.<div>\item Use POSIX bracket expressions like &nbsp;\ttt{[[:lower:]]} instead</div>
In the replacement pattern of a vim substitute command, how do you reference the entire search pattern?	\item \ttt{\&amp;}
In the replacement pattern of a vim substitute command, how do you reference the text found in the previous search?	\item \ttt{\~{}}
In the replacement pattern of a vim substitute command, how do you uppercase the first letter of an expression?	\item \ttt{\textbackslash uexpr}<div>\item ie \ttt{\textbackslash u} is the operator and \ttt{expr} is the expression</div>
In the replacement pattern of a vim substitute command, how do you lowercase the first letter of an expression?	\item \ttt{\textbackslash lexpr}<div>\item ie \ttt{\textbackslash l} is the operator and \ttt{expr} is the expression</div>
In the replacement pattern of a vim substitute command, how do you uppercase a sequence of letters in an expression?	\item \ttt{\textbackslash Uexpr\textbackslash E}<div>\item ie \ttt{\textbackslash U} is the operator and \ttt{expr} is the expression</div><div>\item If \ttt{\textbackslash E} is missing, it'll just run to the end of the replacement</div>
In the replacement pattern of a vim substitute command, how do you lowercase a sequence of letters in an expression?	\item \ttt{\textbackslash Lexpr\textbackslash E}<div>\item ie \ttt{\textbackslash L} is the operator and \ttt{expr} is the expression</div><div>\item If \ttt{\textbackslash E} is missing, it'll just run to the end of the replacement</div>
How can you do a vim search \&amp; replace on a pathname containing \ttt{/}?	\item Use another character like \ttt{;} as the delimiter instead:<div>\item \ttt{:\%s;/pattern;/replacement;g}</div>
What are buffers and windows in vim?	\item A buffer holds text<div>\item A window is a view into a buffer</div>
How do you open a file in binary mode in vim?	\item \ttt{vim -b filename}
How do you enable incremental search in vim?	\item \ttt{:set incsearch}
How do you diff files in vim?	\item \ttt{vim -d file1 file2 file3 file4}
How do you denote a comment in a .vimrc file?	"\item Start with \ttt{""}"
In vim's visual mode, how do you select up to and including the space after the next word?	\item \ttt{aw}
In vim's visual mode, how do you select up to the end of the next word?	\item \ttt{iw}
What're the two ways to create a new horizontal window in vim?	\item \ttt{:split}, \ttt{Ctrl+Ws}<br />
What're the two ways to create a new vertical window in vim?	<div>\item \ttt{:vsplit}, \ttt{Ctrl+Wv}</div>
How do you open a file in a new window in vim?	\item \ttt{:split filename}
How do you split off a horizontal window of a specific size in vim?	\item \ttt{:15split} will create a 15-line window
How do you create a new window in vim and do housekeeping?	\item \ttt{:new}
How do you open a window for a new file in vim only if the file exists?	\item \ttt{:sfind filename}
How do you open a new readonly window in vim?	\item \ttt{:sview filename}
How do you move between windows in vim?	\item \ttt{Ctrl+Wh, Ctrl+Wj, Ctrl+Wk, Ctrl+Wl}
How do you move to the previous window in vim?	\item \ttt{Ctrl+Wp}
How do you rotate windows in each direction in vim?	\item \ttt{Ctrl+Wr}, \ttt{Ctrl+WR}
How do you exchange windows in vim?	\item \ttt{Ctrl+Wx},&nbsp;\ttt{Ctrl+WX}
How do you move a window to the edges of the screen in vim?	\item \ttt{Ctrl+WH, Ctrl+WJ, Ctrl+WK, Ctrl+WL}
How do you resize windows to equal size in vim?	\item \ttt{Ctrl+W=}
How do you increase and decrease a window's height in vim?	\item \ttt{Ctrl+W+}, \ttt{Ctrl+W-}
How do you increase and decrease a window's width in vim?	\item \ttt{Ctrl+W&gt;},&nbsp;\ttt{Ctrl+W&lt;}
How do you maximize a window's width in vim?	\item \ttt{Ctrl+W|}
How do you store a set of folds in vim?	\item \ttt{:mkview}
How do you load a previously saved set of folds in vim?	\item \ttt{:loadview}
How do you toggle a fold in vim?	\item \ttt{za}
How do you delete a fold in vim?	\item \ttt{zd}
How do you create a fold in vim?	\item \ttt{zf} followed by a movement command
How do you recursively toggle a set of folds in vim?	\item \ttt{zA}
How do you reduce the fold level in vim?	\item \ttt{zm}
How do you increase the fold level in vim?	\item \ttt{zr}
How do you enable the fold margin in vim?	\item \ttt{:set foldcolumns=4} to display 4 levels of fold
How do you toggle the case of all characters in a line in vim?	\item \ttt{\~{}\~{}}
How do you enable indent-based folding in vim?	\item \ttt{:set foldmethod=indent}
How do you delete all folds in vim?	\item \ttt{zD}
How do you enable C-style indenting in vim?	\item \ttt{:set cindent}
How do you autocomplete a line in vim?	\item \ttt{Ctrl+X, Ctrl+L}
How do you complete by keyword within a file in vim?	\item \ttt{Ctrl+X, Ctrl+N}<div>\item \ttt{Ctrl+P} to skip back a match; enter to accept</div>
How do you complete by keyword, including included files in vim?	\item \ttt{Ctrl+X, Ctrl+I}<div>\item \ttt{Ctrl+P} to skip back a match</div><div>\item Enter to accept</div>
How do you autocomplete with the omni function in vim?	\item \ttt{Ctrl+X, Ctrl+O}<div>\item \ttt{Ctrl+P} to skip back a match</div><div>\item Enter to accept</div>
How do you autocomplete by filename in vim?	<div>\item \ttt{Ctrl+X, Ctrl+F}</div><div>\item \ttt{Ctrl+P} to skip back a match</div><div>\item Enter to accept</div>
<div>How do you autocomplete by tag in vim?</div>	<div>\item \ttt{Ctrl+X, Ctrl+]}</div><div>\item \ttt{Ctrl+P} to skip back a match</div><div>\item Enter to accept</div>
What's omni autocomplete in vim?	\item A user-defined filetype-dependent autocomplete.
How do you navigate to a tagged location in vim?	\item \ttt{Ctrl+]} with the cursor over an identifying keyword
How do you return from a tagged location to your previous location in vim?	\item \ttt{Ctrl+T}
What're exuberant tags in vim?	\item An extension of \ttt{ctags} that makes it useful for other languages
How do you enable syntax highlighting in vim?	\item \ttt{:syntax enable}
How do you search through local files in vim?	\item \ttt{:vimgrep pattern filepattern}
How can you save session state in vim?	\item \ttt{:mksession}<div>\item Restore it with \ttt{:so Session.vim}</div>
How can you open vim's command history?	\item \ttt{Ctrl+F}
How do you define a macro in a makefile?	\item \ttt{NAME=value}
How do you use a macro in a makefile?	\item \ttt{\$(NAME)}
What's the default behavior when \ttt{make} is called?	\item It'll process the first recipe in the file called \ttt{makefile} not starting with \ttt{.}
What are make's two most imporant implicit rules?	\item Targets ending in \ttt{.o} are automatically derived from the file with the same filename but ending \ttt{.c/.cpp/etc}<div>\item Targets without an extension are automatically derived from the file with the same name but ending in \ttt{.o}. Other automatically-generated \ttt{.o} files are linked in.&nbsp;</div>
What's the variable for setting the C++ compiler in make?	\item \ttt{CXX}
What's the variable for defining flags for the C++ compiler in make?	\item \ttt{CXXFLAGS}
What's the variable for defining libraries to be given to the linker in make?	\item \ttt{LDLIBS}
What's the variable for defining flags for the linker in make?	\item \ttt{LDFLAGS}
What distinguishes Java's StringBuffer and StringBuilder?	\item StringBuilder is faster<div>\item StringBuffer is concurrency-safe</div>
What's the boolean type in C++, and where is it found?	\item \ttt{bool}, and it's included automatically
What's the bit format of a IEEE754 double in most languages?	<div>\item From most significant to least:</div>\item 1 bit sign<div>\item 11 bit exponent</div><div>\item 52 bit mantissa</div>
How is the exponent of a double encoded in IEEE754?&nbsp;	\item Using offset binary:&nbsp;<div>\item 1 corresponds to an exponent of -1022</div><div>\item 2046 corresponds to an exponent of 1023</div>
How can you calculate the $i$th Gray codeword in C?&nbsp;	\item \ttt{(i &gt;&gt; 1) \^{} i}
How do you calculate the sign of a permutation?	\item Count the number of inversions ($i &lt; j$ st $\pi_i &gt; \pi_j$) in the permutation.<div>\item An odd number implies a sign of -1, an even number a sign of +1</div>
What's the use of the \ttt{xargs} command in Unix?	\item It executes the given command with whitespace-separated tokens taken from standard input
How can you control the number of arguments \ttt{xargs} reads in during each execution?	\item \ttt{xargs -n 1} will read 1 argument at a time
What's the general outline of a problem amenable to binary search?	\item You have a monotonic function $f(x)$ and a predicate $p(y)$, and you want to search a finite domain for an argument $x$ which causes $p(f(x))$ to be true.
What are the common variants of problems amenable to binary search?	\item Given a monotonic function $f$ and a monotonic predicate $p$,&nbsp;<div>\item Upper bound: find the maximum $x$ such that $p(f(x))$ is true</div><div>\item Lower bound: find the minimum $x$ such that $p(f(x))$ is true</div>
How would you code up the upper-bound binary search variant?	<div>\item Given a target \ve£target£</div>\item Define a predicate \ve£p: v -&gt; (v &lt;= target)£<div>\item Define \ve£lo = 0, hi = length - 1£</div><div>\item Define \ve£best_so_far = null£</div><div>\item \ttt{while lo &lt;= hi</div><div>\\....x = (lo + hi)/2</div><div>\\....if p(arr[x])&nbsp;</div><div>\\........best\_so\_far = x</div><div>\\........lo = x + 1</div><div>\\....else</div><div>\\........hi = x - 1}</div><div>\item Then check if \ve£best_so_far£ matches \ve£x£</div>
How do you connect to a database in PSQL?	\item \ttt{psql databasename}
How do you get help in PSQL?	\item \ttt{\textbackslash h commandname} for SQL commands<div>\item \ttt{\textbackslash ? commandname} for psql commands</div>
When creating a table in SQL, how can you implicitly create a foreign key constraint?	\item \ttt{CREATE TABLE cities (<div>\\ country\_code char(2) REFERENCES countries</div><div>\\);}</div>
In the select clause before a join, how can you retrieve only the attributes of one contributing table?	\item \ttt{SELECT a.* FROM a INNER JOIN b;}
What's CRUD with respect to databases?	\item Create<div>\item Read</div><div>\item Update</div><div>\item Delete</div><div>\item ie the four fundamental operations on persistant storage</div>
In a SQL execution plan, what are the costs measured in?	\item Arbitrary units, but by convention a single disk page fetch will cost 1.0.&nbsp;
In a PSQL query plan, what are the two costs that appear on each row?	\item The cost for any preprocessing needed<div>\item and the total cost</div>
How can you get more detailed information on the runtime of a query plan in PSQL?	\item \ttt{EXPLAIN ANALYZE query} will actually run the query and display a summary of how much time was spent on each component of the plan<br />
How do you set a default value for a column in SQL?	\item \ttt{colname coltype DEFAULT defaultval'}
What's an important choice to make when enforcing a compound foreign key constraint?	\item Whether to allow some components of the key to be null
How do you instruct PSQL whether to allow nulls in a foreign key constraint?	\item \ttt{FOREIGN KEY (a, b) REFERENCES c(d, e) MATCH SIMPLE} to allow nulls<br />\item \ttt{FOREIGN KEY (a, b) REFERENCES c(d, e) MATCH FULL} to disallow nulls
How do you write a function in PL/pgPSQL?	\item \ttt{CREATE OR REPLACE FUNCTION fname(argname1, argtype1, argname2, argtype2)<div>\\ RETURNS rettype AS&nbsp;</div><div>\\ \$\$</div><div>\\ DECLARE</div><div>\\ ....variable declarations</div><div>\\ BEGIN</div><div>\\ ....fn body</div><div>\\ END;</div><div>\\\$\$ LANGUAGE plpgsql;}</div>
How do you declare variables in a PSQL function definition?	\item \ttt{DECLARE<div>\\varname1 vartype1;</div><div>\\varname2 vartype2&nbsp;:= initialval;}</div>
How do you set a variable in PSQL functions?	\item \ttt{varname := val;}
How do you import a function from a file in PSQL?	\item \ttt{\tbs i filename.sql}
How do you run a function in PSQL?	\item \ttt{SELECT fnname(argval1, argval2);}
In SQL, what's a stored procedure?	\item A subroutine stored on the database which queries can call
In SQL, what's a trigger?	\item A routine that'll be called before or after certain operations on the database
What're the common trigger events in PSQL?	\item Before or after inserts<div>\item Before or after updates</div>
How would you write a trigger in PSQL to execute for each row after an update to a table?	\item \ttt{CREATE TRIGGER triggername<div>\\ AFTER UPDATE ON tablename</div><div>\\ FOR EACH ROW EXECUTE PROCEDURE procname();}</div>
How do you add a column to a table in SQL?	\item \ttt{ALTER TABLE tablename ADD colname coltype;}
What's a rule in PSQL?	\item A description of how to alter a query's AST
How do you create a rule in PSQL that'll execute when a row is inserted into a table?	\item \ttt{CREATE RULE rulename&nbsp;AS&nbsp;<div>\\ ON INSERT TO tablename&nbsp;<div>\\ DO INSTEAD&nbsp;</div><div>\\ query</div><div>}&nbsp;</div></div>
When constructing row-level triggers in PSQL, how do you refer to the row being inserted or the row being replaced?	\item \ttt{NEW} and \ttt{OLD} resp.
What's the function of a pivot table?	\item Cross-tabulation; counting the number of datapoints with each pair of possible values in two attributes
What's the Levenshtein distance?	\item Another name for the string edit distance
What's a trigram text search?	\item Breaking each string in the database into trigrams<div>\item and doing the same for the pattern string</div><div>\item then calculating the best match against a pattern by counting the number of matching trigrams.</div>
In natural language processing, what's a stop word?	"\item A word that's so common that it's useless to search against, and is filtered out from any search query.<div>\item ie ""the""</div>"
What's the purpose of the metaphone algorithm?	\item An algorithm for indexing words by their pronunciation, by converting the input string to a standardized approximation of the input's pronunciation
What kind of data scale are modern SQL databases viable up to?	\item Several terabytes.
When is a SQL database preferable over other database types?	\item When data is fairly homogeneous<div>\item When the data conforms to an structured schema</div>
When is a SQL database inappropriate?	<div>\item When greater flexibility than a rigid schema is needed&nbsp;</div>\item When significant horizontal scaling is needed<br /><div>\item When very high volume reads and writes are needed</div><div>\item When only large blobs of data need to be stored</div>
What's the effect of the Unix \ttt{cat} command?	\item Prints the file's contents to standard output
What's the conjugate prior of the Bernouilli distribution?	\item The Beta distribution
What is $\Gamma(n)$ equivalent to when $n$ is a positive integer?	\item $\Gamma(n) = (n-1)!$
What's the simplest way to do feature selection in machine learning?	\item Calculate the mutual information between each feature $X_j$ and the class label $Y$<div>\item Discard all but the $k$ features with the highest MI</div>
What's the definition of the logit function?	\item $\ln \frac{x}{1-x}$
How are the logistic and logit functions related?	\item They're inverses
What's the change of variables formula in probability?	\item If $y = f(x)$ is monotonic (and hence invertible),<div>\item $p_y(y) = p_x(x)|\frac{dx}{dy}|$</div>
What's the conjugate prior of the uniform distribution?	\item The Pareto distribution
What's the information form of a Gaussian distribution?	\item When it's written in terms of the canonical parameters
What's the product of two Gaussian distributions?	<div>\item $XY \sim N(\Lambda_x \mu_x + \Lambda_y \mu_y, \Lambda_x + \Lambda_y)<b>$</b></div>
What're the parameters of the Wishart distribution?	\item $S$, the scale matrix<div>\item $\nu$, the degrees of freedom</div>
What's the Wishart distribution a generalization of?	\item The Gamma distribution generalized to positive definite matricies
What's the usual use of the Wishart distribution?	\item To model uncertainty in precision matricies
What's the definition of the Wishart distribution?	\item $Wi(\Lambda | S, v) \propto |\Lambda|^{\frac{\nu-D-1}{2}} e^{-\frac{1}{2} \text{tr}(\Lambda S^{-1})}$
When is the normalization constant for the Wishart distribution well-defined?	\item When $\nu &gt; D+1$
In machine learning, what's the scatter matrix of a series of observations?	\item $S = \sum x_i x_i^T$
What's the mean of a Wishart distribution?	\item $\mu = \nu S$
What's the mode of a Wishart distribution?	\item $(\nu - D - 1)S$<div>\item which only exists if $\nu &gt; D + 1$</div>
If $x_i \sim \mathcal{N}(0, \Sigma)$, what's the distribution of the scatter matrix?	\item $S \sim \text{Wi}(\Sigma, N)$
How is the Wishart distribution related to the inverse Wishart distribution?	\item If $\Lambda \sim Wi(S, \nu)$<div>\item then $\Sigma \sim IW(S^{-1}, \nu + D + 1)$</div>
What does MVN stand for in machine learning?	\item Multivariate normal (distribution)
What's the MAP estimate of a Gaussian's covariance matrix given an inverse Wishart prior?	\item $\hat\Sigma = \frac{S_0 + S_\mu}{N_0 + N}$<br />\item where&nbsp;<div>\item $S_\mu$ is the scatter matrix of the observations relative to&nbsp;$\mu$&nbsp;<br /><div>\item $N_0 = \nu_0 + D + 1$ is the strength of the prior<br /><div>\item $S_0$ is the scale matrix of the prior</div></div></div>
What's a common alternative parameterization to the inverse Gamma distribution?	\item The inverse chi squared distribution
What are the problems with the inverse Gamma distribution when used as a Gaussian variance prior?	\item The strength of the distribution is encoded in both parameters<div>\item The conversion from the Wisart distribution to the Gamma distribution introduces a lot of ugly $\frac{1}{2}$ constants</div>
What's the natural conjugate to the normal distribution on $(\mu, \Sigma)$?	\item The normal inverse Wishart
What's the definition of the normal inverse Wishart distribution?	\item $\text{NIW}(\mu, \Sigma | m, \kappa, \nu, S) = \mathcal{N}(\mu | m, \frac{1}{\kappa}\Sigma) \times \text{IW}(\Sigma | S, \nu)$
What are the parameters of the normal inverse Wishart distribution?	\item $m$ is the prior mean for $\mu$<div>\item $\kappa$ is the strength of $\mu$'s prior</div><div>\item $S$ is (proportional to) the prior mean for $\Sigma$</div><div>\item $\nu$ is the strength of $\Sigma$'s prior</div>
How many free parameters does the normal inverse Wishart distribution have?	\item Three;&nbsp;<div>\item confidence in the mean is inversely proportional to the variance</div>
What are the problems with the MAP estimate?	\item Doesn't indicate confidence<div>\item Using it will overestimate confidence<br /><div>\item Inherently an atypical point</div></div><div>\item Not invariant wrt reparameterization</div>
What's a credible interval?	\item A $100(1-\alpha)\%$ credible interval is a contiguous region of the (one dim) parameter space that contains $1-\alpha$ of the posterior probability mass&nbsp;
What's a central interval?	\item A credible interval for which the left and right tails have equal mass
What's HPD stand for in machine learning?	\item Highest posterior density (regions)
What're the highest posterior density regions in machine learning?	\item The $100(1-\alpha)\%$ HPD regions are defined by the set $\{\theta : p(\theta| \mathcal{D}) \geq p^*)$<div>\item where $p^*$ is defined by</div><div>\item $1 - \alpha = \int_{\theta : p(\theta|\mathcal{D}) &gt; p^*} p(\theta|\mathcal{D})d\theta$&nbsp;</div><div>\item ie its the threshold such that the HPD regions contain $1-\alpha$ of the probability mass</div>
How do you calculate the HPD threshold?	\item Imagine the distribution immersed in water: we lower the water level until $1-\alpha$ of the distribution is revealed.<div>\item This lends itself to binary search if the inverse CDF is easily computable</div><div>\item or search over sorted data points if it isn't.</div>
What's the model selection problem in machine learning?	\item Deciding how to set the model's parameters to avoid overfitting and underfitting
What are the two main approaches to the model selection problem?	\item Cross-validation with one setting of the parameters in each fold. Select the setting which minimizes the generalization error.<div>\item Bayesian model selection. Construct the posterior of the models given the data and pick the MAP model.</div>
What's the marginal likelihood in machine learning?	\item $p(\mc{D}| m) = \int p(\mc{D}|\theta) p(\theta|m)d\theta$<br />
What're two other names for the marginal likelihood in machine learning?	\item Integrated likelihood<div>\item Evidence</div>
If there's a uniform prior over the models, what does Bayesian model selection reduce to?	\item Picking the model that maximizes the marginal likelihood
What's the Bayesian Occam's razor effect?	\item When using Bayesian model selection and computing the marginal likelihood for each model<div>\item models with a larger number of parameters do not necessarily have a higher marginal likelihood, protecting us from overfitting</div><div>\item This is in contrast to using $p(\mc{D}|\hat \theta_{MLE(m)})$ or $p(\mc{D}|\hat \theta_{MAP(m)})$ to evaluate the models, which would lead to a preference for more parameters</div>
What's the conservation of probability mass principle?	\item A PDF always sums to 1<div>\item so a complex model which can predict many things will spread its mass thinly, so on a specific&nbsp;dataset it&nbsp;won't obtain as large a probability during Bayesian model selection as a simpler model.</div>
When using a conjugate prior, how can you calculate the marginal likelihood?	<div>\item Extract the normalization constants as so:</div>\item $p(\theta) = q(\theta)/Z_0$<div>\item $p(\mc{D}|\theta) = q(\theta)/Z_l$</div><div>\item $p(\theta|\mc{D}) = q(\theta)/Z_N$</div><div>\item Then $p(\mc{D}) = \frac{Z_N}{Z_0 Z_l}$</div>
What's the BIC in ML?	\item Bayesian information criterion
How is the BIC calculated in ML?	\item $\text{BIC} = \ln p(\mc{D}| \hat \theta_{mle}) - \frac{\text{dof}(\hat \theta_{mle})}{2}\ln N$<div>\item where $\text{dof}$ is the number of degrees of freedom in the model</div>
What's the intuitive interpretation of the BIC in ML?	\item It's effectively the minimum description length of the data using that model:&nbsp;<br /><div>\item it has a term for how well the model describes the data, minus the amount of information needed to describe the model itself</div>
What does the BIC approximate?	\item The log maringal likelihood: $\text{BIC} \approx \ln p(\mc{D})$
What's the use of the BIC in ML?	\item Often the marginal likelihood can be hard to compute<div>\item and in that case the BIC serves as a decent approximation</div>
What's the Bayesian approach when it's not clear how to set the parameters of the prior?	\item Put a hyper-prior on the prior:<div>\item $p(\mc{D}|m) = \int \int p(\mc{D}|\theta)p(\theta| \alpha, m) p(\alpha | m) d\theta d\alpha$</div><div>\item The hyper-prior can usually be uninformative, as the higher in the Bayesian hierarchy you go, the less sensitive the results are to the parameters.&nbsp;</div>
What's empirical Bayes?	\item When conducting model selection with an unknown parameter $\alpha$ in the prior, rather than integrating it out just optimize it wrt the marginal likelihood<br />
What's the Bayes factor?	\item The ratio of posterior probabilities between two possible models:<div>\item $BF_{1, 0} = \frac{p(\mc{D}|M_1)}{p(\mc{D}|M_0)}/\frac{p(M_1)}{p(M_0)}$</div>
What distinguishes the Bayes factor from the likelihood ratio?	\item In the BF, the parameters have been integrated out<div>\item allowing models of different complexity to be compared</div>
How should the Bayes factor be interpreted?	\item $BF &gt; 10$ is strong evidence for its numerator<div>\item $BF &lt; 0.1$ is strong evidence for its denominator</div>
What's the takehome of the Jeffreys-Lindley paradox?	\item If you use improper priors during model selection, the posterior can change arbitrarily<div>\item Improper priors are only allowed over the parameters that the competing models share&nbsp;</div>
How's the Haldane prior defined?	\item $Beta(0, 0)$
What's the use of the Haldane prior?	\item It's an alternative to $\text{Beta}(1,1)$ as an uninformative prior<div>\item which won't alter the MLE of say the uniform distribution</div>
What's the problem with the Haldane prior?	\item It's improper.<div>\item The posterior will only be proper on the uniform distribution if at least one head and one tail are observed</div>
What's sensitivity analysis in machine learning?	\item Checking how much you conclusions change when the modelling assumptions are perturbed
When are reads not atomic in Java?	\item When it's a read of a non-volatile long or a double.
What's a defensive copy in concurrent programming?	\item Returning a copy of internal state rather than the state itself<div>\item so no-one else can possibly mutate it.</div>
What are Java Callables?	\item A \ttt{Callable} is an alternative to \ttt{Runnable} that returns a result.
How are Java Callables used?	\item Implement \ttt{Callable&lt;T&gt;}, where \ttt{T} is the return type<div>\item Call \ttt{executorService.submit(callable)}, and get a \ttt{Future&lt;T&gt;} back</div><div>\item Call \ttt{future.get()} which will return the result when it's done.</div>
How do you implement a Java \ttt{Callable&lt;T&gt;}?	\item Implement \ttt{call()} which returns a \ttt{T}
What's the classes of Java's atomics framework?	\item Classes like \ttt{AtomicInteger, AtomicReference}<div>\item Classes like \ttt{AtomicIntegerArray, AtomicReferenceArray}</div><div>\item Classes like \ttt{AtomicIntegerFieldUpdater&lt;T&gt;, AtomicReferenceFieldUpdater&lt;T, U&gt;}</div><div>\item Classes like \ttt{AtomicMarkableReference} and \ttt{AtomicStampedReference}</div>
What's the use of Java's \ttt{AtomicReferenceFieldUpdater&lt;T, V&gt;}?	\item Allows atomic updates to any \ttt{volatile} field of type \ttt{V} of any object of type \ttt{T}.
What's the use of Java's \ttt{AtomicStampedReference&lt;V&gt;}?	\item Maintains an object reference along with an integer stamp that can be updated atomically.
What are the most important methods in Java's \ttt{AtomicInteger} class?	\item \ttt{addAndGet(int delta)}<div>\item \ttt{compareAndSet(int expect, int update)}</div><div>\item \ttt{get()}</div><div>\item \ttt{set(int newValue)}</div><div>\item \ttt{getAndSet(int newValue)}</div>
What's Java's basic lock class?	\item \ttt{ReentrantLock}, which implements the \ttt{Lock} interface
How do Java semaphores work?	\item \ttt{acquire()} gets a permit and decrements the Semaphore's count.<div>\item \ttt{release()} releases a permit back to the Semaphore</div>
What's a \ttt{CyclicBarrier} in Java?	\item A synchronization object that will cause threads to block until $n$ threads have arrived at it.<div>\item Can also be given a barrier action for the last entering thread to execute when the barrier trips</div><div>\item Called `cyclic' because it can be reset</div>
What's the basic way to use threads in Java?	\item Pass a \ttt{Runnable} to a \ttt{Thread} constructor<div>\item Call \ttt{thread.start()}</div>
What's a Java \ttt{ThreadGroup}?	\item A way to organize threads into a tree.<div>\item Create it by calling the \ttt{ThreadGroup} in a name and possibly a parent \ttt{ThreadGroup}<br /><div>\item Then pass the \ttt{threadGroup} to a thread's constructor, and the thread can use it to access the other threads in the group.&nbsp;</div></div>
What's the statistical power of a test?	\item The probability of correctly rejecting the null hypothesis when the null hypothesis is false.
What's a Type II error in statistics?	\item When the null hypothesis is false but is accepted anyway
What's a Type I error in statistics?	\item When the null hypothesis is true but is rejected anyway
What's another name for the power of a statistical test?	\item Its sensitivity
What're intrinsic locks in Java?	\item Every Java object can implicitly act as a lock
What's a monitor lock in Java?	\item Another name for an intrinsic lock
What're the two built-in locking constructs in Java?	\item Methods marked \ttt{synchronized}<div>\item Blocks of the form \ttt{synchronized (lockObject) \{ .. \}}</div>
What's a reentrant lock?	\item One that can be acquired again by the thread that holds it.
Are Java intrinsic locks reentrant?	\item Yup
What's a liveness failure in concurrent programming?	\item When the program gets into a state such that it's permanently unable to make forward progress<br />
How much overhead is involved in a context switch between threads in Linux?	\item About 1us&nbsp;
How long is a Linux timeslice typically?	\item About 10ms
How much overhead is there in a context switch between processes in Linux?	\item About 10us
What's the visibility problem in concurrent programming?	\item When a variable is altered, it might only be immediately altered in the CPU's own cache<div>\item Publishing it to main memory can sometimes take a deliberate action</div>
When are reordering optimizations permitted by the Java spec?	\item When the reordering would make no difference to that specific thread
How can you make reads of Java 64 bit doubles \&amp; longs atomic?	\item By marking them \ttt{volatile}<br />\item By guarding them with a lock
How do Java intrinsic locks affect variable visibility?	\item The values of the variables visible to a thread immediately before releasing an intrinsic lock will be visible to the next thread &nbsp;that gets the lock
What's the effect of Java's \ttt{volatile} keyword?	<div>\item Fields decorated with it</div>\item will not have their value cached by the CPU<div>\item will not have their accesses reordered with respect to other memory operations</div>
What's publication in concurrent programming?	\item Making an object available outside of it's current scope
What are the three conditions on \ttt{volatile}'s use in Java?	\item Writes to the variable do not depend on its current value, or alternatively only a single thread updates its value<div>\item The variable is not part of any invariant which concerns other state variables</div><div>\item Locking isn't required for any other reason while the variable is being accessed</div>
What's the danger in publishing mutable state from a concurrency perspective?	\item If a reference to mutable state is published, then it can be mutated without having to partake in the owner's synchronization policy
What does it mean for an object to escape in concurrent programming?	\item The object can be referenced by some method whose behaviour isn't fully specified by the owner of the object&nbsp;
What's an alien method in concurrent programming?	\item A method whose behaviour isn't fully specified by the owner of an object it acts upon
What's the danger with publishing \ttt{this} from a constructor?	\item Even if \ttt{this} is published as the last statement in the constructor,&nbsp;<div>\item it could give access to the object before it's fully constructed</div>
Why is it dangerous to start a thread from a constructor?	\item Because it very often allows a reference to \ttt{this} to escape,&nbsp;<div>\item either by explicitly passing \ttt{this} to the new thread</div><div>\item or by passing an inner class of type \ttt{Thread} or \ttt{Runnable}, which has an implicit reference to the containing class&nbsp;</div>
What's the best way to avoid problems with publishing \ttt{this} from a constructor in Java?	\item Use a private constructor and a public factory method
What's thread confinement in concurrent programming?	\item Issues with shared mutable data can be avoided by not sharing it
What's the usual way to implement thread confinement in Java?	\item Use the \ttt{ThreadLocal} class
How do you set the initial value of a Java \ttt{ThreadLocal} variable?	\item Subclass it and override \ttt{initialValue()}, a method which determines what \ttt{get()} will return prior to \ttt{set()} being called
What's stack confinement in concurrent programming?	\item Thread confinement by way of only storing mutable state in local variables.
What's the importance of Java's volatile keyword when it comes to publishing objects?	\item Publishing an object via a volatile variable constitutes safe publication&nbsp;
What's the importance of \ttt{final} variables from the perspective of concurrency?	\item Publishing an object via a final field constitutes safe publication
What's effective immutability in concurrent programming?	\item An object which is technically mutable, but which isn't modified after initialization.
What's the advantage of effectively immutable objects in concurrent programming?	\item They can be used \&amp; treated as if they were immutable
What are the sufficient conditions for an object to be safely shared?	\item Operations on the object must all be thread-safe<div>\item The object must be safely published</div>
What's safe publication in concurrent programming?	\item Making an object's state and a reference to the object visible at the same time.&nbsp;
What's a synchronization policy in concurrent programming?	\item The definition of how an object coordinates access to its state so as to preserve invariants and maintain postconditions
What's instance confinement in concurrent programming?	\item Encapsulating state so that all access to it has to go through a specific object
What's the Java monitor pattern?	\item Encapsulate all the mutable state of an object and guard it with the object's own intrinsic lock
What're the disadvantages of a public lock in concurrent programming?	\item Verifying that a public lock is properly used requires analyzing the whole program rather than a single object
What're the advantages of public locks in concurrent programming?	\item Allows client-side locking
What's the best way to publish mutable state without letting a client modify it?	\item Publish a copy of the state.
What's client-side locking in Java?	\item If an object synchronizes on a public lock,<div>\item then to conduct several operations on the object in an atomic manner, you can acquire the public lock first</div>
How do Java's synchronized collection classes work?	\item They hold a collection in a synchronized wrapper.
What are Java's concurrent map types?	\item \ttt{ConcurrentHashMap}<div>\item \ttt{ConcurrentSkipListMap}, which is a \ttt{NavigableMap}</div>
What are Java's concurrent queue interfaces?	\item \ttt{BlockingDeque}<div>\item \ttt{BlockingQueue}</div><div>\item \ttt{TransferQueue}, which allows producers to wait on consumers</div>
What's Java's \ttt{ConcurrentHashMap} synchronization policy?	\item Lock striping<div>\item weakly consistent iterators</div><div>\item approximate global operations (like \ttt{size} or \ttt{isEmpty})</div>
What's a weakly consistent iterator in Java?	\item It'll traverse elements as they existed when the iterator was created<div>\item but may or may not display updates to those elements</div>
What's Java's concurrent List type?	\item \ttt{CopyOnWriteArrayList}
What's Java's concurrent Set type?	\item \ttt{CopyOnWriteArraySet}
What are the six main concurrent queue implementations in Java?	\item \ttt{ArrayBlockingQueue}<div>\item \ttt{LinkedBlockingQueue}</div><div>\item \ttt{PriorityBlockingQueue}</div><div>\item \ttt{SynchronousQueue}</div><div><div>\item \ttt{DelayQueue}</div><div>\item \ttt{LinkedTransferQueue}</div></div>
What's a Java \ttt{SynchronousQueue}?	<div>\item A concurrent queue where each remove op waits on an insert op</div>
What's a Java \ttt{DelayQueue}?	<div>\item A concurrent queue where elements cannot be taken until a delay has expired</div>
What's a Java \ttt{LinkedTransferQueue}?	<div>\item A queue where producers can wait for consumers to receive elements</div>
What's serial thread confinement in concurrent programming?	\item Transferring an object to another thread and ensuring that it's not used by the original owner after the transfer
At an abstract level, what's the easiest way to implement serial thread confinement?	\item Use a blocking queue
What's work stealing in concurrent programming?	\item A producer-consumer pattern where consumers take work from the back of other consumer's deques when they run out of their own&nbsp;
What are Java's implementations of \ttt{BlockingDeque}?	\item \ttt{ConcurrentLinkedDeque} (unbounded, lock-free)<div>\item \ttt{LinkedBlockingDeque} (optionally bounded, locking, preferred)</div>
What are the two basic ways to respond to an \ttt{interrupt} request in Java?	\item Propagate the \ttt{InterruptedException}<div>\item Catch the \ttt{InterruptedException} and call \ttt{interrupt} on the current thread</div>
What's Java's latch type?	\item \ttt{CountDownLatch}
How does a latch work in concurrent programming?	\item It's a synchronizer which delays threads until it reaches its terminal state
What's a synchronizer in concurrent programming?	\item Any object that coordinates the control flow of threads based on its state
How do you represent asynchronous computations in Java?	\item \ttt{Future}s, usually implemented by \ttt{FutureTask}s
What's Java's semaphore type?	\item \ttt{Semaphore}
What are the four standard \ttt{Executor} implementations in Java?	\item \ttt{Executors.newFixedThreadPool()}<div>\item \ttt{Executors.newCachedThreadPool()}</div><div>\item \ttt{Executors.newSingleThreadExecutor()}</div><div>\item \ttt{Executors.newScheduledThreadPool()}</div>
What does \ttt{Executors.newCachedThreadPool()} produce?	\item An \ttt{ExecutorService} which can dynamically add and reap threads as needed
What does \ttt{Executors.newScheduledThreadPool()} do?	\item Creates an \ttt{ExecutorService} with a fixed number of threads that supports delayed and periodic task execution, similar to \ttt{Timer}
What's the difference between Java's \ttt{Executor.execute()} and \ttt{ExecutorService.submit()}?	\item \ttt{ExecutorService.submit()} returns a future that can be used to track execution
What are the \ttt{invoke} methods of Java's \ttt{ExecutorService}?	\item \ttt{invokeAll()} takes a collection of callables and returns a collection of futures, one for each callable<div>\item \ttt{invokeAny()} takes a collection of callables and returns the result of the first that completes successfully</div>
How do you shut down a Java \ttt{ExecutorService}?	\item \ttt{service.shutdown()}, then \ttt{service.awaitTermination()}
How do you schedule asynchronous tasks in Java?	\item Use \ttt{Executors.newScheduledThreadPool()} to get a new \ttt{ScheduledExecutorService}<div>\item then call \ttt{service.schedule(runnable, delay)}</div>
What's Java's \ttt{CompletionService}?	\item A combination of \ttt{Executor} and \ttt{BlockingQueue}<div>\item \ttt{Callables}s can be submitted to it&nbsp;</div><div>\item and the *completed* \ttt{Future}s will be queued for access by \ttt{take()} (blocks) and \ttt{poll()} (returns null)</div>
What's Java's standard implementation of \ttt{CompletionService}?	\item \ttt{ExecutorCompletionService}
What's a common problem with \ttt{ThreadLocal} in Java and thread pools?	\item The lifespan of any object using a \ttt{ThreadLocal} variable must not exceed the lifespan of the task<div>\item else it might pollute the next task the same thread executes</div>
When do thread pool architectures work best?	\item When threads are homogeneous<div>\item When threads are independent</div>
What's thread starvation deadlock?	\item When a task creates \&amp; waits on another task that'll need a resource<br /><div>\item but the pool of such resources is already consumed</div>
What does it mean for a thread pool to become clogged?	\item When there are too many long-running tasks compared to the number of threads available in the pool<div>\item all the threads end up working on the long-running tasks</div><div>\item and the response time for any shorter tasks suffers</div>
How do you find out how many processors a system has in Java?	\item \ttt{Runtime.getRuntime().availableProcessors()}
What's the optimal number of threads for an $n$ CPU system?	\item Usually $n$ or $n+1$ if it's computationally bottlenecked<br /><div>\item $(1 + \frac{\text{wait time}}{\text{compute time}})n$ for IO bottlenecked tasks</div>
How does a standard Java \ttt{ExecutorService} decide whether to reap a thread?	\item It'll reap the thread when it's idle time exceeds the \ttt{keepAliveTime}, a value passed to the \ttt{ThreadPoolExecutor} constructor
What's a saturation policy in concurrent programming?	\item What to do when a resource (like spaces in a bounded queue) have all been consumed
How do you control in what order tasks are executed by a Java \ttt{ExecutorService}?	\item Pass a \ttt{BlockingQueue&lt;Runnable&gt; workQueue} to the \ttt{ThreadPoolExecutor} constructor that implements the ordering heuristic you want.
How do you alter the saturation policy of a standard Java \ttt{ExecutorService}?	\item Customize the \ttt{RejectedExecutionHandler} passed to the \ttt{ThreadPoolExecutor} constructor<div>\item Standard customizations are provided as subclasses of \ttt{ThreadPoolExecutor}</div>
What are the standard saturation policies available for Java \ttt{ExecutorService}s?	\item \ttt{AbortPolicy}, which causes an exception to be thrown<div>\item \ttt{CallerRunsPolicy}, which causes the task to be run on the caller's thread</div><div>\item \ttt{DiscardPolicy}</div><div>\item \ttt{DiscardOldestPolicy}</div>
How can you stop a Java \ttt{ExecutorService} from being modified after creation?	\item Wrap it in an \ttt{unconfigurableExecutorService} object.
What's the easiest way to add logging or monitoring to a Java thread pool?	\item Extend \ttt{ThreadPoolExecutor} and override \ttt{beforeExecute}, \ttt{afterExecute} and similar.
What's the best way to parallelize recursive tasks in Java?	\item Use a \ttt{ForkJoinPool} and pass it subclasses of \ttt{ForkJoinTask}s
What are the subclasses of a \ttt{ForkJoinTask}?	\item \ttt{RecursiveTask}, which returns a result<div>\item \ttt{RecursiveAction}, which doesn't.</div>
How do you usually subclass Java's \ttt{RecursiveTask}?	\item You override \ttt{compute()}, using the inherited \ttt{invoke}, \ttt{fork} and \ttt{join} methods to start subcomputations using the same pool
What're the four approaches to safe publication in Java?	\item Volatile variables<div>\item Final variables</div><div>\item Static initializers</div><div>\item Lock-guarded variables</div>
What's a phaser in Java?	\item \ttt{Phaser} is a generalization of \ttt{CyclicBarrier} and \ttt{CountDownLatch}&nbsp;
How does Java's \ttt{Phaser} compare to its predecessors?	<div>\item Allows the threshold to be modified dynamically&nbsp;</div><div>\item Has \emph{generations}, which track how many times the barrier has been broken</div><div>\item Has tiering, which allows phasers to be structured into a tree for use with large numbers of threads</div><div>\item Has monitoring, which means the phaser's state can be tracked</div>
What's the best way to provide random numbers to threads in Java?	\item \ttt{ThreadLocalRandom}, which eliminates the contention issues that global PRNGs have
What does DMA stand for in computer architecture?	\item Direct memory access
What's the front side bus in most computer architectures?	\item The component that links the CPUs to the north bridge<div>\item Eliminated as a discrete component in modern architectures in favour of an on-chip solution</div>
What's the northbridge in computer architecture?	\item The motherboard component that manages communication between the CPUs and the `fast' system components (like the RAM) and the southbridge<div>\item Eliminated as a discrete component in modern architectures in favour of on-CPU memory management</div>
What's the southbridge in computer architecture?	\item Manages communication between the northbridge and the `slow' parts of the system<div>\item Eliminated in modern architectures when the northbridge was eliminated</div>
What's direct memory access in computer architecture?	\item The ability for certain devices to access system memory without involving the CPU
What's the standard Intel chipset architecture nowadays?	<div>\item Cores communicate via QPI</div>\item Each core has access to memory, graphics and platform controller hub<div>\item PCH with access to the rest of the system</div>
What's QPI stand for in computer architecture?	\item QuickPath Interconnect, Intel's core communication tech
What's PCH stand for in computer architecture?	\item Platform controller hub, Intel's replacement for the southbridge
At a high level, what distinguishes SRAM and DRAM?	\item Static RAM is fast and expensive<div>\item Dynamic RAM is slow and cheap</div>
What's the electrical architecture of a SRAM cell?	\item Six transistors; four form a bistable switch and the other two allow the current state of the switch to be read/written
What's the electrical architecture of a DRAM cell?	\item A transistor and a capacitor.
What's leakage in DRAM?	\item The logical value is stored on a capacitor, and the charge held there disappates very quickly&nbsp;
How is leakage remedied in DRAM?	\item Refresh cycles.&nbsp;<div>\item Read the memory row then write it back.</div>
Why does reading a DRAM cell take much longer than an SRAM cell?	\item Need to wait for the capacitor to discharge<div>\item Need to amplify the signal</div><div>\item Need to write the value that was read out back to the capacitor</div>
How is demultiplexer size explosion limited in RAM?	\item By transmitting the address to the RAM in two parts:&nbsp;<div>\item first the row address is sent, demultiplexed, and the corresponding row line activated \&amp; read out.</div><div>\item then the column address is sent, demultiplexed, and the bit corresponding to the column line is sent to out output</div><div>\item Then both column \&amp; row addresses can be reset</div>
Where is SRAM usually used?	\item For on-die caches
What's SDRAM?	\item Synchronous DRAM
What's DDR in computer architecture?	\item Double Data Rate DRAM, a successor to SDRAM
What's the CAS latency in computer architecture?	\item How many cyces it takes the RAM to read out a value once the column address selection has been received
What's the word size of most modern SDRAM?	\item 64 bits
What does it mean for computer memory to be double-pumped?	\item It'll transmit two words per cycle&nbsp;
How does modern DRAM optimize row address selection \&amp; column address selection?	\item The memory controller can ask for the next 1, 2, 4, 8 words following the first address<div>\item The memory controller can `keep the row open' and submit a new column address selector without having to respecify the row address selector.</div>
What's the row precharge time in computer architecture?	\item The time it takes to delatch the previous row and prepare to accept a new row address selector
What's the active to precharge delay in computer architecture?	\item The time needed after a row address selection before the next row address selection can be precharged<div>\item Usually two or three times the row precharge time</div>
What's the memory command rate in computer architecture?	\item How many cycles it takes the memory controller to issue a new command
How often must a DRAM cell be refreshed?	\item Usually once every 64ms
How are DRAM cells read?	\item Every cell on a row is read simultaneously, and all are subsequently written/refreshed simultaneously.<div>\item Only the bit specified by the column address selector will be output though</div>
What distinguishes DDR from SDRAM?	\item SDRAM transmits data on the leading edge of the clock signal<div>\item DDR transmits data on the leading and falling edge of the clock signal</div>
What's the difference between DDR and DDR2?	\item The memory's internal frequency is twice that of the external frequency.
In computer architecture, what are the L1i and L1d caches?	\item L1 instruction cache<div>\item L1 data cache</div>
Why are instruction caches used by most processors?	\item Decoding instructions is very slow
How is the L2 cache split between code and data?	\item It usually isn't. Both the L1i and L1d caches treat it as the next level of the memory hierarchy though
What's a cache line?	\item (usually) 64 bytes of contiguous words, the unit of caching in most modern architectures
What's a cache tag in computer architecture?	\item The portion of the memory address that a cache line corresponds to<div>\item (on a 64 byte cache line for example, the low six bits will be zeroed)&nbsp;</div>
How many data transfers does a cache line correspond to in modern architectures?	\item A 64 byte cache line and a 64 bit word corresponds to 8 trasfers
How does a memory address correspond to a location in most modern caches?	\item The leading bits form the tag<div>\item The middle bits identify the cache set</div><div>\item The trailing bits form an offset into the cache line</div>
What're the aliases of a cache line?	\item The addresses of all possible memory locations that could be stored in that cache line
What's an exclusive vs an inclusive cache in computer architecture?	\item Exclusive caches copy a line back to the next level of the hierarchy when they're evicted from the current level<div>\item Inclusive caches store any line in the current level in all higher levels, so eviction only entails a deletion rather than a copy&nbsp;</div>
What's a dirty cache line in computer architecture?	\item A cache line whose modifications haven't been copied back to main memory
What's cache coherency in computer architecture?	\item The fact that different processors with different caches should all have the same uniform view of memory
How is cache coherency maintained in most multiprocessor architectures?	<div>\item Processors watch eachother's memory requests</div><div>\item Dirty cache lines are not allowed to be present in any other processor's cache</div><div>\item Clean cache lines can reside in arbitrarily many caches</div><div>\item Implemented by a protocol called MESI</div>
How does random write time react to changes in working set size?	\item It's a staircase, with a leading edge whenever the working set exceeds the size of a cache
What's a fully associative cache?	\item One where each cache line can hold a copy of any memory location
What's the problem with a fully associative cache?	\item The processor has to check every cache line to see if the memory location it's looking for has been cached<div>\item This requires a lot of circuitry to do quickly</div>
What's the most common use of a fully associative cache?	\item TLB caches of a few dozen entries on some Intel processors.
What's a direct mapped cache?	\item One where each memory location corresponds to a single cache line
What's the problem with direct-mapped caches?	\item High eviction rates if you're unlucky<div>\item Large multiplexers needed&nbsp;</div>
What's a set associative cache?	\item The memory address is broken into a tag (highest bits) and set address (middle bits)<div>\item All entries in the corresponding cache set have their tags compared against the tag simultaneously, and their data read out simultaneously.</div><div>\item The successful match has its data output</div>
What does it mean for a cache to be 8-way set associative?	\item It's a set-associative cache where each set contains 8 tags
How is cache size related to associativity in a set associative cache?	\item $\text{cache size} = \text{cache line size} \times \text{associativity} \times \text{number of sets}$
What's the most common kind of CPU cache in 2014?	\item An 8-way set-associative cache
What's a processor prefetch?	\item If the processor can predict which memory location will be needed next, it'll start the memory access early
What's a write-through cache implementation?	\item One where changes to a cache line are immediately written to main memory
What's a write-back cache implementation?	\item When a cache line is written to, it's marked as dirty.&nbsp;<div>\item When a dirty cache line is evicted, it's written back to memory</div>
What's the problem with write-back caches?	\item They damage cache coherency<div>\item Deletions take some time</div>
What's the MESI cache protocol?	<div>\item A protocol for maintaining cache coherency in write-back caches</div>\item A cache line can be marked as modified, exclusive, shared or invalid.<div>\item These represent whether the cache line is to be written to and whether any other processor has a copy of the line.</div><div>\item Processors snoop on eachother's writes to Shared lines and invalidate their own cached version of a line if another processor writes to it.</div>
In the MESI protocol, what's an RFO?	\item A request for ownership,&nbsp;<div>\item which requests the other processor invalidates their cache line so the sender can write to theirs&nbsp;</div>
What's the problem with hyperthreading technologies?	\item They split the cache between them, possibly dramatically lowering the cache hit rate<br />
What're hyperthreads?	\item Threads that share almost all the resources of a CPU except the register.<div>\item This allows one thread to take advantage of spare CPU resources while the other is waiting on reads, and allows reads to be executed concurrently</div>
Are L1 caches generally virtually or physically addressed?	\item Virtually addressed, so they have to be flushed when the page table changes
Are L2 and L3 caches generally virtually or physically addressed?	\item Physically, as their latency gives plenty of time for the virtual to physical conversion to be done
From a caching perspective, what's the problem with self modifying code?	\item The L1i cache assumes that code pages are immutable<div>\item so if changes are detected a lot of pessimistic assumptions have to be made</div>
What's the critical word protocol in computer architecture?	\item If the word the processor needs to fetch from memory won't be the first in its cache line<div>\item the memory controller can ask for that word - the critical word - first, and then backfill the cache line afterwards</div>
What's the job of a CPU's Memory Management Unit?	\item To take a page table provided by the OS and use it to implement virtual addressing
How many levels do modern page tables have?	\item At most 4
How is a page table used?	\item If the page table has (say) 4 levels, the address is split into 5 parts<div>\item The leading bits are used for an index into the Level 4 directory</div><div>\item which gives a pointer to a Level 3 directory that the second group of bits index into,</div><div>\item etc</div><div>\item and the Level 1 directory gives a pointer to a memory page that the last group of bits index into</div>
How are page table trees assigned to threads?	\item Each process gets its own page table
What's the standard page size in most computers?	\item 4KB
What's ASLR in computer architecture?	\item Address Space Layout Randomization, where the code, heap, stack, libraries of an executable are mapped to random locations for security reasons<br />
What's the TLB cache?	\item A cache (hierarchy) for page table lookups<div>\item usually small and fully associative, but more recently larger and set associative</div>
How is the TLB used?	\item The virtual address is broken into a tag, which is an address into the page table, and an offset<div>\item The tag is looked up in the TLB</div><div>\item and the offset is added to it</div>
Why can't TLB entries be prefetched by processors?	\item Because the processor might prefetch an invalid tage table walk
What are the caches in a modern TLB hierarchy?	\item (Instruction) ITLB<div>\item (Data) DTLB</div><div>\item and a unified L2TLB</div>
What's the structure of a Haswell L1 DTLB?	\item 100 entries over 4kB, 2MB and 1GB pages<br /><div>\item all 4-way set associative</div>
What's the structure of Haswell's L2 TLB?	\item 1024 entries shared over 4KB and 2MB pages<div>\item 8 way associative</div>
Are TLBs per core or per processor?	\item Per core
What are the two approaches to dealing with the TLB across multiple processes?	\item Either flush the TLB whenever the page table tree changes<div>\item Or extend the TLB tags to uniquely ID the page table tree they refer to</div>
What's the two main advantages of extending TLB tags?	\item A lot of context switches are to the kernel and/or virtual memory manager for a very short time. Without extended tags, this leads to two flushes of the TLB.<br /><div>\item Switching between threads within a process also requires a trip to the kernel. Again, this would lead to two flushes without tags.</div>
What's the advantage of large page sizes?	\item Fewer entries in the page table<div>\item Lower chance of a TLB miss for contiguous data<div>\item If it's built into the OS, the page table depth can be reduced</div></div>
What's the downside of large page sizes?	\item A lot of memory operations require alignment to page boundaries, so large pages waste more space<br /><div>\item Large pages on most systems need to be comprised of many smaller pages, and finding contiguous regions of free space can be difficult.</div>
What's the standard structure of a x86-64 page table?	\item Four levels each dispatching 9 bits<div>\item and a offset of 12 bits</div>
What's the size of the standard virtual address?	\item 48 bits
What are Extended Page Tables/Nested Page Tables?	\item An Intel/AMD virtualization technology which allows the page table on the host machine to be extended to provide virtual addresses to processes in the guest machine<br />
What's the effect of virtualization on page table lookups?	\item More levels have to be searched through<div>\item The TLB can't tag individual processes in the guest machine</div>
When's a hardware prefetch usually triggered?	\item Traditionally when there're two cache misses to adjacent cache lines<div>\item but nowadays larger `strides' of up to 256 bytes might also be recognised</div>
How many memory accesses can modern CPUs have going simultaneously?	\item 8 or 16
What're the main limitations of hardware prefetching?	\item It won't be triggered by misses on different pages<br /><div>\item It'll only spot very simple access patterns</div>
What's SIMD in computer architecture?&nbsp;	\item Single instruction, multiple data<div>\item ie parallel instructions that can be found on some processors</div>
How do you group subexpressions in a regex without capturing them into a variable?	\item \ttt{(?:abc)} will group without capturing into a \ttt{\tbs i} variable
What's an important distinction with things like RegEx's \ttt{\tbs t}?	\item Used in a regex it's a regex metacharacter that'll match against a tab character<div>\item Used in a string it's a string metacharacter that'll insert a tab character</div>
What's the regex lookahead operator?	\item \ttt{(?=abc)} will try to resolve to a position that is followed by \ttt{abc}
What's the regex lookbehind operator?	\item \ttt{(?&lt;=abc)} will try to resolve to a position that follows \ttt{abc}
What's the regex negative lookahead operator?	\item \ttt{(?!abc)} will try to resolve to a position that isn't followed by \ttt{abc}
What's the regex negative lookbehind operator?	\item \ttt{(?&lt;!abc)} will try to resolve to a position that isn't after \ttt{abc}
Where does a regex usually start when searching for the next match?	\item The end of the last match
What's a multiline mode in regex?	\item A switch that'll cause \ttt{\$} and \ttt{\^{}} to be interpreted as start- and end-of-line characters rather than start- and end-of-string characters.&nbsp;
How do you create a case-insensitive regex in Java?	"\item \ttt{Pattern.compile(""expression"", Pattern.CASE\_INSENSITIVE)}"
Using a single line of code, how can you test whether a regex appears in a string in Java?	"\item \ttt{Pattern.matches(""regex"", ""string"")} will return true or false"
How do you insert comments into a Java regex?	"\item \ttt{Pattern.compile(""\# comment \tbs n \# another comment"", Pattern.COMMENTS)}"
How do you match against a whitespace character in Java regexes?	"\item \ttt{Pattern.compile(""\tbs \tbs s"")}<div>\item First backslash escapes the second</div>"
How do you view a Java regex as it was received by the function?	\item \ttt{System.out.println(compiledPattern.pattern().toString())}
How do you search and replace with regexes in Java?	"\item \ttt{Pattern.compile(""pattern"")} to get a \ttt{pattern}<div>\item \ttt{pattern.matcher(""text"")} to get a \ttt{matcher}</div><div>\item \ttt{newText = matcher.replaceAll(""substitute"")} to replace all occurances&nbsp;</div>"
How do you pass multiple bit flags to a function in Java?	"\item \ttt{Pattern.compile(""text"", Pattern.CASE\_INSENSITIVE|Pattern.COMMENTS)}"
How do you write a regex over several lines in Java?	"\item \ttt{Pattern.compile(""line1 \tbs n"" + ""line2"", Pattern.COMMENTS)}<div>\item \ttt{COMMENTS} flag causes the pattern to ignore whitespace</div>"
How do you match against a tab character in a Java regex?	"\item \ttt{Pattern.compile(""\tbs t"")}<div>\item Only one backslash needed as Java string parsing will convert it to a tab character before passing it to the regex engine</div>"
What's a Unicode code point?	\item The number (usually written in hexadecimal and prepended by \ttt{U+}) that corresponds to a certain character
How do you escape a unicode code point in Java?	\item \ttt{\tbs u2345}
What do unicode regexs consider to constitute a character?	\item A single code point.&nbsp;<div>\item So combining characters are their own characters</div>
What's the shorthand for matching against a digit in Java regexes?	\item \ttt{\tbs d}
What's the shorthand for matching against a non-digit in Java regexes?	\item \ttt{\tbs D}
What's the shorthand for matching against a whitespace character in Java regexes?	\item \ttt{\tbs s}
What's the shorthand for matching against a non-whitespace character in Java regexes?	\item \ttt{\tbs S}
What's the shorthand for matching against a word character in Java regexes?	\item \ttt{\tbs w}
What's the shorthand for matching against a non-word character in Java regexes?	\item \ttt{\tbs W}
How do you match against a Unicode character with a specific quality in a Java regex?	\item \ttt{\tbs p\{quality\}}
How do you match against a Unicode character without a specific quality in a Java regex?	\item \ttt{\tbs P\{ quality \}}
What's Java's regex quality for ASCII punctuation?	\item \ttt{\tbs p\{Punc\}}
What's Java's regex quality for ASCII lower case letters?	\item \ttt{\tbs p\{Lower\}}
What's Java's regex quality for ASCII upper case letters?	\item \ttt{\tbs p\{Upper\}}
How do you match against an intersection of two character classes in Java regex?&nbsp;	\item \ttt{[[a-d]\&amp;\&amp;[b-e]]}<br />
How do you match against the union of two character classes in Java regexes?	\item \ttt{[[a-d][b-e]]}<div>\item \ttt{[a-db-e]}</div>
How do you match against a word boundary in Java regex?	\item \ttt{\tbs b}
How do you match against the beginning of the input in Java regexes?	\item \ttt{\tbs A}
How do you match against the end of the input in Java regexes?	\item \ttt{\tbs Z}
How do you match against the end of the previous match in Java regexes?	\item \ttt{\tbs G}
What's Java's restriction on what can appear in a regex lookbehind?	\item It can only match a finite amount of text
How do you turn case sensitivity on and off within a Java unicode regex?	\item \ttt{(?i)} and&nbsp;\ttt{(?-i)}&nbsp;will turn it on/off for the duration of the parenthesized expression it sits in<br /><div>\item \ttt{(?i:pattern)} and \ttt{(?-i:pattern)} will turn it on/off for the pattern following</div>
How do you enable multiline mode in Java regexes?	"\item \ttt{Pattern.compile(""pattern"", Pattern.MULTILINE)}"
Does \ttt{.} match line terminators in Java regexes?	\item No, but it can be enabled with the \ttt{Pattern.DOTALL} switch
How do you toggle literal mode in a Java regex?	\item \ttt{\tbs Q} to start a literal segment<div>\item \ttt{\tbs E} to end the literal segment</div>
What's literal mode in Java regexes?	\item A portion of the regex where no character other than the literal termination character (usually \ttt{\tbs E}) is considered a metacharacter
How can you fetch a subexpression of the current regex match in Java from outside the regex string?	\item \ttt{matcher.group(4)} to get the 4th parenthesized subexpression
How do you capture a named subexpression in Java regexes?	\item \ttt{(?&lt;name&gt;pattern)}
How do you recall a named subexpression in a Java regex?&nbsp;	\item \ttt{\tbs k&lt;name&gt;}
How do you access a named group from the current match in Java, from outside the regex?	"\item \ttt{matcher.group(""name"")}"
What's atomic grouping in a regex?	\item A parenthesized subexpression that matches as much as it can and then becomes immutable - it won't back off later to allow later expressions to match against the text it's covered
How do you construct an atomic grouping in Java regexes?	\item \ttt{(?&gt;pattern)}
What are the reluctant quantifiers in Java regexes?	\item \ttt{*?},&nbsp;\ttt{??},&nbsp;&nbsp;\ttt{\{3, 5\}?}, etc<div>\item They'll match as little as possible</div>
How do you match against an expression at least 7 times in Java regexes?	\item \ttt{pattern\{7,\}}
How do you match against an expression exactly 7 times in a Java regex?	\item \ttt{pattern\{7\}}
What are Java regex's possessive quantifiers?	\item \ttt{*+}, \ttt{++}, \ttt{\{3, 5\}+}<div>\item Syntactic sugar for atomic groupings; once they've matched they won't back off</div>
What's Java's underlying regex engine?	\item Traditional NFA
In an alternation in an NFA regex, which alternative will be selected if several could fit?	\item The first one that fits
What are the two universal rules about how a regex will select matches?	\item Matches that begin earlier are always preferred<div>\item The standard quantifiers (\ttt{*, ?, +, \{m, n\}}) are greedy</div>
What do NFA and DFA stand for in the context of regexes?	\item Nondeterministic finite automaton<div>\item Deterministic finite automaton</div>
Intuitively, how do NFA regex algorithms work?	\item They crawl the string until they get a match against the first component of the pattern<div>\item and then try to match the next components iteratively, backtracking if needs be</div>
Intuitively, how do DFA regex algorithms work?	\item They scan the string, maintaining a list of all the possible matches to the pattern
What's a common mistake with the zero-or-more quantifier in regexes?	"\item Having a regex of the form \ttt{a*} not realizing it'll match the empty string on a text \ttt{""b""}"
What's a subtle distinction between the characters matched by \ttt{[\^{}a]} and \ttt{.} in most regexes?	\item \ttt{[\^{}a]} will match a newline<div>\item \ttt{.} won't</div>
How do you get the matched text from a regex in Java?	\item After a matching operation, \ttt{matcher.group()}
How do you see whether a regex matches some part of a string in Java?	\item \ttt{matcher.find()} will return a boolean (and advance the match pointer)
How can you restrict the region of a string targeted by a Java regex?	\item \ttt{matcher.region(int start, int end)}
What does Java's transparant bounds regex flag do?	\item It allows lookaround operators to check outside the region of text to be matched against
How can you test whether passing additional input to a regex could create another match?	\item Call \ttt{matcher.find()} and then \ttt{matcher.hitEnd()} to see whether the matcher hit the end of the string while trying to match
How do you get the start \&amp; end indices of a Java regex match?&nbsp;	\item \ttt{matcher.start()}, \ttt{matcher.end()}
How do you store a match result from a Java regex?	\item \ttt{matcher.toMatchResult()}, which will return a \ttt{MatchResult} object
How do you test whether a Java regex exactly matches a region of text?	\item \ttt{matcher.matches()}&nbsp;
How do you test whether a Java regex matches the start of a region of text?	\item \ttt{matcher.lookingAt()}
How do you move to the next match of a Java regex?	\item \ttt{matcher.find()}<div>\item Will return false if there are no further matches</div>
How do you get the indices delimiting the text matching the $i$th subexpression of a Java regex?	\item \ttt{matcher.start(i)},&nbsp;\ttt{matcher.end(i)}
How do you replace the first instance of a Java regex in a text?	"\item \ttt{matcher.replaceFirst(""replacement"")}"
How do you reference subexpressions in a regex from a replacement string in Java?	\item \ttt{\$1} matches the first subexpression, \ttt{\$2} the second, etc
How do you reference the text matching a Java regex from a replacement string?	\item \ttt{\$0}
What's the most efficient way of doing a lot of search \&amp; replaces on Java strings using regex?	"\item Create a \ttt{StringBuffer}<div>\item and repeatedly call \ttt{matcher.find()}, \ttt{matcher.appendReplacement(buffer, ""replacement"")}, which will copy the text up to the start of the match then append the replacement string.</div><div>\item Then call \ttt{matcher.appendTail(buffer)} to append the remaining text after the final match.</div>"
How can you test whether passing additional input to a Java regex would stop the previous match from succeeding?	\item \ttt{matcher.requireEnd()}
What's a context switch in computer architecture?	\item Can mean a switch between threads<div>\item Can mean a switch between processes</div><div>\item Can mean a domain transition</div>
What's a trap in computer architecture?	\item An event that causes a transition from user privilege to supervisor privilege<div>\item If a trap occurs while already in supervisor privilege, it doesn't cause a domain transition</div>
What does a process switch entail?	\item Change from user to supervisor protection domain<div>\item Change stacks: switch from user stack to a kernel stack</div><div>\item Save user state on the kernel stack</div><div>\item Do kernel stuff</div><div>\item Kernel thread switch</div><div>\item Restore user state&nbsp;</div><div>\item Change from supervisor protection domain to user</div>
What are common causes of traps in computer architecture?	\item Trap calls, explicit system calls to trigger a trap<div>\item Exceptions, like accessing invalid memory</div><div>\item External events like packet arrivals or disk operations completing</div>
When can context switches occur?	\item Only when the computer's in privileged mode
What're two other names for kernel mode?	\item Supervisor mode<div>\item Priveleged mode</div>
What does Yegge think Google does wrong?	\item It focuses on products over platforms
Why's it a better idea to build a platform than a product?	\item Because platforms can be extended without the owner's interference
What's the goal in building a platform?	\item To encapsulate some computation and data into something that can be treated as a service&nbsp;
What's availability in the context of CAP?	\item Any consumer can reach some copy of the data it wants
What's an example of a CA but not P distributed system?	\item Databases which provide distributed transactions
What's an example of a CP but not A distributed system?	\item An ACID database which prevents transactions while there's a partition
What's an example of an AP but not C distributed system?	\item A system which uses caching in the advent of an availability failure
What's the weak CAP conjecture?	\item That to improve a system's C, A, or P, you have to trade off in one of the other two&nbsp;
What's yield in the context of distributed systems?	\item The probability of a request being completed<div>\item The probability of an update being applied</div>
What's harvest in the context of distributed systems?	\item The completeness of an answer to a query<div>\item The visibility of an update</div>
What yield do good distributed systems aim for?	\item Four or five nines.
What's the simplest strategy for trading harvest for yield in distributed systems?	<div>\item Spread data over many nodes, and answer a query using whatever data is visible within a timeout</div>
What're orthogonal mechanisms in distributed systems?	\item Components that have very little or no runtime interface to other mechanisms<div>\item So if they fail, they don't affect anyone else</div>
What's the typical range of the server-to-administrator ratio?	\item 2:1 on less automated services<div>\item 2,500:1 on ideal highly automated services</div>
What are three simple tenets to designing web-scale services?	\item Expect failures. Any component may crash or be stopped at any time.<div>\item Keep things simple. Few dependencies, simple installation.</div><div>\item Automate everything possible.</div>
How should the development, test and operations teams of a webscale service be structured?	\item They should work as closely together as possible.
What's the best way to test the failure path of a distributed system?	\item Never shut it down normally, just hard-fail it and see how it recovers.
What's the acid test as to whether a distributed service is sufficiently fault tolerant?	\item Whether the ops team is willing to bring down any server at any time without draining its workload first
How does power consumption scale with clock frequency? What's the relevance to distributed system design?	\item Cubically.<div>\item So lots of low-power servers might be a better idea than a few high-powered ones</div>
What should be the versioning policy for web-scale software?	\item One supported version at any one time<div>\item One supported hardware at any one time.&nbsp;</div><div>\item but *tolerate* multiple concurrent versions and hardware</div>
What're the prerequisites for developing web-scale software in a full environment?	\item A way to deploy the system to a single test server<div>\item A way to quickly check the system's health</div>
How should protocols for human intervention in distributed systems be written?	\item As scripts, not as multi-step documents!
What's the rule of thumb for a complex optimization being worth it compared to a simple one in distributed systems?&nbsp;	\item When it brings order-of-magnitude improvements to performance
Where should throttling be implemented in distributed systems?	\item At all major component boundaries
How should the partitioning of a distributed system be designed?	\item To be infinitely fine-grained, usually meaning a hash table<div>\item Ex: if you partition data over nodes by name prefix for example, eventually all names starting with P won't fit on one server.&nbsp;</div>
At roughly what rate does emergency human intervention in a system go wrong?&nbsp;	\item About 20\% of the time
What are the four strategies for dealing with latency when designing distributed services?	\item Suppress coupling between components<div>\item Asynchronous interactions from the beginning</div><div>\item Horizontal data decompositiion from the beginning</div><div>\item Design for active/active configuration</div>
What's an active/active configuration in distributed systems?	\item One where all nodes partake in servicing requests, and in case of failure traffic is moved onto the other node<div>\item Contrasts with active/passive, where one node is dormant until the active one fails&nbsp;</div>
Roughly how far is a 10ms RTT equivalent to in fiber?	\item 1000km
What's the speed of light in a fiber?	\item About $\sim $200,000km/s
What's the average round-trip latency of the last mile of an internet connection?	\item 20-50ms
What's the typical round trip latency for the first hop of a mobile connection?	\item 100-1000ms
What's the basic idea of MapReduce?	\item Users specify<div>\item a map function that processes each key-value pair in the data to produce an intermediate set of key-value pairs</div><div>\item a reduce function that takes an intermediate key and the intermediate values with that key, and returns another (usually much smaller) set of values&nbsp;</div>
How is a MapReduce invocation distributed across hardware?	\item Input data is partitioned into splits of $\sim$64MB each, and a single node computes the map function for each split, storing the result on a local disk.<div><div><div>\item Intermediate key space is partitioned by the hash of the key, and a single node computes the reduction for one partition of the space&nbsp;</div></div></div><div>\item The location of the result for each key for each map worker is passed back to the master,</div><div>\item who passes all the locations for a given partition of the key space to the relevant reduce worker.</div><div>\item When the reduce worker completes, it sorts the output and writes its result to a temporary file in the output directory and then atomically renames the file to the final name</div>
What information does the master track about execution in MapReduce?	\item The state of each map task and reduce task (idle/in progress/completed)<div>\item The identities of the worker machines</div><div>\item The locations of the intermediate files</div>
How does MapReduce deal with worker failures?	\item Workers are pinged regularly.<div>\item If a map worker fails to respond to a ping, their work is re-executed and all workers are notified of the failure</div><div>\item If a reduce worker fails to respond to a ping before they've reported their work complete, their work is re-executed</div>
How does MapReduce respond to master failure?	\item It aborts execution. Clients can retry if they desire.
How many partitions of the intermediate key space are typically used in MapReduce?	\item A small multiple of the number of workers that're expected to be used
How does MapReduce deal with straggling tasks?	\item When a MR operation is close to completion, the master schedules backup executions of the last few tasks
How does MapReduce deal with bad records?	<div>\item Before each execution of map or reduce, the worker stores the sequence number of the input</div>\item If a worker encounters an error, it sends a last-gasp packet to the master with that sequence number<div>\item When the master has seen the same sequence number more than once, it tells the next worker attempting the task to skip that record</div>
What's the problem solved by a consensus algorithm?	\item A collection of processes can each propose a value<div>\item We want to select a single value from them, if there are any proposals</div><div>\item Processes should be able to learn the proposed value</div><div>\item Only a value that has been proposed can be chosen</div><div>\item Only a single value is chosen</div><div>\item No process learns that a value has been chosen unless it actually has been.</div>
What are the three roles in a consensus algorithm?	\item Proposers<div>\item Acceptors</div><div>\item Learners</div><div>\item A single process can act in more than one role though</div>
What are the communication assumptions of most consensus algorithms?&nbsp;	\item Messages can take arbitrarility long to be delivered,<div>\item can be duplicated</div><div>\item can be lost</div><div>\item but can't be corrupted</div>
What are the node failure assumptions of most consensus algorithms?&nbsp;	\item Nodes can stop<div>\item Nodes operate at arbitrary speed</div><div>\item Nodes can restart</div><div>\item Nodes can remember information across restarts</div>
What's the proposer's algorithm in the first phase of the Paxos when choosing a value?	\item A proposer selects a proposal number $n$ and sends a prepare request with number $n$ to a majority of acceptors.
What's the acceptor's algorithm in the first phase of the Paxos when choosing a value?	\item If an acceptor receives a prepare request with a number $n$ greater than that of any prepare request to which it has already responded, then it responds with<div>\item a promise not to accept any more proposals numbered less than $n$</div><div>\item the highest-numbered proposal it's accepted (if any)</div>
What's the proposer's algorithm in the second phase of the Paxos when choosing a value?	\item If the proposer receives a response to its prepare requests for number $n$ from a majority of acceptors,<div>\item then it responds with an accept request to each of them with number $n$ and value $v$,&nbsp;</div><div>\item where $v$ is the highest-numbered value amongst the responses, or any value if the responses reported no proposals</div>
What's the acceptor's algorithm in the second phase of the Paxos when choosing a value?	\item If an acceptor receives an accept request for a proposal numbered $n$,&nbsp;<div>\item it accepts the proposal unless it has already responded to a prepare request having a number greater than $n$&nbsp;</div>
How do learners learn the accepted value in the Paxos algorithm?	\item The trivial approach is to have each acceptor tell each learner when it accepts the proposal<div>\item A refined approach is to select a distinguished learner (usually the leader) who propagates the accepted proposal to the listeners</div>
How is liveness ensured in Paxos?	\item By selecting a distinguished proposer (usually the leader) who makes all the proposals.
What's the Fischer-Lynch-Paterson impossibility result?	\item That a reliable algorithm for electing a leader must make use of either randomness or time
How does the Paxos algorithm ensure two proposals aren't issued with the same number?	\item Different proposers choose their numbers from disjoint sets<div>\item and each proposers remembers in stable storage the highest number she's tried to issue so far</div>
What's the bully algorithm for electing a leader?	\item On each node<div>\item The node broadcasts an election message to all other nodes with higher IDs</div><div>\item If it doesn't get any response, it wins the election and broadcasts its victory</div><div>\item If it hears from a node with a higher ID, it waits for a certain amount of time for any process with a higher ID to broadcast itself as the winner. If it times out, it rebroadcasts the election message.</div><div>\item If it gets an election message from a node with lower ID, it responds with an alive message</div><div>\item If it gets a victory message from a node with lower ID, it initiates a new election</div>
How does the &nbsp;first phase of the ring algorithm for electing a leader start?	<div>\item Every node starts as a non-participant</div>\item If a node notices a lack of leader, it creates an election message containing its ID and sends it clockwise.
In the first phase of the ring algorithm for selecting a leader, what does a node do if it's a participant when it receives an election message?	<div>\item If the received ID is smaller than its own the message is discarded</div><div>\item if the received ID is larger than its own the message is forwarded</div><div>\item if the received ID is the same as its own, the node starts acting like a leader.&nbsp;</div>
In the first phase of the ring algorithm for electing a leader, what does a process which is a non-participant do when it receives an election message?	\item It marks itself as a participant and forwards the message with the ID sub'd for the larger of its own and the received ID.
What's the second phase of the ring algorithm for electing a leader?	\item The leader node marks itself as a non-participant and sends a victory message out with it's ID<div>\item When a non-leader node receives a victory message it marks itself as a non-participant and forwards the message</div><div>\item When the leader node receives the victory message it discards the message</div>
define residual&nbsp;	the difference between the measured value of a datum and its estimated value in a regression model
What's demand paging in computer architecture?	\item The OS only copies a disk page into physical memory if an attempt is made to access it
At a low level, how does demand paging work?	\item An attempt is made to access a page<div>\item If the page is valid</div><div>\item If the page is invalid, a page-fault trap occurs, in which</div><div>\item if the reference is a valid reference to secondary memory, page it in by scheduling the necessary disk operation</div><div>\item Resume the interrupted instruction</div>
What's an invalid page in computer architecture?	\item A page which currently resides in secondary memory
What's the difference between \ttt{compareAndSet} and \ttt{weakCompareAndSet} in Java's atomics?	\item The \ttt{weak} version doesn't impose a happens-before ordering on the variable<div>\item This makes it more efficient on some platforms, but also might make the compare fail for no apparent reason</div><div>\item Don't use it</div>
How do you implement a custom unmodifiable Collection in Java?	\item Derive from \ttt{AbstractCollection}<div>\item Implement \ttt{iterator()} without its \ttt{remove()} method</div><div>\item Implement \ttt{size()}</div><div>\item Advised to implement a no-arg constructor and a constructor that takes a collection</div>
How do you implement a custom modifiable Collection in Java?	\item Derive from \ttt{AbstractCollection}<div>\item Implement \ttt{iterator()} with its \ttt{remove()} method</div><div>\item Implement \ttt{size()} and \ttt{add()}</div><div>\item Override any other method you want</div><div>\item Advised to implement a no-arg constructor and a constructor that takes a collection</div>
How do you implement an \ttt{Iterator} in Java?	\item Implement \ttt{hasNext()} and \ttt{next()}<div>\item and optionally \ttt{remove()}</div>
What does Java's \ttt{==} do?	\item Compares reference equality
How do you override \ttt{equals(Object obj)} in Java?	\item Test if \ttt{obj == null}<div>\item Test if \ttt{this == obj}</div><div>\item Test if \ttt{obj instanceof Class}</div><div>\item Cast to \ttt{Class}</div><div>\item Test hash codes</div><div>\item Test member equality</div>
When should you consider overriding equals?	\item When it's an immutable type.
What are the core components of Java's NIO?	\item Channels<div>\item Buffers</div><div>\item Selectors</div>
What are the four primary channels in Java NIO?	\item FileChannel<div>\item DatagramChannel (UDP)</div><div>\item SocketChannel (TCP)</div><div>\item ServerSocketChannel (listen for TCP connections)</div>
What are the core buffer implementations in Java's NIO?	\item ByteBuffer, CharBuffer, etc - one for each primative
What's the use of a selector in Java NIO?	\item It allows a single thread to handle multiple channels
What's the difference between NIO channels and streams?	\item Channels are bidirectional<div>\item Channels are asynchronous</div><div>\item Channels always read/write to a Buffer</div>
How do you get an input channel for a file in Java?	"\item Create a \ttt{FileInputStream(""name"")}<div>\item Call \ttt{fileInputStream.getChannel()}</div>"
How many bits do you need in a Bloom filter for a 1\% error rate?	\item $\sim$10 bits per element
What's the time complexity of a radix sort?	\item $O(kn)$, where $k$ is the length of the key
What's Google's BigTable?	\item A sparse, distributed, multi-dimensional sorted map
What's BigTable's map indexed by?	\item Row key (string)<div>\item Column key (string)</div><div>\item Timestamp</div>
What's a tablet in BigTable?	\item A range of rows that constitutes a unit of load balancing
What type are the values in BigTable?	\item Strings.
What are column families in BigTable?	\item A grouping of column keys that form the basic unit of access control and memory accounting
How is versioning done in BigTable?	\item Versions of a cell are stored in descending timestamp order<div>\item Clients can specify how old a cell must be before it's garbage collected</div>
What kind of indices do you use when writing a binary search?	\item A closed range!
When should a binary search's loop terminate?	\item When the lower index is strictly larger than the upper index
How should you update the lower or upper index after a binary search loop?	\item \ttt{lower = midpoint + 1}<div>\item \ttt{upper = midpoint - 1}</div>
Where should you test for equality in a binary search?	\item Inside the loop!
In a binary heap over an array, where will you find the children of node $i$?	\item At $2i+1$ and $2i+2$
How do you insert an element into an array heap?	\item Add it in the last position and bubble it up&nbsp;
How do you delete an element from a binary heap over an array?	\item Swap the element with the last element<div>\item Shorten the array by one</div><div>\item Bubble the old-last element down.</div>
What's the idea in the Join-Idle-Queue algorithm?	\item Tokens for idle workers are load balanced across the dispatchers
What's the problem the Join-Idle-Queue algorithm solves?	\item How to distribute work from many dispatchers across many workers<div>\item while keeping response times low</div>
How does Join-Idle-Queue distribute its idle workers?	\item Either by chosing a dispatcher at random to notify of its idleness<div>\item Or sampling $d$ dispatchers and choosing the one with the least number of queued idles&nbsp;</div>
What does $-1$ correspond to in two's compliment?&nbsp;	\item All ones.
How do you detect an overflow when adding two two's compliment numbers?	\item If the two highest carry bits are 10 or 01
What's the simplest solution to the dining philosophers problem?	\item Number the forks and insist the philosophers pick up the lowest numbered fork first
How do you call the default \ttt{hashCode} implementation in Java, even if it's been overridden?	\item \ttt{System.identityHashCode(obj)}
If you induce an ordering on locks using their hash codes, how can you deal with the case where two locks have the same hash code?&nbsp;	\item Add a third tie-braking lock.<div>\item Have to get the tie-breaking lock before you get the other two locks</div>
When should you be wary of calling alien methods?	\item When you're holding a lock, since it's impossible to know what other locks the alien will try and get
What's an open call in concurrent programming?	\item A method call made without holding a lock
What's the best way to diagnose deadlocks?	\item Identify all locations in the code where more than one lock is taken simultaneously<div>\item Check that the lock ordering is consistent across all these locations</div>
How do you get a lock in an interruptable manner in Java?	\item \ttt{obj.lockInterruptibly()}<div>\item Throws \ttt{InterruptedException}</div>
How do you trigger a thread dump from the command line on Unix?	\item \ttt{Ctrl+\tbs}
What's a thread dump?	\item Like a stack trace, but for threads and their locking information
What's \ttt{jstack}?	\item A command line tool which when fed a Java process ID will print the thread dump
How do you list all processes in Unix?	\item \ttt{ps -e}
What's the usual solution to livelock problems?	\item Introduce randomness, usually a random backoff
Why does frequent lock contention degrade performance so badly?	\item Causes extra context switches<div>\item When a thread blocks, it wastes the rest of its quantum</div>
What's lock elision in concurrent programming?	\item If a compiler notices that an object is only visible to one thread (ex: it's in local scope)<div>\item it'll optimize out any lock acquisitions on that object</div>
When is spin-waiting preferable to suspension?	\item Spin waiting is preferable when the thread will only block for a short time<div>\item Suspenson is preferable when the thread will block for a long time</div>
What's lock striping in concurrent programming?	\item Replacing a lock that guards multiple variables with multiple locks to guard subsets of those variables
When's it advantageous to split a lock in concurrent programming?	\item When the lock suffers moderate contention
What's the downside to lock striping?	\item It's harder to acquire all the locks.
How do you acquire an arbitrary set of intrinsic locks in Java?	\item Through recursion
What's a hot field in concurrent programming?	\item A field that every mutative method on an object has to acquire the lock for (like the \ttt{size} of a collection)
What's the advantage of \ttt{Atomic} Java primitives over explicit locking?	\item They use very fine grained processor primatives to conduct the locking.
What's the problem with object pooling in Java?	\item In modern JVMs, \ttt{new} is very fast - ten instructions or less<div>\item So object pooling is a serious loss for all but the most heavyweight objects</div>
What's the foundation of the Miller-Rabin test?	\item If $p$ is prime, there are no square roots of 1 mod $p$ other than $1, -1$<div>\item Fermat's Little Theorem</div><div>\item $Z/pZ$ is generated by the elements between 2 and $2(\ln n)^2$</div>
What's Fermat's Little Theorem?	\item $a^{p-1} \equiv_p 1$ for all $a$
What's the difference between \ttt{&gt;&gt;&gt;} and \ttt{&gt;&gt;} in Java?	\item \ttt{&gt;&gt;&gt;} is the unsigned right shift, introducing a zero on the left<div>\item \ttt{&gt;&gt;} is the signed right shift, replicating the sign bit on the left</div>
Do shift or bitwise operators have higher precedence in Java?	\item Shift operators
Do arithmetic or shift operators have higher precedence in Java?	\item Arithmetic operators.
How can you encourage thread interleavings when testing concurrent Java code?	\item Use more threads than there are processors<div>\item Judicious use of \ttt{thread.yield()} (though this might be a no-op on some platforms!)</div>
What's the best way to time threads when testing concurrent Java code?	\item Use a \ttt{CyclicBarrier} and have its barrier action start/stop a timer<div>\item Get times with \ttt{System.nanoTime()}</div>
What's dynamic compilation in Java?	\item If a method is used often enough, the JVM might compile it on-the-fly to machine code
What's the difference between \ttt{Thread.start()} and \ttt{Thread.run()} in Java?	\item Thread start causes the JVM to call \ttt{run()} on a new thread<div>\item Thread run just runs executes the method</div>
What's the idiom for using an explicit lock in Java?	<div>\item Acquire the lock</div>\item Immediately afterwards INSIDE A TRY BLOCK do some work<div>\item INSIDE THE FINALLY BLOCK release the lock</div>
What's hand over hand locking?	\item Have a lock for each node in a linked list<div>\item The lock guards both the data and the next pointer</div><div>\item so you have to acquire the lock before you can progress down the list</div>
What's the problem with fair locking in Java?	\item It significantly reduces throughput. Only use it when a lock will be held for a long time.
What's the easiest way to implement a read-write lock in Java?	\item Using \ttt{ReadWriteLock} and \ttt{ReentrantReadWriteLock}
How do you use a \ttt{ReadWriteLock} in Java?	\item \ttt{rwLock.readLock()} gets the read lock<div>\item \ttt{rwLock.writeLock()} gets the write lock</div>
How is the Fisher information defined?	\item $I(\phi) = \mbb{E}\left[\left(\frac{d \ln p(X|\phi)}{d\phi}\right)^2\right]$
What's the intuitive interpretation of the Fisher information?	\item It's a way of measuring how much information a rv $X$ carries about a parameter $\phi$
What are two alternative definitions of the Fisher information?	\item Variance of the score<div>\item Expectation of the observed information</div>
What's the definition of the score in statistics?	\item $\frac{d \ln p(X|\phi)}{d\phi}$<br />
What's the intuitive interpretation of the score in statistics?	\item Indicates how sensitive the likelihood is to a parameter
What's the definition of the observed information in statistics?	\item $\mathcal{J}(\theta^*) = -H(\ln p(X|\theta))|_{\theta^*}$<div>\item where $H$ is the Hessian</div><div>\item usually evaluted at the MLE</div>
What's the alternative way of calculating the Fisher information?	<div>\item Under certain regularity conditions,</div>\item $-\mbb{E}\left[\frac{d^2}{d\phi^2} \ln p(X|\theta)\right]$<br />
What's the Jeffrey's prior for the Dirichlet distribution?	\item $p(\theta) \propto \text{Dir}(\frac{1}{2}, \dotsc, \frac{1}{2})$
What's the translation invariant Jeffrey's prior?	\item $p(x) \propto 1$
What's the scale invariant Jeffrey's prior?	\item $p(s) \propto 1/s$ for some constant $s$
What's a robust prior?	\item A prior which has very heavy tails so as not to have too much of an influence on the result
What's the advantage of using a mixture of conjugate priors?	\item A mixture of conjugate priors is also conjugate<div>\item A mixture of conjugate priors can approximate any prior</div>
What does it mean to `borrow statistical strength'?	\item If you infer a hyperparameter from the data<div>\item then volumes of the independent variable space containing many datapoints can help deduce the parameters for volumes of the variable space containing few datapoints</div>
What's GDI in Windows?	\item Graphics Device Interface, the technology underlying (and preceding) WinForms
At what point during construction are XAML event handlers attached?	\item After the \ttt{Name} property has been set<div>\item but before any other property is set</div>
"What's the purpose of the \ttt{xmlns=""longstring""} property in XAML?&nbsp;"	\item It identifies the namespace to be used to qualify that element and it's children, allowing XAML elements to be mapped to framework elements
How do you declare multiple XML namespaces in the same tree?	"\item They need to be declared with different prefixes to be used with any identifiers from that namespace<div>\item Typically: \ttt{xmlns:x=""longstring""}</div>"
What's WinRT?	\item An unmanaged, low-level API for Windows.&nbsp;<div>\item Replacement for the ancient WinAPI</div>
What are the projections of the API exposed by WinRT?&nbsp;	\item \ttt{Windows.UI.Xaml} for XAML apps<div>\item \ttt{Windows.UI.WebUI} for HTML apps</div><div>\item \ttt{System} for .NET</div><div>\item \ttt{Windows} for general purpose WinRT</div>
What's the Windows app package manifest?	\item The \ttt{Package.appxmanifest} file that describes the app
How do you exit the splash screen in Windows 8 apps?	\item Call \ttt{Window.Current.Activate}
What are Win 8 app capabilities?	\item The permissions granted to an app
What are Win 8 contracts?	\item A way to cooperate with other apps or with Windows<div>\item Every contract has a source that initiates a task and a target that completes it&nbsp;</div>
What properties of a Windows 8 app does the package manifest describe?	\item Application-level properties (name, orientation, etc)<div>\item Capabilities (permissions)</div><div>\item Declarations (contracts)</div><div>\item Content URIs (URLs whose JS can be called)</div><div>\item Packaging</div>
Why are C\# classes that back XAML marked \ttt{partial}?	\item Because the definition in the \ttt{.cs} file is merged with a \ttt{.cs} file generated from the XAML
How do you name an XAML element?	"\item \ttt{Name=""nme""} attribute"
How do you cause a method to trigger when an XAML element is clicked on?	"\item Use the \ttt{Click=""MethodName""} attribute"
What method should always be in a code class that backs an XAML document?	\item A public constructor that calls \ttt{this.InitializeComponent()}
What does \ttt{this.InitializeComponent()} do in XAML backing code?	\item Associates the XAML-defined content with the instance of the class
What's the XAML application definition?	\item The \ttt{App.xaml} and \ttt{App.xaml.cs} files that handle application-level tasks
What's the entrypoint to an XAML application?	\item By default, the constructor of the \ttt{App} class
What's the default-generated \ttt{AssemblyInfo.cs} file do for XAML apps?	\item It contains a pile of information that can be managed elsewhere. Don't use it.
What's an extended splash screen in a Win 8 app?	\item A splash screen that has more functionality (like a loading bar) than the standard dumb image
What's globalization in app development?	\item Designing your app so it adapts to different markets without any need for manual customizations
Where is WinRT support for globalization found?	\item In \ttt{Windows.Globalization}
What's localization in app development?	\item The explicit activity of customizing an app for a specific market
How do you support localization in Win 8 apps?	"\item Identify XAML elements with \ttt{x:Uid=""UniqueID""}<div>\item Add a project folder with the relevant language code (ie \ttt{en-GB, en-CA})</div><div>\item Add a Resources file to the folder, where you can define custom \ttt{UniqueID.PropertyName}, \ttt{value} pairs for that language code</div>"
How do you test the localizability of a Win 8 app?	\item Use the Pseudo Language of VS's multilingual app toolkit&nbsp;
What're XLIFF files?	\item An XML standard for localizable data
What's the C\# equivalent of declaring a XAML object element?	\item Instantiating a class with it's default constructor
What's the C\# equivalent of defining an attribute in a XAML element?	\item Setting a property of an object or hooking up an event handler
What are the typical namespaces in use in XAML?	\item No prefix: standard UI&nbsp;<div>\item \ttt{x} prefix: XAML lang</div><div>\item \ttt{local} prefix: a custom namespace added with \ttt{using:}</div><div>\item \ttt{d} prefix: design-time information</div><div>\item \ttt{mc} prefix: markup compatibility&nbsp;</div>
What's an XAML property element?	\item One of the form \ttt{&lt;ClassName.PropertyName&gt;}, within a \ttt{&lt;ClassName&gt;} element.<div>\item Its content corresponds to assigning to that property</div>
What're type converters in WPF?	\item A property with a type derived from \ttt{TypeConverter} and decorated with \ttt{[TypeConverter]}&nbsp;<div>\item can be set up to automatically convert certain other types when they're given as values to the property in XAML</div>
What're markup extensions in XAML?	"\item Attribute strings of the form \ttt{""\{MarkupExtensionName PositionalParameterVal, NamedParameter=NamedParameterVal\}""}<div>\item which allow you to instantiate an instance of the \ttt{MarkupExtension} class</div><div>\item which will pass out a value via \ttt{markupExtension.ProvideValue}</div>"
In XAML markup extensions, how do you refer to the current element?	\item \ttt{Self}
In XAML, how do you escape a string which would otherwise be parsed as a markup extension?	\item Using an empty pair of curly braces: \ttt{\{\}\{...body...\}}
How do you add an item to a dictionary in XAML?	"\item \ttt{&lt;ValueTypeName x:Key=""key""&gt;val&lt;/ValueTypeName&gt;}"
What're the XAML rules for processing object element children?	\item If the type implements \ttt{IList}, call \ttt{Add(child)}&nbsp;<div>\item If the type implements \ttt{IDictionary}, call \ttt{Add(key, child)}&nbsp;</div><div>\item If the parent has a `content' property, try to set \ttt{parent.Content = child}</div><div>\item If the child is plain text, a type converter exists to transform the child into the parent type, and the parent element has no properties set, feed the child into the converter and use the output as the parent object instance.</div><div>\item Raise an error.</div>
How do you manually parse XAML?	\item Use \ttt{Windows.UI.Xaml.Markup}'s \ttt{XamlReader.Load} method
How do you associate a XAML element with a code-behind file?	"\item \ttt{x:Class=""Namespace.ClassName""}"
How do you reference a resource file from XAML?	"\item \ttt{""ms-appx:///path/to/file""}"
How do you add resource files to a Windows 8 app in VS?	\item Add the file to the project with a build action of content
What are .xbf files in Windows 8?	\item XAML binary files; the compiled, streamlined form of XAML files
What are panels in XAML?	\item Any element that supports the arrangement of multiple children
What's the root of XAML layout classes inheritance hierarchy?&nbsp;	\item \ttt{UIElement}
How can you get a Win8 app \ttt{FrameworkElement}'s actual size?	\item The \ttt{ActualHeight} and \ttt{ActualWidth} properties<div>\item but these should only be accessed from a \ttt{LayoutUpdated} event handler</div>
What's the only public subclass of \ttt{UIElement} in Win 8 apps?	\item \ttt{FrameworkElement}
What's the unit of measurement for length properties in XAML?	\item Logical pixels, which might be different from physical pixels depending on size, resolution and DPI (Windows will scale the quantities automatically)
What're the possible settings for \ttt{HorizonalAlignment} in XAML?	\item Left<div>\item Center</div><div>\item Right</div><div>\item Stretch</div>
What's content alignment in the XAML UIF?	\item \ttt{HorizontalContentAlignment} controls how the contents of an element are placed, as opposed to the element itself
How do you rotate an element in an XAML layout?	\item Set the \ttt{RenderTransform} property of the element to a \ttt{RotateTransform}<div>\item Set the \ttt{RenderTransformOrigin} or \ttt{CenterX, CenterY} properties</div>
How can you procedurally get a XAML element's final position and size after transformations have been applied?	\item Get the total transform with \ttt{element.TransformToVisual(null)}<div>\item Then apply \ttt{transform.TransformBounds(new Rect(0, 0, element.ActualWidth, element.ActualHeight))}</div>
How can you construct `3D' transforms in XAML?	\item Use the \ttt{PlaneProjection} type
How do you get the current size of the window in &nbsp;the XAML UIF?	\item Using \ttt{Window.Current.Bounds}, preferably from inside a \ttt{Window.Current.SizeChanged} event handler
What's a common mistake with \ttt{SizeChanged} event handlers in XAML UIF?	\item Forgetting to detach the handler when removing a page, which will stop it from being GC'd
What are the standard panels of the XAML UIF?	\item Canvas<div>\item StackPanel</div><div>\item Grid</div><div>\item VariableSizedWrapGrid</div>
How do you use the \ttt{Canvas} XAML UIF panel?	\item Set the \ttt{Canvas.Left} and \ttt{Canvas.Top} attributes in its child elements
What are attached properties in XAML?	\item Attributes of the form \ttt{ProviderType.Method} whose values are passed to a static method of the specified type
How do you control the z-index of children of an XAML UIF &nbsp;element?	\item Either alter the order they're listed in<div>\item Or set their \ttt{Canvas.ZIndex} property</div>
What's the use of XAML UIF's \ttt{Canvas} panel?	\item Allows precise, lightweight placement of elements.
What's the use of XAML's \ttt{StackPanel} element?	\item Allows vertical or horizontal `stacking' of it child elements
Naively, how do you use the XAML UIF \ttt{Grid} element?	"\item Use \ttt{&lt;Grid.RowDefinitions&gt;} containing \ttt{&lt;RowDefinition/&gt;} to add rows<div>\item Use \ttt{&lt;Grid.ColumnDefinitions&gt;} containing \ttt{&lt;ColumnDefinition/&gt;} to add columns</div><div>\item Use the \ttt{Grid.Row=""3""} and \ttt{Grid.Column=""4""} attached attributes to place elements in the grid.</div><div><br /></div>"
How do you get an XAML UIF element to span \ttt{Grid} rows?	"\item \ttt{Grid.RowSpan=""2""}"
What're the sizing options for XAML UIF \ttt{Grid} rows and columns?	\item Absolute<div>\item Autosizing: \ttt{Auto} uses as little space as possible</div><div>\item Proportional: \ttt{3*} will split the available space between every row using proportional sizing, using the number to weight the split</div>
What's XAML UIF's \ttt{VariableSizedWrapGrid}?	\item Basically a \ttt{StackPanel} (not a \ttt{Grid}!) which wraps elements to the next row/column when the current row/column runs out of space<br />
What are the five strategies for dealing with content overflow in XAML UIF?	\item Clipping<div>\item Scrolling</div><div>\item Scaling</div><div>\item Wrapping</div><div>\item Trimming (clipping with ellipses for text)</div>
In XAML UIF, are overflow strategies applied before or after transforms?	\item Before. So an item will be clipped before it's scaled.
What's the easiest way to set up a scrollbar in XAML UIF?	\item Use a \ttt{ScrollViewer} element and put your content inside it
What are snap points in XAML UIF?	\item A feature of \ttt{ScrollViewer} that allows you to `snap to' content when touch-scrolling ends
What're the easiest ways to scale in XAML UIF as a way of avoiding overflow?	\item Use the \ttt{Viewbox} element to zoom to fit automatically<div>\item Use the \ttt{ScrollViewer}'s pinch-to-zoom functionality</div>
What's the symbol for bits and what's the symbol for bytes?	\item 4kb: 4 kilobits<div>\item 4kB: 4 kilobytes</div>
What's a dependency property in XAML UIF?	\item A way to (almost) arbitrary associate data with UIF objects.<div>\item Calling \ttt{elem.SetValue(TypeName.PropName, val)} effectively creates an attribute on \ttt{elem} called \ttt{TypeName.PropName} with value \ttt{val}&nbsp;</div>
What's the C\# equivalent of a XAML UIF dependency property?	\item A custom public, static field with the suffix \ttt{Property}&nbsp;whose type is \ttt{DependencyProperty}<div>\item which is registered with \ttt{DependencyProperty.Register}<br /></div>
What's a property wrapper in XAML UIF?	\item Instance accessors for a static dependency property&nbsp;
Why should XAML UIF property wrappers not have any logic?	\item Because they're only there for convenience at compile time - the \ttt{GetValue}, \ttt{SetValue} methods will be called directly at runtime
What are the three features that XAML UIF dependency properties enable?	\item Notification when their value changes<div>\item Property inheritance</div><div>\item Multiple value providers</div>
What're the priorities of the most common providers to XAML UIF dependency properties?	\item Active animations<div>\item Local value (set with assignment)</div><div>\item Template properties</div><div>\item Style setters</div><div>\item Property inheritance</div><div>\item Default value (the initial value the property was registered with)</div>
How do you clear the locally-set value from a dependency property in XAML UIF?	\item Use \ttt{elem.ClearValue(ElemType.PropName)}
How are XAML UIF attached properties related to dependency properties?	\item Attached properties are a form of dependency property<div>\item Setting \ttt{Provider.AttachedProp = val} on an element \ttt{elem} calls \ttt{elem.SetValue(Provider.AttachedProp, val)}</div>
How do you create a new XAML UIF attached property?	\item Use \ttt{DependencyProperty.RegisterAttached}
What's a routed event in XAML UIF?	\item An event which when raised by an element, bubbles up the element tree to its root, getting raised by each element on the way&nbsp;
What's the visual tree in the Win 8 UIF?	\item The formal tree describing the relationship between objects and their children
Why shouldn't you manually alter the visual tree in the Win 8 UIF?	\item Because a later restyling of controls can alter the visual tree
How are dependency properties related to routed events in the Win 8 UIF?	\item They use the same basic structure as dependency properties, but with \ttt{RoutedEvent} fields rather than \ttt{DependencyProperty} fields.
What's the most important difference between routed events and dependency properties in the Win 8 UIF?	\item You can't define your own routed events
How do you attach a handler to a routed event in the Win 8 UIF?	"\item In the XAML file: \ttt{&lt;ElemName EventName=""HandlerName""&gt;}&nbsp;<div>\item In the code-behind file: \ttt{void HandlerName(object sender, EventNameArgs e)}</div>"
How do you halt bubbling in Win 8 UIF routed events?&nbsp;	\item Set \ttt{eventArgs.Handler = true}
Why might events on some Win 8 UIF controls not bubble up?	\item The control might be designed to swallow certain events (like \ttt{PointerReleased} on a \ttt{Button})
What's a common confusion with routed events in the Win 8 UIF?	\item There are only 23 actual routed events, but there are *many* more events that pass a \ttt{RoutedEventArgs} (or derived) instance to their handler.<div>\item This was done for compatibility with Silverlight. They don't actually bubble up.</div>
What's a common mistake when handling routed events in the Win 8 UIF?&nbsp;	\item Setting \ttt{eventArgs.Handled = true} only provides the *illusion* that they've stopped bubbling.<div>\item Ancestors can still receive routed events if they go out of their way to.</div>
At a high level, what are commands in the Win 8 UIF?	<div>\item They're version of events intended for use with interface-independent actions (like \ttt{Open} or \ttt{Refresh})</div>
How is a command defined in the Win 8 UIF?	\item By implementing \ttt{ICommand}, which has methods<div>\item \ttt{Execute}&nbsp;</div><div>\item \ttt{CanExecute}, which indicates whether the command is enabled</div><div>\item \ttt{CanExecuteChanged}, an event which is raised when \ttt{CanExecute} changes&nbsp;</div>
What's the advantage of Win 8 UIF commands over events?	\item Many UIF controls have a \ttt{Command} property that can be set to any \ttt{ICommand}<div>\item and when the control is clicked, the command's \ttt{Execute} method is called</div><div>\item and the control's \ttt{IsEnabled} property reflect's the command's \ttt{CanExecute} property</div>
What're the guidelines on dealing with input in Win 8 UIF apps?	\item Use the built-in interactions wherever possible<div>\item When you can't, code for touch because you'll get the mouse \&amp; pen behaviour for free</div><div>\item Optimize for specific input devices if it makes sense&nbsp;</div>
What are the three categories of touch event in the Win 8 UIF?	\item Pointers (lowest level events)<div>\item Gestures (motions calculated from pointer events)</div><div>\item Manipulations (prolonged gestures which result in a continuous change)</div>
How do you discover what pointer devices are available in the Win 8 UIF?	\item Use the \ttt{PointerDevice} class
What are the basic classes associated with pointer input in the Win 8 UIF?	\item \ttt{Pointer}, which describes a pointer (like a finger or a cursor)<div>\item \ttt{PointerPoint}, which describes the state of a pointer</div><div>\item \ttt{PointerPointProperties}, which gives more detailed information about the pointer's state</div>
With Win 8 UIF touch input, what are intermediate points?	\item Collections of \ttt{PointerPoints} that might have accumulated between successive \ttt{PointerMoved} events
What's a common mistake when interpreting \ttt{PointerPressed} events in the Win 8 UIF?	\item Assuming they'll always be paired with a \ttt{PointerReleased} event
What's it mean to capture a pointer in the Win 8 UIF?	\item \ttt{elem.CapturePointer(ptr)} will cause \ttt{elem} to receive all events from \ttt{ptr} irrespective of whether it lies in the element's boundary
What does it mean for a Win 8 UIF control to be hit-testable?	\item It's possible for the control is receive pointer events
How do you find out which elements overlay a point in the Win 8 UIF?	\item Use \ttt{VisualTreeHelper.FindElementsInHostCoordinates}
What are the basic gestures in the Win 8 UIF?	\item Tap<div>\item Press \&amp; hold</div><div>\item Double tap</div><div>\item Cross slide</div><div>\item Edge gesture</div>
How do you manually interpret gesture events in Win 8 UIF?	\item Create a \ttt{GestureRecognizer}<div>\item Set \ttt{gr.GestureSettings} to the gestures you want</div><div>\item Register handlers for those gestures</div><div>\item Forward pointer events from the element to the gesture recognizer</div>
What's a common mistake with the Win 8 UIF's \ttt{GestureRecognizer}?	\item It's only intended for use with simple shapes or custom controls; built-in controls like \ttt{Button} can mess with it&nbsp;
What's the simplest way of receiving gesture events in the Win 8 UIF?	\item Register with the \ttt{UIElement} simple gesture events
What are the common manipulations in the Win 8 UIF?	\item Swiping<div>\item Turning</div><div>\item Pinch/stretch</div>
What's the simplest way of receiving manipulation events in the Win 8 UIF?	\item Use the \ttt{ManipulationXXX} events on \ttt{UIElement}<div>\item and set the \ttt{ManipulationMode} property</div>
How do you set a flags enum in XAML?	"\item Use comma-separated values: \ttt{ManipulationMode=""Rotate, Scale""}"
What's a common problem with manipulations in the Win 8 UIF?	\item They use the UI thread, so can be laggy.<div>\item Use the \ttt{ScrollViewer} if possible, which uses a second thread, and use the manipulation events just to keep other components in sync</div>
What pointer devices are well-supported by Win 8 UIF?	\item Touch<div>\item Pen</div><div>\item Mouse</div>
What are the threads in a Win8 app?	\item One UI thread for each window<div>\item As many background threads as you want</div>
What's special about UI threads in Win 8 apps?	\item They're the only ones that can create or call UI objects<div>\item They're generally not re-entrant: a call from a UI thread can make a call back to the UI thread without worrying about deadlock</div><div>\item They can't call other UI threads</div>
What are agile objects in Win8 apps?	\item WinRT objects which can be created and used by any thread, as opposed to just UI threads
What's an ASTA thread in Win 8 apps?	\item App Single-Threaded Apartment thread, another name for a UI thread&nbsp;
How are WinRT async operations represented?	\item As \ttt{IAsyncOperation} and \ttt{IAsyncAction}s<div>\item which can be freely converted to and from .NET \ttt{Task}s</div>
How do you use async/await in C\#?	\item Mark a method \ttt{async} with a return type of \ttt{Task}, \ttt{Task&lt;int&gt;}, or (if necessary \ttt{void}<div>\item \ttt{await} some \ttt{Task} inside the method.</div>
How can you use the C\# \ttt{async} control flow for APIs that don't return a \ttt{Task} or \ttt{IAsyncXXX}?	\item Wrap the API calls using a \ttt{TaskCompletionSource}, which has a \ttt{Task} property you can return
When an event is raised on a XAML object, which thread is it run on?	\item The thread which created the object
How can you call back to a Win 8 UI thread from a worker thread?	\item Use the \ttt{Window}'s \ttt{window.Dispatcher.RunAsync} method to run a delegate on the UI thread
What's a view in WinRT terminology?	\item A window along with it's UI thread
How do you create a new window in the Win 8 UIF?	\item Call \ttt{CoreApplicationView.CreateNewView()}<div>\item Wait for \ttt{Application.OnWindowCreated()} to be called, which will happen on the new UI thread</div><div>\item Initialize the new window on the new UI thread</div><div>\item Use the \ttt{ApplicationViewSwitcher} on the old UI thread to show the new window</div><div>\item Best done using an async wrapper method</div>
What's the root element of a Win8 UIF window?	\item A \ttt{Frame}
How do \ttt{Page}s relate to \ttt{Frame}s in Win 8 UIF apps?	\item All \ttt{Page}s are contained in a \ttt{Frame}<div>\item The \ttt{Frame} enables page-to-page navigation</div>
How do you navigate between pages in a Win 8 UIF app?	\item Call the frame's \ttt{Navigate} method with the type of page you want to move to, and possibly a config object too&nbsp;<div>\item The page will be instantiated and navigated to, calling \ttt{OnNavigatedTo} with an event args parameter that contains the config object that was passed</div>
How does a Win 8 UIF \ttt{Frame} manage its pages?	\item As a backwards stack and a forwards stack, allowing you to move forwards and backwards between pages<div>\item By default though, they are *not* kept alive!</div>
How do you make a Win8 app \ttt{Frame} keep a page alive while it's inactive?&nbsp;	\item Set the page's \ttt{NavigationCacheProperty}
How do you maintain navigation history as part of session state in a Win 8 app?	<div>\item Use the \ttt{NavigationHelper} class</div>
How do you change the app theme in Win 8 apps?	\item Change the \ttt{Application.RequestedTheme} property
What are content controls in the Win 8 UIF?	\item Controls which can only contain a single item. Mostly buttons.
What's the difference between a click and a tap in the Win8 UIF?	\item Any UI Element can raise a tap in response to a pointer event<div>\item A Button raises a click in response to a pointer event or some keyboard events&nbsp;</div>
How do you automate controls in a Win8 UIF app?	\item Use the \ttt{Automation.Peers} namespace
What's a flyout in the Win8 UIF?	\item A dialog box with a light dismiss behaviour: clicking outside it dismisses it
What's the usual source of icons for Win 8 apps?&nbsp;	\item The \ttt{SymbolIcon} class, which represents glyphs from the Segoe UI font
How do you create a Win 8 UIF icon from arbitrary text?	\item Use the \ttt{FontIcon} class.
What's an \ttt{AppBarButton} in the Win 8 UIF?	\item A circular button with an icon and a label.
What's a \ttt{HyperlinkButton} in the Win8 UIF?	\item A text button that can be used to launch a URI
What's the Win8 UIF's \ttt{RepeatButton}?	\item A button which will raise \ttt{Click} events as long as it's pressed
What's&nbsp;the Win8 UIF \ttt{AppBarToggleButton}?	\item A toggle button in a circle with an icon and a label.
What're the guidelines for Win 8 app bottom bars?	\item They should have context-specific commands&nbsp;<div>\item They should prefer to be close to the edge</div>
What're the design guidelines for Win 8 app top bars?	\item Navigation is the usual use, but it can be anything<div>\item Generally taller than the bottom bar</div>
How do you implement app bars in the Win 8 UIF?	\item \ttt{AppBar} for the top bar<div>\item \ttt{CommandBar} for the bottom bar</div>
What are item controls in&nbsp;the Win8 UIF?	\item Controls which contain a collection of items
What's a selector in&nbsp;the Win8 UIF?	\item A subtype of \ttt{ItemControl} which allows the selection of objects
What happens when you add an arbitrary object to a Win8 UIF items control's content?	\item It's wrapped. In the case of a \ttt{ListBox}, it's placed in a \ttt{ListBoxItem} element
What's UI virtualization in&nbsp;the Win8 UIF?	\item When dealing with a large number of object, item controls only wrap objects while they're on screen<div>\item When an object passes off screen, its container is recycled for use by another item</div>
What's a combo box in&nbsp;the Win8 UIF?	\item An items control which implements a drop-down menu.
What's a list box in the Win8 UIF?	\item An items control which implements a scrolling multi-select list
What's a list view in&nbsp;the Win8 UIF?	\item An items control which is basically a prettier \ttt{ListBox} with drag-and-drop support
What's a grid view in&nbsp;the Win8 UIF?	\item A two-dimensional \ttt{ListView} with wrapping
What's a flip view in&nbsp;the Win8 UIF?	\item An items control which allows the user to flip through one item at a time
What's a semantic zoom in&nbsp;the Win8 UIF?	\item A kind of zooming that switches between higher and lower level views of some content
What's a menu flyout in&nbsp;the Win8 UIF?	\item A more restricted dropdown menu than \ttt{ComboBox} meant for menus&nbsp;
What are the controls for displaying chunks of text in&nbsp;the Win8 UIF?	\item \ttt{TextBlock}<div>\item \ttt{RichTextBlock}</div>
What's a rich text block in the Win8 UIF?	\item A text block which supports&nbsp;<div>\item in-text UI elements</div><div>\item overflow to separate elements</div>
What's a \ttt{TextBox} in&nbsp;the Win8 UIF?	\item A control that allows for text entry
What's an input scope in the Win8 UIF?	\item It's a property of a \ttt{TextBox} that allows you to alter whether the software keyboard displayed should be the one for URLs, for emails, for numbers, etc
What's a \ttt{RichEditBox} in&nbsp;the Win8 UIF?	\item A thin wrapper over the rich text formatting API of WinRT which allows styled text input
How do you construct absolute URIs in Win 8 apps?	"\item \ttt{new Uri(this.BaseUri, ""relative/uri"")}"
What's the form of Win 8 URIs?	\item Because the form of the URI is \ttt{scheme://domainName/path}<div>\item but omitting \ttt{domainName} will imply the current app's full name</div>
What's a nine-grid in the Win 8 UIF?	\item A feature of the \ttt{Image} type that allows you to dynamically modify an image for use as a border
What's the easiest way to construct an image pixel-by-pixel in the Win 8 UIF?	\item Use a \ttt{WritableBitmap} as an \ttt{Image}'s \ttt{Source}<div>\item Use {writableBitmap.PixelBuffer.AsStream()} to push in bytes</div>
What's the problem with frequent calls to Windows APIs in the Win 8 UIF?	\item WinRT is unmanaged, and managed-to-unmanaged calls are much more expensive than managed-to-managed calls
How do you deal with automatic scaling of images in Win 8 apps?	\item Provide three images:<div>\item&nbsp;\ttt{imageName.scale-100.jpg}</div><div>\item \ttt{imageName.scale-140.jpg}</div>\item \ttt{imageName.scale-180.jpg}<div>\item and in the app, just load \ttt{imageName.jpg}</div><div>\item Can also put them in three appropriately named folders</div>
What are automatic resource qualifiers in the Win8 UIF?	\item Special filename modifiers (like \ttt{scale-140}) which the app will consume automatically
How can you get or modify the raw information in an image from the Win8 UIF? &nbsp;&nbsp;	\item Use the \ttt{BitmapDecoder} class
What's the best way to perform standard transformations on image data from the Win 8 UIF?	\item Use the \ttt{BitmapTransform} class
Which is generally preferred of \ttt{DateTime} and \ttt{DateTimeOffset} in .NET?	\item \ttt{DateTimeOffset}
What're media extensions in the Win 8 UIF?	\item Another name for media foundation components
What's the simplest way of playing video or audio in the Win 8 UIF?	\item \ttt{MediaElement}<div>\item possibly with \ttt{AreTransportControlsEnabled} enabled</div>
How do you add or get the markers associated with a video from the Win8 UIF?	\item \ttt{mediaElement.Markers}
What's the advanced way to display video in the Windows 8 UIF?	\item Using the \ttt{MediaPlayer} class of the Player Framework
What're the two ways to deal with custom media streams in the Win 8 UIF?&nbsp;	\item Make a custom media extension<div>\item Use the \ttt{MediaStreamSource} class</div>
What are the usual ways of capturing video in Win 8 apps?	\item \ttt{CameraCaptureUI} for a self-contained solution<div>\item \ttt{CaptureElement} for a lower-level solution</div>
What are the three main classes used for vector graphics in the Win8 UIF?	\item \ttt{Shape}, a 2D drawing<div>\item \ttt{Geometry}, an abstract representation of a drawing</div><div>\item \ttt{Brush}, which represents a way of filling an element</div>
How can you ameloriate performance issues with complex vector graphics in the Win 8 UIF?	\item Use \ttt{UIElement}'s \ttt{CacheMode} to enable cached composition, which causes updates to vector graphics to only redraw the `dirty' parts
What's GPU overdraw?	\item When the same pixel is drawn more than once for the same scene
What are styles in the Win8 UIF?	\item They're to XAML as CSS is to HTML
How do you create a style in&nbsp;the Win8 UIF?	"\item In the Resources property of a control, create an&nbsp;\ttt{&lt;Style x:Key=""StyleName"" TargetType=""TargetName""&gt;} element<div>\item In the style element, create \ttt{&lt;Setter Property=""PropertyName"" Value=""val""/&gt;} elements.&nbsp;</div>"
How do you use a style in the Win8 UIF?	"\item From within subtree of the elemen the style was defined on:<div>\item \ttt{&lt;TargetName Style=""\{StaticResource StyleName\}""&gt;}</div>"
How do you implement inheritance in styles of the Win8 UIF?	\item Set the \ttt{BasedOn} attribute of a style element
What's an implicit style in&nbsp;the Win8 UIF?	\item A style without a \ttt{x:Key} or \ttt{x:Name} attribute<div>\item The style then applies to all elements of its target type</div>
How do Win8 UIF styles account for themes?	\item There's a \ttt{ThemeResource} property that can store multiple \ttt{ResourceDictionary}s
How does the \ttt{StaticResource} markup extension locate styles in&nbsp;<!--anki-->the Win8 UIF?	\item It walks up the tree until it finds a resource with a matching name
What's a control template in&nbsp;<!--anki-->the Win8 UIF?	\item A way to define a custom tree of elements for any control
How do you define a template in&nbsp;<!--anki-->the Win8 UIF?	\item Populate a \ttt{&lt;ControlTemplate&gt;} element with the visual tree you want<div>\item and use the markup extension \ttt{\{TemplateBinding DependencyPropertyName\}} to get the value of dependency properties from the target control</div>
What's a \ttt{ContentPresenter} in&nbsp;<!--anki-->the Win8 UIF?	\item A lighter-weight \ttt{ContentControl} meant for use with templates
What are visual states in&nbsp;<!--anki-->the Win8 UIF?	\item A type \ttt{VisualState} which represents the state of a control, allowing templates to take them into account
What are state groups in&nbsp;<!--anki-->the Win8 UIF?	\item \ttt{VisualState}s are grouped into \ttt{VisualStateGroup}s, and the control is always in one state from each group
How do templates make use of visual states?	"\item Anywhere inside a template, define a \ttt{&lt;VisualStateManager.VisualStateGroups&gt;} property element<div>\item and within that, define \ttt{&lt;VisualStateGroup x:Name=""GroupName""&gt;} elements</div><div>\item and within that, define \ttt{&lt;VisualState x:Name=""StateName""&gt;} elements</div>"
What's the \ttt{Binding} markup extension in&nbsp;<!--anki-->the Win8 UIF?	<div>\item A way to declaratively tie the values of two properties together<br /></div>
How do you write a simple binding in the Win8 UIF?	"<div>\item On the source element, add a \ttt{Name=""sourceName""} attribute</div><div>\item On the targe element, add a \ttt{TargetProp=""\{Binding ElementName=sourceName, Path=sourceProp\}""} attribute</div>"
How can you add default values to a binding in the Win8 UIF?	\item Add a \ttt{FallbackValue} property to the \ttt{Binding} extension
How can you bind data to a property which cannot be set to null in the Win8 UIF?	\item Use the \ttt{TargetNullValue} attribute of the \ttt{Binding} extension
When binding data in the Win8 UIF, how can you select the source element relative to the target one?	\item Use the \ttt{RelativeSource=\{RelativeSource relation\}} attribute of \ttt{Binding}
What's the restriction on what can be bound in the Win8 UIF?	\item The target property must be a dependency property.
How can you bind data in both directions simultaneously in the Win8 UIF?	\item Set the \ttt{BindingMode} of the \ttt{Binding} to \ttt{TwoWay}
When binding data from a text box&nbsp;in the Win8 UIF, how can you stop it from updating until typing completes?	\item Set \ttt{UpdateSourceTrigger=Explicit} on the \ttt{Binding}<div>\item then explicitly call \ttt{UpdateSource} when the \ttt{TextBox} loses focus</div>
What's a data context in the Win8 UIF?	\item A way to implement an implicit data source for binding within a tree
How do you implement a data context in the Win8 UIF?	\item Set the \ttt{DataContext} of an element to the desired source object<div>\item Any bindings in the tree without source objects specified will search up the tree until they find a non-null \ttt{DataContext}&nbsp;</div>
What are common shorthands for \ttt{Binding}s that use \ttt{DataContext}s in the Win8 UIF?	\item The first positional parameter is always the source property name, ie \ttt{\{Binding Length\}} will bind to the \ttt{Length} property of the \ttt{DataContext}<div>\item If no source property is named, then the property is assumed to be the whole object, ie \ttt{\{Binding\}} binds to the whole \ttt{DataContext} object</div>
How do you bind data to an items control in the Win8 UIF?	\item Set the \ttt{ItemsSource} property to a \ttt{Binding}
When binding data to a collection in the Win8 UIF how can you ensure the collection view stays updated?	\item Make the collection implement \ttt{INotifyCollectionChanged}, usually via \ttt{ObservableCollection}
What's the use of a \ttt{DataTemplate}&nbsp;in the Win8 UIF?	\item A way to transform data into a visual representation
How do you implement a data template&nbsp;in the Win8 UIF?	<div>\item In a control's \ttt{XXXTemplate} property,</div>\item Declare a \ttt{&lt;DataTemplate&gt;} element, containing any old tree of controls&nbsp;<div>\item and in it make any bindings needed to a data context that'll be provided by the host element&nbsp;</div>
How can you change templates at runtime&nbsp;in the Win8 UIF?	\item Use a \ttt{DataTemplateSelector}, if the parent control allows them
What's a value converter&nbsp;in the Win8 UIF?	\item A way to transform a data source to the target type when using bindings
How do you implement value converters&nbsp;in the Win8 UIF?	"\item Implement \ttt{IValueConverter} and its \ttt{Convert, ConvertBack} methods<div>\item Add an instance of the converter to the element's \ttt{Resources} with \ttt{&lt;local:ConverterName x:Key=""converterName""&gt;}</div><div>\item Reference it in the \ttt{Binding} with \ttt{Converter=\{StaticResource converterName\}}</div>"
What's the easiest way to display a grouped view of a collection&nbsp;in the Win8 UIF?	\item Make the \ttt{DataContext} a \ttt{CollectionViewSource}<div>\item Pass it a grouped collection<br /><div>\item Give the items control a \ttt{GroupStyle}</div></div>
What's the best way to manage selection of items in a data-bound collection&nbsp;in the Win8 UIF?	\item Use a \ttt{CollectionViewSource} and its \ttt{CurrentItem} property
What are two Win8 UIF features that can help with binding large collections?	\item Scrolling placeholders<div>\item Incremental rendering</div>
What're major and minor types in Media Foundation?	\item Major types are generic types of data - video, audio, captioning<div>\item Minor types are formats - usually identifying a codec</div>
What are the three categories of Media Foundation component?	\item Sources<div>\item Transforms</div><div>\item Sinks</div>
What's a media sample in Microsoft Media Foundation?	\item A packet of data which is passed through the pipeline
What're data buffers in Microsoft Media Foundation?	\item The parts of a media sample that holds frame information (or similar)<div>\item Are fetched from the underlying MF system, which recycles them for performance reasons&nbsp;<br /></div>
What's a topology builder in Microsoft Media Foundation?	\item A component that takes a partial topology containing only sources and sinks<div>\item and which chains transforms it finds in the registry until some combination fit</div>
What's a media session in WMF?	\item It holds all the MF components, and pulls samples from the source through the MFTs and sends them to the sinks
What's a hierarchical Bayes model?	\item A model where the parameters are distributed by some hyperparameters,&nbsp;<div>\item and maybe the hyperparameters are distributed according to some hyper-hyperparameters, etc</div>
What's a multi-level model another name for?	\item A hierarchical Bayes model
How's empirical Bayes usually used?	\item To get a point estimate of some hyperparameters by applying a uniform prior to them and taking the maximum posterior estimator (equiv. MLE)<br />
What's `the evidence procedure' another name for?	\item Empirical Bayes
Why is empirical Bayes usually safe to apply to hyperparameters?	&nbsp;\item Because the hyperparameters typically have a much lower dimensionality than the parameters, so are less susceptible to overfitting
What's a variance stabilizing transform in ML?	\item If $var[X] = \sigma^2(\mu)$ and $Y = f(X)$<div>\item then $f$ is a variance stabilizing transform iff $var[Y] \approx f^\prime(\mu)^2 \sigma^2(\mu)$ is independent of $\mu$</div>
How is the definition of a variance stabilizing transform derived?	\item Using a Taylor series expansion of the transformed variable
How are statistical decision problems usually formalized?	\item As a game against Nature:<div>\item Nature has a state $y \in \mathcal{Y}$ and generates an observation from it $x \in \mathcal{X}$</div><div>\item Based on $x$ we pick an action $a \in \mathcal{A}$ and incur a loss $L(y, a)$ due to it</div><div>\item The goal is to devise an optimal decision policy $\delta : \mathcal{X} \rightarrow \mathcal{A}$ that'll minimize the expected loss</div>
What's another name for the maximum expected utility principle?	\item Rational behaviour
What's the Bayes decision rule?	\item In Bayesian decision theory, the goal is to make the decision that'll minimize the posterior expected loss
Given a 0-1 loss function in Bayesian decision theory, which estimate should be used?	\item The MAP estimate
What's a 0-1 loss function?	\item A loss function which is 0 when the action chosen corresponds to the underlying state<div>\item and 1 otherwise&nbsp;</div>
Given a $l_2$ loss function in Bayesian decision theory, which estimator will minimize the loss?	\item The posterior mean
What's the $l_2$ loss function?	\item $L(y, a) = (y - a)^2$
What's the minimum MSE estimator in Bayesian decision theory?	\item The posterior mean of the distribution
Given a $l_1$ loss function in Bayesian decision theory, what's the optimal estimator?	\item The posterior median
What's the $l_1$ loss function in Bayesian decision theory?	\item $L(y, a) = |y - a|$
What's the ROC in ROC curve stand for?	\item Receiver operating characteristic
What's the definition of a ROC curve?	\item A plot of true positive rate (y axis) vs false positive rate (x axis) of a family of models
What's AUC stand for in machine learning?	\item Area under the ROC curve
What's EER stand for in machine learning?	\item Equal error rate
What's the definition of the equal error rate in machine learning?	\item Given a one-parameter family of models, it's the rate at which the true positive rate equals the false positive rate
What's the cross over rate another name for?	\item The equal error rate
What's recall another name for in machine learning?	\item The sensitivity
What's a common alternative to a ROC curve when dealing with very rare events?	\item A precision-recall curve
What's the problem with ROC curves when dealing with very rare events?&nbsp;	\item The large number of negatives means the curve will be compressed over to the extreme left
What's the summary statistic precision another name for in machine learning?	\item Positive predictive value
What does the statistic `average precision at $K$' mean?	\item It's the expected precision of the first $K$ elements to be recalled
What's the F1 score in machine learning?	\item $F_1 = \frac{2}{1/P + 1/R}$<div>\item where $P$ is the precision of a model and $R$ is it's recall</div>
How is the $F_1$ score generalized to multi-class models?	\item Macro-averaged $F_1$<div>\item Micro-averaged $F_1$</div>
What's the macro-averaged $F_1$ score?	\item $\frac{1}{C}\sum F_1(c)$
What's the micro-averaged $F_1$ score?	\item The $F_1$ score calculated by pooling all classes' counts into a single contingency table<div>\item equivalently, the score calculated by class-weighting each class's $F_1$ score</div>
What's the difference between the macro and micro $F_1$ scores?	\item Macro assigns equal weights to each class<div>\item Micro weights classes by their size</div>
What's the goal of inverse reinforcement learning?	\item To infer a utility function from some set of behaviours
What's the multi-armed bandit problem?	\item Given a bank of one-armed bandits with unknown payoff functions, which arms should you pull and in one order?&nbsp;&nbsp;
What're Gitten indices?	\item An approach to optimizing the exploration-exploitation tradeoff implicit in the multi-armed bandit problem
What's the contextual bandit problem?	\item It's like the multi-arm bandit problem, but each bandit - and the player - has a feature vector, giving you some knowledge about them
What's the Thompson sampling approach to multi-armed bandit models?	\item At each step, pick the action with a probability equal to the probability with which that action is the optimal action
What's the upper confidence bound approach to the multi-armed bandit problem?	\item You should either pick actions that are believed to be optimally beneficial<div>\item or actions for which there's currently a large uncertainty in the outcome</div>
What's the sampling distribution of an estimator?	\item The distribution of an estimator $\hat \theta = \delta(\mathcal{D})$ over many sampled datasets $\mathcal{D}$ from the same model
What's a parametric bootstrap?	\item The unknown distribution's parameters are estimated with $\hat \theta(\mathcal{D})$&nbsp;<div>\item and a sampling distribution is generated using these parameters</div>
What's a non-parametric bootstrap?	\item Sample with replacement from the dataset $\mathcal{D}$ to generate the sampling distribution
Intuitively, how does the Fisher information matrix carry information about the variance of a distribution?	\item If a distribution's peak is `sharp' (so its second derivative is large there), the variance must be quite low
Under common regularity conditions, how is the MLE of a parameter $\theta$ distributed as the number of samples approaches infinity?	\item $\hat \theta \rightarrow \mathcal{N}(\theta^*, \mathbf{I}_N(\theta^*)^{-1})$<div>\item where $\theta^*$ is the true value of the parameter and $\mathbf{I}_N$ is the Fisher information matrix</div>
What're the standard errors of a sampling distribution on the vector-valued parameter $\theta$?	\item $\hat{se}_k = \frac{1}{\sqrt{\mathbf{I}_N(\hat \theta)_{kk}}}$<br /><div>\item where $\mathbf{I}_N$ is the Fisher information matrix and $\hat \theta$ is the MLE</div>
What's the risk in frequentist decision theory?	\item $R(\theta^*, \delta) = \mbb{E}_{\tilde{D} | \theta^*} [ L(\theta^*, \delta(\tilde{D})) ]$<div>\item where $\tilde D$ is nature's distribution and $\delta$ is the decision procedure&nbsp;</div>
What's the definition of the posterior expected loss in Bayesian decision theory?	\item $\rho(\delta|D) = E_{\theta | D} [ L(\theta, \delta(x)) ]$&nbsp;<div>\item where $\delta$ is the decision procedure and $\theta$ is nature's state</div>
What's the difference between Bayesian posterior expected loss and frequentist risk?	\item PEL averages over the unknown parameter $\theta$ and conditions on the data $D$<div>\item Risk averages over the data's distribution $\tilde D$ and conditions on unknown parameter $\theta^*$</div>
What's the Bayes risk in frequentist statistics?	\item $R_B(\delta) = \mbb{E}_{\theta^*} [R(\theta^* |\delta)]$<div>\item where $p(\theta^*)$ is a prior on $\theta^*$</div>
What're two other names for the Bayes risk in frequentist statistics?	\item Integrated risk<div>\item Preposterior risk</div>
What's a Bayes estimator in frequentist statistics?	\item A decision rule $\delta_B$ that minimizes the Bayes risk $R_B(\delta)$
How are Bayes estimators connected to the posterior expected loss?	\item If you minimize the (Bayesian) posterior expected loss for each observation $x$, you get a (frequentist) Bayes estimator
What's another name for a Bayes estimator?	\item A Bayes decision rule
What's the most common alternative to Bayes risk?	\item Minimax risk: pick the decision rule that minimizes the maximum risk you're exposed to over all possible settings of nature's parameters
What's the problem with using the minimax risk in frequentist statistics?	\item It's overly pessimistic&nbsp;
What does it mean for a frequentist estimator to be admissable?	\item There is no other estimator which leads to strictly lower risk over all settings of nature's parameters
What's it mean for an estimator to be consistent in frequentist statistics?	\item If $\hat \theta(\mathcal{D}) \rightarrow \theta^*$ as the size of $\mathcal{D}$ goes to infinity
What's the definition of the bias of an estimator in frequentist statistics?	\item $\text{bias}(\hat \theta) = E_{p(\mathcal{D}|\theta^*)}[\hat \theta (\mathcal{D}) - \theta^*]$
What's the Cramer-Rao inequality?	\item If an unbiased estimator $\hat \theta$ is applied to a size-$n$ sample from a distribution with parameter $\theta^*$, then<div>\item $\text{prec}(\hat \theta) \leq n I(\theta^*)$</div><div>\item where $I$ is the Fisher information matrix</div><div>\item (under certain regularity conditions)</div>
What's the bias-variance tradeoff&nbsp;in frequentist statistics?	\item $\text{mean squared error} = \text{variance} + \text{bias}^2$<div>\item so if you want to minimize the MSE, sometimes it pays to use a biased estimator</div>
How is the risk of an estimator usually assessed in frequentist statistics?	\item Using a validation set
What's regularized risk minimization in frequentist statistics?	\item When you add a complexity-penalty term to the risk function to discourage overfitting
What's the one standard error rule in frequentist statistics?	\item Given a set of models<div>\item pick the simplest model whose risk is at most one standard error above the risk of the best model</div>
Intuitively, what's the use of the VC dimension in statistics?	\item It's a measure of the size of a real-valued parameter space
Give a bound on the error in estimating the risk of a hypothesis picked from a finite hypothesis space.	\item $P\left(\max_{h \in \mathcal{H}}|R_{emp}(\mathcal{D}, h) - R(p^*, h)| &gt; \epsilon \right) \leq 2 \frac{|\mathcal{H}|}{e^{2N\epsilon^2}}$<div>\item where $N$ is the size of the dataset $\mathcal{D}$ and $p^*$ is the true distribution</div>
What's the empirical risk in frequentist statistics?	\item It's the expectation of the loss function when taken over the observed data (the empirical distribution)
What's a surrogate loss function?	\item Some common loss functions (like 0-1) can be hard to optimize<div>\item so they're often substituted for friendlier functions, often a convex upper bound on the unfriendly function&nbsp;</div>
What's the stopping rule problem with p-values?	\item Their calculation can differ on when the experiment was chosen to terminate (eg after $n$ trials or after $n$ successful trials)<div>\item even if the observed data is the same</div>
What's the likelihood principle in statistics?	\item Inference should be based on the likelihood of the observed data, not on hypothetical future data that hasn't yet been observed
What order do pixels generally appear in bitmap files?	\item Blue, green, then red
What's edge tracing in computer vision?	\item Collecting the pixels belonging to an edge into a list
What are the three main categories of edge detection algorithms?	\item Derivative operators<div>\item Template-matching (Sobel, Kirsch)</div><div>\item Edge model similarity</div>
What's the differential operator approach to edge detection?	\item Calculate the central differences across each pixel, $\Delta_2(x, y)$<div>\item Threshold $\| \Delta_2(x, y) \|$</div>
What's local edge coherence in computer vision?	\item A measure of how well a predicted edge pixel is continued,&nbsp;<div>\item calculated from the change in predicted edge direction between neighbouring pixels</div><div>\item minus a penalty for edges of greater than unit width</div>
How does Sobel edge detection work?&nbsp;	\item Two $3\times 3$ matricies are convolved with the image<div>\item The matricies approximate a kind of derivative in the $x$ and $y$ direction respectively</div><div>\item Their sum-square is then thresholded</div>
How does Kirsch edge detection work?	\item Eight $3 \times 3$ matricies are convolved with the image<div>\item each representing an edge orientation</div><div>\item and the maximum of the eight results is taken for each pixel</div>
At a high level, how does the Marr-Hildreth edge detector work?	\item Convolve the image with a LoG operator<br /><div>\item Find the zero-crossings</div>
What's the LoG operator in computer vision?	\item Laplacian of the Gaussian operator<div>\item common in edge detection</div>
How does Marr-Hildreth detect edges at different scales?	\item LoGs with different variances are used, and the union of their output is taken
What're the main stages of the Canny edge detection algorithm?	\item A filter emulating the first derivative of the Gaussian is applied<div>\item Then pixels which aren't local maxima are removed</div><div>\item Then a hysteresis step is applied</div>
How does the Canny algorithm suppress non-local maxima?	\item Using the value of the surface at the two points where the gradient vector at the pixel intersects the boundary of the pixel<div>\item The value of the surface at a point is calculated using linear interpolation between the&nbsp;nearest two neighbours</div>
What's hysteresis in edge detection?	\item An upper and lower threshold are defined<div>\item and any pixel which is either above the upper threshold&nbsp;</div><div>\item or above the lower threshold \emph{and} connected to a pixel above the threshold</div><div>\item are retained</div>
What's the definition of the filter used in the Shen-Castan edge detector?	\item The infinite symmetrical exponential filter<div>\item $a\cdot e^{-p(|x|+|y|)}$</div><div>\item with parameters $a, p$</div>
How is the ISEF usually realised in code?	\item As a recursive filter, calculated in each direction independently
What're the stages in the Shen-Castan algorithm?	\item Apply the ISEF to an image $I$ to get a filtered image $S$<div>\item Calculate $B = S-I$, the band-limited Laplacian</div><div>\item Set all positive pixels to 1 and all negative to -1 to get the binary Laplacian image</div><div>\item Clean the BLI up with false zero-crossing suppression, adaptive gradient and hysteresis methods&nbsp;</div>
What's the adaptive gradient method in computer vision?	\item If a pixel has been detected as an edge<div>\item then in a small window around that pixel in the original image, the direction it indicates should have two different gray levels on either side, divided by the vector of the edge</div>
What's false zero crossing suppression in computer vision?	\item A false zero crossing is one where either<br /><div>\item the Laplacian changes from positive to negative, but the gradient is negative</div><div>\item the Laplacian changes from negative to positive, but the gradient is positive</div><div>\item These cases are considered spurious in edge detection</div>
What's the BLI in computer vision?	\item The binary Laplacian image<div>\item which is the Laplacian with all positive pixels mapped to 1 and all negative pixels mapped to 0</div>
What's ISEF stand for in computer vision?	\item Infinite symmetric exponential filter
What are three common color transforms to use when carrying out edge detection?	\item Average all three channels<div>\item $T_1 = \frac{R}{R+G+B}$ or $T_2 = \frac{B}{R+G+B}$</div><div>\item Hue of HSV</div>
What's a good tool for debugging dependency properties in WPF?	\item \ttt{DependencyPropertyHelper.GetValueSource}
What're the five steps in calculating the value of a dependency property in WPF?	\item Determine the base value<div>\item If an expression has been given, evaluate it</div><div>\item Apply animations</div><div>\item Coerce (applies a transform if one's been provided)</div><div>\item Validate (applies a validator if one's been provided)</div>
How can you change the value of a dependency property without changing the value of its source in WPF?	\item \ttt{DependencyObject.SetCurrentValue}
What's an attached property in WPF?	\item A dependency property that can be attached to arbitrary objects<div>\item (like \ttt{&lt;StackPanel TextElement.FontSize=30&gt;})&nbsp;</div>
How do you programmatically set the value of dependency properties in WPF?	\item \ttt{element.SetValue(PropertyName, value)}
What's the easiest way to attach custom data to a WPF element?	\item By setting it's \ttt{Tag} dependency property
What's a panel in WPF?	\item An element that supports the arrangement of multiple children
What's the restriction on using \ttt{ActualHeight} and \ttt{ActualWidth} in WPF?	\item The layout process is asynchronous, so the should only be ready from a handler for the \ttt{UIElement.LayoutUpdate} event
What are the two categories of 2D transforms in WPF?	\item \ttt{LayoutTransform}s, which are applied before the layout process<div>\item \ttt{RenderTransform}s, which are applied after the layout process and immediately before the element is rendered</div>
What are two common mistakes with transforms in WPF?	\item They can only be applied to native WPF content<div>\item Transforms don't affect the \ttt{ActualHeight}/\ttt{ActualWidth} of an object ever</div>
What are virtualizing panels in WPF?	\item Panels which automatically discard offscreen elements to optimize performance
What's a useful tool for debugging \ttt{Grid} panels in WPF?	\item Set \ttt{ShowGridLines} to true.
How do you give a \ttt{Grid} cell a background in WPF?	\item Add a \ttt{Rectangle} with the appropriate \ttt{Fill}.<div>\item It'll automatically stretch to fill the cell, and the content can sit on top of it&nbsp;</div>
What's star sizing in WPF?	\item Setting a \ttt{Grid}'s \ttt{RowDefinition}'s width to \ttt{2*} or similar<div>\item will assign it a width as a weighted fraction of the panel's width</div>
What are routed events in WPF?	\item Events that'll move through the visual tree, triggering any handlers installed on the elements they pass through
What are the routing strategies available for WPF routed events?	\item Bubbling (moves up tree)<div>\item Tunneling (moves from root down tree to source)</div><div>\item Direct (only raised on source element)</div>
What does a \ttt{Preview} prefix on a WPF event mean?	\item It's a tunneling event that precedes a bubbling event<br /><div>\item (or vice versa)</div>
What's the use of \ttt{PreviewXXX} events in WPF?	<div>\item By handling a \ttt{PreviewXXX} event on its way down the tree, an element can prevent the \ttt{XXX} event from being raised and bubbling up</div>
What're attached events in WPF?	"\item Elements can register handlers for events they don't define themselves<div>\item like \ttt{&lt;Window ListBox.SelectionChanged=""Handler""&gt;}</div>"
What's a \ttt{WeakEventManager} in WPF?	\item It allows you to attach weak event handlers to routed events<div>\item which means that an object raising the event doesn't hold a strong reference to its &nbsp;weak listeners</div>
What does it mean for a WPF element to `capture' an input device?	\item It'll receive all events from that input device regardless of where it is on the screen
What are commands in WPF?	\item Versions of events intended for things divorced of specific IO<div>\item like cut/copy/paste</div>
What's an \ttt{InputBinding} in WPF?	\item A way to associate several different input combinations with the same command
What are controls in WPF?	\item Standardized but flexible UI components<div>\item ex: drop down menus, tabs, etc</div>
What's a common mistake with text rendering in WPF?	\item Not setting the \ttt{TextOptions.TextFormattingMode} and \ttt{TextOptions.TextRenderingMode} properties to optimal values for the size of the text&nbsp;
What're \ttt{FlowDocument}s in WPF?	\item Controls intended for large chunks of text which require complex formatting
What are the two main ways to include binary resources in WPF applications?&nbsp;	\item With the build action \ttt{Resource}, which embeds it in the assembly<div>\item With the build action \ttt{Content}, which leaves it loose but records the relative location of the file in the assembly</div>
How can you reference compile-time WPF resources in XAML?	"\item \ttt{&lt;Image Source=""foldername/filename.gif""&gt;}<div>\item Only works for embedded/registered resources!</div>"
What's the `site of origin' in WPF?	\item Some sort of location against which XAML URIs of the form<div>\item&nbsp;\ttt{pack://siteOfOrigin:,,,,/filename.jpg}&nbsp;</div><div>\item are resolved</div>
How do you access compile-time resources from C\# in WPF?	"\item Embedded resources: \ttt{new Uri(""pack://application:,,,/resourcename.jpg"")}<div>\item Loose resources: \ttt{new Uri(""pack://siteOfOrigin:,,,/resourcename.jpg"")}</div>"
How do you define a logical resource in XAML in WPF?	"\item Under \ttt{&lt;AncestorName.Resources&gt;} create an element which has a \ttt{x:Key=""keyName""}&nbsp;attribute"
How do you reference a logical resource from XAML in WPF?	"\item \ttt{AttributeName=""\{StaticResource keyName\}""}, which means the resource will be applied once<div>\item \ttt{AttributeName=""\{DynamicResource keyName\}""}, which means the resource will be reapplied every time it changes</div>"
How can you share logical resource dictionaries across files in XAML?	\item Put the resource directory in its own file<div>\item se the \ttt{ResourceDictionary.MergedDictionaries} element to include it</div>
How can you cause a WPF logical resource to be copied to each location it's referenced from instead of shared?	\item \ttt{x:Shared=False}
What's the main restriction on static logical resources in XAML?	\item They have to be declared before they can be referenced<div>\item so to reference the resource from the same element, use property-element syntax</div>
What's property element syntax in XAML?	\item Rather than setting an attribute within a XAML element, you can set it as the content of a subelement with the attribute's name<div>\item ie \ttt{&lt;Window.Background&gt;value&lt;/Window.Background&gt;} vs \ttt{&lt;Window Background=value&gt;}&nbsp;</div>
What's the main restriction on dynamic logical resources in XAML?	\item Only dependency properties can be dynamically bound
How can you statically reference a WPF logical resource from C\#?	"\item Call \ttt{elementName.FindResource(""resourceName"")}"
How can you add a dynamic reference to a logical resource from C\# in WPF?	"\item \ttt{elemName.SetResourceReference(ClassName.PropName,""resourceName"")}"
How should you reference system settings from a WPF application?	\item Using dynamic references to the logical resources (\ttt{XXXKey}) in \ttt{SystemParameters}, \ttt{SystemColors}, \ttt{SystemFonts}<div>\item because they might change while your app is running</div>
How do you create a WPF data binding from procedural code?	\item Create a \ttt{Binding} object<div>\item Set \ttt{binding.Source} and \ttt{binding.Path}</div><div>\item Attach it to a target property with \ttt{elemName.SetBinding(ClassName.PropName, binding)}</div>
How can you data bind to objects that don't have a \ttt{SetBinding} method in WPF?	\item \ttt{BindingOperations.SetBinding(targetObj, PropName, binding)}
How do you bind data from a named XAML object in WPF?	"\item \ttt{AttributeName=""\{Binding ElementName=name, Path=propName.otherPropName\}}"
How do you bind data from a relatively defined source in XAML?	"\item \ttt{AttrName=""\{Binding RelativeSource=\{RelativeSource FindAncestor, AncestorType=\{x:Type desiredType\}\}""}<div>\item It's pretty powerful</div>"
How do you data bind from arbitrary .NET objects in XAML?	"\item Add the object to some ancestor element's resource dictionary<div>\item then \ttt{AttrName=""\{Binding Source=\{StaticResource resourceName\}, Path=pathName\}""}</div>"
When binding data from a plain .NET object, how can you get the target to update when the source does?	\item Implement \ttt{INotifyPropertyChanged} on the source object<div>\item (or inherit from one of the \ttt{Observable} classes that does it for you)</div>
What's a data context in WPF?	\item By setting the \ttt{DataContext} property of an element,&nbsp;<div>\item all bindings without sources in the element's subtree will automatically use the nearest context as a source</div>
What does it mean when a data binding in WPF doesn't have a \ttt{Path} attribute?	\item The binding is to the entire source object
How do you alter the formatting of a data bound string in XAML?	\item \ttt{\{Binding StringFormat=\{\}\{0\} thing(s), Source=sourceName, Path=pathName\}}<div>\item where any old formatting string can be used</div>
What's a data template in WPF?	\item A chunk of UI which is used to render an arbitrary .NET object
How do you define a data template in XAML?	\item Create a \ttt{&lt;DataTemplate&gt;} element<div>\item and in it use implicit bindings \ttt{\{Binding Path=pathName\}} which will be provided a source object via data context when the template is used</div>
What are template selectors in WPF?	\item Elements with \ttt{XXXTemplate} properties also have \ttt{XXXTemplateSelector} properties<div>\item which all you to insert custom code that'll select the template to be used</div>
What's a value converter in WPF?	\item An object implementing \ttt{IValueConverter} that can be plugged into data bindings' via the \ttt{Converter} parameter in order to adapt a source type to a target type
What's a collection view in WPF?	\item When you bind against an \ttt{IEnumerable} in WPF, a \ttt{CollectionView} object is automatically inserted that supports things like sorting, selecting and grouping
How can you bind data from the currently selected item in WPF?&nbsp;	\item A forward slash in the \ttt{Path} attribute of a binding corresponds to the currently selected item
How can you synchronize the selected item across several representations of the same collection in WPF?	\item Set \ttt{IsSynchronizedWithCurrentItem} to true
What're the two data providers in WPF?	\item \ttt{XMLDataProvider}, which allows binding against the contents of chunks of XML<div>\item \ttt{ObjectDataProvider}, which allows more complex operations on .NET objects like parameterized instantiation and binding from methods</div>
What's the best way to do input validation in WPF?	\item Set the binding's \ttt{ValidationRule} parameter to an \ttt{ValidationRule}-derived object
How do you make updates to a UI field change the binding source in WPF?&nbsp;	\item Set the \ttt{BindingMode} of the binding to \ttt{TwoWay} or \ttt{OneWayToSource}
How can you modify when a two-way binding target will modify its source in WPF?	\item Set the \ttt{UpdateSourceTrigger} parameter on the binding
What are some advanced multi-binding features in WPF?	\item \ttt{CompositeCollection}, which aggregates multiple collections<div>\item \ttt{MultiBinding}, which aggregates the results of multiple bindings</div><div>\item \ttt{PriorityBinding}, which processes multiple bindings in order and updates its value as they complete</div>
How can you create an asynchronous data binding in WPF?	\item Set the binding's \ttt{IsAsync} attribute to true<div>\item (generally though this should be avoided in favour of asynchronous background code)</div>
What is the product rule of probability for events A and B?&nbsp;	p(AB) = p(A|B)p(B) = p(B|A)p(A)&nbsp;<div>&gt; where p(AB) means the probability of the intersection of A and B&nbsp;</div>
What is the generalized sum rule of probability for events A and B?&nbsp;	p(A+B) = p(A) + p(B) - p(AB)&nbsp;<div>&gt; where p(AB) means both A and B</div><div>&gt; simple sum rule, when A and B do not overlap</div><div>&gt; Jaynes; derived from the product rule and basic logic applied repeatedly&nbsp;</div>
What is the principle of indifference in probability? how does Jaynes derive it?&nbsp;	the probability of n equivalent possibilities is each 1/n; if a reasoning system led to any other result than this, then a mere permutation of labels could change their probabilities<div>&gt; Jaynes PTLoS, unique result following Keynes 1921&nbsp;</div>
Accd to Jaynes, what must be true of the function for a probability under standard notation?&nbsp;	it must be a monotonic increasing function btwn 0 and 1<div>&gt; Jaynes&nbsp;</div>
Accd to Jaynes, why is probability subjective and why is it objective?&nbsp;	it is subjective because it must <i>begin</i> from a particular state of knowledge, while it is objective because once that state of knowledge has been established, the rules of probability will lead to the same mathematical estimates<div>&gt; Jaynes&nbsp;</div>
Accd to Jaynes, is randomness a property of the world? if so, why? if not, what is it?&nbsp;	"no; n/a; the belief that randomness is a real property existing in Nature is a form of the mind projection fallacy which says, in effect, ""I don't know the detailed causes -- <i>therefore</i>&nbsp;-- Nature does not know them""&nbsp;<div>&gt; Jaynes quote p 74 PTLoS; eg ""randomization in shaking a set of balls in an urn does not affect Nature's workings in any way, it only ensures that no human is able to exert any willfull inlfuence on the result""</div>"
Accd to Jaynes, what is a sampling distribution?&nbsp;	a system for reasoning from some specified hypothesis to potentially observable data&nbsp;<div>&gt; Jaynes p 84&nbsp;</div>
How does Jaynes describe the logical relationship between prior and posterior probabilities?&nbsp;	"""one man's prior probability is another man's posterior probability""&nbsp;<div>&gt; classic quote&nbsp;<br /><div>&gt; Jaynes p 89; ""there is really only one kind of probability; our different names for them refer only to a particular way of organizing a calculation""&nbsp;</div></div>"
What does Jaynes think about describing the probability distribution of some parameter? why?&nbsp;	"it is misleading; that verbiage implies that the parameter itself is ""distributed"" in some way, whereas it is the probability for the possible values of that parameter that is distributed over a range of values&nbsp;<div>&gt; type of mind projection fallacy; Jaynes p 108&nbsp;</div>"
What is variance a property of with respect to some parameter that is measured once in an experiment?&nbsp;	variance is a property of the <i>probabillity distribution function for that measurement</i>, not of the measurement itself, which will only take one value upon measurement<div>&gt; Jaynes p 113; vs variance which can also be defined for a frequency distribution of sample measurements, but only if it is measured more than once (actually &gt;= 3 times, IIUC)&nbsp;</div>
What are the most common methods of going from the posterior distribution function to estimate that Jaynes discusses? (3)&nbsp;	"1) Mean of the posterior pdf, via minimizing the mean squared error of the estimate (Gauss, and the lowest MSE possible is the variance)&nbsp;<div>2)&nbsp;Median of the posterior pdf, via minimizing the sum of the error (Laplace)&nbsp;</div><div><div>3) Mode of the posterior pdf (if given a constant prior, this is equivalent to the ""maximum likelihood estimate"" as named by Fischer, even though Gauss and Laplace used this too and just called it the ""most probable value"")&nbsp;</div></div><div>&gt; Jaynes p 173; each of these had benefits in various situations, depends on which type of errors are relatively worse in the scenario you are working under; eg, MSE depends on the scale of the parameters, and it weights outliers as more important&nbsp;</div>"
What is the relative importance of removing bias and minimizing variance of an estimator? why?&nbsp;	"they are equally important; both can contribute to the error of the estimator over the sampling distribution&nbsp;<br /><div>&gt; Jaynes PTLoS 511 - 514; ""Why do orthodoxians put such exaggerated emphasis on bias? We suspect that the main reason is simply that they are caught in a psychosemantic trap of their own making. When we call the quantity ([B] - a) the ""bias"", that makes it sound like something awfully represensible, which we must get rid of at all costs. If it had been called instead the ""component of error orthogonal to the variance"", as suggested by the pythagorean form of (17.2), it would have been clear to all that these two contributions to the error are on an equal footing; it is folly to decrease one at the expense of increasing the other. This is just the price one pays for choosing a technical terminology that carries an emotional load, implying value judgments; orthodoxy falls constantly into this tactical error.""&nbsp;</div>"
What's a panchromatic image in image processing?	\item One where the brightness at a point $x, y$ is given by a single number $f(x, y)$
What's a pel in image processing?	<div>\item A picture element</div>\item Another name for a pixel
What's the checkerboard effect in image processing?	\item The effect you get from reducing the resolution of an image
What's a point spread function in&nbsp;image processing?	\item A description of how an operator transforms its subject, characterised by its effect on a point source
What's false contouring in&nbsp;image processing?	\item The effect you get from reducing the number of grey levels in an image
When can you get away with reducing the number of grey levels in an image?	\item When it's very detailed so doesn't have any shallow gradients
What're simple sufficient conditions for the wavelet transform admissability condition to be satisfied?	\item The wavelet is square-integrable<div>\item The wavelet has zero mean</div>
What's the intuitive interpretation of a square integrable function?	\item It's a function with finite energy
Why are functions of finite power of interest in wavelet theory?	\item Because they effectively have finite energy when a window of finite duration is applied
What does $x[n]$ represent in wavelet theory when $x$ is a continuous function?	\item The function $x(t)$ converted to a discrete time series by sampling every $\Delta t$
What's $l_2(\mathbb{Z})$ in wavelet theory?	\item The space of discrete time signals of finite energy, $\sum |x[n]|^2 &lt; \infty$
What's a Banach space?	\item A complete normed vector space&nbsp;
What's a complete metric space?	\item A space such that every Cauchy sequence in the space converges to a limit in the space
What's a Cauchy sequence?	\item A sequence such that for any $\epsilon$, there's a $N$ such that for all $n &gt; N$, $\|x_{n+1} - x_n\| &lt; \epsilon$
What's a Hilbert space?	\item A complete inner product space.
What's a separable space?	\item A space which contains a countable, dense sequence of elements such that every nonempty open subset of the space contains an element of the sequence
How are the range \&amp; null spaces of a linear operator and its adjoint related?	<div>\item If $\text{range}(T^*)$ and $\text{range}(T)$ are both closed,</div>\item $\text{range}(T)^\perp = \text{null}(T^*)$<div>\item $\text{range}(T^*)^\perp = \text{null}(T)$</div>
What's the Neumann expansion for linear operators?	\item If $\|T\| &lt; 1$ under the $p$-norm,<div>\item $(1 - T)^{-1} = \sum_{k=0}^\infty T^k$</div>
What's the evaluation functional in wavelet theory?	\item $\mathcal{E}_t [x] = x(t)$
What's the Frechet-Riesz theorem?	\item Any bounded linear functional $f$ on a Hilbert space can be uniquely represented as $f[x] = \langle \phi, x \rangle$ for some $\phi$
How can the reproducing kernel of a Hilbert space with a bounded evaluation functional be defined?	\item Write the evaluation functional as an inner product $\mathcal{E}_t[x] = \langle e_t, x \rangle$ with some $e_t$<div>\item The reproducing kernel is defined as $K(t, t^\prime) = \langle e_{t^\prime}, e_t \rangle$</div>
In terms of its evaluation functional, when does a Hilbert space have a reproducing kernel?	\item When the evaluation functional is bounded
What're some useful properties of reproducing kernels?	\item If it exists in a Hilbert space, it's unique<div>\item $x(t) = \langle K, x \rangle_t$</div>
What's the space of test functions of rapid decay, $\mathcal{T}$?	\item The space of functions which are<div>\item absolutely integrable over&nbsp;$\mathbb{R}$</div><div>\item infinitely differentiable everywhere on&nbsp;$\mathbb{R}$</div><div>\item dominated by every negative power of $t$ as $t \rightarrow \infty$</div>
What's usually considered to be the dual of a function space?	\item The space of linear functionals on that space
How is the dual of a function space usually denoted?	\item If the space is $\mathcal{T}$, the dual is $\mathcal{T^\prime}$
What's an analytic function?	\item One which is locally given by a convergent power series
What's a regular function?	\item One which is analytic and single-valued
When is a projection in a Hilbert space orthogonal?	<div>\item When its range and null spaces are orthogonal&nbsp;</div>\item And exactly when it's self-adjoint
What are the properties needed for a set of subspaces to form a multi-resolution analysis set?	\item Nesting: $\mathcal{V}_m \subset \mathcal{V}_{m-1}$<div>\item Completeness: $\bigcup \mathcal{V}_m = L_2(\mathbb{R})$, $\bigcap \mathcal{V}_m = \{0\}$</div><div>\item Multi-resolution: $x(t) \in&nbsp;\mathcal{V}_m \iff x(2t) \in&nbsp;\mathcal{V}_{m-1}$</div>
When will an infinite combination over an orthonormal basis converge?	\item $\sum c_n \phi_n$ converges iff $c \in l_2(\mathbb{Z})$<br />
What're three ways of characterizing complete orthonormal sets in Hilbert spaces?	\item $\{\psi_n\}$ is complete&nbsp;<div>\item iff the only vector orthogonal to it is 0<div>\item iff all linear combinations over the set with coefficients in $l_2$ forms the entire space</div></div><div>\item iff Parseval's relation holds for every member of the space</div>
What's Parseval's relation for vectors?	<div>\item Given a complete orthonormal set $\{ \phi_n \}$ in a Hilbert space, for any $x$,</div>\item $\|x\|^2 = \sum |\langle \phi_n, x \rangle |^2$
How can you write the reproducing kernel of a space in terms of a complete orthonormal basis set $\{\phi_n\}$?	\item $K(t, t^\prime) = \sum \phi_n^*(t) \phi_n (t^\prime)$
\emph{When} can you write the reproducing kernel of a space in terms of a complete orthonormal basis set $\{ \phi_n \}$?	\item When $\sum |&nbsp;\phi_n(t) |^2 \leq \infty$ for all $t$
What's the Einstein integration convention?	\item All repeated continuous variables occuring in bras and kets are integrated over
How do you write $\phi(t)$ in bra-ket notation?	\item $\langle t | \phi \rangle$&nbsp;using the reproducing kernel
How do you write $\phi^*(t)$ in bra-ket notation?	\item $\langle \phi | t \rangle$ using the reproducing kernel
What does $\omega$ represent in wavelet theory?	\item $\omega(t) = \frac{1}{\sqrt{2\pi}}e^{-iwt}$
How do you write the Fourier analysis and synthesis equations in Dirac notation?	\item $X(\omega) = \langle \omega | t \rangle \langle t | x \rangle = \langle \omega | x \rangle$<div>\item $x(t) = \langle t | \omega \rangle \langle \omega | x \rangle = \langle t | x \rangle$</div>
What does $t$ represent in $\langle t |$?	\item An evaluation functional element $e_t$ such that $x(t) = \langle e_t, x \rangle$
In Fourier analysis, what are the completeness and orthonormality relations for a basis?	\item Completeness: $|\omega \rangle \langle \omega | = \mathbf{1}$<div>\item Orthonormality: $\langle \omega | \omega^\prime \rangle = \delta(\omega - \omega^\prime)$</div>
What's a complete orthonormal basis for $L_2[0, T_0]$?	\item $\phi_n(t) = \frac{1}{\sqrt{T_0}}e^{in\omega_0t}$ with $n \in \mathbb{Z}$ and $\omega_0T_0 = 2\pi$
Intuitively, what does the Riesz-Fischer theorem say?	<div>\item If you form a linear combination of $\phi_n(t) = \frac{1}{\sqrt{T_0}}e^{in\omega_0t}$ using any sequence of coefficients $\{c_n\} \in l_2(\mathbb{Z})$, it'll converge to a Lebesgue measurable function on $[0, T_0]$</div>
What's the Poisson summation formula?	\item For $x[n]$ and $X(\omega)$ defined so that the $\frac{1}{2\pi}$ coefficient is entirely in the reconstruction formula<div>\item $\sum_{\mathbb{Z}} x(t + 2n\pi) = \sum_{\mathbb{Z}} X(n) e^{int}$</div>
What's a Fourier basis for $l_2[0,N)$?	\item $p_{kn} = \frac{1}{\sqrt{N}}e^{2i\pi kn/N}$ with $0 \leq k, n &lt; N$<div>\item ($k$ is the frequency parameter, $n$ is the time parameter)</div>
Intuitively, what's Parseval's relation?	\item It says that the energy of the Fourier transform of a function is the same as the energy of the function&nbsp;
What's a band-limited function?	\item One whose Fourier transform has support limited to $[-\Omega, \Omega]$&nbsp;
What's $L_2^\Omega(\mathbb{R})$?<br />	\item The space of $\Omega$-band-limited functions with finite energy
What's the reproducing kernel of $L_2^\Omega(\mathbb{R})$?	\item $K(t, t^\prime) = \frac{\sin[\Omega(t - t^\prime)]}{\pi(t - t^\prime)}$
What's the inverse Fourier transform of $\mathbf{1}_{[-\Omega, \Omega]}$?	\item $\frac{1}{\pi t} \sin \Omega t$
What're a set of orthonormal basis functions for $L_2^\Omega(\mathbb{R})$?	\item $p_{n}(t) = \frac{\Omega}{\pi}\text{sinc}\left(\frac{\Omega}{\pi}t - n\right)$
What's the linear bandwidth variable for a band-limited function?	\item $B = \frac{1}{2\pi}\Omega$
What're the orthonormal basis functions for $L_2^\Omega(\mathbb{R})$ in terms of the linear bandwidth variable?	\item $p_n(t) = \sqrt{2B} \,\text{sinc}(2Bt - n)$
Intuitively, what's the sampling theorem?	\item The sampling frequency should be twice the highest frequency in order to perfectly reconstruct a function
What's the $L_2(\mathbb{R})$ basis analysis operator?	\item For a given basis $\{\phi_n(t)\}$,&nbsp;<div>\item $T_\phi : L_2(\mathbb{R}) \rightarrow l_2(\mathbb{R})$<br /><div>\item $T_\phi \{x(t)\} = [\cdots, \langle \phi_n | x \rangle, \cdots]^T$</div></div>
What's the $L_2(\mathbb{R})$ basis synthesis operator?	<div>\item For a given basis $\{\phi_n(t)\}$,&nbsp;</div><div>\item $T^+_\phi : l_2(\mathbb{R}) \rightarrow L_2(\mathbb{R})$</div>\item $T^+_\phi \{c\} = \sum_\mathbb{Z} c_n \phi_n(t)$
Given a basis $\{\phi_n\}$, what's the basis operator on $L_2(\mathbb{R})$?	<div>\item $T^+_\phi T_\phi : L_2(\mathbb{R}) \rightarrow L_2(\mathbb{R})$</div>\item $T^+_\phi T_\phi = | \phi_n \rangle \langle \phi_n |$
What's the condition number of a normal linear operator?	\item $\kappa = \left| \frac{\lambda_{max}}{\lambda_{min}} \right|$
What's the condition number of an arbitrary (possibly non-normal) linear operator?	\item $\kappa = \frac{\sigma_{max}}{\sigma_{min}}$, where $\sigma_i$ are the singular values of the matrix
What does it mean for two sets of vectors $\{v_i\},\{w_j\}$ to be biorthogonal?	\item $\langle v_i, w_j \rangle = \delta_{ij}$<div>\item but neither the $v_i$s or $w_j$s need be orthogonal sets</div>
How are Riesz bases defined?	\item Given a complete orthonormal basis $\{\phi_n\}$<div>\item and an invertible and continuous linear operator $L$&nbsp;</div><div>\item define $\xi_n = L| \phi_n \rangle$, $\chi_n = (L^{-1})^* | \phi_n \rangle$</div>
What's the most important property of Riesz bases?	\item $\{\xi_n\}$ and $\{\chi_n\}$ are biorthogonal
What're the completeness relations for biorthogonal bases?	\item $|\xi_n \rangle \langle \chi_n | = \mathbf{1}$<div>\item $|\chi_n \rangle \langle \xi_n | = \mathbf{1}$</div>
What're the expansion formulae for biorthogonal bases?	\item $|x\rangle = \langle \xi_n | x \rangle | \chi_n \rangle$<div>\item $|x\rangle = \langle \chi_n | x \rangle | \xi_n \rangle$</div>
Given a linear operator $A : \mathbb{C}^n \rightarrow \mathbb{C}^m$, $m \leq n$, how do you recover the solution $\hat x$ to the equation $Ax = y$ with minimal norm?	\item $\hat x = A^+ u$, where $u$ is any solution to $AA^+u = y$<div>\item If $A$ is nondegenerate, then this reduces to $\hat x = A^\dagger_R y$</div>
What's the right pseudoinverse of a linear operator $A$?	\item $A^\dagger_R = A^+ (AA^+)^{-1}$<div>\item (such that $AA^\dagger_R = \mathbf{1}$)&nbsp;</div>
Given a linear operator $A : \mathbb{C}^n \rightarrow \mathbb{C}^m$, $m &gt; n$, how do you recover the vector $\hat x$ which minimizes $\|Ax - y\|$?	\item $\hat x = A^\dagger_L y$
What're the frame inequalities on a finite vector space?	\item If linear operator $A$ has singular values $\sigma_i$<div>\item $\sigma_{min} \| y \|^2 \leq \langle AA^*y, y \rangle&nbsp;\leq \sigma_{max} \|y\|^2$</div><div>\item for all $y$</div>
What's a frame in wavelet theory?	\item Any set of vectors $\{c_j\}$ such that, when interpreted as columns of a matrix $A$, the frame inequalities are satisfied
In a finite dimensional space, what are the frame bounds equal to?&nbsp;	\item Given a frame $\{c_i\}$ and matrix formed from it $A$, the frame bounds are $\sigma_{max}$, $\sigma_{min}$, the extreme singular values of $A$
What's it mean for a frame to be `tight' in wavelet theory?	\item The frame bounds, $A, B$, are equal<div>\item So it mimics an orthogonal matrix</div>
How can you construct a tight frame from a non-tight frame?	\item Choose $c^\prime_k = \frac{1}{\sqrt{AA^+}} &nbsp;c_k$
What's an exact basis?	\item One where removing an element would make it incomplete
What's an unconditional basis?	\item A basis where there are constants $A$, $B$ such that<div>\item $A \leq \frac{\|\sum c_n \phi_n \|^2}{\|c\|^2}&nbsp;\leq B$ for every $c \in l_2(\mathbb{Z})$ in the space</div>
What's a frame in $L_2(\mathbb{R})$?	\item A set of functions $\{\phi_n\}$ such that there are constants $A, B$ (the frame bounds) satisfying<div>\item $A \|x\|^2 \leq \sum |\langle \phi_n, x \rangle |^2 \leq B \|x\|^2$</div><div>\item for every $x \in L_2(\mathbb{R})$</div>
When is a frame a Riesz basis?	\item When it's exact
What's the frame operator on $L_2(\mathbb{R})$?	\item $T^*_\phi T_\phi \{x(t)\} = \sum \langle \phi_n, x \rangle \phi_n (t)$
What's the frame redundancy ratio?	\item Given frame bounds $A, B$, it's $B/A$
What's the use of the frame redundancy ratio?	\item It approximates the condition number of the frame operator<div>\item A finite redundancy ratio that's not too large or small is needed for stable synthesis or recovery</div>
How do you define a dual frame?	\item Given a frame $\{\phi_n\}$ with an invertible frame operator, the dual is defined as<div>\item $\xi_n = (T^+_\phi T_\phi)^{-1} \phi_n$</div>
How do the frame bounds of a dual frame relate to those of the primal?	\item If the primal has bounds $A, B$, the dual has bounds $B^{-1}, A^{-1}$
What're the dual frame reconstruction equations?	\item $x(t) = T^+_\xi T_\phi \{x(t)\}$<div>\item $x(t) = T^+_\phi T_\xi \{x(t)\}$</div>
Given a frame $\{\phi_n\}$, of all the $c$ that minimize the difference between the LHS and RHS of $x = \sum c_n \phi_n$, what's the solution with minimum norm?	\item $c_n = \langle \xi_n, x \rangle$ where $\{\xi_n\}$ is the dual frame to&nbsp;$\{\phi_n\}$<div>\item Works for the dual too</div>
How do you write the reproducing kernel in a Hilbert space that has dual frames $\{\phi_n, \xi_n\}$?	\item $K(t, t^\prime) = \sum \xi^*_n(t)\phi_n(t^\prime)$
When can a function $x(t) \in L_2(\mathbb{R})$ be uniquely reconstructed from coefficients $\langle \phi_n, x\rangle$ or $\langle \xi_n, x\rangle$?	\item When $\phi_n, \xi_n$ form dual frames
Given a frame, how can you construct the dual?	\item If the frame redundancy ratio is close to 1, there's an iterative algorithm that can approximate the dual.
What're the advantages of frames over bases?	\item Redundancy:&nbsp;<div>\item better approximation of CWT coefficients</div><div>\item robustness to quantization effects</div><div>\item fewer restrictions on choices of analyzing basis functions</div><div>\item signal can be reconstructed even with missing coefficients</div>
What're the problems with using frames vs bases?	\item Difficult to use for signal reconstruction since the dual frame has to be computed, which can be slow and complex
What's the convolution theorem in Fourier analysis?	\item $\mathcal{F}[x * y] = \mathcal{F}[x]\mathcal{F}[y]$&nbsp;
What's the inverse convolution theorem in Fourier analysis?	\item $\mathcal{F}[xy] = \mathcal{F}[x]*\mathcal{F}[y]$&nbsp;
How is convolution defined?	\item $x*y = \int_D x(s)y(t-s) ds$
What's the intuitive interpretation of convolution?	\item Suppose a linear, time-invariant system has a response $y(t)$ to an impulse $\delta(0)$<div>\item and write a signal $x$ as&nbsp;$x(t) = \int x(s)\delta(t-s) ds$&nbsp;</div><div>\item then the system's response to $x$ is $(x*y)(t) = \int x(s)y(t-s)ds$</div>
What's the result of convolving a sequence of length $m$ with a sequence of length $n$?	\item A sequence of length $m+n-1$
How do you use standard DFTs to compute the convolution of two sequences of length $m$ and $n$?&nbsp;	\item Pad the two sequences at the back with zeroes to $m+n-1$<div>\item Take the DFT of each sequence, multiply the two, then take the inverse DFT</div>
How do you write a convolution of finite sequences as a matrix equation?	\item $y = h * x$ is written as $y = Hx$,&nbsp;where $H$ has rows<div>\item $\begin{pmatrix}</div><div>h_{M-1} &amp; \dotsc &nbsp; &nbsp;&amp; h_0 &nbsp; &nbsp;&amp; 0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp; \dotsc &nbsp; &nbsp;&amp; 0 &nbsp; &nbsp; &nbsp; &nbsp;&amp; 0 \\</div><div>0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp; h_{M-1} &amp; \dotsc &amp; h_0 &nbsp; &nbsp; &nbsp; &amp; 0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp; \dotsc &amp; 0 \\</div><div>\vdots &nbsp; &nbsp;&amp; \vdots &nbsp; &nbsp;&amp; \vdots &amp; \vdots &nbsp; &nbsp;&amp; \vdots &nbsp; &nbsp;&amp; \vdots &amp; \vdots \\</div><div>0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp; \dotsc &nbsp; &nbsp;&amp; 0 &nbsp; &nbsp; &nbsp; &nbsp;&amp; h_{M-1} &amp; \dotsc &nbsp; &nbsp;&amp; h_0 &nbsp; &nbsp;&amp; 0 \\</div><div>0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp; &nbsp;0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&amp;\dotsc &nbsp;&amp; 0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp; h_{M-1} &amp; \dotsc &amp; h_0</div><div>\end{pmatrix}$&nbsp;</div>
What's the definition of the correlation between two continuous functions?	\item $[h \star x](t) = \int h(s)x(t+s) ds$
What's another name for a system function?	\item A filter
What're the eigenfunctions of a continuous linear time-invariant system?	\item $u(t) = e^{st}$, $s \in \mathbb{C}$
What're the eigenfunctions for a discrete linear time-invariant system?	\item $u(z) = \frac{1}{z^n}$, $n \in \mathbb{Z}$<br />
What's a Laurent series?	\item A convergent series of the form $f(z) = \sum_{-\infty}^\infty a_n(z-c)^n$
How's the Z transform defined?	\item $\mathcal{Z}\{x[n]\} = \sum_{-\infty}^\infty \frac{x[n]}{z^n}$&nbsp;
What's the convolution theorem for Z transforms?	\item $\mathcal{Z}\{x * h \} = \mathcal{Z}\{x\}\mathcal{Z}\{h\}$
What's the Z transform of $x[n-k]$?	\item $\mathcal{Z}\{x[n-k]\} = \frac{1}{z^k} \mathcal{Z}\{x[n]\}$
What's the Z transform of $x[-n]$?	\item $\mathcal{Z}\{x[-n]\} = \mathcal{Z}\{x[n]\}(\frac{1}{z})$
What's the Z transform of $x^*[n]$?	\item $\mathcal{Z}\{x^*[n]\} = \mathcal{Z}^*\{x[n]\}(z^*)$
What's the Z transform of $\frac{1}{a^n}x[n]$ when $a &gt; 0$?	\item $\mathcal{Z}\{\frac{1}{a^n}x[n]\} = \mathcal{Z}\{x[n]\}(az)$
Intuitively, how does the Z transform relate to the Fourier transform?	\item Evaluating the Z transform on $z = e^{iw}$ (the unit circle) is equivalent to computing the Fourier transform
How's the inverse Z transform defined?	\item $\mathcal{Z}^{-1}\{X(z)\} = \frac{1}{2\pi i}\oint_C X(z) z^{n-1}dz$&nbsp;<div>\item where $C$ is a path within the region of convergence and circling the origin</div>
What's the Z transform equivalent of $\mathcal{F}\{x\}(\omega + \pi)$?	\item&nbsp;$\mathcal{F}\{x\}(\omega + \pi) = \mathcal{Z}\{x\}(-z)$<div>\item where $z = e^{i\omega}$</div>
What's the Z transform equivalent of $\mathcal{F}^*\{x\}(\omega)$?	\item $\mathcal{F}^*\{x\}(\omega) = \mathcal{Z}\{x\}(\frac{1}{z})$ where $z = e^{i\omega}$
What's a spectrum in Fourier analysis?	\item $S(\omega) = |\mathcal{F}\{x[n]\}(\omega)|^2$<div>\item ie the frequency energy spectrum</div>
What's a FIR filter in Fourier analysis?	\item Finite impulse response filter
What's the Fejer-Riesz theorem?	\item If $S(\omega) = \sum_{|k| \leq N-1} s_k e^{-ik\omega}$ is real and non-negative<div>\item it can be written as $S(\omega) = |H(\omega)|^2$&nbsp;</div><div>\item where $H(z) = \sum_0^{N-1} \frac{h_n}{z^n}$ is unique up to an arbitrary phase and has all its roots on or in the unit circle</div>
What's a PR-QMF in wavelet theory?	\item Perfect reconstruction quadrature mirror filter bank
Intuitively, what's the use of a PR-QMF?	\item It'll split a signal into low- and high-pass components at half the original sampling rate<div>\item with exact reconstruction from the components</div>
How are convolution and correlation related?	\item Correlating with $h[n]$ is equivalent to convoluting with $h[-n]$
What's the Z transform of $x[n]$ when downsampled?	\item Let $y[n] = x[2n]$ be the downsampled signal<div>\item Then $Y(z) = \frac{1}{2} [X(\sqrt{z}) + X(-\sqrt{z})]$</div>
What's the Z transform of $x[n]$ when upsampled?	\item Let $y[2n]&nbsp;= x[n]$, $y[2n+1] = 0$ be the upsampled signal<div>\item Then $Y(z) = X(z^2)$</div>
For an IIR PR-QMF filter bank, how should the analysis filters $g_0, g_1$ and synthesis filters $h_0, h_1$ be related?	<div>\item QMF requirement: $H_1(z) = H_0(-z)$</div>\item PR requirements:&nbsp;<div>\item $G_0(z) = H_0(\frac{1}{z})$, $G_1(z)=H_1(\frac{1}{z})$</div><div>\item $H_0(z)G_0(z) + H_0(-z)G_0(-z) = 2$</div>
What's the QMF property for infinite filters in the frequency domain if the frequency is restricted to the unit circle?	\item $H_1(\omega) = -e^{-i\omega}H_0^*(\omega + \pi)$
In wavelet theory, what do $g_0, g_1, h_0, h_1$ usually refer to?	\item $g_0$ is the low-pass analysis filter<div>\item $g_1$ is the high-pass analysis filter</div><div>\item $h_0$ is the low-pass synthesis filter</div><div>\item $h_1$ is the high-pass synthesis filter</div>
How are wavelets derived from a mother wavelet?	\item $\psi_{\tau \eta} = \mathcal{T}_\tau \mathcal{D}_\eta \psi(t)$
How is the windowed Fourier transform defined as an inner product?	\item $\xi_{\tau\omega}(t) = \mathcal{M}_\omega \mathcal{T}_\tau w^*(t)$ where $w$ is the window function<div>\item Then $S_{\tau\omega} = \langle \xi_{\tau \omega} | s \rangle$</div>
What's $\mathcal{M_\omega}$ in wavelet theory?	\item The modulation operator&nbsp;$\mathcal{M_\omega} w(t) = e^{i\omega t} w(t)$
What's $\mathcal{T}_\tau$ in wavelet theory?	\item The translation operator&nbsp;$\mathcal{T}_\tau w(t) = w(t - \tau)$
How is the windowed inverse Fourier transform defined as an inner product?	\item Let $\chi_{\tau \omega} = \frac{1}{\sqrt{2\pi} \|w\|^2} \xi_{\tau \omega}(t)$<div>\item Then $s(t) = \langle&nbsp;\chi_{\tau \omega} | S(\tau, \omega) \rangle$</div>
When do the analyzing and synthesizing functions for the windowed Fourier transform coincide?	\item When the window function is normalized so that $\|w\| = \frac{1}{\sqrt{2\pi}}$
What's the reproducing kernel for a Fourier transform with a normalized window function?	\item $K_{\tau\omega;\tau^\prime \omega^\prime} = \langle \xi_{\tau\omega} | \xi_{\tau^\prime \omega^\prime} \rangle$
What's the intuitive interpretation of the reproducing kernel of a windowed Fourier transform when applied to $L_2(\mathbb{R}^2)$?	\item It's a projection onto the range space of the windowed fourier transform operator
What does $\mathcal{W}(t, \tau)$ represent in wavelet theory?	\item $\mathcal{W}(t, \tau) = \sum_{-\infty}^\infty |w(t-m\tau)|^2$<div>\item ie the energy of a discretized window function $w$ centered on $t$ when sampled every $\tau$</div>
How is the dual window function defined for a discretized windowed Fourier transform?	\item $\tilde w(t) = \frac{1}{T_0}\frac{w^*(t)}{\mathcal{W}(t, \tau_0)}$
What's the use of the dual window in the discretized windowed Fourier transform?	\item If the synthesis functions exist, they'll be generated by time translations and frequency modulations of the dual window function &nbsp;&nbsp;
What are sufficient conditions for a function to be recovered from its discretized windowed Fourier transform?	\item The window $w(t)$ has compact support $[0, T_0]$<div>\item The fundamental shift and frequency satisfy $\tau_0 \omega_0 \leq 2\pi$</div><div>\item There are positive, finite $A, B$ such that $A \leq \frac{2\pi}{\omega_0 \tau_0} \|w\|^2 \leq B$</div>
How are the frame and dual frame defined for a discretized windowed Fourier transform?	\item $\xi_{mn}(t) = \mathcal{M}_{n\omega_0} \mathcal{T}_{m\tau_0} w^*(t)$<div>\item $\chi_{mn}(t) = \mathcal{M}_{n\omega_0} \mathcal{T}_{m\tau_0} \tilde w(t)$</div>
What's the reconstruction formula for a discretized windowed Fourier transform in terms of the frame and dual frame functions?	\item $|s \rangle = |\chi_{mn} \rangle\langle \xi_{mn} | s \rangle$
Intuitively, what's the Balian-Low theorem?	\item If a windowed discretized Fourier transform has $\omega_0 \tau_0 = 2\pi$ and a frame exists for it<div>\item then the window must be `badly behaved' in either the time or frequency domain</div>
How're the time and frequency widths of a window function defined?	\item $\sigma_t^2 = \frac{\int (t-\bar t)^2 |w^2(t)| dt}{\int |w^2(t)| dt}$, where $\bar t = \frac{\int t |w^2(t)| dt}{\int |w^2(t)| dt}$&nbsp;<div>\item $\sigma_f^2 = \frac{\int (f-\bar f)^2 |W^2(f) | df}{\int |W^2(f)| df}$, where $\bar f =&nbsp;\frac{\int f |W^2(f)| dt}{\int |W^2(f)| df}$</div>
How are the time width and frequency widths of a window function related?	\item $\sigma_t \sigma_f \geq \frac{1}{4\pi}$
How is the continuous wavelet transform of a function defined?	\item $X_{\tau\eta} = \langle \psi_{\tau \eta} | x \rangle$&nbsp;
How is the dilation operator defined in the continuous wavelet transform?	\item $\mathcal{D}_\eta \psi(t) = \frac{1}{\sqrt{|\eta|}}\psi\left(\frac{t}{\eta}\right)$
How do the dilation and translation operators commute?	\item $\mathcal{D}_\eta \mathcal{T}_\tau = \mathcal{T}_{\eta \tau} \mathcal{D}_\eta$
What's the Fourier transform of $x(\eta t)$?	\item $\frac{1}{\eta} X \left(\frac{\omega}{\eta} \right)$
What's the distinguishing property of constant-Q filter banks?	\item The ratio of RMS bandwidth to central frequency is the same for all filters in the bank
Do wavelets form constant-Q filter banks?	\item Yup
What's the admissability condition on a mother wavelet that enables recovery of a signal from its transform?	\item $C_\psi = \int \frac{|\Psi(\omega)|^2}{|\omega|}d\omega$ is finite<div>\item (note $\Psi$ is the Fourier transform of the wavelet)</div>
How is the dual to the continuous wavelet transform defined? &nbsp;	\item $\chi_{\tau \eta} = \frac{1}{C_\psi |\eta|^2} \psi_{\tau\eta}$
What's the recovery equation for the continuous wavelet transform in terms of the dual wavelet functions?	\item $|x \rangle = \langle \psi_{\tau \omega} | x \rangle | \chi_{\tau \omega} \rangle$
What's Parseval's relation for the continous wavelet transform?	\item If $x, y$ have CWT coeffs $X_{\tau \eta}, Y_{\tau, \eta}$, then<div>\item $\langle y | x \rangle = \langle Y | X \rangle$</div>
What's the reproducing kernel of the space of CWT coefficients?&nbsp;	\item $K_{\tau\eta;\tau^\prime \eta^\prime} = \langle \psi_{\tau\eta} | \psi_{\tau^\prime \eta^\prime} \rangle$
What's the projection operator from $L_2(\mathbb{R}^2)$ onto the range of the CWT?	\item The reproducing kernel $K_{\tau\eta;\tau^\prime \eta^\prime}$
What're sufficient conditions for a mother wavelet to be admissable?	\item If it's got finite energy and zero mean (equiv. no DC Fourier component)
How do you discretize the continuous wavelet transform so as to preserve scale invariance?	\item Use the grid $\{\eta_m = \pm \eta_0^m, \tau_n = n\eta_0^m\tau_0\ | m, n \in \mathbb{Z}\}$<div>\item Is not time-translation invariant</div>
How do you discretize the continuous wavelet transform so as to preserve time translation invariance?	\item Use the grid $\{\eta_m = \pm \eta_0^m, \tau_n = n\tau_0\ | m, n \in \mathbb{Z}\}$<div>\item Is not scale invariant</div>
How is the continuous wavelet transform discretized into the undecimated wavelet transform?	\item By using the time-translation-preserving grid with $\eta_0 = 2$ and $\tau_0 = 1$
If you discretize the CWT on the scale-preserving grid, how do the frame bounds (if they exist) respond to changes in $\eta_0$ and $\tau_0$?	\item As $\eta_0 \rightarrow 1$ and $\tau_0 \rightarrow 0$<div>\item then $\left|\frac{A-B}{A+B}\right| \rightarrow 0$</div>
What's the a'trous condition?	\item An interpolation function $f[n]$ satisfies the a'trous condition if $f[2n] = \delta_{0n}$
What's the use of a'trous interpolators in wavelet theory?	\item They ensure that when doubling the scale of a wavelet, even values will be interpolated exactly
What's the Lagrange a'trous filter?	\item An a'trous filter which uses Lagrange polynomials evaluated at $0.5$ for the filter coefficients of odd indices
What's the advantage of the Lagrange a'trous filter?	\item The interpolation given by the filter of order $2N-1$ is exact at all indices if the target function is a polynomial of order at most $2N-1$
What's the Haar scaling function?	\item $\phi(t) = 1$ on $0 \leq t \leq 1$, $0$ otherwise
What's a scaling function?	\item A function satisfying the scaling equation<div>\item $\phi(t) = \sqrt{2} h_0[n] \cdot \phi(2t-n)$</div><div>\item where $h_0[n]$ are known as the low-pass filter coefficients</div>
What's the basis for the Haar MRA subspaces $\mathcal{V}_m$?	\item $\phi_{mn}(t) = \mathcal{D}_{2^m} \mathcal{T}_n \phi(t)$<div>\item where $\phi(t)$ is the Haar scaling function</div>
What's the Haar scaling equation?	\item $\phi(t) = \phi(2t) + \phi(2t-1)$<div>\item which is satisfied by the Haar scaling function</div>
What's $\mathbf{P}_m$ in wavelet theory?	\item The ``approximation'' projection from $L_2(\mathbb{R})$ onto the MRA subspace $\mathcal{V}_m$&nbsp;
How's $\mathbf{E}_m$ defined in wavelet theory?	\item $\mathbf{E}_m x = \mathbf{P}_{m-1}x - \mathbf{P}_m x$<div>\item ie it's the&nbsp;``detail'' projection onto $\mathcal{V}_m^\perp$</div>
How are the Haar wavelet functions defined in terms of the Haar scaling functions?	\item $\psi_{mn}(t) = \frac{1}{\sqrt{2}} (\phi_{m-1, 2n}(t) - \phi_{m-1, 2n+1}(t))$
How are the Haar wavelet coefficients defined in terms of the Haar scaling coefficients on the finer scale?	\item Coefficient for $\psi_{mn}$ is&nbsp;<div>\item $d_{mn} = \frac{1}{\sqrt{2}}(c_{m-1,2n} - c_{m-1, 2n+1})$</div><div>\item where $c_mn$ are the coefficients of the scaling functions $\phi_{mn}$</div>
What's the wavelet equation?	\item $\psi(t) = \sqrt{2} h_1[n] \star \phi(2t-n)$<div>\item where $h_1[n]$ are the high-pass filter coefficients and $\phi$ is the scaling function</div>
What's the Haar wavelet equation?	\item $\psi(t) = \phi(2t) - \phi(2t-1)$<div>\item where $\phi$ is the scaling function</div>
How is the MRA subspace $\mathcal{V}_{m-1}$ written in terms of $\mathcal{V}_{m}$?	\item $\mathcal{V}_{m-1} =&nbsp;\mathcal{V}_m \oplus&nbsp;\mathcal{V}_m^\perp$
With the MRA subspaces $\mathcal{V}_m$, is it increasing or decreasing $m$ that corresponds to finer detail?	\item Decreasing. $\mathcal{V}_{-\infty}$ is perfect resolution
How is the MRA subspace $\mathcal{V}_{m}$ written in terms of detail subspaces alone?	\item $\mathcal{V}_{m} = \oplus_{k &gt; m} \mathcal{V}_k^\perp$&nbsp;
How are the scaling \&amp; wavelet transforms at a scale written in terms of the next finer scale?	<div>\item $\psi_{mn}(t) = h_1[k-2n] \star \phi_{m-1, k}(t)$ where $h_1$ is a high-pass filter</div>\item $\phi_{mn}(t) = h_0[k-2n] \star \phi_{m-1, k}(t)$ where $h_0$ is a low-pass filter<br />
What's the intuitive version of writing the scaling \&amp; wavelet coefficients in terms of the coefficients at the next finer scale?	\item You analyze the scaling coefficients at scale $m-1$ to get the coefficients at the coarser scale $m$<div>\item by correlating them with a low (scaling) or high (wavelet) pass filter, then taking all even numbered samples.</div>
What's a half-band filter?	\item A filter which reduces the maximum bandwidth of the input by a factor of 2
What are the Shannon MRA subspaces equivalent to?	\item $\mathcal{V}_m$ is the subspace of functions whose band is limited to $\frac{1}{2^m}[-\pi, \pi]$
What are the low-pass filter coefficients for the Shannon scaling function?	\item $h_0[n] = \frac{1}{\sqrt{2}}\text{sinc}\, \frac{n}{2}$
What's the Shannon mother scaling function?	\item $\phi = \text{sinc\,} t$
What's the Shannon mother wavelet function?	\item $\psi(t) = \text{sinc}(t-\frac{1}{2})-2\text{sinc}(2t-1)$
Intuitively, what's Meyer's wavelet?	\item It's Shannon's wavelet with the edges of its frequency spectrum smoothed a little
How are the scaling and wavelet coefficients written in terms of the scaling and wavelet transforms?	\item Wavelet coeffs: $d_{mn} = \langle \psi_{mn} | x \rangle$<div>\item Scaling coeffs: $c_{mn} = \langle \phi_{mn} | x \rangle$</div>
How are the scaling and wavelet coefficients at a given scale written in terms of the next finer scale?	<div>\item $d_{mn} = h_1[k-2n] \star c_{m-1, k}$ where $h_1$ is a high-pass filter</div>\item $c_{mn} = h_0[k-2n] \star c_{m-1, k}$ where $h_0$ is a low-pass filter
How are the scaling coefficients at a certain scale written in terms of the coefficients of the next coarser scale?	\item $c_{m-1, n} = h_0[2k+n]*c_{mk} + h_1[2k+n]*d_{mk}$<div>\item where $h_0$ is a low pass filter and $h_1$ is a high pass filter</div>
What's the intuitive version of writing the scaling coefficients in terms of the coefficients at the next coarser scale?	\item You synthesize the coefficients at scale $m-1$ from the coefficients at the coarser scale $m$<div>\item by interpolating $c_{mn}$ and $d_{mn}$ with zeroes at odd $n$</div><div>\item then convolving the results with a low-pass ($c$) and high-pass ($d$) filters</div><div>\item then adding the two together&nbsp;</div>
Intuitively, what happens in the analysis stage of the undecimated wavelet transform?	\item The&nbsp;filters are interpolated with zeroes so at the $m$th scale, only multiples of $2^m$ are nonzero&nbsp;<div>\item then the signal is correlated with them directly (without downsampling)</div>
Intuitively, what happens in the synthesis stage of the undecimated wavelet transform?	<div>\item Upsample the approximation and detail signals by interpolating the coefficients with zeroes,</div><div>\item then convolve the results with the filters</div><div>\item and sum the two outputs</div>
What are two other names for the undecimated wavelet transform?	\item Shift-invariant&nbsp;wavelet&nbsp;transform<div>\item Redundant wavelet transform</div>
How do you write the low-pass filter in terms of the scaling function of a wavelet transform?	\item $h_0[n] = \sqrt{2} \phi(t) \star \phi(2t-n)$&nbsp;
How do you write the high pass filter in terms of the scaling and wavelet mother functions of a wavelet transform?	\item $h_1[n] = \sqrt{2} \psi(t) \star \phi(2t-n)$&nbsp;
What can you say about the support of a filter and the support of the scaling function of a wavelet transform?	\item If the low-pass filter $h_0[n]$ has compact support on $[0, N-1]$, so does $\phi(t)$<div>\item If $\phi(t)$ has compact support on $[0, N-1]$, then $h_0[n]$ has at most $N$ nonzero elements</div>
What can you say about the support of a filter and the support of the mother wavelet function of a wavelet transform?	\item If the high-pass filter $h_1[n]$ has compact support on $[0, N-1]$, so does $\psi(t)$<div>\item If $\psi(t)$ has compact support on $[0, N-1]$, then $h_1[n]$ has at most $N$ nonzero elements</div>
What's a low-pass function?	\item One with a nonzero average value
What three constraints are imposed on the low-pass filter coefficients $h_0[n]$ when the scaling function is normalized, orthonormal and real?	<div>\item $\sum_n h_0[n] = \sqrt{2}$</div><div>\item $\sum_n h_0[2n] = \sum h_0[2n+1] = \frac{1}{\sqrt{2}}$</div><div>\item $h_0[n] \star h_0[n-2k] = \delta_{0k}$</div>
What's the partition-of-unity property of a wavelet transform's scaling function?	\item $\sum_n \phi(t+n) = 1$
What three constraints are imposed on the high-pass filter coefficients $h_1[n]$ when the scaling function is normalized, orthonormal and real?	<div>\item $\sum_n h_1[n] = 0$</div><div>\item $h_1[k]\star h_1[k+2n] = \delta_{0n}$</div><div>\item $h_1[k]\star h_0[k+2n] = \delta_{0n}$</div>
How is the Fourier transform of a scaling function written in terms of the Fourier transforms of the low-pass filter?	\item $\Phi(\omega) = \prod \left(\frac{1}{\sqrt{2}} H_0\left(\frac{\omega}{2^n}\right)\right)$
How is the orthonormal basis property of the scaling functions $\phi_{mn}$ represented in the frequency domain?	\item $\| \Phi (\omega + 2n\pi) \|^2_n = 1$
How is the Fourier transform of the wavelet function written in terms of the Fourier transform of the high-pass filter?	\item $\Psi(\omega) = \prod \frac{1}{\sqrt{2}} H_1\left(\frac{\omega}{2^n}\right)$
How is the orthonormal basis property of the wavelet functions $\psi_{mn}$ represented in the frequency domain?	\item $\|\Psi(\omega + 2n\pi)\|^2_n = 1$
How is the orthogonality between wavelet functions $\psi_{mn}$ and scaling functions $\phi_{mn}$ represented in the frequency domain?	\item $\langle \Phi(\omega + 2n\pi), \Psi(\omega + 2n\pi) \rangle_n = 0$
What's the paraunitary matrix of a PR-QMF in wavelet theory?	\item $\mathbf{H}(\omega) = \frac{1}{\sqrt{2}}\left( \begin{matrix}<div>H_0(\omega) &amp; H_0(\omega + \pi) \\</div><div>H_1(\omega) &amp; H_1(\omega + \pi)&nbsp;</div><div>\end{matrix} \right)$</div>
How can the paraunitary matrix be used to capture the orthonormality of the scaling \&amp; wavelet functions?	\item $\mathbf{H}^+(\omega) \mathbf{H}(\omega) = \mathbf{I}$
What conditions on the the wavelet \&amp; scaling function lead to the QMF condition on infinite filters?	\item The orthonormality of the wavelet \&amp; scaling functions<div>\item and the selection of $-e^{-i\omega}$ as the scaling factor in</div><div>\item $H_1(\omega) = p(2\omega) e^{\pm i \omega}H_0^*(\omega + \pi)$</div>
What's an order-$n$ spline?	\item A function that's piecewise $n$th-degree polynomial<div>\item and is continuous and continuously differentiable to order $n-1$</div>
What's a b-spline?	\item A basis spline, a unique spline associated with a set of control points<div>\item into which any spline can be linearly decomposed&nbsp;</div>
What's the cascade algorithm in wavelet theory?	\item A way to construct scaling functions from filter coefficients.<br /><div>\item Uses the scaling equation for interpolation</div><div>\item and the partition of unity for the base case</div>
What's a linear phase filter?	\item A filter where the phase response is linear wrt frequency<div>\item corresponding to a constant shift in time (the phase delay)</div>
What are biorthogonal filters?	<div>\item A set of synthesis filters $\{h_0, h_1\}$ derived from the scaling function $\phi(t)$</div><div>\item and analysis filters $\{h_0^\prime, h_1^\prime\}$&nbsp;derived from the scaling function $\phi^\prime(t)$</div><div>\item where $\phi, \phi^\prime$ are biorthogonal</div><div><br /></div>
How can the orthogonality conditions on the scaling \&amp; wavelet functions of a biorthogonal filter scheme be captured by paraunitary matrices?	\item $\mathbf{H}^\prime (\omega) \mathbf{H}^+(\omega) = \mathbf{1}$<div>\item where $\mathbf{H}^\prime$ is constructed from the dual filters $h_0^\prime,&nbsp;h_1^\prime$</div>
How can a discrete time signal be interpreted as a continuous signal in wavelet theory?	\item By treating the discrete data as samples and using the sampling theorem to reconstruct the `original' signal<br /><div>\item The sampling theorem reconstruction most closely resembles the inverse wavelet transform on the Shannon wavelet, but any scaling function with a zero mean time can be used.&nbsp;</div>
How do you write a wavelet analysis step as a matrix multiplication?&nbsp;	\item $\left( \begin{matrix}<div>h_0 &amp; h_1 &amp; h_2 &amp; h_3 &amp; 0 &amp; 0&nbsp;&nbsp;&amp; 0 &amp; 0\\</div><div>h_3 &amp; -h_2 &amp; h_1 &amp; -h_0&nbsp;&nbsp;&amp; 0 &amp; 0&nbsp;&amp; 0 &amp; 0\\</div><div><div>0 &amp; 0 &amp;&nbsp;h_0 &amp; h_1 &amp; h_2 &amp; h_3&nbsp;&nbsp;&amp; 0 &amp; 0\\</div><div>0 &amp; 0 &amp;&nbsp;h_3 &amp; -h_2 &amp; h_1 &amp; -h_0&nbsp;&nbsp;&amp; 0 &amp; 0\\</div></div><div><div>0 &amp; 0 &amp;&nbsp;0 &amp; 0 &amp; h_0 &amp; h_1 &amp; h_2 &amp; h_3 \\</div><div>0 &amp; 0 &amp;&nbsp;0 &amp; 0 &amp;&nbsp;h_3 &amp; -h_2 &amp; h_1 &amp; -h_0 \\</div><div>h_2 &amp; h_3 &amp; 0 &amp; 0&nbsp;&nbsp;&amp; 0 &amp; 0&nbsp;&amp;&nbsp;h_0 &amp; h_1 \\</div></div><div><div>h_1 &amp; -h_0 &amp;&nbsp;0 &amp; 0&nbsp;&nbsp;&amp; 0 &amp; 0&nbsp;&amp; h_3 &amp; -h_2</div></div><div>\end{matrix} \right)</div><div>\mathbf{x}</div><div>=</div><div>\left(</div><div>\begin{matrix}&nbsp;</div><div>c_0 \\</div><div>d_0 \\</div><div>c_1 \\</div><div>d_1 \\</div><div>c_2 \\</div><div>d_2 \\</div><div>c_3 \\</div><div>d_3&nbsp;</div><div>\end{matrix} \right)$</div><div>\item This is usually followed by a reordering to put all the $c_i$s before the $d_i$s</div>
What's a housekeeping step to perform when carrying out a wavelet transform step by direct convolution?	\item Given a length $N$ signal and a length $M$ filter, the result of a convolution is length $N+M-1$<div>\item So during analysis, discard the first $M-1$ points from the output before downsampling&nbsp;</div><div>\item and during synthesis, discard the last $M-1$ points from the output before summing</div>
How do you write a wavelet synthesis step as a matrix multiplication?&nbsp;	\item Using the transpose of the analysis matrix.
What are four useful functions when using Python interactively?	\item \ttt{help(), help(x)}<br /><div>\item \ttt{dir(ns)} which list the objects in a particular namespace&nbsp;</div><div>\item \ttt{locals()} which lists the objects in the local namespace</div><div>\item \ttt{globals()} which lists the objects in the global namespace</div>
How do you carry out division on integers in Python 3?	\item \ttt{5/2} returns the float \ttt{2.5f}<div>\item \ttt{5//2} returns the integer \ttt{2}</div>
How do you include a module in Python?	\item \ttt{import moduleName}
How's a list literal denoted in Python?&nbsp;	"\item \ttt{[1, ""two"", 3L]}"
In what ways can you get a slice of a list&nbsp;in Python?	\item \ttt{list[3:]} to get every element from the 3rd onwards<div>\item \ttt{list[-3:]} to get the last 3 elements</div><div>\item \ttt{list[2:4]} to get elements 2, 3 \&amp; 4</div>
What's the difference between tuples and lists in Python?	\item Tuples are immutable
How's a tuple literal denoted in Python?	"\item \ttt{(1, ""two"", 3L)}"
How do you create a one-element tuple in Python?	\item \ttt{(1,)}<div>\item The \ttt{,} is necessary!</div>
In what ways can you denote a string in Python?	"\item \ttt{'string'}<div>\item \ttt{""string""}</div><div>\item \ttt{'''string'''}</div><div>\item \ttt{""""""string""""""}</div>"
How do you create a set in Python?	"\item \ttt{\{1, ""two"", 3L\}}"
How is a dictionary literal denoted in Python?&nbsp;	"\item \ttt{x = \{1: ""one"", ""two"": 2L\}}"
What's the restriction on dictionary keys in Python?	\item They must be an immutable, hashable type
How do you create a file object in Python?	"\item \ttt{f = open(""filename"", ""w"")}"
How do you serialize and deserialize complex objects in Python?	\item Use the \ttt{cPickle} class
How do you write an if-else-if statement in Python?	\item \begin{verbatim}<div>if condition1:</div><div>&nbsp; &nbsp; code&nbsp;<div>elif condition2:</div><div>&nbsp; &nbsp; code&nbsp;</div><div>else: &nbsp;</div><div>&nbsp; &nbsp; code</div></div><div>\end{verbatim}</div>
How do you write a for loop in Python?	\item \ttt{for x in list:}
How do you declare a function in Python?	\item \ttt{def functionName(x, y, z):}
What's returned by a Python function with no return statement?	\item \ttt{None}
Which structure handles errors in Python?	\item \begin{verbatim}<br /><div>try:</div><div>&nbsp; &nbsp; do something risky</div><div>except IOError as error:</div><div>&nbsp; &nbsp; handle error</div><div>except EmptyFileError as error:</div><div>&nbsp; &nbsp; handle other error</div><div>else:</div><div>&nbsp; &nbsp; do another thing if there's no errors</div><div>finally:</div><div>&nbsp; &nbsp; and always do this</div><div>\end{verbatim}</div>
How do you denote a line comment in Python?	\item \ttt{\# comment}
How do you define a module in Python?	\item Each file is implicitly its own module
How do you create a docstring in Python?	"\item \begin{verbatim}<div>def function():</div><div>""""""docstring""""""</div><div>\end{verbatim}</div>"
How do you declare a class in Python?	\item \ttt{class Classname:}
How do you inherit from another class in Python?	\item \ttt{class ClassName(ParentName):}
How're initializers defined in Python?	\item \ttt{def \_\_init\_\_(self, other, args):}
How do you define the string representation of a class in Python?	\item \ttt{def \_\_str\_\_(self):}
How are methods denoted in Python?	\item They're functions which take (by convention) a first argument called \ttt{self}
How do you deliberately destroy a variable in Python?	\item \ttt{del x}<div>\item Destroys the \emph{variable}, not the object!</div>
What numeric types are available in Python?	\item Integers<div>\item Floats (doubles)</div><div>\item Complex numbers</div><div>\item Booleans</div>
How are booleans implemented in Python?	\item As the numbers \ttt{0, 1}, just with different string representations
How do you write an imaginary number in Python?	\item \ttt{3j}
How can you include the contents of a module in Python?	\item \ttt{from moduleName import *}<div>\item Don't do this though</div>
What's Python naming convention?	\item Lowercase \&amp; underscores for variables, functions and modules<div>\item Pascal case for classes</div>
How do you append one list to another list using slices in Python?	\item \ttt{front[len(x):] = back}<div>\item List will expand to accomodate the new elements</div>
How do you prepend to a list using indices in Python?	\item \ttt{back[:0] = front}<div>\item List will expand to accomodate the new elements</div>
Are slices or list methods usually preferred in Python?	\item List methods - they communicate intent more effectively
How do you test membership in Python?	\item \ttt{elem in elems}
How do you initialize a list to copies of an element in Python?	\item \ttt{[initial, elements] &nbsp;* count}
How do you copy nested lists in Python?	\item Use \ttt{copy.deepcopy}
How can you return multiple objects from a function in Python?	\item In the function: \ttt{return (x, y)}<div>\item At the call site: \ttt{a, b = f()}</div><div>\item (the \ttt{a, b} is implicitly converted to a tuple)</div>
How can you return a variable number of arguments from a function in Python?	\item In the function: \ttt{return (x, y, z)}<div>\item At the call site: \ttt{a, *b = f()}</div><div>\item (the \ttt{*} indicates \ttt{b} will capture any excess returns)&nbsp;</div>
What kinds of pattern matching appear on the LHS of an assignment in Python?	\item \ttt{[a, b] = f()}, pattern matching against a list<div>\item \ttt{(a, b) = f()}, pattern matching against a tuple</div><div>\item \ttt{a, b = f()}, pattern matching against a tuple</div>
How do you create a set of sets in Python?	\item Make the inner sets \ttt{frozenset}s, which are immutable and hashable
What're string constants in Python?	\item Things like \ttt{string.whitespace} and \ttt{string.digits} that describe what Python thinks of as whitespace and digits on your system
What's the string modulus operator in Python?	"\item The old way of formatting strings, before \ttt{string.format}<div>\item \ttt{""one \%s three"" \% \{""two""\}}</div>"
What's the best way to use the string modulus operator in Python?	"\item Use formatting speficiers of the form \ttt{""\%(name)""}<div>\item and pass a dictionary containing the key \ttt{name}</div>"
What's the default character set of Python 3 strings?	\item Unicode.
Which values are falsy in Python?	\item Numeric zeroes<div>\item Empty strings</div><div>\item Empty data structures (usually)</div><div>\item \ttt{None}</div>
How can you test if a variable falls in a numeric range in Python?&nbsp;	\item \ttt{if 0 &lt; x &lt; 10:}
What's the inequality operator in Python?	\item \ttt{!=}<div>\item \ttt{&lt;&gt;}</div>
How can you get the docstring associated with a Python function?	\item \ttt{f.\_\_doc\_\_}
How do you define a default argument for a function in Python?	\item \ttt{def fun(arg=default):}
How do you pass an argument by parameter name in Python?	\item \ttt{f(param=value)}
How do you implement variable-number argument functions in Python?	\item \ttt{def fun(*x)} will collect excess arguments into a tuple<div>\item \ttt{def fun(**x)} will collect excess keyword arguments into a dictionary</div>
How do you modify a global variable from within a function in Python?	\item Bring it into scope with \ttt{global a}<div>\item Then \ttt{a = b}</div>
How do you write a lambda expression in Python?	\item \ttt{lambda x, y: expr}
How do you get the name of a function in Python?	\item \ttt{f.\_\_name\_\_}
How do you implement a decorator function in Python?	\item Create a function \ttt{d} that takes another function as its first arg and returns another function<div>\item Write&nbsp;</div><div>\item \begin{verbatim}</div><div>@d</div><div>def f():</div><div>\end{verbatim}</div><div>\item Then calling \ttt{f} will instead call the function returned by \ttt{d(f)}</div>
How can you get the module search path in Python?	\item \ttt{sys.path}
How do you denote a private function in a module in Python?	\item Give it a name starting with an underscore<div>\item Isn't actually private, just \ttt{from mod import *} will fail to find it</div>
What's the \verb|builtin| namespace in Python?	\item A proxy for the \ttt{\_\_builtins\_\_} module that has things like \ttt{len, min} in
What's the problem with the builtin namespace in Python?	\item It's unqualified, so it's easy to accidentally override some of its members&nbsp;
How do you make a Python script executable?	\item Put a function call in file scope.
How can you tell if a Python module is being called as the main module of a script?	\item \ttt{if \_\_name\_\_ == '\_\_main\_\_':}
What's Python's \ttt{shelve} module?	\item A way to create dictionaries that reside on disk rather than in memory.<div>\item Allows access into the dictionary without loading the entire thing</div>
How do you raise an exception in Python?	"\item \ttt{raise IOError(""message"")}"
What's the general exception catch block in Python?	\item \ttt{except:}
What's the null statement in Python?	\item \ttt{pass}
What happens if you pass more than one argument to a Python exception?	\item They'll be stored in the \ttt{exceptionVar.args} list
How are assertions implemented in Python?	<div>\item If \ttt{\_\_debug\_\_ = True} then</div><div>\item \ttt{assert expression, exceptionArg} will raise an&nbsp;\ttt{AssertionError(exceptionArg)} if the expression evaluates to false</div>
What're context managers in Python?	\item Objects with \ttt{\_\_enter\_\_, \_\_exit\_\_} methods<div>\item that'll be called automatically on entry to \&amp; exit from&nbsp;</div><div>\item \ttt{with obj as varName:}</div>
How do you create an object in Python?	\item \ttt{x = ClassName()}<br />
How do you create a field in Python?	\item \ttt{x.fieldName = value}<div>\item It'll be created if it doesn't exist</div>
What's a common problem with class variables in Python?	\item If \ttt{x} has type \ttt{T} and the value of \ttt{x.y} is asked for<div>\item but \ttt{x} doesn't have a \ttt{y} variable</div><div>\item then it'll look for \ttt{T.y} instead</div><div>\item and only throw an error if it can't find that either</div>
How do you create a static method in Python?	\item Decorate a method with \ttt{@staticmethod}<div>\item Static methods take no \ttt{self} or \ttt{Class} argument!</div>
How do you create a class method in Python?	\item Decorate a method with \ttt{@classmethod}<div>\item The method will be passed the class as its first argument&nbsp;</div>
How do you refer to the base class in Python?	\item \ttt{super(class, self)}
What must you do when writing a subclass's initializer in Python?	\item Call \ttt{super(class, self).\_\_init(x, y)\_\_} as the first statement in the initializer
How are constructors defined in Python?	\item They're not. Initializers are though.
What's the GIL in Python?	\item The Global Interpreter Lock, which ensures only one Python thread can be run at a time.
How do you define a private method in a Python class?	\item Prefix it with \ttt{\_\_}&nbsp;
How are private methods implemented by the Python compiler?	\item The method name is mangled by prefixing it with \ttt{\_classname}
How do you define a property using decorators in Python?	\item Decorate the getter with \ttt{@property}<div>\item (optionally) decorate the setter with \ttt{@getterName.setter}</div>
How do you define a destructor in Python?	\item Define a \ttt{\_\_del\_\_} method
When are destructors called in Python?	\item When the reference count for the object reaches zero.
What's risky about implementing Python destructors?	\item If it's called when the program is shutting down, members of the global namespace might already have been deleted
What's preferred to Python destructors?	\item A \ttt{cleanup} method&nbsp;<div>\item Possibly called from an&nbsp;\ttt{\_\_exit\_\_} method for use with \ttt{with}</div>
What's the main problem with memory management in Python?	\item Circular references.
How do you inherit from multiple classes in Python?	\item \ttt{class ClassName(Parent1, Parent2):}
When multiple parents are defined, how does Python search for inherited variables?	\item Depth-first search,&nbsp;<div>\item going left to right through the listed parents of each class</div>
How are packages defined in Python?	\item They're implicitly defined by directories which contain a (possibly empty) \ttt{\_\_init\_\_.py} file
How do you do package initialization in Python?	\item Put it in the \ttt{\_\_init\_\_.py} file in the same directory
What's \ttt{\_\_all\_\_} in Python?	\item If present in&nbsp;&nbsp;\ttt{\_\_init\_\_.py}, it lists all the names which should be loaded when \ttt{from packageName import *} is called&nbsp;
Should you generally prefer flat or nested package structures in Python?	\item Flat.
How do you make modules in a package private in Python?&nbsp;	\item Prefix their names with an \ttt{\_}
How do you get the type of a Python object?	\item \ttt{type(x)}
What's the base of the inheritance hierarchy in Python?	\item For most `new-style' classes (ie all classes in Python 3) it's \ttt{object}
How do you test whether an object is of a certain class in Python?	\item \ttt{isinstance(x, T)}
How do you test whether an object is a subclass of a type in Python?	\item \ttt{x issubclass T}
What's a special method attribute in Python?	\item An element of a class that's declared as a method, but isn't intended to be used like one<div>\item Instead it's called by the Python runtime<br /><div>\item Usually has a name like \ttt{\_\_xxx\_\_}</div></div>
How do you implement indexing on a Python object?	\item Implement \ttt{\_\_getitem\_\_, \_\_setitem\_\_}
How do you override the operators for a Python object?	\item Implement \ttt{\_\_add\_\_} to override \ttt{(+)}, etc
How do you delete parts of a list in Python?	\item \ttt{del x[1:3]}
What's a metaclass in Python?	\item The class of a class, usually \ttt{type}
How do you instantiate class objects via \ttt{type} in Python?	"\item \ttt{x = type(""ClassName"", (baseClass1, baseClass2), \{attrib1: val1, attrib2: val2\})}"
What's an attribute in Python?	\item Something that's `attached' to an object; and can be accessed via \ttt{obj.attributeName}
How do you create your own metaclasses in Python?	\item Inherit from \ttt{type}
What's the use in metaclasses in Python?	\item It allows you to design classes on the fly
How do you set the metaclass of a class in Python?	\item \ttt{class ClassName(metaclass=MetaclassName):}
What're abstract base classes in Python?	\item Classes that can be added to a class's inheritance tree that ensure it has certain attributes<br /><div>\item Typechecking, basically</div>
How do you create your own abstract base classes in Python?	\item Set the metaclass of the class to \ttt{ABCMeta}
How do you use abstract base classes in Python?	\item Create a class with the desired properties<div>\item Register it with the baseclass via \ttt{AbstractBaseClassName.register(className)}</div><div>\item Then \ttt{className issubclass AbstractBaseClassName} will be \ttt{True}</div>
Where are abstract base classes most encountered in Python?	\item In the \ttt{collections} library, with stuff like \ttt{Hashable}, \ttt{Iterable}, etc
How do you denote abstract methods in Python?	\item \ttt{@abstractmethod} in a class with \ttt{ABCMeta} as its metaclass<br />
What's the effect of \ttt{@abstractmethod} in Python?	\item Any class whose inheritance hierarchy contains an \ttt{@abstractmethod} which hasn't been overridden can't be instantiated
How do you denote an abstract property in Python?	\item \ttt{@abstractproperty} in a class with \ttt{ABCMeta} as its metaclass
What's the easiest database to use with Python?	\item \ttt{sqllite3}, because it's included in the standard library
How do you iterate over the lines of a file in Python?	\item Iterate over a file handle
What's the generative approach to building a ML classifier?	\item Create a joint model $p(y, x)$<div>\item Condition on $x$ to get $p(y|x)$</div>
What's the discriminative approach to building a ML classifier?	\item Fit a model of the form $p(y|x)$ directly
What's the gradient of the likelihood in logistic regression?&nbsp;	\item $\mb{g}(\mb{w}) = \mb{X}^T(\mb{y} - \mb{\mu})$<div>\item where $\mu$ is the mean of the Bernouilli distribution used in the regression</div>
What's the update rule in steepest descent?	\item $\theta_{k+1} = \theta_k - \eta_k g(\theta_k)$<div>\item where $\eta_k$ is the $k$th step size</div><div>\item and $g$ is the gradient function&nbsp;</div>
What's a global convergence algorithm in ML?	\item An optimization algorithm which is guaranteed to converge to the local optimum (if it exists) no matter where it starts
What's line search in ML?	\item A heuristic for use with gradient descent algorithms<div>\item which says that once you've chosen your direction of descent $d$,</div><div>\item pick the step size $\eta$ so as to minimize $\phi(\eta) = f(\theta_k + \eta_k d)$</div><div>\item which can be done with an arbitrary 1d minimization algorithm</div>
What's the typical behaviour of the steepest descent algorithm with naive line search?	\item A zig-zag path<div>\item that results from the fact that the minimum of $\phi(\eta) = f(\theta_k + \eta_k d)$&nbsp;</div><div>\item is either a stationary point or a point such that the direction of steepest descent is perpendicular to $d$</div>
What's the heavy ball method in ML?	\item It's a way to suppress zig-zagging in line search heuristics<div>\item by adding a momentum term $\mu_k (\theta_k - \theta_{k-1})$ to the update rule that produces $\theta_{k+1}$</div><div>\item where $\mu$ controls the strength of the momentum term</div>
What's the usual use of the conjugate gradient method?	\item Solving large, sparse linear systems.&nbsp;<div>\item (for dense ones, iterative methods are no faster than factoring and backsubstitution)</div>
What's the update rule in Newton's Algorithm for vector-valued updates in ML?	\item $\mb{\theta}_{k+1} = \mb{\theta}_k - \eta_k \mc{H}^{-1}(\mb{\theta}_k)\mb{g}(\mb{\theta}_k)$<div>\item where $\mb{g}$ is the gradient and $\mc{H}$ is the Hessian</div>
When is Newton's algorithm applicable?	\item When the function is strictly convex
Intuitively, what's the Levenberg Marquardt algorithm?	\item A variant of Newton's algorithm intended for use with non-convex functions<div>\item which interpolates between Newton's algorithm and steepest descent</div>
What's the truncated Newton algorithm?	<div>\item A variant of Newton's algorithm intended for use with non-convex functions</div>\item The conjugate gradient method is used to solve $\mb{H}^{-1}(\theta_k)\mb{g}(\theta_k)$<div>\item but if negative curvature is detected, the CG iterations are truncated</div>
What's IRLS stand for in ML?	\item Iteratively reweighted least squares
Simply, how's the iteratively reweighted least squares algorithm work?&nbsp;	\item At each iteration, the diagonal covariance matrix $\mb{S}$ is formed for the Bernouilli distribution used by the logistic regression problem<div>\item Then the working response vector $\mb{z}$ is found</div><div>\item and the next step $\mb{w}^\prime$ is calculated to be the vector which solves the weighted least squares problem with weights $\mb{S}$ and target $\mb{z}$</div>
What's the use of the iteratively reweighted least squares algorithm?	\item To iteratively solve GLMs
What's the use of quasi-newton methods?	\item Newton's algorithm requires computing the Hessian, which can be expensive to do directly<div>\item Quasi-newton algorithms build up the Hessian at each step using information from the gradient vector at that point &nbsp;</div>
What're the most popular quasi-Newton algorithms?	\item BFGS, named after it's authors.<div>\item Low memory BFGS, which is a variant that doesn't store the Hessian explicitly but calculates $\mb{H}^{-1}\mb{g}$ on demand using a quantity of memory linear in the dimension of the space&nbsp;</div>
If the data is linearly seperable, what's the MLE of logistic regression's parameters?	\item The linear threshold unit
What's the linear threshold unit in ML?	\item $\mbb{I}(\mb{w}^T\mb{x} &gt; w_0)$<div>\item which can be thought of as an infinitely steep sigmoid</div>
How do you apply $l_2$ regularization to logistic regression?	\item Add a penalty term $\lambda \mb{w}^T\mb{w}$ to the logistic regression likelihood<div>\item then pass the modified gradient \&amp; Hessian into whichever gradient based optimizer you were already using</div>
What's a maximum entropy classifier in ML?	\item Another name for multinomial logistic regression&nbsp;
What's the likelihood for a multinomial logistic regression model?	\item $p(y = c | \mb{x}, \mb{W}) = \text{softmax}_{c^\prime}(\mb{w}_c \cdot \mb{x})$
What's the Kronecker product?	\item $\mb{A} \otimes \mb{B}$ is a matrix where each entry $a_{ij}$ in $\mb{A}$ is replaced with $a_{ij} \mb{B}$
How is the MLE of a multinomial logistic regression model generally found?	\item Same way as for simple logistic regression:&nbsp;<div>\item derive the likelihood, its gradient and its Hessian,<div>\item then feed them into a descent-based optimizer.</div></div><div>\item (preferably low-memory BFGS though, because the Hessian in this scales with $C^2$, where $C$ is the number of classes)</div>
What prior is usually used for multinomial logistic regression models?	\item A product of MVNs, one for each class parameter vector $\mb{w}_c$<div>\item all with means of $\mb{0}$ and shared variance $\mb{V}_0$</div>
In ML, how's the energy function defined?	\item It's $E(\theta)$ such that<div>\item $p(\theta| \mc{D}) = \frac{1}{Z}\exp(-E(\theta))$<div>\item where $Z= p(\mc{D})$ is the normalization constant</div></div>
What's the Gaussian approximation to a marginal likelihood?	\item $$p(\mc{D}) \approx \left(\sqrt{2\pi}\right)^D\frac{e^{-E(\theta^*)}}{\sqrt{|H(\theta^*)|}}$$<div>\item where $\theta^*$ is the mode of the posterior</div>
What's the Gaussian approximation to the posterior of a distribution?	\item $$p(\theta|\mc{D}) \approx \frac{1}{Z}e^{-E(\theta^*)}\exp\left(-\frac{1}{2}(\theta - \theta^*)^T\mb{H}(\theta^*)(\theta - \theta^*)\right)$$<div>\item where $\theta^*$ is the mode of the posterior</div>
What're two alternative names for the Gaussian approximation?	\item Laplace approximation, though this is shared with something else in statistics<div>\item Saddle point approximation in physics</div>
Intuitively, how is the BIC derived?	\item Take the Gaussian approximation to the log marginal likelihood,&nbsp;<br /><div>\item then approximate $|\mb{H}(\theta^*)|$ by approximating $\mb{H}(\theta^*) = N\mb{\hat&nbsp;H}$, where $\mb{\hat&nbsp;H}$ is a fixed matrix</div>
What's the Occam factor in ML?	\item A term that turns up when deriving the BIC,<div>\item $\ln p(\theta^*) - \frac{1}{2}\ln | \mb{H}(\theta^*)|$, where $\theta^*$ is the posterior mode</div><div>\item which represents the model's complexity</div>
What're the options for constructing predictive distributions for logistic regression models?	\item Constructing the predictive distribution explicitly is requires intractable integrals, so the alternatives are:<div>\item Use the posterior mean as a point estimate of the parameters</div><div>\item Monte Carlo approximation</div><div>\item Probit approximation</div>
What's the probit function?	\item The CDF of the standard normal:<div>\item $\Phi(a) = \int_{-\infty}^a \mc{N}(x|0, 1)dx$</div>
What's the probit approximation in logistic regression?	\item If you've got a Gaussian approximation to the posterior of a logistic regression model<div>\item you can approximate its predictive distribution by substituting $\Phi\left(\sqrt{\frac{\pi}{8}}\mb{w}^T\mb{x}\right)$ for $\text{sigm}(\mb{w}^T\mb{x})$</div><div>\item and then correlating it with the Gaussian posterior</div>
What's a qq plot in ML?	\item A plot of the quantiles of one distribution against another<br />
How's residual analysis done for a regression model?	\item Calculate the residuals $r_i = y_i - \mb{\hat w}^T \mb{x_i}$<div>\item Plot the residuals on a qq plot against a $\mc{N}(0, \sigma^2)$ distribution</div><div>\item Points off the $y = x$ line indicate possible outliers</div>
What're two names for outlier detection in ML?	\item Residual analysis<div>\item Case analysis</div>
How are outliers defined in a Bayesian perspective?	\item Outliers are points which have low probability under the cross-validated posterior predictive distribution&nbsp;$p(y_i|\mb{x}_i, \mc{D}\backslash\{y_i, \mb{x}_i))$
In outlier analysis, how's the cross-validated posterior predictive distribution usually assessed?	\item Using sampling methods
What's rocking in ML?	\item When using a batch algorithm on a dataset that's too large to fit in memory<div>\item after a pass over the data, rather than immediately loading the start of the data again, start at the end and pass \emph{backwards} through it.</div>
How's regret defined in ML?	\item $\text{regret}_k = \frac{1}{k}\sum_1^k f(\theta_i, z_i) - \min_{\theta^* \in \Theta} \frac{1}{k}\sum_1^k f(\theta^*, z_i)$
Intuitively, what's regret in ML?	\item The difference between the average loss incurred by updating your estimate of the parameter $\theta$ after each new sample $z$<div>\item and the smallest loss that could be achieved by maintaining some single estimate throughout the process</div>
What's the simplest algorithm for online regret minimization?	\item Online gradient descent: $\mb{\theta}_{k+1} = \text{proj}_\Theta(\mb{\theta}_k - \eta_k \mb{g}_k(\mb{\theta}_k))$
What's the main difference between optimizing wrt regret and optimizing wrt risk in ML?	\item Minimizing regret is with respect to past losses - it's Bayesian<div>\item Minimizing risk is with respect to future losses - it's frequentist</div>
What's stochastic optimization?	\item Optimization where some of the variables in the objective function are random
What's Polyak-Ruppert averaging?	\item The average of a set of values can be computed online as&nbsp;<div>\item $\bar \theta_k = \frac{k-1}{k} \bar \theta_{k-1} + \frac{1}{k}\theta_k$</div>
What's SGD in ML?	\item Stochastic gradient descent, a version of gradient descent to be used with a stochastic objective
What's a learning rate schedule in SGD?	\item The set of step sizes $\eta_k$
What're the Robbins-Monro conditions?	\item $\sum \eta_k = \infty$<div>\item $\sum \eta_k^2 &lt; \infty$</div>
What's the use of the Robbins-Monro conditions?	\item SGD with a learning rate schedule satisfying the Robbins-Monro conditions is guaranteed to converge
What are two common learning rate schedules in SGD?	\item $\eta_k = \frac{1}{k}$<div>\item $\eta_k = \frac{1}{(\tau_0 + k)^\kappa}$, where $\tau_0$ slows early iterations and $\kappa$ controls how quickly old iterations are forgotten</div>
How do you usually optimize the parameters for SGD?	\item It's hard in general but<div>\item store an initial subset of the incoming data and test out various parameters on it</div><div>\item Choose the parameters which lead to the fastest decrease in the objective, and apply them to the rest of the data</div>
What's early stopping in ML?	\item Monitoring performance on the validation set and terminating training when the performance starts to drop
What's adagrad in ML?	\item Adaptive gradient, a heuristic for SGD that scales the step size per feature:<br /><div>\item $\eta_{ik} = \frac{1}{\tau_0 + \|g_{ik}\|}\cdot \eta_k$</div><div>\item where $g_{ik}$ is a vector of the $i$th components of all previous steps&nbsp;</div>
What's an epoch in ML?	\item When simulating online data by sampling without replacement from the training set, it's a single pass over all the data<div>\item after which you repeat from the beginning</div>
What's a mini-batch in ML?	\item When working with online algorithms, it can be advantageous to process new data in chunks. Each chunk of $B$ samples is a mini-batch.
What's a typical mini-batch size in ML?	\item $B \approx 100$
What're the two advantages of SGD over standard gradient descent?	\item Evaluating the precise gradient on a large dataset is often a waste of time, as the gradient will have to be recomputed at the next step anyway. It's usually better to have a noisy estimate and move through the space quickly, which is what SGD does.<div>\item SGD's less likely to get stuck in shallow local minima because of the `noise' implicit in making decisions on only a subset of the data</div>
What's the LMS algorithm?	\item The least mean squares algorithm, a SGD algorithm for computing the MLE for linear regresson
What's the update rule in the LMS algorithm?	<div>\item $\mb{\theta}_{k+1} = \mb{\theta}_k - \eta_k(\mb{\theta}^T_k \mb{x}_k - y_k)\mb{x}_k$</div><div>\item ie the step is $\mb{x}_k$ weighted by the size of the error in the prediction</div>
What're two other names for the LMS algorithm?	\item The delta rule<div>\item The Widrow-Hoff rule</div>
What're the steps in the perceptron algorithm?	\item Let $y_i \in \{-1, +1\}$. The perceptron algorithm is descent algorithm with the update rule<div>\item $\mb{\theta}_k =&nbsp;\mb{\theta}_{k-1} + \eta_k(\text{sign}(\mb{\theta}_k^T \mb{x}_i) - y_i)\mb{x}_i$</div>
What's the intuitive explanation of the perceptron algorithm?	<div>\item It's a descent algorithm for solving binary logistic regression problems</div>\item At each step, if the prediction based on the current parameters is correct, nothing is done.<div>\item If the prediction is wrong and $\mb{x}_i$ is misclassified, a step is taken in the direction of $\mb{x}_i$.</div>
When will the perceptron algorithm work?	\item It'll converge exactly when the data is linearly separable&nbsp;
What's the Bayesian approach to online learning?	\item $p(\theta| \mc{D}_{1:k}) \propto p(\mc{D}_{k}| \theta, \mc{D}_{1:k-1})p(\theta|\mc{D}_{1:k-1})$
Why can the Bayesian approach to online learning end up faster than SGD?	\item By modeling the posterior variance of each parameter, a different learning rate is effectively associated with each parameter<div>\item which is a simple way to model the curvature of the space</div>
Which of generative and discriminative classifiers are generally easier to fit?	\item Generative;<div>\item generative classifiers like GDA just need counting and algebra,</div><div>\item while discriminitive classifiers like logistic regression require solving optimization problems</div>
Which of generative and discriminative classifiers can easily add a new class?	\item Generative;<div>\item in discriminative models, all the parameters interact, so the model must be retrained if a new class is added</div>
Which of generative and discriminative classifiers generally handle missing features better?	\item Generative&nbsp;<div>\item since discriminative models assume that $\mb{x}_k$ is always available to be conditioned upon</div>
Which of generative and discriminative classifiers are generally better for dealing with unlabeled data?	\item Generative
Which of generative and discriminative classifiers can generally be inverted to compute $p(\mb{x}|y)$?	\item Generative, because it deals with $p(y, \mb{x})$ and so treats each parameter symmetrically
Which of generative and discriminative classifiers can generally handle input preprocessing?	\item Discriminative&nbsp;<div>\item where things like basis function expansion are acceptable</div><div>\item while in generative models, transformations of the inputs tends to lead to features correlated in complex ways&nbsp;</div>
Which of generative and discriminative classifiers generally make stronger assumptions?	\item Generative<div>\item because generative classifiers tend to make strong independence assumptions that are rarely valid</div>
What're three of the most useful properties of the exponential family of distributions?	<div><div>\item They're the only family with conjugate priors</div></div>\item&nbsp;Subject to certain constraints, they're the only distributions with finite-sized sufficient statistics<div>\item Subject to certain constraints, they're the family with the least number of assumptions</div>
When is a distribution a member of the exponential family?	\item When it can be written as<div>\item $p(\mb{x}|\mb{\theta}) = h(\mb{x}) \exp[\eta(\mb{\theta})^T \phi(\mb{x}) - A(\eta(\mb{\theta}))]$</div>
What's $\phi(\theta)$ in the definition of a member of the exponential family?	\item A vector of sufficient statistics
What's $A(\mb{\theta})$ in the definition of a member of the exponential family?	\item The cumulant function, defined as&nbsp;<div>\item $A(\mb{\theta}) = \ln Z(\mb{\theta})$</div><div>\item where $Z$ is the partition function</div>
What's $h(\mb{x})$ in the definition of a member of the exponential family?	\item The scaling constant
What's a natural exponential family?	\item One where $\phi(\mb{x}) = \mb{x}$
What's another name for the cumulant function?	\item The log partition function
How is the partition function defined for a member of the exponential family?	\item $Z(\mb{\theta}) = \int_{\mc{X}} h(\mb{x})\exp[\mb{\theta}^T\phi(\mb{x})] d\mb{x}$
When's a distribution a member of a curved exponential family?	<div>\item When it can be written in the form of an exponential-family distribution and</div><div>\item $\dim(\mb{\theta}) &lt; \dim(\mb{\eta(\theta)})$</div>
What's $\eta$ in the definition of a member of an exponential family?	\item The mapping from the parameters $\mb{\theta}$ to the canonical parameters $\mb{\eta}$&nbsp;
When's a distribution in the exponential family in canonical form?	\item When $\eta(\mb{\theta}) = \mb{\theta}$&nbsp;
What does it mean for a representation of a family of distributions to be minimal?	\item Each distribution in the family is uniquely identified by a setting of the family parameters
What does it mean for a representation of a family of distributions to be overcomplete?	\item Some distribution in the family is encoded by more than one setting of the family parameters
What's the canonical form of the Bernouilli distribution as a member of the exponential family?	\item $\text{Ber}(x|\mu) = (1-\mu)\exp\left[x \ln \left(\frac{\mu}{1-\mu}\right)\right]$
What're the canonical parameters of a family of exponential distributions?	\item They're the $\mb{\theta}$ when $\eta = \text{id}$&nbsp;
What're the canonical parameters of the Bernouilli distribution?	\item $\theta = \ln \left(\frac{\mu}{1-\mu}\right)$
What're the canonical parameters of the multinouilli distribution?	\item $\left[\ln \frac{\mu_k}{\mu_K}\right]_k$ for $1 \leq k \leq K-1$<div>\item (the $K$th term is excluded because the $\mu_k$ must sum to 1)</div>
What's the cumulant function for the Multinouilli distribution?	\item $A(\theta) = -\ln \mu_K$
What're the simplest sufficient statistics for the univariate Gaussian distribution?	\item $\phi(x) = (x, x^2)$
What're the canonical parameters for the univariate Gaussian?	\item $\mb{\theta} = \left(\frac{\mu}{\sigma^2}, -\frac{1}{2\sigma^2}\right) = \left(\lambda \mu, -\frac{1}{2}\lambda \right)$<div>\item (the $-\frac{1}{2}$ can be embedded in the sufficient statistics mind you)</div>
What're the first and second cumulants of a distribution?	\item $\mbb{E}[X]$<div>\item $\text{var}[X]$</div>
What are the first and second moments of a distribution?	\item $\mbb{E}[X]$<div>\item $\mbb{E}[X^2]$</div>
What's the relationship between cumulants and moments?	\item Two distributions with the same cumulants will have the same moments, and vice versa<div>\item Cumulants are just easier to work with in some problems, and moments are easier to work with in others</div>
How're the cumulants of a distribution defined?	\item The $n$th cumulant $\kappa_n$ is the $n$th coefficient in the Maclaurin expansion of the cumulant generating function:<div>\item $g(t) = \sum_{1}^\infty \kappa_n \frac{t^n}{n!}$</div>
How's the cumulant generating function defined?	\item $g(t) = \ln \mbb{E}[e^{tX}]$
How's the moment generating function defined?	\item $M(t) = \mbb{E}[e^{tX}]$
How are cumulants calculated from the cumulant generating function?	\item To get the $n$th cumulant<div>\item differentiate $g(t)$ $n$ times and evaluate it at zero</div>
What's the main advantage of cumulants over moments?	\item $g_{X+Y}(t) = g_X(t) + g_Y(t)$
Intuitively, what's the Pitman-Koopman-Darmois theorem?	\item It says that under certain regularity conditions, distributions in the exponential family are the only distributions with finite sufficient statistics
What's the main restriction of the Pitman-Koopman-Darmois theorem?	\item It only applies to distributions with support that's independent of the parameters
What's the idea in the method of moments?	\item Draw a sample<br /><div>\item Estimate the population moments from the sample</div><div>\item Use the population moments to deduce the population parameters</div>
How's the likelihood of a distribution in the exponential family written?	\item $p(\mc{D}|\theta) \propto \exp(N\eta^T \bar s - NA(\eta))$<div>\item where $\eta$ are the canonical parameters and $\bar s$ is the sample mean of the sufficient statistics</div>
How's the prior of a distribution&nbsp;in the exponential family written?	\item $p(\theta|\nu_0, \tau_0) \propto \exp(\nu_0 \eta^T \bar \tau_0 - \nu_0 A(\eta))$<div>\item where $\nu_0$ is the size of the pseudo-data</div><div>\item and $\bar \tau_0$ is the mean of the sufficient statistics on the pseudo-data</div>
Given a conjugate prior, how's the posterior of a distribution in the exponential family usually written?	\item Using the same distribution with<div>\item size $\nu_0 + N$</div><div>\item sufficient statistics $\frac{\nu_0 \bar \tau_0 + N \bar s}{\nu_0 + N}$</div><div>\item where $\nu_0$ is the size pseudo-data of the prior,&nbsp;</div><div>\item $\bar \tau_0$ is the mean of the sufficient statistics of the pseudo-data</div><div>\item $\bar s$ is the mean of the sufficient statistics of the data</div>
What's the definition of the maxent distribution?	\item Given $k$ constraints $\mbb{E}_p[f_k(x)] = F_k$<div>\item then the maximum entropy distribution of all those satisfying the constraints is</div><div>\item $p(x| \lambda) \propto \exp\left(-\sum \lambda_k f_k(x)\right)$</div><div>\item where $\lambda_k$ is the inverse temperature wrt the $k$th constraint, chosen to satisfy the constraints and unitarity</div>
What's a generalized linear model?	\item A generalization of linear regression whose output distribution is in the exponential family (rather than just being normal)
What's $\Psi$ usually denote in generalized linear models?	\item The invertible function that takes the mean parameter $\mu$ to the canonical parameter $\theta$<div>\item $\Psi(\mu) = \theta$</div>
In generalized linear models, how's $\Psi$ related to the cumulant function?	\item $\Psi^{-1}(\theta) = A(\theta)$
What's $\eta_i$ represent&nbsp;in generalized linear models?	\item $\eta_i = w^Tx_i$, some linear function of the inputs
What's the mean function&nbsp;in generalized linear models?	\item The $g^{-1}$ that relates the linear function of the inputs $\eta$ to the mean parameter $\mu$<div>\item $g^{-1}(\eta) = \mu$</div>
What's the link function&nbsp;in generalized linear models?	\item The inverse of the mean function<div>\item $g(\mu) = \eta$</div>
What're the usual restrictions on the link function&nbsp;in generalized linear models?	\item $g$ must be invertible<div>\item $g^{-1}$ must range over all possible $\mu$</div>
What's the canonical link function?	\item $g(\mu) = \Psi(\mu)$<div>\item so $\theta = \eta = w^T x$</div>
What's $\sigma^2$ usually represent&nbsp;in generalized linear models?	\item The dispersion parameter, which is proportional to the variance in the response<div>\item Usually 1</div>
What's the form of a generalized linear model with a scalar response variable?	\item $p(y_i | \theta, \sigma^2) = \exp\left[\frac{1}{\sigma^2}(y_i \theta - A(\theta)) + c(y_i, \sigma^2)\right]$<div>\item where $c$ is the normalization constant</div>
How do you fit a generalized linear model?	\item Same way as a logistic model: gradient descent \&amp; co
What's the Fisher scoring method?	\item Using the expected Hessian (ie the Fisher information matrix) instead of the actual Hessian<div>\item usually in gradient descent methods</div>
How is Bayesian inference usually carried out using&nbsp;generalized linear models?	\item Via Monte Carlo Markov Chain methods<div>\item Sometimes Gaussian approximation or variational inference</div>
What's probit regression?	\item A binary-response generalized linear model where the mean function is the probit function<div>\item $g^{-1}(\eta) = \Phi(\eta)$</div><div>\item Very similar to logistic regression</div>
What's a random utility model?	\item Set the utility for response $y_i = c$ on input $x_i$ to $u_{c,i} = w^Tx_i + \delta_{c,i}$<div>\item where $\delta_{c,i}$ is a normal random variable.</div><div>\item Then predict the response to be the choice with the greatest utility: $y_i = \arg \max_c u_{c, i}$</div>
What's the latent variable interpretation of probit regression?	\item It's a binary-response random utility model with normal random utility errors
What's modeled by the random parts of a random utility model?	\item Factors that might be relevant to decision making that we havent (or can't) explicitly include in the model
What's ordinal probit regression?	\item Binary probit regression generalized from the latent variable perspective:<div>\item rather than the normally-distributed difference-of-utilities $z_i$ simply being judged against a single decision boundary $z_i = 0$</div><div>\item instead the real line is partitioned, with partition $j$ corresponding to the response $y = j$</div>
What's a multivariate probit model?	\item It's a generalization of the latent variable perspective on binary probit regression:<div>\item instead of picking the class with the greatest randomized utility</div><div>\item the response vector has one binary variable $y_{ic}$ for each class $c$,&nbsp;</div><div>\item and $y_{ic} = 1$ if the randomized utility $u_{ic} &gt; 0$&nbsp;</div>
What're two other names for multi-task learning?	\item Transfer learning<div>\item Learning to learn</div>
How's hierarchical Bayes usually used for multi-task learning?	\item Suppose we have $J$ models $p(x|\beta_j)$<div>\item Then draw the $\beta_j$ from some prior $p(\beta_j|\beta_*)$</div><div>\item and train the model by optimizing over both the $\beta_j$ and $\beta_*$</div><div>\item Once it's done, $\beta_*$ can be discarded</div>
What's a simple trick used to apply hierarchical Bayes to spam filtering?	\item Create copies of each feature $x_i$:&nbsp;<div>\item $x_i$, representing the feature</div><div>\item $(x_i, j)$ for users 1 through $J$, representing the feature occuring for user $j$</div><div>\item Training this model is equivalent to training a hierarchical Bayes model</div>
What's domain adaptation in ML?	\item A kind of multi-task learning where the tasks are all the same<div>\item ex: training a classifier on both email and news stories</div>
What's conjoint analysis in ML?	\item Figuring out which features of a product consumers like best<div>\item Reduces to multi-task feature selection</div>
What's negative transfer in ML?	\item When a multi-task approach does worse than solving each task separately<div>\item due to correlations in the model that don't actually exist in the data</div>
What's a GLMM?	\item Generalized linear mixed-effects model
What're `fixed effects' in ML?	\item A frequentist term that refers to unknown parameters $\alpha$ that're shared between groups
What's `random effects' in ML?	\item A frequentist term referring to unknown parameters $\beta_j$ that vary randomly between groups
What's the form of a GLMM?	\item For groups $j$ and items $i,j$<div>\item $\mbb{E}[y_{ij}|x_{ij}, x_j] = g(\phi_1(x_{ij})^T\beta_j + \phi_2(x_j)^T\beta^\prime_j + \phi_3(x_{ij})^T\alpha + \phi_4(x_j)^T\alpha^\prime)$</div><div>\item where $x_{ij}$ are the item features</div><div>\item and $x_j$ are group features</div>
What's a mixed model in ML?	\item A model with both fixed and random effects
What's GEE in ML?	\item Generalized estimating equations, a frequentist approach to deducing the population&nbsp;parameters of a GLMM<div>\item Statistically inefficient though and not recommended&nbsp;</div>
How do you usually fit a GLMM model?	\item Fully Bayes methods: variational Bayes,&nbsp;Monte Carlo Markov chains<div>\item Empirical Bayes: expectation maximization, variational expectation maximization</div>
What're LETOR problems in ML?	\item Learning to rank problems
What's the pointwise approach to LETOR?	\item Calculating the `relevency' of each item to a query<div>\item then sorting by relevency</div>
What's the problem with the pointwise approach to LETOR?	\item It penalizes errors low down in the list as much as it does errors at the top<div>\item It makes relevancy decisions without knowing anything about other possibly relevant documents</div>
What's the pairwise approach to LETOR?	\item For each pair of items $j, k$<div>\item let $y_{jk}$ be the indicator that $j$ has a greater relevancy than $k$</div><div>\item Then learn a model for the $y_{jk}$</div>
What's RankNet in ML?	\item A neural network for pairwise LETOR that uses the model<div>\item $p(y_{jk} = 1 | x_j, x_k) = \text{sigm}(w^T(x_j-x_k))$</div>
What's the Plackett-Luce distribution?	\item For a permutation $\pi$,<div>\item $p(\pi|s) = \prod_i \frac{s_i}{\sum_{i\leq j} s_j}$</div><div>\item where $s_j$ is the score of the item in the $j$th position in the output under some scoring function $s$</div>
How is the Plackett-Luce distribution derived?	\item By starting at the top of the list and conditioning on items which have already been ranked:<div>\item so if $\pi = (A, B)$</div><div>\item then $p(\pi) = p(\text{$A$ ranked first})p(\text{$B$ ranked second} | \text{$A$ ranked first})$</div><div>\item where the probability of an option being ranked is proportional to its score compared to the scores of all the items which have yet to be ranked</div>
What's the ListNet model in ML?	\item An approach to pairwise LETOR using the Plackett-Luce model with a linear score function
What's the equivalent of maximizing the likelihood in terms of cross-entropy?	\item Minimizing the cross-entropy loss between the posterior \&amp; empirical distributions
What's mean reciprocal rank in ML?	\item A loss function for ranking systems<div>\item defined as the mean of $1/r(q)$ over all queries $q$, where $r(q)$ is the rank of the first relevent document in response to $q$</div>
What's the precision at $k$ in ML ranking problems?	<div>\item For a permutation $\pi$,</div><div>\item $\text{P@k}(\pi) = \frac{1}{k}\text{(number of relevant documents in the first $k$ positions)}$</div>
What's the average precision in ML ranking problems?	<div>\item Given a permutation $\pi$,</div>\item $\text{AP}(\pi)&nbsp;= \left( \sum_\text{k is relevant} \text{P@k}(\pi) \right) / \text{number of relevant documents}$
What's the mean average precision in ML ranking problems?	\item It's a loss function, defined as the mean $\text{AP}$ over all queries
What's the discounted cumulative gain in ML ranking problems?	\item A loss function. Given the relevencies $r$ in ranked order,<div>\item&nbsp;$\text{DCG@k(r)} = \sum_{i \leq k} d(i)r_i$</div><div>\item where $d$ is the discounting function</div>
What's the problem with discounted cumulative gain, and how is it usually solved?	\item It's dependent on the length of the list returned&nbsp;<div>\item and it's solved by using the ideal DCG, which is the maximum DCG taken over all possible permutations&nbsp;</div>
What're Kendall's $\tau$ statistics?	\item A way of measuring the correlation between two rankings:<div>\item $\tau(\pi, \pi^*) = \frac{1}{2\sum_{u &lt; v} w_{uv}} \cdot \sum_{u &lt; v} w_{uv}[\text{2 if $u, v$ are in the same order in both rankings, 0 otherwise}]$</div><div>\item aka the weighted pairwise inconsistency</div>
How are loss functions used in Bayesian approaches?	\item The model is fit using solely the likelihood and the prior<div>\item and then actions (such as setting the threshold) can be chosen at test time to minimize future expected loss</div>
How are loss functions used in frequentist approaches?&nbsp;	\item Try and minimize empirical loss on the training set&nbsp;
What's the use of a surrogate loss function in ML?	\item Frequentists try and minimize the expected loss on the training set, but loss functions typically aren't diff'able wrt the model parameters<div>\item so often a surrogate loss function - like the negative log likelihood - is used instead.</div>
What's the weighted approximate-rank pairwise loss?	\item A surrogate ranking&nbsp;loss function that approximates the precision@k loss:<div>\item To calculate the $\text{WARP}$ on scoring function $f$, query $x$ and label $y = c$&nbsp;</div><div>\item calculate the score $f(x,c^\prime)$ for each $c^\prime$ and find the rank $k$ of label $c$</div><div>\item then the $\text{WARP}$ is the sum of the first $k$ weights in the nonincreasing sequence $\alpha_i$</div>
What's the most common example of a GLM?	\item Logistic regression
What's a right stochastic matrix?	\item A nonnegative matrix whose&nbsp;rows all sum to 1
What's a conditional probability table?	\item A table of the values of $p(y|\mb{x})$ for all the values the discrete $\mb{x}$ can take on
What's the first order Markov assumption?	\item $x_{t+1} \perp x_{1:t-1} | x_t$
What's the intuitive interpretation of the first order Markov assumption?	\item Given the present, the future is independent of the past
What's a graphical model in ML?	\item A way to represent independence assumptions as a lack of edges between the nodes that represent different variables
What's an alternative name for graphical models in ML?	\item Independence diagrams
What's a directed graphical model in ML?	\item a graphical model whose graph is a DAG&nbsp;
What're some alternative names for DGMs?	\item Bayesian network<div>\item Belief network</div><div>\item Causal network</div>
What's the ordered Markov property?	\item Given a directed graphical model and a topological ordering, it's the assumption that a node is independent of all its predecessors except its parents, given its parents
What's a TAN model in ML?	\item Tree-augmented naive Bayes;&nbsp;<div>\item naive Bayes weakened to the assumption that the correlations in its independent variables can be represented by a tree DGM&nbsp;</div>
What's a hidden Markov model?	\item A model which has two kinds of variables:<div>\item the hidden variables $z_t$ which form a Markov chain</div><div>\item the observed variables $x_t$, each of which depend only on the corresponding $z_t$</div>
What's state estimation in ML?	\item Inferring the states of some hidden variables given the values of the observed variables \&amp; the model parameters
What're the two parts of the model of a hidden Markov model?	\item The transition model, described by $p(z_t|z_{t-1})$<div>\item The observation model, described by $p(x_t|z_t)$</div>
What's a probabilistic expert system?	\item A probabilistic model - usually a graphical model - created by hand
What's knowledge engineering in ML?	\item The process of converting some domain expertise to a model
What's a leak node in ML?	\item A variable in a graphical model which in some way represents things that the model doesn't explicitly embed<div>\item (like an unknown disease in a medical diagnosis model)&nbsp;</div>
What's a BN2O model in ML?	\item A bipartite graphical model with noisy observation variables which are an OR of the hidden variables
What's a directed GGM?	\item A directed Gaussian graphical model, a DGM where the CPDs all have the form<div>\item $p(x_t|x_{\text{pa}(t)}) = \mc{N}(x_t|\mu_t + w_t^Tx_{\text{pa}(t)}, \sigma_t^2)$</div>
What's the joint distribution on a GGM?	\item If the CPD for variable $t$ has mean $\mu_t$, variance $\sigma^2_t$ and weights $w_{ts}$, then the joint is a normal distribution with<div><div>\item $\mu = [\mu_i]$</div><div>\item $\Sigma = (I - W)^{-1}\text{diag}(\sigma^2_i)(I - W)^{-T}$</div></div>
What's a CPD in ML?	\item Conditional probability distribution
What's another name for directed GGMs?	\item Gaussian Bayes nets
What's the probability of the evidence in ML?	\item Given a set of visible variables, it's $p(x_v|\theta)$<div>\item aka the likelihood of the data</div>
What's a common partition of the hidden variables in ML?	\item Query variables $x_q$, which we're interested in knowing the state of<div>\item Nuisance variables $x_n$, which we're not</div>
How are nuisance variables dealt with in probabilistic inference?	\item They're marginalized out
What's the difference between inference and learning to a Bayesian?	\item Ideologically there isn't one.<div>\item but there are usually a lot more hidden variables than there are parameters, so generally hidden variables should be integrated out since point methods would overfit&nbsp;</div>
What's it mean for a set of variables to be exchangable in ML?	\item Exchanging their indices doesn't change the sufficient statistics
What's plate notation in ML?	\item If some part of a graphical model is in a box with a number $N$ in the bottom-right<div>\item then that represents the same part repeated $N$ times&nbsp;</div>
What's complete data in ML?	<div>\item A model in which all the variables are fully observed</div>\item so no hidden variables or missing data
What's the main advantage of having complete data in a DGM?	\item The likelihood decomposes according to graph structure<br />
What's it mean for the likelihood of a DGM to decompose according to the graph structure?	\item The likelihood can be written as<div>\item $p(\mc{D}|\theta) = \prod p(\mc{D}_t|\theta_t)$</div><div>\item where $\mc{D}_t$ is the data for variable $t$ and its parents</div>
What's the advantage of having a DGM's likelihood decompose according to the graph's structure?	\item If the prior factorizes over the variables too&nbsp;<div>\item ie $p(\theta) = \prod p(\theta_t)$</div><div>\item then the posterior factorizes over the graph's structure too, so the posterior for each variable can be calculated independently</div>
What's an I-map in ML?	\item A graph $G$ is an I-map for a distribution $p$<div>\item if $I(G) \subseteq I(p)$</div>
What's $I(G)$ for a graph $G$ denote in ML?	\item The set of all conditional independence assumptions encoded in the graph
What's $I(p)$ for a distribution $p$ denote in ML?	\item The set of all conditional independence assumptions that hold for $p$
What's the use of I-maps in ML?	\item If $G$ is an I-map for $p$<div>\item then it's `safe' to use $G$ to reason about the conditional independence properties of $p$</div>
What's a minimal I-map for a distribution $p$?	\item the graph $G$ which is an I-map for $p$ such that no $G^\prime \subset G$ is also an I-map for $p$
What's d-separation in ML?	\item An undirected path $P$ in a graphical model is d-separated by a set $E$ iff<div>\item $P$ contains $s \rightarrow m \rightarrow t$ such that $m \in E$</div><div>\item or $P$ contains $s \leftarrow m \rightarrow t$ such that $m \in E$</div><div>\item or $P$ contains $s \rightarrow m \leftarrow t$ such that $m \not \in E$ and no descendent of $m$ is in $E$ either</div>
What's it mean for a set $A$ to be d-separated from $B$ by $E$ in ML?	\item Over the graphical model $G$, every path from $A$ to $B$ is d-seperated by $E$
What's the directed global Markov property on graphical models?	\item $x_A \perp_G x_B | x_E$ if and only if $A$ is d-separated from $B$ by $E$
What's the use of the Bayes ball algorithm?	\item An algorithm for deciding whether sets of variables $A, B$ are d-separated by $E$
Intuitively, how does the Bayes ball algorithm work?	\item Shade all the variables in the evidence set $E$<div>\item Place `balls' at each node in $A$</div><div>\item Let the balls move around, ignoring directionality in general but obeying certain rules.</div><div>\item See if any of the balls end up in $B$</div>
What're the rules on the balls' movement in the Bayes ball algorithm?	\item A ball can't pass through a chain $x \rightarrow y \rightarrow z$ if $y$ is shaded<div>\item A ball can't pass through a fork $x \leftarrow y \rightarrow z$ if $y$ is shaded</div><div>&nbsp;\item A ball can \emph{only} pass through a collider $x \rightarrow y \leftarrow z$ if $y$ is shaded</div>
What's Berkson's `paradox'?	<div>\item Suppose you have two independent coins.&nbsp;</div><div>\item Conditioning on their sum couples them. &nbsp;&nbsp;</div>
What're two other names for Berkson's paradox?	\item Explaining away<div>\item Intercausal reasoning</div>
What's the directed local Markov property?	\item $t \perp (\text{nd}(t) \backslash \text{pa}(t)) | \text{pa}(t)$<div>\item where $\text{nd}(t)$ are the non-descendents of $t$</div>
How are the directed local,&nbsp;directed&nbsp;global and ordered Markov properties related?	\item They're equivalent
What's the Markov factorization property?	\item Any distribution $p$ which is Markov wrt a graph $G$ can be factored over the graph's structure
What's $\text{mb}(t)$ denote in ML graphical models?	\item The Markov blanket of $t$, the set of nodes that renders $t$ conditionally independent of every other node in the graph
What're the coparents of a node in a graph?	\item The parents of the node's children
What's the Markov blanket of a node in a DGM comprised of?	\item The parents of the node<div>\item The children of the node</div><div>\item The coparents of the node</div>
What's the full conditional of a node in a DGM?	\item The conditional distribution of a node wrt its Markov blanket
What're influence diagrams in ML?	\item DGMs augmented with&nbsp;<div>\item decision nodes (rectangles)</div><div>\item utility nodes (diamonds)</div>
What's another name for influence diagrams in ML?	\item Decision diagrams
What's an information arc in an influence diagram?	\item An edge in the graph from a chance to node to a decision node<div>\item representing that the outcome of the rv contributes to the decision&nbsp;</div>
What's the value of perfect information of a variable in ML?	\item The difference in utility between the expected payoff<div>\item and the expected payoff if the state of the variable is available to contribute to your decision</div>
What's a POMDP in ML?	\item A partially observed Markov decision process<div>\item ie a hidden Markov model augmented with decision \&amp; payoff components&nbsp;</div>
What's a MDP in ML?	\item A Markov decision process<div>\item ie a fully-observed Markov model augmented with decision \&amp; payoff components&nbsp;</div>
What're LVMs in ML?	\item Latent Variable Models where the observed variables are correlated because they arise from some set of hidden variables
What does $p_k(x)$ denote when dealing with LVMs in ML?	\item The $k$th base distribution<div>\item $p(x|z = k) = p_k(x)$</div><div>\item where $z$ is a discrete latent variable&nbsp;</div>
What's a mixture model in ML?	\item A latent variable model with a single discrete scalar latent variable<div>\item so called because the distribution over the observed variables is a mixture of the base distributions</div>
What form of LVMs are we usually concerned with?	\item LVMs with a one-to-one mapping between latent and observed variables<div>\item since if they're vector-valued variables, this can represent any of the other kinds of LVM</div>
What's a MOG model in ML?	\item Mixture of Gaussians, a mixture model where each base distribution is a Gaussian
What's a useful property of MOG models?	\item They can approximate any distribution on $\mbb{R}^D$
What're the two main applications of mixture models?	\item Black-box density models<div>\item Clustering</div>
What's a mixture of multinouillis model?	\item A mixture model where the conditional density is a product of multinouilli distributions, one for each output scalar
What's the responsibility in ML clustering?	\item The responsibility of cluster $k$ for point $i$ is the posterior probability that $i$ belongs to cluster $k$<div>\item $r_{ik} = p(z_i = k| x_i)$</div>
What's soft and hard clustering in ML?	\item Soft clustering involves computing the posterior&nbsp;<div>\item Hard clustering just uses the MAP to assign a point to a cluster</div>
What's a mixture of experts model in ML?	\item A mixture model where the mixing weights and mixture densities can depend on the input<div>\item allowing different parts of the input space to be `judged' by different distributions</div>
What's a gating function in ML?	\item In a mixture of experts model, it's a function of the input which determines which components of the input space are judged by which `expert'
What's a mixture density network in ML?	\item A variant of a mixture of experts model where both the gating functions and the expert distributions are implemented by neural networks<div>\item These are more flexible than a MOE but slower to train</div>
What's a hierarchical mixture of experts model in ML?	\item An extension of the mixture of experts model where each expert is itself a mixture of experts
What's the unidentifiability problem in ML?	\item In a LVM with a $K$ latent variables<div>\item the posterior can be multi-modal, with each peak corresponding to a different labelling of the variables (up to $K!$ peaks in fact)</div>
How can unidentifiability cause a problem for Bayesian inference?	\item If you draw samples from a multi-modal distribution and try to average them to estimate the mean<div>\item you'll end up with a meaningless point somewhere between the modes</div>
If you draw a number of samples from a posterior distribution which has unidentifiable variables, why is it okay to average the predictive distributions that arise from using these samples as parameter estimates?	\item The likelihood's multimodal because it can't distinguish between labellings<div>\item and so it's also invariant as to which mode the parameter estimates came from</div>
What's the intuitive interpretation of the EM algorithm?	\item `E' step: infer the values of the latent variables<div>\item `M' step: optimize the parameters given the inferred latent variables</div><div>\item Repeat</div>
What's the complete data log likelihood in ML?	\item $l_c(\theta) = \sum \ln p(x_i, z_i | \theta)$<div>\item Typically this isn't directly computable, as the $z_i$ are hidden</div>
What's the auxiliary function in the EM algorithm?	\item $Q(\theta, \theta^{t-1}) = \mbb{E}[l_c(\theta) | \mc{D}, \theta^{t-1}]$<div>\item where $t$ is the current iteration</div>
How's the EM algorithm defined in terms of the auxiliary function?	\item E step: construct the function $Q(\theta, \theta^{t-1})$<div>\item M step: compute $\theta^t = \arg \max_\theta Q(\theta, \theta^{t-1})$</div>
What's the usual use of the EM algorithm?	\item Estimating the MLE or MAP of a latent variable model&nbsp;
What's the E step in the EM algorithm for a Gaussian mixture model?	\item With $K$ base functions, compute the responsibilities<div>\item $r_{ik} = \frac{\pi_k p(x_i| \theta_k^{t-1})}{\sum \pi_{k^\prime} p(x_i| \theta_{k^\prime}^{t-1})}$</div>
What's the M step in the EM algorithm for Gaussian mixture models?	<div>\item With $K$ base functions,</div>\item $\pi_k = \frac{1}{N} r_k$<div>\item $\mu_k = \sum_i \frac{r_{ik}}{r_k} x_i$</div><div>\item $\Sigma_k = \sum_i \frac{r_{ik}}{r_k} (x_i - \mu_k) (x_i - \mu_k)^T$</div><div>\item $\theta^t = [(\pi_k, \mu_k, \Sigma_k)]_k$</div><div>\item where $r_k = \sum_i r_{ik}$</div>
What's a common preprocessing step to carry out on data before applying ML algorithms?	\item Subtract the mean<div>\item Divide by the standard deviation</div><div>\item This can speed convergence</div>
How does the K-means algorithm relate to EM?	\item It's EM for GMMs with&nbsp;<div>\item $\pi_k = \frac{1}{K}$ and $\Sigma_k = \sigma^2 I$ fixed, leaving only $\mu_k$ free</div><div>\item and the responsibilities estimated as $r_{ik} \approx \mbb{I}(k = z_i^*)$, where $z_i^* = \arg \max_k p(z_i = k | x_i, \theta)$</div>
What's the E step in the K-means algorithm?&nbsp;	\item Calculate $z^*_i = \arg \min_k \| x_i - \mu_k \|$<br /><div>\item and assign point $i$ to cluster $z^*_i$</div>
What's the M step in the K-means algorithm?	\item Calculate $\mu_k = \frac{1}{N_k} \sum_{i : z_i^* = k} x_i$<div>\item ie the mean of the points in cluster $k$</div>
How's the reconstruction error usually defined for compression algorithms?	<div>\item Given input data $[x_i]$,</div>\item $J = \frac{1}{N}\sum_i \|x_i - \text{decode}(\text{encode}(x_i))\|^2$<div>\item (or another loss function than the square distance)</div>
What's the compression interpretation of the K-means algorithm?	\item The K-means algorithm can be thought of as an iterative scheme for minimizing the error of a vector quantitization scheme with a $K$ vector codebook<div>\item where the prototype vectors are $\mu_k$</div>
What's a vector quantitization scheme?	\item A compression scheme for vector data<div>\item with a codebook consisting of $K$ `prototype' vectors</div><div>\item Datapoints are mapped to the nearest prototype</div>
What's the rate of a compression scheme?	\item The number of compressed bits needed per bit of input
What's farthest point clustering in ML?	\item A EM-for-clustering initialization scheme<div>\item where the first point is picked randomly from the dataset</div><div>\item and subsequent points are picked to be as far from those already selected as possible</div>
What's the `growth' approach to initializing EM for clustering?&nbsp;	\item Score each cluster based on the weight assigned to it<div>\item If some cluster scores sufficiently high, split it in two,&nbsp;</div><div>\item with the parameters of the two new clusters being random perturbations of the old one</div>
What's the collapsing variance problem in ML?	\item When fitting something like a GMM<div>\item setting the centre of one of the Gaussians to be equal to one of the datapoints,&nbsp;</div><div>\item then letting the variance go to zero</div><div>\item results in an infinite likelihood &nbsp;</div>
What's the solution to the collapsing variance problem?	\item Enforce a prior on the parameters and work with the posterior rather than the likelihood
When applying EM to calculate the MAP estimate of a GMM, what prior is usually used?	\item Dirichlet on the mixture weights<div>\item Normal inverse Wishart on the mean and variance</div>
How does EM usually fail?	\item Through numerical issues with close-to-singular matrices
What're common settings for the NIW hyperparameters when estimating the MAP of a GMM using EM?	\item $\kappa_0 = 0$, so the means are unregularized<div>\item $S_0 = \frac{1}{K^{1/D}}\text{diag}(s_1^2, \dotsc, s_D^2)$, where $s_j^2$ is the pooled variance for dimension $j$</div><div>\item $\nu_0 = D+2$, indicating the weakest possible proper prior</div>
What's the form of the usual gating function for mixture of experts models?	<div>\item $\pi_{ik} = \mc{S}(V^Tx_i)_k$</div><div>\item where $\pi_{ik}$ are the mixture weights and $V$ are the gating parameters</div>
What's a family marginal in ML?	\item For a graphical model, its<div>\item $p(x_{it}, x_{i,\text{pa}(t)}|\mc{D}_i, \theta)$</div><div>\item ie the joint posterior on a given node and its parents</div>
What're the ESS in the EM algorithm?	\item The expected sufficient statistics, the output of the E step
How do you calculate the MLE of a Student distribution?	<div>\item Use the scale mixture construction of the Student distribution</div>\item then apply iterative methods like EM
How can Student's distribution be written as a mixture of Gaussians?	<div>\item With a Gaussian scale mixture:</div>\item $$\mc{T}(x|\mu, \Sigma, \nu) = \int \mc{N}\left(x \middle| \mu, \frac{1}{z}\Sigma\right) \text{Ga}\left(z \middle| \frac{1}{2}\nu,&nbsp;\frac{1}{2}\nu\right) dz$$
How do you use the EM algorithm to find the MLE of a Student's distribution?	\item Approximate the distribution with a Gaussian scale mixture integral<div>\item Treat the scale parameter as the latent variable</div>
What's a generalized EM algorithm?	\item EM where the M step involves an iterative optimization algorithm rather than a closed-form update
What's the conjugate distribution to the categorical distribution?	\item The Dirichlet distribution
What's the digamma function?	\item $\psi(x) = \frac{d}{dx}\ln \Gamma(x)$
What prior do you use when applying EM to probit regression?	\item $\mc{N}(0, V_0)$
What's Jensen's inequality in probability theory?	\item For a convex $\varphi$,<div>\item $\varphi(\mbb{E}[X]) \leq \mbb{E}[\varphi(X)]$</div>
What're the main steps in the theoretic derivation of the EM algorithm?	\item Show that the expected complete data log likelihood (ie $Q$) is a lower bound on the observed data log likelihood (ie $l$)<div>\item Show that it's a tight lower bound<br /><div>\item The lower bound is monotonic increasing wrt the iteration count $t$<br /><div>\item So the observed data log likelihood is monotonically increasing too</div></div></div>
What's the general structure of the batch EM algorithm?	\item If $s_i(\theta)$ is the E step of calculating expected sufficient statistics for data case $i$ assuming parameters $\theta$<div>\item and $\theta(\mu)$ is the M step of calculating new parameters from the sum of the ESS<br /><div>\item then batch EM involves computing $\mu^\text{new} = \sum s_i(\theta(\mu))$,&nbsp;</div><div>\item then updating $\mu = \mu^\text{new}$ until converged</div></div>
What's the general structure of the incremental EM algorithm?	\item If $s_i(\theta)$ is the E step of calculating expected sufficient statistics for data case $i$ assuming parameters $\theta$<div>\item and $\theta(\mu)$ is the M step of calculating new parameters from the sum of the ESS<br /><div>\item then incremental EM involves&nbsp;running through $i$ in a random order, calculating&nbsp;</div><div>\item $s^\text{new}_i = s_i(\theta(\mu))$,&nbsp;</div><div>\item then $\mu = \mu + s_i^\text{new} - s_i$,&nbsp;</div><div>\item then updating $s_i = s_i^\text{new}$&nbsp;</div></div><div>\item until converged</div>
What's the general structure of the stepwise EM algorithm?	\item If $s_i(\theta)$ is the E step of calculating expected sufficient statistics for data case $i$ assuming parameters $\theta$<div>\item and $\theta(\mu)$ is the M step of calculating new parameters from the sum of the ESS<br /><div>\item then stepwise EM involves running through $i$ in a random order, and in step $k$ computing</div></div><div>\item $\mu = (1-\eta_k)\mu + \eta_k s_{i}(\theta(\mu))$</div><div>\item until converged</div><div>\item where $\eta_k$ is the step size, which must satisfy the Robbins-Monro conditions&nbsp;</div>
When implementing an update scheme $\mu = (1-\eta_k)\mu + \eta_k s$ in incremental EM, how can you modify it to make it a sparse update?	\item Define $m = \frac{1}{\prod_{j \leq k-1} (1 - \eta_j)}\mu$<div>\item Then use updates $m = m + \frac{\eta_k}{\prod_{j \leq k} (1 - \eta_j)}s$</div><div>\item In the context of EM, scaling the result by a global constant has no effect</div>
How do batch, incremental and stepwise EM compare?	<div>\item Stepwise only needs constant memory</div>\item Stepwise \&amp; incremental are much faster than batch<div>\item Accuracy of stepwise is as good as batch</div><div>\item Accuracy of incremental is worse than both</div>
What's annealed EM?	\item An EM variant in which the `temperature' of the posterior is raised, smoothing it<div>\item the global maximum is then found<br /><div>\item and tracked while the temperature falls</div></div>
What's Monte Carlo EM?	\item EM where in the E step, the expected sufficient statistics are approximated by averaging samples $z_i^s \sim p(z_i|x_i, \theta^t)$
What's stochastic EM?	\item Similar to Monte Carlo EM, but only one sample is drawn
What's variational EM?	\item A variant of EM for when it's difficult to infer the log likelihood in the E step<div>\item Instead, a variational lower bound on the likelihood is used</div>
What're two names for the general class of algorithms that includes EM?	\item Bound optimization algorithms<div>\item Minorize-maximize algorithms</div>
What's over-relaxed EM?	\item EM where the parameters are updated as a linear interpolation of their old value and their traditional-EM-calculated values
In unsupervised frequentist learning, what's the usual way to select how many parameters your model should use? Ex: number of base distributions in a mixture model	\item Look for the `knee' or `kink' in the test set MSE curve wrt increasing parameter count&nbsp;<div>\item Should go from a steep drop (indicating the extra parameters are useful) to a shallow drop (indicating the extra parameters might be `unnatural')</div>
What's the usual tool for automating `kink finding' in model selection?	\item Gap statistics
What's the model used in factor analysis?	\item It's a LVM with $D$ observed variables and $L$ latent variables, and<div>\item $p(x|z, \theta) = \mc{N}(Wz+\mu, \Psi)$</div><div>\item $z \sim \mc{N}(0, I)$</div><div>\item where $\Psi$ is a diagonal $D \times D$ matrix</div>
What's the factor loading matrix in factor analysis?	\item The matrix $W$ which relates the latent variables to the mean of the distribution
How's probabilistic principle components analysis relate to FA?	\item It's factor analysis with an orthonormal $W$ and $\Psi = \sigma^2 I$
Why's the variance matrix diagonal in factor analysis?	\item Because it forces correlations to be explained by the latent variables rather than being `baked in' to the variance matrix
How can factor analysis be thought of in terms of MVNs?	\item FA is a low rank parameterization of an MVN;<div>\item if you marginalize out the latent variables, the visible variables are distributed as a MVN with covariance $WW^T + \Psi$</div><div>\item ie a MVN with $O(LD)$ parameters, as opposed to the $O(D^2)$ parameters of a full MVN</div>
What's a one-hot encoding?	\item An encoding scheme where the codewords are binary numbers with one set bit and the others cleared
What're the latent factors in FA?	<div>\item If $p(z_i|x_i, \theta) \sim \mc{N}(m_i, \Sigma_i)$&nbsp;</div><div>\item then $m_i$ are the latent factors</div>
What's another name for the latent factors in FA?	\item Latent scores
What's a biplot?	\item A projection of high-dimensional data onto 2D where&nbsp;<div>\item data are displayed as points</div><div>\item the unit vectors along each dimension are displayed as vectors</div>
What's the cause of the unidentifiability problem in FA?	\item The likelihood is invariant under any rotation of the factor loading matrix $\hat W = RW$ where $RR^T = I$
How many orthonormal matricies of size $L \times L$ are there?	\item $\frac{1}{2}L(L-1)$
What're founder variables in FA?	\item If you solve the unidentifiability problem by making the weights matrix lower triangular<div>\item then the first $L$ of $D$ visible variables affect the interpretation of the latent factors, so must be chosen carefully</div>
What's sparse factor analysis?	\item FA, with the unidentifiability problem solved by enforcing a sparse prior on the weights
What's varimax in FA?	\item A solution to the unidentifiability problem which tries to find a rotation matrix $R$ such that $RW$ is sparse and hence more easily interpretable<br />
What's the mixture of factor analyzers model?	\item Take $K$ FA models $W_k, \mu_k$&nbsp;<div>\item and have $x_i$ modelled by the one indicated by $q_i \in \{1, \dotsc, K\}$</div>
How does a mixture of factor analyzers compare to a mixture of Gaussians?	\item MFA is a low-rank approximation of a GMM, having $O(KLD)$ parameters compared to $O(KD^2)$
How's principle components analysis compare to FA?	\item It's FA with&nbsp;<div>\item an orthonormal $W$&nbsp;</div><div>\item and $\Psi = \sigma^2 I$ with $\sigma^2 \rightarrow 0$&nbsp;</div>
What's another name for probabilistic principle components analysis?	\item Sensible PCA
What's another name for PCA in ML?	\item The Karhunen Loeve transform
What's the synthesis view of classical PCA?	\item Given observations $X$, suppose we want to find an orthonormal basis $\{w_j\} \subset \mbb{R}^D$ and coefficients $\{z_i\} \subset \mbb{R}^L$ such that<div>\item&nbsp;&nbsp;$J(W, Z) = \|X - WZ^T\|^2_F$ is minimized</div><div>\item The solution is $\hat W$, composed from the eigenvectors of the $L$ largest eigenvalues from the empirical covariance matrix $\hat \Sigma$</div><div>\item and $\hat z_i = W^Tx_i$</div>
What's the Frobenius norm?	\item $\|A\|_F = \sqrt{\sum_{ij} a_{ij}^2} = \sqrt{\text{tr}(A^TA)}$
What's the first principle component in PCA?	\item Of the eigenvectors that are drawn from $\hat \Sigma$ and are used to build $\hat W$, its the one with the largest eigenvalue
Intuitively, what do the principle components in PCA correspond to?	\item The directions in which the data has maximal variance
What preprocessing needs to be done before PCA is carried out?	<div>\item The data needs to be centered</div>\item The variances in each direction need to be normalized
How's the correlation of two random variables defined?	\item $\text{corr}(X, Y) = \frac{\text{cov}(X, Y)}{\sigma_X \sigma_Y}$<div>\item ie the Pearson correlation coefficient</div>
What's the analysis view of PCA?	\item Minimizing the reconstruction error&nbsp;<div>\item $J(W, Z) = \|X- WZ^T\|^2$</div><div>\item is equivalent to finding the one-element basis $\{w_1\}$ which maximizes the variance of $\{z_{1j}\}$</div><div>\item then finding the basis vector $w_2$ which, when used to form the basis $\{w_1, w_2\}$ maximizes the variance of $\{z_{2j}\}$ given that the $\{z_{1j}\}$ are already fixed</div><div>\item etc</div>
How do the eigenvectors of $X^TX$ relate to the SVD of $X$?	\item If $X = USV^T$<div>\item then $X^TX$'s eigenvectors are the columns of $V$, with eigenvalues $S^2_{ii}$</div><div>\item aka $V = \text{evec}(X^TX)$, $S^2 = \text{eval}(X^TX)$</div>
How do the eigenvectors of $XX^T$ relate to the singular values of $X$?	\item If $X = USV^T$<div>\item then $XX^T$'s eigenvectors are the columns of $U$, with eigenvalues $S^2_{ii}$</div><div>\item aka $U = \text{evec}(XX^T)$, $S^2 = \text{eval}(XX^T)$</div>
What's the truncated SVD of a matrix?	\item Via the SVD, we can write $X = \sum \sigma_i u_i v^T_i$ with the $\sigma_i$ in order of decreasing magnitude<div>\item The truncated SVD of rank $L$, $X_L$, is what you get when you throw away all but the first $L$ terms of this expansion</div>
What's the approximation error in a truncated SVD approximation?	<div>\item For a rank $L$ approximation its</div>\item $\|X-X_L\|_F \approx \sigma_L$<div>\item and it's the lowest error possible out of all rank $L$ approximations to $X$</div>
How's PCA related to SVD?	\item PCA with $L$ latent variables on data $X$ is exactly the same as the rank $L$ truncated SVD approximation to $X$
How can the sample variance be written in matrix notation when the data is centered?	\item $\hat \Sigma = \frac{1}{N}X^TX$
Intuitively, what's the effect of having a non-zero variance in PPCA?	\item The projections of the datapoints onto the columnspace of $\hat W$ are shrunk towards the empirical mean $\bar x$
What's the MLE for the noise in PPCA?	\item If $\lambda_j$ are the eigenvalues of $\hat \Sigma$, sorted in order of decreasing magnitude<div>\item $\hat \sigma^2 = \frac{1}{D-L} \sum_{L &lt; j \leq D} \lambda_j$</div><div>\item ie its the average variance of the dimensions not used by the projection</div>
How's a PCA model usually fit?	\item Either with eigenvector methods<div>\item or with EM</div>
What's the output of EM when applied to PCA?	\item A weights matrix $\hat W$ that spans the correct subspace, but which isn't orthogonal<div>\item Once EM is finished though, it can be orthogonalized easily&nbsp;</div>
What's an orthogonal matrix in terms of its columns?	\item It's a matrix whose columns form a \emph{orthonormal} set
What's the intuitive interpretation of EM on PCA with $2 \times 1$ weights matrix?&nbsp;	\item Imagine attaching each datapoint in $\mbb{R}^2$ to a stiff rod via a spring<div>\item E step: hold the rod fixed and let the springs' slide around to minimize the energy</div><div>\item M step: hold the points where the springs attach fixed and let the rod slide around to minimize the energy</div>
What're the advantages of fitting a PCA model using EM instead of eigenvector methods?	\item If $N, D \gg L$ then EM is much faster than naive eigenvector methods<div>\item EM works online</div><div>\item EM can handle missing data</div>
What's a Hinton diagram?	\item A visualization of a matrix as a matrix of squares,&nbsp;<div>\item with the size of each square corresponding to the magnitude of the entry</div><div>\item and white/black denoting positive/negative</div>
What's ARD in PPCA?	\item Automatic relevancy determination<div>\item When fitting a model using EM, an ARD heuristic allows you to start at some maximum number of latent variables, and irrelevant weights will be automatically pruned</div>
What's a scree plot in ML?	\item A plot of the magnitudes of the eigenvalues of a matrix, sorted in decreasing order&nbsp;
How can the residual error in a PCA model be related to the data?	\item Using $L$ latent variables and $D$ dimensional data<div>\item $E(L) = \sum_{L &lt; j \leq D} \lambda_j$</div><div>\item where $\lambda_j$ are the eigenvalues of $\hat \Sigma$ sorted in decreasing order</div>
What's the fraction of variance explained in PCA?	\item $F(L) = \frac{\sum_{j \leq L} \lambda_j}{\sum_{j \leq L_\text{max}} \lambda_j}$<div>\item ie the ratio of all the eigenvalues involved in a $L$-dimension model compared to the eigenvalues involved in the best possible model</div>
Why doesn't PCA generate U-shaped curves on test sets?	\item Because it's not a probabilistic model, it's a compression technique<br /><div>\item Giving it more latent dimensions will always allow it to model the test set more accurately. It isn't penalized for using the extra parameters to store small amounts of information</div>
Why doesn't K-means generate U-shaped curves on test sets?	\item Because it's not a probabilistic model, it's a compression technique<div>\item If you give it more centroids, it'll tile the space more densely, so a test vector is more likely to find a nearby centroid</div><div>\item&nbsp;It isn't penalized for using the extra parameters to store small amounts of information</div>
What's the profile likelihood in PCA model fitting?	\item If you can have up to $L_\text{max}$ parameters, let $\gamma_k$ be the error with $k$ parameters<div>\item Now construct a change-point model: for $k \leq L$, let $\lambda_k \sim \mc{N}(\mu_1, \sigma^2)$ and for $k &gt; L$, let $\lambda_k \sim \mc{N}(\mu_2, \sigma^2)$</div><div>\item Then the profile log likelihood at $L$ is defined as the log likelihood of this model</div>
What's the use of the profile log likelihood in PCA?	<div>\item PCA isn't a probabilistic model, so fittings with different number of parameters can't be compared via marginal likelihood</div><div>\item Instead, the profile likelihood $l(L)$ can be calculated for each threshold $L$, and&nbsp;$L^* = \arg \max_L l(L)$ selected as the number of parameters to use</div>
What's the categorical PCA model?	\item $p(y|z, \theta) = \prod_j \text{Cat}(y_j | \mc{S}(W^T_jz + w_0))$<div>\item $z \sim \mc{N}(0, I)$</div>
What's the supervised PCA model?	\item $z \sim \mc{N}(0, I)$, the latent variable of dimension $L$<div>\item $y|z \sim \mc{N}(w^T_y z + \mu_y, \sigma^2_y)$, a scalar target variable</div><div>\item $x|z \sim \mc{N}(W_xz + \mu_x, \sigma^2_x I)$, the vector-valued data</div>
What's another name for supervised PCA?	\item Bayesian factor regression
What's the information bottleneck in ML?	\item In supervised learning with latent variables, you want two things:&nbsp;<div>\item prediction: for the input $X$ to tell you a lot about the target variable $Y$,&nbsp;</div><div>\item compression: for the latent $Z$ to hold as little information about $X$ as possible</div><div>\item ie, minimize the information bottleneck $\mbb{I}(X; Z) - \beta\mbb{I}(Y; X)$</div><div>\item where $\beta$ is a tradeoff between the two: the larger $\beta$, the more important prediction is vs compression</div>
What algorithm is the information bottleneck closely related to?	\item Canonical correlation analysis
What's semi-supervised learning in ML?	\item Supervised learning where the target variable isn't always observed&nbsp;
What's the problem discriminative supervised PCA fixes?	\item Standard supervised PCA pays as much attention to predicting the inputs as it does to predicting the target variable<div>\item By weighting the terms in the log-likelihood, focus can be put on the latter</div>
What's the idea in partial least squares in ML?	\item It's supervised PCA, but with the latent variables partitioned into two subspaces:<div>\item $z^x_i$ are used to explain the relation between the inputs</div><div>\item $z^s_i$ are used to explain the relation between the inputs and the output</div>
What's the model used in partial least squares?	\item $z^s \sim \mc{N}(0, I)$, $z^x \sim \mc{N}(0, I)$<div>\item $y|z \sim \mc{N}(W_yz^s + \mu_y, \sigma_y^2I)$</div>\item $x|z \sim \mc{N}(W_xz^s + B_xz^x + \mu_x, \sigma_x^2I)$
Intuitively, what's canonical correlation analysis?	\item A symmetric, unsupervised version of partial least squares:<div>\item Each view $x^k$ of the problem gets its own latent variable subspace $z^{x^k}$</div><div>\item and then there's a shared subspace $z^s$ as well</div>
What's the model used in canonical correlation analysis?	\item $z^s \sim \mc{N}(0, I)$<div>\item and for each view&nbsp;$x^k$,</div><div>\item $z^{x^k} \sim \mc{N}(0, I)$<br />\item $x^k|z \sim \mc{N}(W_{x^k}z^s + B_{x^k}z^{x^k} + \mu_{x^k}, \sigma_{x^k}^2I)$</div>
What's the cocktail party problem?	\item An example of blind signal separation:<div>\item You're at a cocktail party and have two ears, each of which gets a linear combination of the conversations going on. Extract each individual conversation.</div>
What's the model used in independent component analysis?	\item $x_t$ is the vector of observations at time $t$,&nbsp;<div>\item $z_{tj} \sim \mc{P}_j$ for $j \in [1, L]$ are the source signals at time $t$, where $\mc{P}_j$ is some non-Gaussian distribution</div><div>\item $x_t \sim \mc{N}(Wz_t + \mu, \Psi)$</div>
What's the difference between PCA and ICA?	\item In PCA, each latent variable is Gaussian<div>\item In ICA, the latent variables can be taken from any \emph{non} Gaussian distribution</div>
What's the prototypical problem that ICA solves?	\item Blind source separation<div>\item ie the cocktail party problem</div>
What's whitening in ML?&nbsp;	\item It's a transformation of the data whose output has a covariance matrix $I$&nbsp;<div>\item It's called whitening because it takes the input vector to a white noise vector</div>
In ICA, what're the generative \&amp; recognition weights?	\item The generative weight matrix is the $W$ which takes the latent variables $z$ to the observations<div>\item The recognition weight matrix is the $V = W^{-1}$ which takes the observations to the latent variables</div>
What's the usual approach to whitening data?	\item Use PCA with as many latent variables as observations
What preprocessing usually needs to be done before ICA can be applied?	\item Center the data<div>\item Whiten the data</div>
What's the objective function when fitting an ICA model?	\item minimize $\text{NLL}(V) = -\sum_j \mbb{E}[\ln v^T_j x]$<br /><div>\item and $V$ is constrained to be an orthogonal matrix</div>
Intuitively, how's the FastICA algorithm work?	\item Construct a Lagrangian that enforces the orthogonality constraint $V^TV = I$<div>\item Then approximate the Hessian of the Lagrangian by making some independence assumptions</div><div>\item and use the approximation to form a Newton update rule</div><div>\item projecting back onto the constraint surface using $V^* = \frac{1}{\|V\|}V$ after each update</div>
What's a Newton update in one dimension?	\item An update in a root-finding algorithm of the form<div>\item $x^\prime = x- \frac{f(x)}{f^\prime(x)}$</div>
What's the kurtosis of a distribution?	\item $\text{kurt}(X) = \frac{1}{\sigma^4}\mu_4 - 3$<div>\item where $\mu_4$ is the 4th central moment</div>
What's the $k$th central moment of a distribution?	\item $\mu_k = \mbb{E}[(X-\mbb{E}[X])^k]$
What's the intuitive interpretation of the kurtosis of a distribution?	\item It describes the `peakiness' of the distribution in comparison to the normal distribution, which has a kurtosis of 0
What's a leptokurtic distribution?	\item A distribution with $\text{kurt}(X) &gt; 0$
What's a platykurtic distribution?	\item A distribution with $\text{kurt}(X) &lt; 0$
What's another name for a leptokurtic distribution?	\item A super-Gaussian distribution
What's another name for a platykurtic distribution?	\item A sub-Gaussian distribution
How's the skewness of a distribution defined?	\item $\text{skew}(X) = \frac{1}{\sigma^3}\mu_3$
Intuitively, how do you interpret the skew of a distribution?	\item Positive skew indicates the right tail is heavier than the left<div>\item Negative skew indicates the left tail is heavier than the right</div>
What's the PDF of the logistic distribution in terms of trigonometric functions?	\item $p(x|\mu, s) = \frac{1}{4s} \text{sech}^2\left(\frac{x-\mu}{2s}\right)$
What's the advantage of the logistic distribution?	\item It's sparser than the Gaussian (like the Laplace distribution), and differentiable everywhere (unlike the Laplace distribution)
When fitting ICA via maximum likelihood, what's commonly used for $G(z) = -\ln p(z)$?	\item $G(z) = \sqrt{z}$, which approximately corresponds to a Laplace-distributed prior<div>\item $G(z) = \ln \text{cosh}(z)$, which approximately corresponds to a logistically-distributed prior&nbsp;</div>
When fitting ICA via EM, what's an alternative to assuming a specific form for the priors $G(z)$?	\item Use a mixture of $K$ Gaussians&nbsp;<div>\item then calculate $\mbb{E}(z|x, \theta)$ by summing over all $K^L$ settings of the mixture weights</div>
What's the negentropy of a distribution?	\item $\text{negentropy}(X) = \mbb{H}(\mc{N}(\mu, \sigma^2))-\mbb{H}(X)$<div>\item where $\mu, \sigma^2$ are the mean and variance of $X$</div>
What's the use of negentropy?	\item Since the Gaussian is maximally entropic for a given mean and variance, it's non-negative&nbsp;<div>\item and large if the distribution is far from being Gaussian</div>
What's the multi-information of a distribution?	\item $I(X) = \mbb{KL}\left(X \middle| \prod_j X_j \right)$<div>\item ie it's the amount of information gained by considering a distribution as a whole vs considering its components independently</div>
What's the infomax principle?	\item When doing supervised learning, with inputs $x$, outputs $y$ and a system we design $\phi$<div>\item we should try and pick $\phi$ to maximize the flow of information between $x$ and $y$</div><div>\item represented by the mutual information $\mbb{I}(x, y)$</div>
What are some equivalents to fitting an ICA model by maximizing the likelihood?	\item Maximize the negentropy of the latent variables<div>\item Minimize the multi-information of the latent variables</div><div>\item Maximize the mutual information between the latent variables and the observed variables</div>
Why isn't the mutual information between the response and each &nbsp;input variable enough to `solve' the feature selection problem?	\item Because you can have models like $y = x_1 \oplus x_2$ over binary variables<div>\item where each input variable alone doesn't tell you anything about the response</div>
What's Bayesian variable selection?	\item Let $\gamma_j = 1$ if feature $j$ is relevant, and $\gamma_j = 0$ otherwise<div>\item Compute $p(\gamma|\mc{D})$ for all $2^D$ values of $\gamma$</div><div>\item Calculate some summary statistic (like the mode) of the posterior to help choose the model&nbsp;</div>
What's the median model approach to variable selection?	\item If $\gamma_j$ indicates whether variable $j$ is relevant<div>\item then the median model uses variables is $\hat \gamma = \{ j : p(\gamma_j = 1 | \mc{D}) &gt; 0.5\}$</div>
What're inclusion probabilities in feature selection?	\item The marginals $p(\gamma_j = 1 | \mc{D})$, where $\gamma_j$ indicates the relevance of variable $j$
What's the $l_0$ pseudo-norm?	\item The number of nonzero elements in the vector
What prior's usually used for the relevancy variables $\gamma_j$ in Bayesian feature selection?	\item $p(\gamma) = \prod \text{Ber}(\gamma_j|\pi_0)$
How do you write a product of Bernouillis in terms of the $l_0$ pseudo-norm?	\item $\prod \text{Ber}(\gamma_j | \pi_0) = \pi_0^{\|\gamma\|_0}(1-\pi_0)^{D-\|\gamma\|_0}$
How can a Bernouilli log-likelihood be written in terms of sparsity?	\item $\ln p(\gamma|\pi_0) = -\lambda \|\gamma\|_0 + C$<div>\item where $\lambda = \ln \frac{1-\pi_0}{\pi_0}$</div>
What's the spike and slab model?	<div>\item A model for feature selection problems, where the weights are distributed as</div>\item $p(w_j|\sigma^2, \gamma) = \delta_0(w_j)$ if $\gamma_j = 0$<div>\item $p(w_j|\sigma^2, \gamma) = \mc{N}(w_j|0, \sigma^2\sigma^2_w)$ if $\gamma_j = 1$</div><div>\item where $\sigma^2_w$ controls how big we expect the coefficients of $w_j$ to be</div><div>\item and $\sigma^2$ is the global noise level</div>
What's the inspiration for the spike and slab model?	\item If $\gamma = 0$, then feature $j$ is irrelevant so on centered data the associated weight $w$ would be 0.<div>\item If $\gamma = 1$, we should make the least number of assumptions possible about the weights, so use a Gaussian (which approximates a uniform `slab' when $\sigma_w^2$ is large enough&nbsp;</div>
What is the use of Kendall's tau correlation?&nbsp;	used in performing <i>non-linear</i>&nbsp;correlation btwn data sets<br /><div>&gt; vs spearman which is an extension of r^2 to ranks</div><div>&gt; kendall is more niche, but can be good in certain circs</div>
In genetics, what is the mc use of the q-q plot?&nbsp;	to characterize the extent to which the observed distribution of the test statistic follows the expected distribution<div>&gt; i.e., expected = null distribution</div>
What's the binary mask model in ML?	\item A model for feature selection problems.<div>\item The weights are $\gamma_j w_j$, where</div><div>\item $\gamma_j \sim \text{Ber}(\pi_0)$</div><div>\item $w_j \sim \mc{N}(0, \sigma^2_w)$</div>
What's another name for the binary mask model?	\item The Bernouilli-Gaussian model
From a Bayesian perspective, how does $l_0$ regularization arise in ML?	\item From applying a Bernouilli prior to each inclusion variable $\gamma_j$<br /><div>\item which gives rise to a $\lambda\|w\|_0$ term in the negative log posterior&nbsp;</div>
What're wrapper methods in ML?	\item Feature selection algorithms that work by searching through the parameter space<div>\item and fitting the model at each point&nbsp;using some generic method</div>
What's a common optimization to wrapper methods in ML?	\item If the wrapper method involves taking a single-bit step from $\gamma_\text{old}$ to $\gamma_\text{new}$&nbsp;<div>\item then computing the loss function $f(\gamma_\text{new})$ can often be done with a rank-1 update</div>
What loss function do you get after applying $l_0$ regularization to the binary mask model?&nbsp;	\item $f(w) = \|y -Xw\|_2^2 + \lambda\|w\|_0$
What's the single-best-replacement algorithm for feature selection?	\item Start with $\gamma = 0$<div>\item At each step, flip the single bit that'd most reduce the loss function</div>
What's the orthogonal least squares algorithm for feature selection?	\item If the complexity penalty (ie $\lambda\|w\|_0$) is ignored<div>\item then single best replacement reduces to adding the feature</div><div>\item $\arg \min_{j \not \in \gamma_t} \min_w \| y - X_{\gamma_t \cup j} w\|^2$</div><div>\item ie just keep adding the feature which most reduces the loss</div>
What's the orthogonal matching pursuits algorithm for feature selection?	\item It's similar to orthogonal least squares, but `freeze' the weights and instead solve<div>\item $\arg \min_{j \not \in \gamma_t} \min_\beta \| y - Xw_t - \beta X_{:,j}\|^2$</div><div>\item ie pick the feature whose column is closest to the residual.</div>
How does the orthogonal matching pursuits algorithm compare to orthogonal least squares in terms of performance?	\item OMP only requires one least squares calculation per iteration, so is much faster<div>\item It's less accurate though</div>
What's the matching pursuits algorithm for feature selection?	\item An even faster/more inaccurate variant of orthogonal matching pursuits: just keep picking the feature whose vector $X_{:,j}$ most strongly correlates with the current residual $y - Xw_t$
What's the backwards selection algorithm for feature selection?	\item Start with a saturated model $\gamma = 1$ and delete the worst feature at each step
What's another name for the orthogonal least squares algorithm for feature selection?	\item Greedy forward selection
How do the forward selection and backwards selection algorithms for feature selection compare?	\item Forward selection is faster because you only need to fit a very small model initially<div>\item Backward selection gives relevancy decisions the `context' of all the other variables that depend on it</div>
What's the stochastic search approach to feature selection?	\item Use a stochastic algorithm to generate a set $\mc{S}$ of high-scoring models<div>\item Approximate the posterior probability of any specific model in the set as</div><div>\item $p(\gamma|\mc{D}) \approx \frac{e^{-f(\gamma)}}{\sum_{\gamma^\prime} e^{-f(\gamma^\prime)}}$</div><div>\item where $f$ is a loss function that approximates the negative log of the joint $p(w, \mc{D})$</div>
What's $l_1$ regularization?	\item The practice of applying a Laplace prior to each weight, $w_j \sim \text{Lap}(0, 1/\lambda)$<div>\item which gives rise to a $\lambda\|w\|_1$ term in the log posterior</div>
What's the effect of $l_0$ regularization in feature selection?	\item It converts a discrete sparsity-promotion problem over the inclusion variables $\gamma \in \mbb{B}^D$ into a continuous optimization problem over the weights $w \in \mbb{R}^D$<div>\item It leads to a very `noisy' surface though</div>
What's the effect of $l_1$ regularization in feature selection?	\item For large enough $\lambda$, it can be thought of as a convex approximation to a non-convex $l_0$ regularization<div>\item which encourages the variables to be sparse</div><div>\item It's not a smooth surface though!</div>
What's lasso stand for in ML?	\item Least absolute shrinkage and selection operator
What's the LASSO problem for linear regression?	\item $\min_w \text{RSS}(w)$ such that $\|w\|_1 \leq B$
How's $l_1$ regularization correspond to lassos?	\item A large regularization coefficient $\lambda$ corresponds to a small bound $B$ on $\|w\|_1$
What's the advantage of using lasso over $l_1$ regularization?	\item The lasso enforces a bound, but it's objective is smooth
Intuitively, why does $l_1$ regularization result in sparse solutions, but $l_2$ doesn't?	\item Translate both to constrained optimization problems: $\|w\|_1 \leq B_1$ and $\|w\|_2 \leq B_2$, with objective $f(w)$<div>\item Optimal soln is the lowest level set of $f$ that intersects the constraint surface</div><div>\item $l_1$ surface has corners - sparse solutions - which are very likely to be the point of intersection.</div><div>\item $l_2$ surface is smooth; points corresponding to sparse solns are no more likely to be the first intersection than other points</div>
What's a subderivative?	\item A subderivative of a convex $f\colon \mc{I} \rightarrow \mbb{R}$ at $\theta_0$ is a scalar $g$ such that<div>\item $f(\theta) - f(\theta_0) \geq g(\theta - \theta_0)$ for all $\theta \in \mc{I}$</div>
What's the intuition for subdifferentials?	\item They're an extension of derivatives for non-smooth functions
What's a subdifferential?	\item It's the closure of the set of subderivatives of a function at a point&nbsp;
What's the subdifferential of a function at a point where it's smooth?	\item $\partial f (\theta_0) = \frac{df(\theta_0)}{d\theta}$<br />
How's the subdifferential of a function at a point denoted?	\item $\partial f(\theta_0)$
In terms of subdifferentials, when's a point a minimum of a function?	\item When $0 \in \partial f(\theta_0)$
What's the $\text{soft}(a; \delta)$ function?	\item $\text{soft}(a; \delta) = \text{sign}(a)(|a|-\delta)_+$<div>\item where $x_+ = \max (x, 0)$ is the positive part of $x$</div>
If you apply $l_1$ regularization to linear regression, what's the optimal weight $w_j$?	<div>\item $\hat w_j = \text{soft}\left(\frac{c_j}{a_j}; \frac{\lambda}{a_j}\right)$</div><div>\item where $a_j, c_j$ are defined by $\frac{\partial}{dw_j}\text{RSS}(w) = a_j w_j + c_j$</div>
How does ridge regression compare to lasso regression?	\item Ridge regression enforces a $l_2$ complexity penalty<div>\item Lasso regression enforces a $l_1$ complexity penalty</div>
If you take the OLS solution coefficients to a linear regression problem and hard threshold them, what are you effectively doing?	\item Subset selection - ranking the features by weight of their solution coefficient, then selecting the first $K(\lambda)$&nbsp;
What's a disadvantage of lasso regression?	\item It results in a biased estimate of the weights, since even large weights are shrunk towards zero by the soft thresholding it enforces
What's a regularization path?	\item The curve described by the weight estimate $\hat w$ as regularization strength $\lambda$ changes
What's the shrinkage factor of a lasso solution?	\item It's the ratio $B/B_\text{max}$ of the bound $B$ for a specific model to the bound $B_\text{max}$ which no longer constrains the parameters
What's the LARS algorithm?	\item `Least angle regression and shrinkage', an adaptation of lasso regression<div>\item which makes use of the fact that the regularization path is piecewise linear to compute the path very cheaply</div>
What's it mean for an algorithm to be model selection consistent?	\item As $N \rightarrow \infty$, it recovers the true sparsity pattern $w^*$
What's $\lambda_\text{max}$ in regularization methods?	\item The regularization strength at which all the weights are clamped to zero
What's debiasing in feature selection?	\item Algorithms like lasso give biased estimators which shrink even large weights towards zero<div>\item But once the support of the weight vector has been identified by a biased algorithm, an unbiased algorithm can be used to calculate unbiased estimates.<br /></div>
What's the problem with using cross-validation to select regularization strength?	\item Because algorithms that use regularization are usually biased<div>\item cross-validation will often choose a $\lambda$ which is too small to result in model selection consistancy&nbsp;</div>
What's a disadvantage of using $l_1$ regularization to select variables?	\item It can be very sensitive to the input
What's frequentist stability selection?	\item Taking a sensitive feature selection algorithm (like lasso)<div>\item and using bootstrap resampling to run it many times</div><div>\item then using the output to estimate the posterior inclusion probabilities of each feature</div>
What's the bolasso feature selection algorithm?	\item Bootstrap lasso: stability selection is applied with lasso regression<div>\item and the approximate posterior probabilities are thresholded (at say 90\%) to decide which features to include</div>
With a linear model and a Laplace prior, which posterior estimators are sparse?	\item Just the mode<div>\item The mean and median aren't</div>
What's a Bayesian alternative to MAP estimation of a linear model over a Laplace prior? &nbsp;	\item MAP with a spike-and-slab prior
What's the coordinate descent algorithm?&nbsp;	\item A model fitting algorithm which cycles through the coordinates $j$ evaluating<div>\item $w^*_j = \arg\min_z f(w + ze_j) - f(w)$</div>
What're active set algorithms in ML?	\item A generalization of coordinate descent which adjust many variables at the same time
What's warm starting in model fitting?	\item Giving an algorithm the value of the weights $\hat w(\lambda_k)$ at some regularization strength $\lambda_k$ and asking it calculate $\hat w(\lambda_{k+1})$<div>\item where $\lambda_{k+1} \approx \lambda_k$</div>
What's a continuation method in model fitting?	\item Rather than calculating the weights $\hat w(\lambda_*)$ at regularization strength $\lambda_*$<div>\item continuation methods calculate a set of solutions leading from $\lambda_\text{max}$ down to $\lambda_*$</div><div>\item making use of warm starting to do this quickly</div>
What's another name for continuation methods in ML?	\item Homotopy methods
What's the most well known example of a homotopy method?	\item LARS
What's the proximal operator?	\item For a convex $R$ (usually a regularizer)<div>\item $\text{prox}_R(y) = \arg\min_z \left(R(z) + \frac{1}{2} \|z-y\|^2_2\right)$</div><div>\item ie it gives a point which minimizes $R$ but is also close to $y$</div>
What's the usual use of the proximal operator?	\item By using it in the update rule of an iterative optimizer, it ensures that a new iterate is close to the old iterate&nbsp;
What's the proximal operator for the regularizer $\lambda\|w\|_1$?	\item $\text{prox}(w) = \text{soft}(\theta, \lambda)$<div>\item where the threshold is applied componentwise</div>
What's the proximal operator for the regularizer $\lambda\|w\|_0$?	\item $\text{prox}(w) = \text{hard}(\theta, \sqrt{2\lambda})$<div>\item where the threshold is applied componentwise</div>
What's the hard thresholding operator?	\item $\text{hard}(a, \lambda) = a\mbb{I}(|a| &gt; \lambda)$
What's the proximal operator for the regularizer $\mbb{I}_S(w)$?	\item $\text{prox}(w) = \text{proj}_S(\theta)$<div>\item where $\text{proj}_S$ is the projection onto set $S$</div>
What's the definition of a projection onto a set?	\item It's a mapping into a subset which is idempotent
What's the most common projection operator into the 1-norm ball?	\item $\text{proj}(w) = \text{soft}(w, \lambda(w))$<div>\item where $\lambda$ is 1 if $\|w\|_1 \leq 1$</div><div>\item and otherwise it's the solution to $\sum (|w_j| - \lambda)_+ = 1$</div>
What's a Bregman distance?	\item It's similar to a metric, but<div>\item isn't necessarily symmetric</div><div>\item doesn't necessarily satisfy the triangle inequality&nbsp;</div>
What's the definition of the spectral step size?	<div>\item For a function $L$,</div>\item $\alpha = \frac{\langle \theta^\prime - \theta,g^\prime - g \rangle}{\|\theta^\prime - \theta\|^2}$<div>\item where $g$ and $g^\prime$ are the gradients at $\theta$ and $\theta^\prime$</div>
How does the spectral stepsize arise?	\item If we approximate the Hessian of $L$ with $\alpha I$,&nbsp;then it must be that<div>\item $\alpha(\theta^\prime - \theta) \approx g^\prime - g$</div><div>\item where $g, g^\prime$ are the gradients of $L$ at $\theta, \theta^\prime$</div><div>\item The spectral step size solves this equation</div>
How does using the spectral step size in gradient descent compare to standard line search algorithms?	\item Spectral step size doesn't guarantee a monotonic decrease in the objective<div>\item but it's much faster &nbsp;</div>
What's the update rule in the proximal gradient algorithm?	<div>\item For a regularizer $R$ and loss $L$,</div>\item $\theta_{k+1} = \text{prox}_{\frac{1}{\alpha_k}R}(\theta_k - \frac{1}{\alpha_k}\nabla L(\theta_k))$<div>\item where $\alpha_k$ is the step size</div>
What's projected gradient descent?	\item Proximal gradient descent with a regularizer of the form $R(\theta) = \mbb{I}_S(\theta)$ for some set $S$
How does proximal gradient descent relate to gradient descent?	\item Proximal gradient descent is equivalent to gradient descent when the regularizer is $R(\theta) = 0$
What's iterative soft threholding?	\item It's proximal gradient descent where $R(\theta) = \lambda\|\theta\|_1$
What's the update rule in Nesterov's method of proximal gradient descent?	<div>\item For a regularizer $R$ and loss $L$,</div>\item $\theta_{k+1} = \text{prox}_{\frac{1}{\alpha_k}R}(\phi_k - \frac{1}{\alpha_k}\nabla L(\theta_k))$<div>\item where $\phi_k = \theta_{k-1} + \frac{k-1}{k-2}(\theta_k - \theta_{k-1})$<br /><div>\item and $\alpha_k$ is the step size</div></div>
How does Nesterov's method relate to proximal gradient descent?	\item It's the same, except the quadratic approximation to the loss function is centered around an interpolation of the previous two parameter values&nbsp;rather than just around $\theta_k$
How do you ensure convergence when using the spectral step size?	\item Require that the objective decrease on average over some sliding window of $M+1$ updates<div>\item If it doesn't, re-calculate the regularization function using the latest parameter value</div>
How can the Laplace distribution be written as a Gaussian scale mixture?	\item $\text{Lap}(x|0, b) = \int \mc{N}(0, z) \text{Ga}(z|1, \frac{1}{2b^2})dz$
How is EM applied to lasso problems?	\item By converting the problem to its Laplace-prior form<div>\item then expanding the Laplace prior as a Gaussian scale mixture, with scale weights $\tau_j$</div><div>\item E step: infer the $\tau_j$</div><div>\item M step: estimate $w$</div>
What's the Laplace prior form of a lasso problem?	\item $\mc{N}(y|Xw, \sigma^2 I)\prod_j \text{Lap}(w_j|0, b)$<div>\item where the prior scale $b$ reflects the lasso bound $B$</div>
What's the Wald distribution?	\item Another name for the inverse Gaussian distribution
What's the definition of a group lasso problem?	\item One which in regularizer form has objective<div>\item $f(w) = \text{RSS}(w) + \lambda \sum \|w_g\|_2$</div><div>\item where each $g$ denotes a group of parameters</div>
What're two alternative regularizers sometimes used in group lasso?	\item $\lambda_g\|w_g\|_\infty$<div>\item $\lambda_g \sqrt{d_g} \|w_g\|_2$, where $d_g$ is the size of group $g$</div>
Why's it important that group lasso use&nbsp;$\|w_g\|_2$ rather than $\|w_g\|_2^2$?	\item The former promotes group sparsity;&nbsp;<div>\item the latter is equivalent to ridge regression</div>
How's lasso generalized to problems where there are multiple parameters $w_{jc}$ for each variable $j$?	\item By group lasso,&nbsp;<div>\item which encourages group sparsity rather than individual sparsity&nbsp;</div>
What's the prior which gives a MAP estimate equivalent to solving a group lasso problem?	\item $p(w|\gamma, \sigma^2) \propto \exp\left(-\frac{\gamma}{\sigma}\sum_g \|w_g\|_2\right)$<div>\item where $\gamma$ scales with $\lambda$ and $\sigma^2$ is the noise in the likelihood</div>
What's the use of fused lasso?	\item It's for problems where we'd like $w_j$ to be similar to $w_{j+1}$<br />
What's the penalty in fused lasso?	\item $\frac{\lambda_1}{\sigma} \sum |w_j| + \frac{\lambda_2}{\sigma}\sum |w_{j+1} - w_j|$<div>\item where $\lambda_1, \lambda_2$ control the relative importance of sparsity and of similarity</div><div>\item and $\sigma^2$ is the noise in the likelihood</div>
What's the penalty in graph-guided fused lasso?	\item $\frac{\lambda_1}{\sigma} \sum_{s \in V} |w_s| + \frac{\lambda_2}{\sigma}\sum_{(s, t) \in E} |w_s - w_t|$<div>\item where $\lambda_1, \lambda_2$ control the relative importance of sparsity and of similarity</div><div>\item and $\sigma^2$ is the noise in the likelihood</div>
How is fused lasso represented as a hierarchical model?	\item $w|\sigma^2, \tau, \omega \sim \mc{N}(0, \sigma^2\Omega^{-1}(\tau, \omega))$<div>\item $\tau_j^2 | b_1 \sim \text{Expon}\left(\frac{1}{2b_1^2}\right)$, the sparsity regularizers</div><div>\item $\omega_j^2 | b_2 \sim \text{Expon}\left(\frac{1}{2b_2^2}\right)$, the similarity regularizers</div><div>\item and $\Omega$ is a tridiagonal matrix</div><div>\item with central entries&nbsp;$\frac{1}{\tau_j^2} + \frac{1}{\omega_{j-1}^2} +&nbsp;\frac{1}{\omega_{j+1}^2} $</div><div>\item and off-diagonal entries $-\frac{1}{\omega^2_j}$</div>
What're some of the problems with lasso models?	\item If there are a group of highly correlated variables, it'll tend to arbitrarily select just one of them to be nonzero<div>\item If $D &gt; N$, lasso will only be able to select $N$ variables before saturating</div><div>\item If $N &gt; D$ but the variables are correlated, it'll often do worse than ridge regression&nbsp;</div>
Intuitively, what're elastic net models?	\item A combination of lasso and ridge approaches that ameloriates some of the problems with lasso models
What's the penalty in vanilla elastic net models?&nbsp;	\item $\lambda_1\|w\|^2_1 + \lambda_2\|w\|^2_2$
What's the grouping effect in elastic net models?	\item If a penalty on $w$ is strictly convex (which elastic net's is)<div>\item then the estimated coefficients of highly correlated variables tend to be equal in magnitude&nbsp;</div>
How're elastic net regression problems usually solved? &nbsp;	\item Elastic net reduces to lasso on suitably modified data<div>\item at which point LARS can be applied</div>
What's the problem with vanilla elastic net, and how is it solved?	\item It produces poor estimators because it shrinks twice: once by the $l_1$ penalty and once by the $l_2$ penalty<div>\item The solution is to scale the computed $\tilde w$ to $\hat w = \sqrt{1 + \lambda_2}\tilde w$</div>
Intuitively, how can elastic net be interpreted in terms of lasso?	\item It's lasso but with a covariance matrix that's shrunk towards $I$ as $\lambda_2$ increases
What're the problems with using a Laplace prior?	\item It's often not sufficiently sparse:<div>\item not enough mass is put at the origin, so it won't suppress noise</div><div>\item not enough mass is put at extreme values, so it shrinks large weights</div>
What's the penalty used in bridge regression?	\item $\lambda\sum |w_j|^b$<div>\item for some $b &gt; 0$</div>
What's the main advantage of using a Laplace prior over something like an exponential power distribution with $b = 0.5$?	\item The Laplace prior gives a convex optimization problem
What properties do different parameters $b$ generate in bridge regression?	\item $b \leq 1$ is sparsity-promoting<div>\item $b \geq 1$ produces convex optimization problems &nbsp;</div>
What's the definition of an exponential power distribution?	\item $\text{ExpPower}(x| \mu, a, b) \propto \exp\left(-\frac{|x - \mu|^b}{a}\right)$
What kind of prior does bridge regression correspond to?	\item An exponential power distribution
What's a hierarchical adaptive lasso model?	\item A lasso model where each weight gets its own tuning parameter:<div>\item $b_j \sim \text{Ga}(a, b)$</div><div>\item $w_j|b_j \sim \text{Lap}(0, b_j)$</div>
What's the advantage of the hierarchical adaptive lasso model over vanilla lasso?	\item Vanilla lasso needs a large $\lambda$ to suppress irrelevant parameters, but this also shrinks relevant parameters<div>\item HAL allows large parameters to `stay large'</div>
What's HAL in ML?	\item Hierarchical adaptive lasso
What distribution do you get when you integrate out the tuning parameters $b_j$ &nbsp;in HAL?	\item A generalized $t$ distribution
What's the form of a generalized $t$ distribution?	\item $\text{GT}(x|\mu, a, c, q) \propto \left(1 + \frac{1}{a}\frac{|x - \mu|^q}{c^q}\right)^{-\frac{1+a}{q}}$
What're the parameters in the generalized $t$ distribution?	\item $\mu$, the mean<div>\item $a$, which controls the degrees of freedom</div><div>\item $c$, the scale</div><div>\item $q$, which controls the sparsity</div>
What's the penalty function that arises from HAL?	\item $(1+a)\sum_j\ln\left(1+\frac{1}{b}|w_j|\right) + C$<div>\item where $C$ is a constant</div>
What're the effects on the penalty of the two parameters $a, b$ in HAL?	\item $a$ increases the strength<div>\item $b$ increases the sparsity</div>
What's the threshold function given rise to by HAL look like?	\item It's flat in the center<div>\item and asymptotically close to $y = x$</div><div>\item and the slope of the transition between the two behaviours increases with $b$</div>
What's a possible alternative to HAL in terms of sparsity-promoting priors?	\item Normal-Jeffreys<div>\item which puts a noninformative Jeffreys prior on the variance of each weight<br /><div>\item that gives marginals $p(w_j) \propto \frac{1}{|w_j|}$</div></div>
How's a Normal-Jeffreys prior compare to HAL models?	\item Normal-Jeffreys has no parameters<div>\item which means there's nothing to tune</div><div>\item but no ability to adapt the level of sparsity</div>
What's a factorial prior?	\item A prior of the form $p(w) = \prod p_j(w_j)$
What's sparse Bayes learning?	\item ARD applied to linear models
What do $\alpha_j$ and $\beta$ denote in the context of ARD?	\item $\alpha_j$ is the weight precision &nbsp;<div>\item $\beta$ is the measurement precision</div>
In ARD when drawing precisions $\alpha_j \sim \text{Ga}(a, b)$, what settings of $a, b$ give the greatest sparsity?	\item The improper prior $a, b = 0$
What're the effects of the shape parameter $\alpha$ and the rate parameter $\beta$ on the Gamma distribution?	\item Increasing $\alpha$ shifts the peak down and to the right<div>\item Increasing $\beta$ reduces the spread of the distribution</div>
What's the effect of a scale parameter on a distribution?	\item Increasing scale stretches the distribution
What's the model used in sparse Bayesian learning?	\item $y|x,w,\beta = \mc{N}(w \cdot x, \frac{1}{\beta})$<div>\item $w \sim \mc{N}(0, A^{-1})$</div><div>\item where $A = \text{diag}(\alpha)$</div>
What's SBL in ML?	\item Sparse Bayesian Learning
What other model does SBL closely resemble?	\item A spike and slab model with a normal likelihood
How is SBL regularized?	\item By applying a Gamma prior to the precisions $\alpha_j, \beta$ with a shape $\leq 1$&nbsp;
When is a Gamma distribution sparsity-promoting?	\item When the shape $\alpha \leq 1$
What're the main steps in sparse Bayesian learning?	<div>\item Regularize the precisions with a Gamma distribution</div><div>\item Estimate the precisions $\alpha_j, \beta$ using the MAP</div><div>\item Use the estimated precisions to calculate a posterior over the parameters $w$</div>
What's the main thing that distinguishes ARD/SBL from MAP estimation?	\item Having estimated the precisions, the effective prior $p(w|\hat \alpha)$ is non-factorial
In what sense are non-factorial priors strictly better than factorial priors?	\item It can be shown that non-factorial objectives always have fewer local minima than factorial objectives&nbsp;<br />
How does sparse coding relate to ICA?	\item It's ICA with<div>\item a possibly non-orthogonal factor loading matrix $W$</div><div>\item and sparsity-promoting priors placed on the $z$</div>
How does the nomenclature of sparse coding carry over to the ICA formalism?	\item The factor loading matrix $W$ is the dictionary<div>\item Each column in $W$ is an atom</div><div>\item If $L &gt; D$, then the representation is overcomplete</div>
What's sparse PCA?	\item PCA with a sparsity promoting prior put on the weights $W$<div>\item \emph{Not} the same as sparse coding</div>
What model is commonly used in sparse coding when trying to learn the dictionary?	\item $\ln p(\mc{D}|W) \approx \sum_i \max_{z_i} [ \ln \mc{N}(x_i|Wz_i, \sigma^2 I) + \ln p(z_i)]$<div>\item where $p(z_i)$ is a Laplace prior</div><div>\item and the columns of $W$ are bounded as $\|w_j\|^2_2 \leq 1$</div>
What's the analysis-synthesis approach to learning a dictionary in sparse coding?	\item Analysis: fix the coefficients $Z$ and solve a least squares problem to estimate $W$<div>\item Synthesis: fix the basis $W$ and solve a lasso problem to estimate $Z$</div><div>\item Repeat!&nbsp;</div>
What's sparse matrix factorization?	\item The intersection of sparse coding and sparse PCA:&nbsp;<div>\item try and simultaenously learn a sparse basis $W$ and sparse coefficients $Z$ such that $X=WZ$</div>
What's the idea in compressed sensing?	\item Suppose $y=Rx+\epsilon$ is a noisy, low dimensional projection of some data $x$, where the sensing matrix $R$ is known.<div>\item If we assume $x = Wz$, ie $x$ is sparse in some basis $W$, then we can still recover $x$ from $y$ using Bayesian inference</div><div>\item despite $y$ being much lower dimension than it!</div>
What's a kernel?	\item It's a real-valued bifunction $\kappa(x, x^\prime)$<br /><div>\item which is typically symmetric&nbsp;</div><div>\item and positive definite</div><div>\item though this isn't required</div>
Conceptually, what does a positive definite kernel function do?	\item It measures the similarity between two objects<br />
What's the infinite-dimensional analogue of a positive definite matrix?	\item A positive definite kernel function
What's the SE kernel?	\item The squared exponential kernel, another name for the Gaussian kernel
What's the Gaussian kernel?	\item $\kappa(x, y) = \exp\left(-\frac{1}{2}(x - y)\Sigma^{-1}(x - y)\right)$
What's the characteristic length scale of a dimension in ML?	\item Given a Gaussian kernel $\kappa$ with diagonal covariance<div>\item the characteristic length scale of dimension $j$ is $\sigma_j$</div>
What's an ARD kernel?	\item A Gaussian kernel with diagonal covariance where some $\sigma_j = \infty$<div>\item since the infinite variance means that dimension $j$ is ignored</div>
What's the bandwidth of a Gaussian kernel?	\item If the kernel is isotropic, it's $\sigma^2$
What's a RBF kernel?	\item A radial basis function kernel,&nbsp;<div>\item a kernel that only depends on $\|x- x^\prime\|$</div>
What's the cosine similarity kernel?	\item $\kappa(x, y) = \frac{\langle x, y \rangle}{\|x\|_2 \|y\|_2}$
What's the Babylonian method for finding square roots?	\item &nbsp;$x_0 \approx \sqrt{S}$<div>\item $x_{n+1} = \frac{1}{2}\left(x_n + \frac{S}{x_n}\right)$</div>
What's the term frequency of a feature in a document?	<div>\item Given feature vector $x$ describing the document, it's</div>\item $\text{tf}(x_{j}) = \ln(1+x_{j})$
What's the inverse document frequency of a feature?	\item Given the feature vectors $x_i$ representing the documents, it's<div>\item $\text{idf}(j) = \ln \frac{N}{1 + \sum_i \mbb{I}(x_{ij} &gt; 0)}$</div><div>\item ie the negated log fraction of the number of documents $j$ appears in</div>
What's the TF-IDF representation of a document?	\item The term-frequency inverse-document-frequency representation,<div>\item $\text{tf-idf}(x_i) = [\text{tf}(x_{ij}) \times \text{idf}(j)]_j$</div>
What's a more robust variant of the cosine similarity kernel for document matching?	\item The TF-IDF kernel:<br /><div>\item $\kappa(x, y) = \text{cosine-sim}(\text{tf-idf}(x), \text{tf-idf}(y))$</div>
What's the Gram matrix of a kernel?	\item Given inputs $\{x_i\}$, it's&nbsp;<div>\item $K = [\kappa(x_i, x_j)]_{ij}$</div>
What's a Mercer kernel?	\item Another name for a positive definite kernel
What's a positive definite kernel?	\item One whose Gram matrix $K$ is positive definite for any set of input&nbsp;
What's a stationary kernel?	\item A translation-invariant kernel, ie there exists a $\tilde \kappa$ such that<div>\item $\kappa(x, y) = \tilde \kappa(x - y)$</div>
What's the polynomial kernel?	\item $\kappa(x, y) = (\gamma x \cdot y + r)^M$<div>\item where $r &gt; 0$</div>
What's an example of a non-Mercer kernel?	<div>\item The sigmoid kernel&nbsp;</div>\item $\kappa(x, y) = \tanh (\gamma x^Ty + r)$
What's a linear kernel?	\item A kernel of the form<div>\item $\kappa(x, y) = x \cdot y$</div>
When's a linear kernel appropriate?	\item When the individual features in the data are already informative<div>\item so the decision boundary is likely already representable as a combination of the original features</div>
What's the usual use of the Matern kernel?	\item It's usually used to define the covariance between points that are a specific distance from eachother
What's the kernel usually used for string comparison?	<div>\item The substring counting kernel</div>\item $\kappa(x, y) = \sum_{s \in \mc{A}^*} w_s \phi_s(x)\phi_s(y)$<div>\item where $\mc{A}$ is the alphabet&nbsp;</div><div>\item and $w_s$ is the weight of substring $s$</div><div>\item and $\phi_s(x)$ counts the number of times $s$ appears as a substring in $x$</div>
How's the substring counting kernel usually calculated?	\item Using suffix trees or arrays to do it in linear time
What's the bag-of-characters string kernel?	\item The kernel you get when you take the substring kernel and set $w_s = 1$ for all $s$ of length 1, and $w_s = 0$ otherwise
What's the bag of words kernel?	\item The kernel you get if you take the substring kernel and set $w_s = 1$ on any $s$ which is bounded by whitespace, and $w_s = 0$ otherwise
What's the $k$ spectrum string kernel?	\item The kernel you get if you take the substring kernel and set $w_s = 1$ for strings of length $k$, and $w_s = 0$ otherwise
How are bag-of-words representations usually constructed for images?	\item Identify regions of interest<div><div>\item Characterize each region by a vector</div></div><div>\item The set of those vectors is the representation of the image</div>
What's a pyramid match kernel?	<div>\item Given a datapoint represented by a feature set,</div>\item the set is mapped to a multi-resolution histogram<div>\item and the histograms are then compared using weighted histogram intersection</div>
What does a pyramid match kernel approximate?	\item Constructing a bipartite map between the elements of the two feature sets&nbsp;<div>\item and then summing the pairwise similarities between matched elements</div>
What's the most common use of pyramid match kernels?	\item Image similarity calculation:<div>\item construct a bag of words representation for each image&nbsp;</div><div>\item then apply the pyramid match kernel to calculate similarities</div>
What's a probability product kernel?	\item $\kappa(x, y) = \int p(z|x)^\rho p(z|y)^\rho dz$<div>\item where $\rho &gt; 0$<br /><div>\item and $p(z|x)$ is often approximated by $p(z|\hat \theta(x))$</div></div>
What's a Fisher kernel?	\item $\kappa(x, y) = s(x)^T\mc{I}^{-1} s(y)$<div>\item where $\mc{I}$ is the Fisher information</div><div>\item and $s(x) = \nabla_\theta \ln p(x|\theta)|_{\hat \theta}$</div>
What's the intuition behind the Fisher kernel?	\item Let $g(x)$ be the direction $x$ would like the parameters $\hat \theta$ to move to maximize its own likelihood<div>\item The Fisher kernel evaluates whether $g(x), g(y)$ are similar with respect to the geometry encoded by the curvature of the likelihood function</div>
What's a kernel machine?	\item A GLM with an input vector of the form<div>\item $\phi(x) = [\kappa(x, \mu_k)]_k$</div>
What're the centroids of a kernel machine?	\item The $\mu_k$ in the definition of the kernel machine's feature vector
What's an RBF network?	\item A kernel machine built on a RBF kernel
What's jittering in data visualization?	\item If a visualization would have a large number of points on top of eachother<div>\item add some uniform noise to them so the group can be seen properly</div>
How can a kernelized feature vector be used for logistic regression?	\item Just use $y|x, \theta \sim \text{Ber}(w^T\phi(x))$
How can a kernelized feature vector be used in linear regression?	\item Just use $y| x, \theta \sim \mc{N}(w^T\phi(x), \sigma^2)$
What's a sparse vector machine?	\item Create a kernel machine with the datapoints as centroids: $\mu_i = x_i$<div>\item Then use a sparsity-promoting prior to select a subset of the centroids</div>
What's a L1VM in ML?	\item A $l_1$ regularized vector machine<div>\item ie a sparse vector machine using a Laplace prior</div>
What's a relevance vector machine?	\item A sparse vector machine whose relevant centroids are selected using ARD/SBL
What's the kernel trick in ML?	\item When building a kernel machine<div>\item rather than working with the kernelized feature vectors</div><div>\item use the original feature vectors and replace all inner products $\langle x, y \rangle$ with a call to $\kappa(x, y)$</div><div>\item The kernel must be Mercer though!</div>
How do you kernelize a nearest neighbour classifier?	\item by noting that $\|x - y\|_2^2 = \langle x, x \rangle + 2\langle x, y \rangle +&nbsp;\langle y, y \rangle$<div>\item and applying the kernel trick</div>
What's the idea in the K-medoids algorithm?	\item It's similar to K-means<div>\item but rather than averaging all the vectors in the group to get a centroid</div><div>\item one of the vectors in the group is chosen to be the centroid itself</div><div>\item In particular, we choose the vector which has the smallest sum of distances to all the other vectors in the group, $m_k = \arg \min_i \sum_{j \in G_k} d(x_i, x_j)$</div>
What's nearest medoid classification?	\item Classification using K-medoids clustering
When kernelizing ridge regression, what are the dual variables often used?	\item $\alpha = (K^T + \lambda I)^{-1} y$<div>\item where $K = XX^T$ in plain ridge regression</div>
What's the use of the dual variables $\alpha$ in kernelizing ridge regression?	\item The primal variables $w$ can be written as $w = X^T \alpha$<div>\item and the predictive mean for input $x$ is $w^Tx = &nbsp;\sum \alpha_i \kappa(x, x_i)$</div>
What's the computational advantage of using the dual variables rather than the primal variables when fitting ridge regression?	\item Computing the dual variables is $O(N^3)$<div>\item Computing the primal variables is $O(D^3)$</div><div>\item so in very-high-dimensional settings, using the dual variables can be advantageous</div>
What's $XX^T$ in terms of inner products?	\item It's the matrix of inner products of the rows of $X$
What's $X^TX$ in terms of inner products?	\item It's the matrix of inner products of the columns of $X$
Given the eigenvectors, $U$, and eigenvalues, $\lambda$, of $XX^T$, what are the eigenvectors and eigenvalues of $X^TX$?&nbsp;	\item $V = X^T U \Lambda^{-\frac{1}{2}}$<div>\item and the eigenvalues are the same</div>
How can the scatter matrix be written as a product of matrices?	\item $\sum x_i x_i^T = X^TX$<div>\item where $X$ is constructed by stacking rows</div>
How do you kernelize PCA?	\item PCA reduces to finding the eigenvectors of the covariance matrix $X^TX$<div>\item which can be further reduced to finding the eigenvectors of the inner product matrix $XX^T$. Replace $XX^T$ with the kernel $K$.</div><div>\item Then to center the feature vectors, replace the kernel with $\tilde K = HKH$, where $H$ is the centering matrix</div>
What's the definition of the centering matrix?	\item $H = I - \frac{1}{N}\mb{1}\mb{1}^T$
What's the use of the centering matrix $H$?	\item If we want the feature vectors of a kernel machine with kernel $K$ to be centered, $\tilde \phi_i = \phi(x_i) - \bar \phi$<div>\item then $\tilde K = HKH$ implements this adjustment</div>
What's one of the main advantages of kernelized PCA over linear PCA?	\item Linear PCA is limited to using $L \leq D$ components<div>\item kPCA can use up to $N$ components</div>
What's multidimensional scaling in ML?	\item It's a way to find a low-dimensional embedding of a set of objects<div>\item such that the Euclidean distances between points in the embedding space approximates the original dissimilarity matrix</div>
What technique is multidimensional scaling closely related to?	\item Kernelized PCA
From a Bayesian standpoint, what're the problems with support vector machines?	\item The sparsity is encoded in a loss function rather than in the prior<div>\item Kernels are encoded using an algorithmic trick, rather than being part of the model</div><div>\item They don't give probabilistic output</div>
At a high level, how're support vector machines derived from the empirical risk?	\item Start with a $l_2$-regularized empirical risk function&nbsp;<div>\item $J(w, \lambda) = \sum L(y_i, w^Tx_i) + \lambda\|w\|^2$</div><div>\item Kernelize the calculation of $w^Tx_i$</div><div>\item Adapt the loss function $L$ to enforce sparsity</div>
What's the epsilon-insensitive loss function?	\item $L_\epsilon(y, \hat y) = 0$ if $|y-\hat y| &lt; \epsilon$<div>\item $L_\epsilon(y, \hat y) = |y-\hat y| - \epsilon$ otherwise</div><div>\item ie any point in an $\epsilon$-tube around the prediction is not penalized</div>
What's SVM stand for in ML?	\item Support vector machine
How's the loss function usually written for SVMs?	\item $J(w) = C \sum L_\epsilon (y_i, w^Tx_i) + \frac{1}{2}\|w\|^2$<div>\item where $L_\epsilon$ is the epsilon-insensitive loss function</div><div>\item and $C$ controls the regularization strength</div>
How's a SVM's loss function $J(w)$ usually minimized?	\item By forming \&amp; solving the quadratic program<div>\item $\min J(w)$ s.t&nbsp;</div><div>\item $y_i \leq w^Tx_i + \epsilon + \xi_i^+, \quad \xi_i^+ \geq 0$</div>\item $y_i \geq w^Tx_i - \epsilon - \xi_i^-, \quad \xi_i^- \geq 0$<div>\item where the slack variables $\xi_i^+, \xi_i^-$ have been chosen such that $y_i = \xi_i^+ + \xi_i^-$</div>
What does the optimal solution to an SVM model look like?	\item $\hat w = \alpha^T X$<div>\item where $\alpha$ is nonnegative and sparse. &nbsp;</div>
What are the support vectors of a SVM?	\item The $x_i$ with nonzero $\alpha_i$ in the solution<div>\item ie the points for which the prediction error lies outside the $\epsilon$ tube</div>
What's the definition of the hinge loss?	\item $L_\text{hinge}(y, \eta) = (1 - y\eta)_+$<div>\item where $\eta$ is the confidence<br /><div>\item ie a slope (determined by $\eta$) into a plateau</div></div>
How are SVMs used for classification?	\item Take a logistic regression classifier and bound its risk of misclassification with $L_\text{hinge}(y, w^Tx)$.<div>\item Then the objective looks like $C\sum L_\text{hinge}(y_i, w^Tx_i) + \frac{1}{2}\|w\|_2$</div><div>\item where $C$ controls the regularization strength.</div><div>\item This can be solved using a linear SVM, getting $\hat w = \alpha^T X$</div><div>\item and predictions $\hat y(x) = \text{sign}\left(\sum \alpha_i \kappa(x_i, x)\right)$</div>
What's the large margin principle?	\item When linearly separating data, there are often many planes that separate the training set<div>\item The plane to choose as the decision boundary should be the one which is the greatest distance from its nearest datapoint &nbsp;</div><div>\item ie, the one with the largest margin</div>
What's a large margin classifier?	\item A classifier whose objective encourages&nbsp;correct predictions<div>\item and implements the large margin principle&nbsp;</div>
What's the most common example of a large margin classifier?	\item SVMs
What's the constrained problem that a SVM classifier tries to solve?	\item $\min_{w, \xi} C\sum\xi_i + \frac{1}{2}\|w\|^2$ such that<div>\item $y_i(w^Tx_i) \geq 1 -\xi_i$</div><div>\item $\xi_i \geq 0$</div>
What do the slack variables in an SVM classifier's constrained problem correspond to?	\item They're soft margin constraints, with $\xi_i &gt; 1$ representing a misclassification
How is the regularization strength $C$ usually set in an SVM classifier?	\item $C = \frac{1}{\nu N}$<div>\item where $0 &lt; \nu \leq 1$ is the fraction of misclassified points that'll be tolerated during the training phase</div><div>\item $\nu$ is set by cross-validation</div>
How can you measure the confidence in a SVM classifier's prediction?	\item Interpret $w^Tx$ as the log-odds ratio $\ln \frac{p(y=1|x)}{p(y=0|x)}$<div>\item Then $p(y = 1|x) = \text{sigm}(a w^Tx + b)$</div><div>\item where $a, b$ are set by maximum likelihood estimation \emph{on a separate validation set} - using the training set leads to severe overfitting!</div><div>\item From a theoretical perspective there's no justification for this though!</div>
How are SVM classifiers usually generalized to multiple classes?	\item One-versus-the-rest: train a classifier for each class \&amp; either deal with ambiguities or pick the prediction with the largest output $w^Tx$<div>\item One-versus-one: train a classifier for each pair of classes and take a plurality vote</div>
What're the problems with the one-versus-the-rest approach to using SVMs for multi-class classification?	\item Two classifiers might predict a point belongs to two different classes<div>\item and while you can pick the prediction with the largest output $w^Tx$, there's nothing that says the outputs of two different classifiers are comparable</div><div>\item is also prone to the class imbalance problem</div>
What's the class imbalance problem?	\item If you train a classifier on a training set which is almost all one class, it can often degrade performance<br />
What's the problem with the one-versus-one approach to generalizing binary classifiers to multi-class problems?	\item There's the possibility for ambiguity when there's no plurality in the vote
What's a common problem with setting the regularization strength $C$ in SVMs?	\item It interacts with the kernel parameters<div>\item ex: if you're using a RBF kernel with variance $\sigma$, then large variance should go with light regularization (ie small $C$)</div>
How can SVMs be interpreted from a Bayesian perspective?	\item Rigorously, they can't - or at least the hinge loss provably doesn't have a corresponding likelihood.&nbsp;<div>\item It does have a corresponding pseudo-likelihood though, which can be represented as a Gaussian scale mixture</div><div>\item which means it can be fit using EM or Gibbs sampling&nbsp;&nbsp;</div>
Are gradient optimizers or cross validation generally quicker?	\item Gradient optimizers
Of the various kernel-based classifiers, which should generally be preferred?	\item RVM if speed matters<div>\item GP if it doesn't</div>
What's the computational complexity of fitting a SVM?	\item $O(N^3)$ generally<div>\item $O(N)$ for a linear kernel</div><div>\item This doesn't include cross-validation time</div>
What's a smoothing kernel?	\item One satisfying&nbsp;<div>\item $\int \kappa(x) dx = 1$, ie unit total mass</div><div>\item $\int x\kappa(x) dx = 0$, ie zero mean</div><div>\item $\int x^2\kappa(x) dx &gt; 0$, ie positive variance</div>
How do you control the bandwidth of a smoothing kernel?	\item Given a smoothing kernel $\kappa$, the bandwidth-adjustable version is<div>\item $\kappa_h(x) = \frac{1}{h} \kappa\left(\frac{x}{h}\right)$</div>
What's the most common smoothing kernel?	\item The Gaussian kernel<div>\item $\kappa(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2}$</div>
What's the Epanechnikov kernel?	\item A smoothing kernel with the form<div>\item $\kappa(x) = \frac{3}{4} (1- x^2)\mbb{I}(|x|\leq1)$</div>
What's the advantage of the Epanechnikov kernel?	\item It's got compact support
What's the disadvantage of the Epanechnikov kernel?	\item It's not smooth at the boundaries of its support
What's the tri-cube kernel?	<div>\item A smoothing kernel with</div>\item $\kappa(x) = \frac{70}{81}(1 - |x|^3)^3\mbb{I}(|x|\leq 1)$<br />
What're the advantages of the tri-cube kernel?	\item It's got compact support<div>\item It's everywhere differentiable</div>
What's the boxcar kernel?	\item A smoothing kernel of the form&nbsp;<div>\item $\kappa(x) = \mbb{I}(|x| \leq 1)$<br /></div>
What's the Parzen window density estimator?	\item $\hat p(x) = \frac{1}{N}\sum \kappa_h (x -x_i)$
Intuitively, what's the Parzen window density estimator doing?	\item Placing a distribution (described by the kernel) on top of each datapoint<div>\item then taking their sum</div>
What's a kernel density estimator another name for?	\item A Parzen window density estimator
What's KDE in ML?	\item Kernel density estimation
How can k-nearest neighbours be interpreted in terms of kernel density estimators?	\item To predict the class of a point $x$, place a boxcar kernel $\kappa_h$ on top of it and increase its bandwidth until $K$ datapoints are encountered.<div>\item Then we can estimate the class posterior as</div><div>\item $p(x|y=c, \mc{D}) = \frac{N_c(x)}{K}$</div><div>\item where $N_c(x)$ is the number of points of class $x$ in the kernel</div><div>\item which is the standard formula for KNN</div>
What's kernel regression?	\item We can approximate the joint density as&nbsp;<div>\item $p(y, x) = \frac{1}{N}\sum \kappa_h(x - x_i)\kappa_h(y-y_i)$</div><div>\item which can be rearranged to show that</div><div>\item $\mbb{E}[y|x] =&nbsp;\frac{1}{C}&nbsp;\sum \kappa_h(x - x_i) y_i$</div><div>\item where $C = \sum_i&nbsp;\kappa_h(x - x_i)$</div>
What's the Nadaraya-Watson model?	\item Another name for kernel regression
What's the median absolute deviation in ML?	\item $\text{MAD} = \text{median}(|x - \text{median}(x)|)$
What's the use of the mean absolute deviation in ML?	\item It provides a robust approximation to the standard deviation<div>\item $\hat \sigma \approx 1.5 \text{MAD}$</div>
How is locally weighted regression derived?	\item Take the estimate of kernel regression and use a general kernel rather than a smoothing kernel:<div>\item $\hat f(x_*) =&nbsp;\sum \kappa(x_*, x_i) y_i$<br /></div><div>\item which effectively fits a constant function locally.&nbsp;</div><div>\item Then generalize it by fitting a linear function locally.</div>
What's the objective function in locally weighted regression?	<div>\item&nbsp;$\min_\beta \sum \kappa(x_*, x_i) [y_i - [\beta(x_*)]^Tx_i]$</div>
What's LOESS in ML?	\item Locally weighted scatterplot smoothing<div>\item a kind of locally weighted regression</div>
What's LOWESS in ML?	\item Another name for LOESS
In locally weighted regression, how are the parameters $\beta(x_*)$ computed for a test case?	\item By solving a least squares problem
Intuitively, what's a Gaussian process?	\item It's a distribution over the space of functions:<div>\item it assumes $p(f(x_1), \dotsc, f(x_N))$ is jointly gaussian,&nbsp;</div><div>\item with $\Sigma_{ij} = \kappa(x_i, x_j)$ being some positive definite kernel function</div><div>\item The idea is that if $\kappa$ considers $x_i, x_j$ to be similar, the value of the function at that point is similar too</div>
In the context of regression, what's the computational complexity of fitting a Gaussian process?	\item $O(N^3)$
What's a GP in ML?	\item A Gaussian process
What's kriging in ML?	\item Another name for Gaussian process regression
How is a Gaussian process usually denoted?	\item $f \sim \text{GP}(m, \kappa)$<div>\item where $m(x)$ is the mean function (usually 0)</div><div>\item and $\kappa(x_1, x_2)$ is the kernel/covariance function</div>
What's a SE kernel in ML?	\item A squared-exponential kernel, aka a Gaussian kernel
What's DACE in ML?	\item Design and Analysis of Computer Experiments<div>\item where you model a model with Gaussian process regression</div><div>\item so you can explore modifying the parameters of the simulation without actually rerunning the simulator</div>
What's the inversion lemma concerning $(M/H)^{-1}$?	<div>\item $(M/H)^{-1} = E^{-1} + E^{-1}F(M/E)^{-1}GE^{-1}$</div>
What's the inversion lemma concerning $(M/H)^{-1}FH^{-1}$?	<div>\item $(M/H)^{-1}FH^{-1} = E^{-1}F(M/E)^{-1}$</div><div><br /></div>
What's the matrix determinant lemma concerning $|M/H|$?	<div>\item $|M/H||H| = |M/E||E|$</div>
Given a block matrix $M = \left( \begin{smallmatrix} A &amp; B \\ C &amp; D \end{smallmatrix} \right)$, what's the Schur compliment $S_D$?	\item $S_D = A - BD^{-1}C$
Given a block matrix $M = \left( \begin{smallmatrix} A &amp; B \\ C &amp; D \end{smallmatrix} \right)$, what's the Schur compliment $S_A$?	\item $S_A = D - CA^{-1}B$
What's the inverse of a block matrix&nbsp;$M = \left( \begin{smallmatrix} A &amp; B \\ C &amp; D \end{smallmatrix} \right)$?	\item $M^{-1} = \left( \begin{matrix}<div>I &amp; -A^{-1} B \\</div><div>-D^{-1} C &amp; I</div><div>\end{matrix} \right)</div><div>%</div><div>\left( \begin{matrix}</div><div>S_D &amp; \\&nbsp;</div><div>&amp; S_A&nbsp;</div><div>\end{matrix} \right)^{-1}</div><div>$</div>
What's the joint distribution for a predictive GP on noise-free observations look like?	\item $\left( \begin{matrix} f \\ f_* \end{matrix} \right) = \mc{N}\left(\left( \begin{matrix} \mu \\ \mu_* \end{matrix} \right),&nbsp;\left( \begin{matrix} K &amp; K_* \\ K^T_* &amp; K_{**}&nbsp;\end{matrix} \right) \right)$<div>\item where $f, X$ are the training points and $f_*, X_*$ are the test points</div><div>\item and $K = \kappa(X, X), K = \kappa(X, X_*), K = \kappa(X_*, X_*)$</div>
How is a GP with noise-free observations used for prediction?	\item Construct the join distribution&nbsp;$p(f_*, f| X_*, X)$<div>\item Use the standard formula for conditioning Gaussians to deduce $p(f_*|X_*, X, f)$</div>
What's the joint distribution for a predictive GP given noisy observations?	\item The same as the noise-free distribution, but with $K$ replaced with $K_y = K + \sigma_y^2 I$<div>\item where the observations $y$ suffer noise $\epsilon \sim \mc{N}(0, \sigma^2_y)$<br /></div>
How can the posterior predicted mean on a test point $x_*$ be written for a GP with noisy observations?	\item $\bar f_* = \sum \alpha_i \kappa(x_i, x_*)$<div>\item where $\alpha = K^{-1}_y y$</div>
What's the factor analysis distance function?	\item $M(l) = \Lambda\Lambda^T + \text{diag}\left(\frac{1}{l^2}\right)$<div>\item where $\Lambda$ is a $D \times K$ matrix, with $K \ll D$</div>
What's the use of the factor analysis distance function?	\item When defining a Gaussian kernel over a vector space, a covariance matrix needs to be selected<br /><div>\item The factor analysis distance function $M(l)$ approximates the covariance matrix as a low rank matrix $\Lambda\Lambda^T$ plus a diagonal matrix $\text{diag}\left(\frac{1}{l^2}\right)$</div><div>\item where the columns of $\Lambda$ correspond to relevant directions,&nbsp;</div><div>\item and the $\text{diag}\left(\frac{1}{l^2}\right)$ defines the variance in the various dimensions &nbsp;</div>
How do you usually set the parameters for the kernel of a SVM?	<div>\item Cross-validation</div>\item Since the SVM's regularization strength is intertwined with the kernel's parameters, it usually has to be done on a grid
How are the kernel parameters for a GP usually estimated?	\item Empirical Bayes, with the pre-noise observations $f$ being marginalized out<br /><div>\item done with continuous optimization methods</div>
What are the components of the marginal likelihood when fitting a GP with noisy observations?	<div>\item $p(y|X) = -\frac{1}{2}yK^{-1}_y y - \frac{1}{2}\ln|K_y| + C$</div><div>\item where the first term describes how well the data fits the model</div><div>\item and the second term describes the complexity of the model</div>
Which covariance matrices generally have very high determinants?	\item Diagonal ones
Which covariance matrices generally have very low determinants?	\item Ones that are almost all $1$s
When fitting a GP, is the marginal likelihood convex wrt to the kernel parameters?	\item Not usually.
What's the `length scale' in GPs?&nbsp;	\item The variance of the kernel:&nbsp;<div>\item a small variance implies that similar points have little to do with eachother</div><div>\item so the function varies very rapidly</div>
How can you approximate the predictive posterior for a GP?	\item Calculate the MAP for the parameters<div>\item Sample points $s$ from around the MAP<div>\item $p(f|\mc{D}) \propto \sum_s w_s p(f|\mc{D}, \theta_s)p(\theta_s|\mc{D})$</div></div>
What's a central composite design in ML?	\item When approximating the posterior of a distribution by sampling points from around the MAP<div>\item it's the sampling strategy of picking points $\pm 1$ standard deviation along each dimension</div>
What's multiple kernel GP?	\item Rather than having a single kernel and optimizing its parameters<div>\item multiple kernel GP uses $\kappa(x, y) = \sum w_j \kappa_j (x, y)$</div><div>\item and optimizes the weights $w_j$</div>
Computationally speaking, what's tricky about calculating the predictive mean of a GP?	\item To compute the predictive mean, you have to invert $K_y$<div>\item which is often poorly conditioned. Cholesky decomposition is preferred.&nbsp;</div>
What's the computational complexity of fitting a GP?	\item The same as inverting $K_y$<div>\item usually $O(N^3)$ via Cholesky decomposition</div>
What's a semi-parametric GP?	<div>\item It's a linear model</div>\item $f(x) = \beta^T \phi(x) + r(x)$<div>\item where $r(x) \sim \text{GP}(0, \kappa)$ models the residuals</div>
What happens if the $\beta$ in a semi-parametric Gaussian process are drawn from a Normal distribution?	\item The semi-parametric model for $f(x)$ becomes a regular old GP
What's the model usually used to adapt GPs to binary classification?	<div>\item $p(y|x) = \text{sigm}(yf(x))$</div><div>\item and $f \sim \text{GP}(0, \kappa)$</div>
Why is the mean usually set to 0 in GP models?	\item Because it makes the math simpler&nbsp;<div>\item and the model can easily accomodate a non-zero empirical mean by raising the variance of the first few points</div>
How are GPs usually adapted to multiclass classification?	\item $y|x \sim \text{Cat}(\mc{S}(f(x)))$<div><div>\item where $f = [f_c]$ is a vector of $C$ latent functions, one for each label</div><div>\item where $f_c \sim \text{GP}(0, \kappa_c)$</div><div>\item and the softmax function $\mc{S}$ is applied componentwise</div></div>
When adapting GP to classification problems, how are the models usually fitted?	\item By analytically deriving the gradient \&amp; hessian<div>\item then applying IRLS to compute the MAP</div>
What model is usually used when adapting GPs for Poisson regression?	\item $y \sim \text{Poi}(r)$<br /><div>\item where $\ln r \sim \text{GP}(0, \kappa)$</div>
How do GPs compare to Bayesian linear regression?	\item Bayesian linear regression with covariance $\Sigma$ is equivalent to a GP with $\kappa(x, y) = x^T\Sigma y$<div>\item Note this is a degenerate covariance function, since it only has $\leq D$ nonzero eigenvalues</div>
What's the consequence of using a degenerate covariance function in a GP?	\item Underfitting usually, since the model isn't flexible enough capture the data<div>\item It'll be overconfident in its fit too, since it isn't aware of the alternatives not represented by the covariance function</div>
What kernel is usually used when constructing GPs over geographic data?	\item A Matern kernel.&nbsp;
What's a linear smoother in ML?	\item A regression function which is linear in its training inputs:<div>\item $\hat f(x_*) = \sum w_i(x_*) y_i$</div>
What's the difference between a linear smoother and a linear model?	\item A linear model is linear in all its inputs<div>\item A linear smoother is only linear wrt the training responses</div>
What're the most common linear smoothers in ML?	\item Kernel regression<div>\item Locally weighted regression</div><div>\item Smoothing splines</div><div>\item GP regression</div>
What's an equivalent kernel in ML?	\item When interpreting a Gaussian process as a linear smoother, the weight functions are found to depend on the inverse of $K$.&nbsp;<div>\item This clouds the issue of whether the weight function has local support<div>\item An equivalent kernel is a $\kappa^\prime$ in terms of which the weight functions can be approximated which clearly demonstrates whether the weights are local or not</div></div>
How does the form of a GP classifier compare to a SVM?	\item In the objective they have the same regularization term $\ln |K|$<div>\item but different likelihoods - hinge in the SVM case and a Gaussian noise likelihood $p(y|f)$ in the GP case</div>
How do sparse kernel machines relate to linear models?	\item They're just linear models with a basis of the form $\phi(x) = [\kappa(x, x_i)]_i$
What's the effective objective function for fitting a univariate smoothing spline?&nbsp;	\item $J(f) = \text{RSS}(f) + \lambda \int \left[\frac{d^m f}{dx^m}(x)\right]^2 dx$<div>\item where the first term controls the fit</div><div>\item and the second term controls the smoothness</div>
What's the form of a univariate smoothing spline?	\item On inputs $\{x_i\}$ with a $m$th-derivative objective, it's a piecewise polynomial&nbsp;<div>\item of degree $2m-1$ in the intervals $[x_i, x_{i+1}]$</div><div>\item and of degree $m-1$ in the tails</div>
How are univariate splines usually fit?	\item Conceptually easiest way is to use ridge regression<div>\item but there are linear time methods too</div>
What's a `knot' with respect to splines?	\item It's the point where two of the polynomial pieces in a spline connect
What're the parameters used for spline regression?	\item The knots and scaling coefficients
What's the method of penalized splines in ML?	\item It's spline regression with a $l_2$ regularizer on the scaling coefficients of each polynomial piece
How are smoothing splines related to GPs?	\item If a regression GP has the kernel $\kappa_{sp}(x, y) = \int_0^1 (x - u)_+(y - u)_+ du$<br /><div>\item then the MAP estimate will be a cubic spline</div><div>\item This is a pretty unnatural kernel though!</div>
What's a thin plate spline in ML?	\item It's a generalization of splines to 2D<div>\item with a regularizer that minimizes $\|\nabla^2 f\|^2$</div>
How can a positive definite kernel be used to construct a RKHS?	\item Since it's positive definite, $\kappa(x, y) = \sum \lambda_i \phi_i(x) \phi_i(y)$<div>\item and if we suppose $f = \sum f_i \phi_i$</div><div>\item then we can define $\langle f, g \rangle = \sum \frac{1}{\lambda_i} f_i g_i$</div><div>\item Then we get the reproducing property $\langle \kappa(x, \cdot), \kappa(y, \cdot) \rangle = \kappa(x, y)$</div>
What's a RKHS in ML?	\item A reproducing kernel Hilbert space; ie a Hilbert space with a kernel $\kappa$ such that<div>\item $\langle \kappa(x, \cdot), \kappa(y, \cdot) \rangle = \kappa(x, y)$</div>
What's the representer theorem in ML?	\item Define an objective $J(f) = L(f) + \frac{1}{2}\|f\|^2_H$<div>\item where $L$ is some convex loss function (like the RSS)</div><div>\item and $\|f\|_H$ is the norm generated by a positive definite kernel $\kappa$</div><div>\item Then the minimizer of $J$ can be written as $f(x) = \sum \alpha_i \kappa(x, x_i)$</div>
How does RKHS regression relate to GPs?	\item Linear regression with a RKHS regularizer generated by $\kappa$<div>\item is identical to MAP estimation with a GP with kernel $\kappa$</div>
What's the model used in GP-LVM?	<div>\item It's based &nbsp;on PCA, but we integrate out $W$, optimize over $Z$, and replace the linear kernel $ZZ^T$ of the latent space with our own kernel $K$. This gives</div><div>\item $y_i|K, \sigma^2 \sim \mc{N}(y_i | 0, K + \sigma^2 I)$</div>
What's a GP-LVM in ML?	\item A Gaussian process latent variable model
How are GP-LVMs usually fit?	\item Gradient based optimization
How do GP-LVMs compare to kPCA?	\item In kPCA we learn a kernelized mapping from the observed space to the latent space<div>\item In GP-LVM we learn a kernelized mapping from the latent space to the observed space</div><div>\item The latter is usually much more effective</div>
What's the main drawback of GPs?	\item They're not sparse, so they'll usually take $O(N^3)$ time to fit
What are template matching methods in ML?	\item Ones which essentially try to represent inputs as a combination of prototypes $\mu_k$
What's the most common example of template matching algorithms in ML?	\item Kernel methods
What's the ARD kernel?	\item $\kappa(x, y) = \theta_0 \exp( -\frac{1}{2}\sum \theta_i (x_i - y_i)^2)$
What's the biggest problem with kernel methods?	\item You need to know a good kernel first
What's the form of an ABM?	\item $f(x) = w_0 + \sum_1^M w_m \phi_m(x; v_m)$<div>\item where $v_m$ are the parameters for basis function $\phi_m$</div>
What's ABM stand for in ML?	\item Adaptive basis function model
What's CART stand for in ML?	\item Classification and regression tree
What's a decision tree in ML?	\item Another name for a CART
What's the idea behind CARTs in ML?	\item Recursively partition the input space<div>\item and define a local model in each space</div>
What's the axis-parallel split model in ML?	\item A CART where each node asks whether the input $j$th component is greater or less than a specified threshold<br />
How can a CART model be used for classification?	\item By storing the distribution over class labels in each leaf
How are CART models with axis-parallel split nodes usually fit?	\item A cost function is defined over the space of datasets $\text{cost}(\mc{D})$<div>\item then the space is partitioned recursively:&nbsp;</div><div>\item at each step, if there is a node deemed by some worth-splitting-function to be worth splitting,&nbsp;</div><div>\item the algorithm searches for the dimension $j$ and threshold $t$ such that splitting the data along $j$ at $t$ minimizes&nbsp;$\text{cost}(\mc{D}_L) + \text{cost}(\mc{D}_R)$, where $\mc{D}_L, \mc{D}_R$ are the datapoints to the left \&amp; right of the threhold</div>
When fitting CART trees, what are common heuristics used in deciding whether to split a node?	\item Will the reduction in cost be sufficiently large?<div>\item Has the tree exceeded maximum depth?</div><div>\item Is the data at the node sufficiently homogeneous?</div><div>\item Is there enough data at the node to be worth splitting?</div>
In classification problems, what's it mean for a subset of the data to be pure?	\item The classification labels are all the same.
define model identifiability	a model for which it is possible to identify the true values of the underlying parameters after obtaining an infinite number of observations for it <br />&gt; as opposed to models for which different combinations of the parameters do not yield different probability distributions for the observed variables 
When fitting a CART for regression, what's the usual cost function?	\item The SSE<br />
When using CART for regression, what's an alternative to the $\sum_\mc{D} (y_i - \bar y)^2$ cost?	\item Fit a linear regression model for each leaf<div>\item using as inputs the features that were chosen on the path from the root</div><div>\item and use the residual error as the cost function</div>
When you're fitting a CART for classification, what are some common cost functions that are used?	\item First, fit a multinouilli model to the data in the leaf, giving class probabilities $\hat \pi_c$<div>\item Then common cost functions are</div><div>\item misclassification rate of the most probable class label by the model</div><div>\item entropy of the model</div><div>\item Gini index of the model</div>
What's the deviance of a multinouilli distribution?	\item Another name for its entropy
What's the information gain of a test?	\item It's the change in entropy between some distribution $Y$ and that distribution when conditioned on a specific outcome of the test, $Y|t(X) = c$
What's the Gini index of a multinouilli distribution?	\item If the distribution has class probabilities $\pi_c$,<div>\item $\sum_c \pi_c(1-\pi_c)$</div>
What's the usual interpretation of the Gini index of a multinouilli distribution?	\item It's the expected error rate;<div>\item $\pi_c$ is the probability of outcome $c$ and $1 - \pi_c$ is the probability it'll be misclassified</div>
What's the usual indicator of overfitting in ML?	\item Validation set error being much higher than training set error
What's the use of pruning in ML?	\item When fitting a CART,&nbsp;<br /><div>\item it's hard to make a good judgement as&nbsp;to whether to split the data at a node using just the next split</div><div>\item Instead, it's better to be liberal when growing the tree, then prune it afterwards by cutting off subtrees that give small reductions in the cost&nbsp;</div>
What's the usual rule of thumb used when pruning CARTs in ML?	\item Evaluate the error of each rooted subtree using cross-validation<div>\item then pick the smallest one within 1 standard deviation of the error of the best&nbsp;</div>
What're the advantages of CART models?	\item They can be converted into logical rules<div>\item They can handle a wide range of inputs</div><div>\item They perform automatic variable selection</div><div>\item They're robust to outliers</div><div>\item They scale well</div>
What're the disadvantages of CART models?	\item They're not very good predictors compared to other kinds of model<div>\item They're unstable - small changes in the input can have large effects on the structure of a tree</div>
How are CART trees usually adapted to handle missing data?	\item Surrogate splits<div>\item Add `missing' as a new value and treat the data as fully observed</div>
What're surrogate splits in CART fitting?	\item During training, for each decisive variable look for other variables with which it is strongly correlated<br /><div>\item If the decisive variable is missing at test time, the surrogate variable(s) can be used instead</div>
What's bagging in ML?	\item If you've got an unstable model/high-variance estimator (like a CART tree)<div>\item then you can reduce the variance by training $M$ different models on different subsets of the data</div><div>\item and then averaging their output</div>
What's the usual problem with bagging in ML?	\item Learning models on different subsets of the same data is prone to producing highly-correlated predictors,&nbsp;<div>\item which limits the variance reduction</div>
What's the random forests approach to improving CARTs?	\item Training several trees on different subsets of the data \emph{and}&nbsp;different subsets of the variables<div>\item then averaging their output</div><div>\item This leads to very accurate predictors!</div>
What're the Bayesian alternatives to bagging?	\item MCMC sampling over the space of model&nbsp;ensembles<div>\item Bayesian inference over the space of model ensembles</div>
What's BART in ML?	\item Bayesian adaptive regression trees<div>\item It's a Bayesian alternative to bagging, which uses Bayesian inference over the space of CARTs to generate the ensemble of CARTs to average</div>
What's a popular alternative to CART models?	\item Hierarchical mixtures of experts
What're the main advantages of HME over CART?	\item HMEs make predictions by averaging over all experts, whereas CARTs just use the model in the leaf<div>\item Fitting a HME involves smooth optimization, vs CARTs greedy discrete approach</div><div>\item It's much easier to take a Bayesian approach to the parameters of a HME than it is a CART</div>
What's the form of a generalized additive model?	\item $f(x) = \alpha + f_1(x_1) + \dotsb + f_D(x_D)$<div>\item where the $f_i$ are modelled by some scatterplot smoother</div><div>\item and $f(x)$ can be mapped to $p(y|x)$ using a link function (like in a GLM)</div>
What's the two kinds of function usually used for the $f_i$ in a generalized additive model?	<div>\item Regression splines</div>\item or more commonly, smoothing splines
When constructing generalized additive models, what's the convention that ensures the additive constant $\alpha$ is uniquely identifiable?	\item Assume $\sum_i f_j(x_{ij}) = 0$
What's the backfitting algorithm for generalized additive models?	\item Fit $\hat \alpha = \frac{1}{N}\sum_i y_i$<div>\item Center the responses: $y_i^\prime = &nbsp;y_i - \hat \alpha$</div><div>\item Update each $f_j$ in turn, using as a target vector the residuals obtained when $f_j$ is omitted</div><div>\item When it converges, ensure the output of each $\hat f_j$ is zero by setting $\hat f_j = \frac{1}{N}\sum \hat f_j(x_{ij})$&nbsp;</div>
What's the sufficient condition for the backfitting algorithm to find a global optimum of a generalized additive model?	\item $X$ has full column rank.<br />
How can the backfitting algorithm be applied to NNs with a top-level GLM?	\item Replace the weighted least squares step of IRLS with a backfitting algorithm where the responses are weighted
What's a GAM stand for in ML?	\item Generalized additive model
What's the computational complexity of fitting a GAM?	\item Using backfitting it's $O(NDT)$, where $T$ is the number of iterations
What's MARS stand for in ML?	\item Multivariate adaptive regression splines
How is a MARS model constructed?	<div>\item $\mc{C} = \{(x_j - t)_+, (t - x_j)_+ : t \in \{x_{ij}\}_i\}_j$</div><div>\item $\mc{M} = \{1\}$</div><div>\item At each step, pick a $h_m \in \mc{M}$ and a reflecting pair $c_1 = (x_j - t)_+, c_2 = (t- x_j)_+$ from $\mc{C}$</div><div>\item Add $h_m c_1, h_m c_2$ to $\mc{M}$ and fit a linear combination of them to the current residual.</div><div>\item When the order of interactions becomes too large, stop adding terms.</div><div>\item Then prune out terms, starting with the one that causes the smallest increase in residual error, until the CV error stops improving.</div>
What's a reflecting pair in MARS?	\item $(x_j - t)_+, (t - x_j)_+$ for some $t \in \{x_{ij}\}_i$
Intuitively, what's the boosting technique in ML?	\item Some basis functions $\phi_i$ are generated by a `base learner' algorithm<div>\item and the base learner is repeatedly applied to weighted versions of the data</div><div>\item where more weight is given to examples that were misclassified in earlier rounds</div>
What's a weak learner in ML?	\item It's another name for the base learner in boosting
What weak learner is boosting most commonly used with?	\item CART models
How do boosted decision stumps compare with the alternatives?	\item Very, very well.<div>\item They turn out lower errors and better-calibrated probabilities than random forests</div><div>\item and are much better than single decision trees</div>
What's the guarantee provided by boosting?	\item For binary classification, it's been proven that any weak learner can be boosted to arbitrarily high performance on the training set<div>\item if it does better than random chance in the first place</div>
What's a decision stump in ML?	\item A 2-leaf CART, usually used for boosting.
How does boosting perform in terms of overfitting?	\item It's very resistant to it<div>\item Often the error on the test set will continue dropping some time after it's reach zero on the training set</div>
How can boosting be viewed from a theoretical perspective?	\item It's a form of gradient descent in the space of functions
What's the optimization problem used in boosting?	\item $\min_f \sum_i L(y_i, f(x_i))$<div>\item where $L$ is a loss function</div><div>\item and $f$ is a ABM</div>
What's L2Boosting?	\item It's forward stagewise additive modelling with a L2 loss<div>\item where $\beta = 1$&nbsp;</div><div>\item and at each step the weak learner is asked to predict the residual</div>
What's gradboost?	\item It's a generic stagewise boosting algorithm that'll work for any loss function
What's adaboost?	\item It's forward stagewise additive modelling with an exponential loss function.<br />
What's logitboost?	\item It's a forward stagewise additive model with a logloss function<div>\item where optimization over $\phi$ is done by using a Newton update scheme</div>
What estimate do you get from optimizing the exponential loss for a binary classifier?&nbsp;	\item $\frac{1}{2}\ln\frac{\pi}{1-\pi}$
What estimate do you get from optimizing the logloss for a binary classifier?	\item $\frac{1}{2}\ln\frac{\pi}{1-\pi}$
What're the two most common smooth upper bounds on the 0-1 loss?	\item Exponential loss<div>\item Logloss, which is nicer computationally</div>
What's the logloss function for binary labels?	\item $\ln(1 + e^{-yf(x)})$
What's the exponential loss function for binary labels?	\item&nbsp;$\exp(-yf(x))$
What's the forward stagewise additive modeling method?	\item A boosting technique:<div>\item $f_0(x) = \arg \min_\gamma \sum_i L(y_i, f(x_i; \gamma))$</div><div>\item Then for $M$ iterations,</div><div>\item $(\beta_m, \gamma_m) = \arg \min_{\beta, \gamma} \sum_i L(y_i, f_{m-1}(x_i) + \beta\phi(x_i;\gamma))$</div><div>\item $f_m(x) = f_{m-1}(x) + \beta_m\phi(x;\gamma_m)$</div><div>\item where $\phi$ is the function generated by the weak learner</div>
What's the main tuning parameter in forward stagewise additive modelling?	\item The number of iterations $M$
What are common criteria for picking the number of iterations $M$ in forward stagewise additive modelling?	\item Early stopping: monitor performance on a separate training set and terminate if it starts to decrease<div>\item Alternatively, use model selection criteria like AIC/BIC</div>
What's the shrinkage approach to improving forward stagewise additive modelling?	\item Use updates of the form<div>\item $f_m(x) = f_{m-1}(x) + \nu\beta_m\phi(x;\gamma_m)$</div><div>\item where $0 &lt; \nu \leq 1$ is the shrinkage parameter</div>
What's the shrinkage parameter in forward stagewise additive modelling usually set to?	\item $\nu \approx 0.1$
What's least squares boosting?	\item Another name for L2boosting
What's a common speed optimization to adaboost?	\item The weights can be updated in an online manner
What're the problems with exponential loss?	\item It puts a lot of weight on misclassified examples,&nbsp;which makes it very sensitive to outliers<div>\item It's not the logarithm of any pmf for binary variables, so it can't be used to recover a probability estimate</div>
What objective is the weak learner passed in adaboost?	<div><div>\item At each step, let</div><div>\item $w_i = \exp(-y_i f_m(x_i))$ be the weights</div><div>\item and ask the weak learner to solve $\phi = \arg\min_{\phi^\prime} w_i \mbb{I}(y \neq \phi^\prime(x_i))$</div></div>
How is the solution updated in adaboost?	\item Given weights $w_i$ and a $\phi$ from the weak learner, let&nbsp;<div><div><div><div>\item $\text{err} = \frac{1}{\sum w_i} \sum w_i \mbb{I}(y_i \neq \phi(x_i))$ be the weighted misclassification rate</div></div></div><div>\item $\beta^\prime = \frac{1}{2}\ln \frac{1 -\text{err}}{\text{err}}$</div><div>\item $f^\prime(x) = f(x) + \beta^\prime \phi(x)$</div></div>
What's the update rule in gradient boosting?	\item Given a loss function $L(y, f)$ and approximation $f_m$, calculate<div>\item $g_i = \left[\frac{\partial L(y_i, f(x_i))}{\partial f(x_i)}\right]_{f_m}$</div><div>\item Then ask the weak learner to solve</div><div>\item $\gamma = \arg\min_\gamma \sum(-g_i -\phi(x_i;\gamma))^2$</div><div>\item and set&nbsp;</div><div>\item $f_{m+1} = f_m(x) + \nu \phi(x;\gamma)$</div><div>\item where $\nu$ is the step size, either constant or found by some linesearch alg</div>
What's binomialboost in ML?	\item It's gradient boosting with a logloss function
What's sparse boosting in ML?	\item It's boosting with a weak learner that just picks the variable which best predicts the residual
What're two other names for sparse boosting?	\item Matching pursuits<div>\item Forward stagewise linear regression</div>
How is sparse boosting related to LARS?	\item As the shrinkage in the update $\nu \rightarrow 0$, it turns into LAR<div>\item with the number of updates $m$ corresponding to the LAR regularization penalty $\lambda$.</div><div>\item If boosting is further modified to allow some variable deletion steps, full LARS is recovered</div>
What's the boosting variant of MARS?	\item Sparse boosting but with smoothing splines rather than linear regression when mapping from the chosen variable $x_j$ to the residual
Why should shallow trees usually be used when applying boosting to CART?	\item Because their variance is low
What's the MART model in ML?	\item The multivariate adaptive regression tree model<div>\item which is gradient boosting with a shallow regression tree as the weak learner</div><div>\item with the modification that after a tree is fitted, the parameters in the leaves are re-estimated to minimize the loss</div>
Intuitively, what are the two reasons boosting performs so well?	\item It's a sort of $l_1$ regularization, but in reverse: rather than starting with a large set of weakly-learnt $\phi_k$ and selecting a subset, you start with the empty step and at each step add a new $\phi_k$<div>\item It can be shown that boosting maximizes the margin</div>
What's L1-Adaboost in ML?	\item A combination of adaboost and $l_1$ regularization<div>\item which greedily adds the best features $\phi_m$ using adaboost</div><div>\item then prines off the irrelevant ones using $l_1$ regularization</div>
How can boosting be viewed from a Bayesian perspective?	\item The output of a boosting algorithm is basically a mixture of experts model<div>\item and the process of boosting can be viewed as a one-at-a-time version of EM:</div><div>\item In the E step, the posterior responsibilities will reflect how well the existing experts explain a datapoint, and if it's a poor fit those datapoints will have the greatest influence on the next expert</div><div>\item and in the M step, we adjust the new expert to best explain the residual between the posterior and the sample</div>
What's the usual consequence of boosting's inability to alter the weight assigned to a $\phi$ it's already added?	\item Unnecessarily large models, since the only option thing the algorithm can do is to re-add the weak learner with a different weight
Conceptually, what's a neural network?	\item A bunch of logistic (or similar) regressions stacked on top of eachother<div>\item with the top layer being either</div><div>\item another logistic (or similar) regression (for classification)</div><div>\item or a linear regression model (for regression)</div>
What's the formal model of a two layer regression neural network?	\item $y|x \sim \mc{N}(w^Tz(x), \sigma^2)$<div>\item $z(x) = g(Vx)$</div><div>\item where $g$ is the activation function, which is applied componentwise&nbsp;</div>
What's a transfer function in neural networks?	\item Another name for an activation function
What are the most common activation functions in neural networks?	\item Sigmoid<div>\item Tanh</div><div>\item Rectified linear units</div>
What's a ReLU in neural networks?	<div>\item Rectified linear unit</div>\item A common transfer function, with the form $\max(0, u)$
What're the hidden layers in neural networks?	\item All the variables except the output and the inputs
What's a mutual inhibition arc in neural networks?	\item An edge between two (or more) outputs that ensures only one of them turns on
What's a multilayer perceptron in ML?	\item Another name for neural networks
What's a universal approximator in ML?	\item A system that can model any suitably smooth function to any desired level of accuracy
What's the most common kind of universal approximator?	\item Neural networks
What's a MLP in ML?	\item A multilayer perceptron
What's the purpose of the hidden layers in a neural network?	\item To learn nonlinear combinations of the inputs, ie feature extraction
When is feature extraction important in ML?	\item When the individual inputs aren't individually very informative (like pixels)
What's a convolutional neural network?	\item One in which each hidden unit takes inputs from a contiguous chunk of the previous layer, its `receptive field'&nbsp;<div>\item and where the weights are tied across the image</div>
What's the use of tying the weights of different hidden units in a neural network together?	\item It ensures that if a feature is learnt from one part of the input domain, it'll be recognised if it appears in other parts&nbsp;<div>\item ie the network is translation invariant</div>
What's a feature map in neural networks?	\item It's the output of a set of replicated hidden units, each corresponding to a different contiguous chunk of the input and with their parameters all tied.<br /><div>\item Each one effectively recognises the same feature, but in different parts of the input</div>
When training neural networks, what's a standard trick to expand the training set?	\item Generate distorted versions of the original data<br />
What's a simple way of generating distorted versions of images?	<div>\item Generate \&amp; apply a random flow field</div>
What's a subsampling layer in neural networks?	\item One which computes a a summary function over each small window in the input&nbsp;
What's a skip arc in a neural networks?	\item An arc that goes directly from input to output
What's a recurrant neural network in ML?	\item One with feedback arcs, forming a nonlinear dynamical system
What's a RNN in ML?	\item Recurrant neural network
What task are RNNs particularly good at?	\item Natural language modelling
What's the main problem with RNNs?	\item They're very hard to train, as the gradient in the weight space commonly vanishes
What's a LSTM in ML?	\item A long short-term memory model<div>\item a variant of RNNs that tries to solve the vanishing gradient problem RNNs are prone to</div>
What's a Hopfield network in ML?	\item A neural network that permits symmetric connections
What's associative memory another name for in ML?	\item A Hopfield network
What's the probabilistic counterpart of a Hopfield network?	\item A Boltzmann machine
What kind of optimization strategy are neural networks usually trained using?&nbsp;	\item Online first-order methods, since they usually use very large training sets
What are the pre- and post-synaptic values in the hidden layers of neural networks?	\item The pre-synaptic value is $a = Vx$, before any nonlinearity is applied<div>\item The post-synaptic value is $z = g(a)$, after the nonlinearity is applied</div>
What are the pre- and post-synaptic values in the output layer of a neural network?	\item The pre-synaptic value is $b = Wz$, before any nonlinearity is applied<div>\item The post-synaptic value is $\hat y = h(b)$, after the nonlinearity is applied</div><div>\item where, if a GLM is being used, $h$ is the canonical link function</div>
What's a NN in ML?	\item Neural network
How are offset/bias terms usually accounted for in NNs?	\item By clamping some variable in each layer to 1
What's the objective used by the backpropagation algorithm for regression problems?	\item $\text{RSS}$
What's the objective used by the backpropagation algorithm for classification problems?	\item The cross entropy
What's the idea in the backpropagation algorithm for NNs?	\item Calculate the gradient of the NLL by applying the chain rule of calculus to the output<div>\item then apply a gradient descent routine</div>
What activation functions are generally preferred when designing neural networks?	\item For hidden nodes, because it's symmetric around 0<div>\item Sigmoid for output nodes, because it's symmetric around 1/2</div>
What does $\delta^v_j$ usually stand for in the context of NNs?&nbsp;	<div>\item If $a$ is the pre-synaptic output of the layer with weights $V$, it's&nbsp;</div>\item&nbsp;$\delta^v_j =&nbsp;\frac{\partial J}{\partial a_j}$<div>\item ie the error signal for that layer</div>
Given a NN with top layer with weights $W$ and a hidden layer with weights $V$, how does backpropagation calculate the error signal for the hidden layer?&nbsp;	\item $\delta^v_j = g^\prime(a_j) w_{:,j}^T \delta^w$<div>\item where $\delta^w$ is the error signal in the top layer</div>
What're the steps in the backpropagation algorithm for training a NN?	\item On input $x$,<div>\item make a forward pass through the network to calculate the pre \&amp; post-synaptic outputs</div><div>\item Then compute the error signal for the top layer $\delta^{(L)}$</div><div>\item and repeatedly backpropagate it to calculate the error signals $\delta^{(l)}$ for all the previous layers</div><div>\item Having done this for all inputs $x_n$, the gradient for layer $l$ is $\sum_n \delta^{(l)}_n z_n$</div><div>\item where $z_n$ is the output of the previous layer</div>
Under the canonical link function, what's the error signal for the top layer of a NN?	\item $\delta^{(L)} = \hat y - y$
What's the identifiability problem with NNs?	\item On a hidden layer with $H$ units<div>\item we can flip all the inputs \&amp; outputs and get the same result, giving $2^H$ equivalent settings of the parameters</div><div>\item and we can change the identities of all the hidden units and get the same result, giving $H!$ equivalent settings of the parameters</div>
How do NN training algorithms usually deal with local minima?	\item Add more data and use a stochastic method<div>\item Perform multiple restarts and pick the model with the best performance&nbsp;</div><div>\item Average the outputs of multiple models (\emph{don't} average the parameters though, they're unidentifiable!)</div>
What's weight decay in the context of NNs?	\item Regularizing a NN model by imposing a prior of $\mc{N}(0, \frac{1}{\alpha}I)$ on the weights<div>\item giving a gradient of $\sum \delta_n^{(l)} z_n + \alpha v$</div>
What's the main reason to center \&amp; normalize the variances of the input in ML? &nbsp;	\item Because then spherical priors make sense.
How is overfitting usually suppressed when training NNs?	\item Early stopping<div>\item Weight decay</div>
How should the layer size for a NN be chosen?	\item As large as is feasible,<div>\item since with sufficiently strong regularization the excess units will be ignored</div>
Why shouldn't the same regularization prior be used for different layers of a NN?	\item Because suppose we shift or scale the training set<div>\item Then we'd like the NN to learn the same function by suitably scaling its internal weights \&amp; bias terms</div><div>\item But this scaling is different for different layers</div><div>\item so a different regularization strength is needed for different layers</div>
What's soft weight sharing in the context of NNs?	\item It's a way to regularize parameters such that similar weights will share statistical strength<div>\item achieved by modelling the weight prior as a mixture of diagonal Gaussians.&nbsp;</div><div>\item Similar weights will have the same mean and variance, and so will draw from the same Gaussian in the mixture</div>
What's a CNN in ML?	\item Convolutional neural network
What's semi-supervised embedding?	\item A way to force neural networks to treat similar objects similarly:<div>\item Let $f(x_i)$ be an embedding of object $x_i$ (ex: $f(x_i)$ is the output of a layer in the NN)</div><div>\item Let&nbsp;$S_{ij}$ indicate whether $x_i$ \&amp; $x_j$ are similar</div><div>\item Define a loss function $L(f(x_i), f(x_j), S_{ij})$ that encourages $f(x_i)$ to be close to $f(x_j)$ if $S_{ij} = 1$</div><div>\item Then the loss function for the network as a whole (usually the NLL) can be augmented with $\lambda L$, with $\lambda$ describing the strength of the supervision</div>
What's the standard algorithm for training NNs with semi-supervised embedding objectives?	\item Adapt stochastic gradient descent:<div>\item First pick a random $(x_n, y_n)$ and take a gradient step to optimize the NLL</div><div>\item Then pick a pair of similar $x_i, x_j$ and take a gradient step to optimize $\lambda L(f(x_i), f(x_j), 1)$</div><div>\item Then pick a random $x_k$ to form the (very probably) dissimilar pair $x_i, x_k$ an take a gradient step to optimize $\lambda L(f(x_i), f(x_k), 0)$</div>
What's an ensemble learning model?	\item $f(y|x, \pi) = \sum_m w_m f_m(y|x)$<div>\item where each $f_m$ is a base model and the $w_m$ are parameters</div>
What's a committee method in ML?	\item Another name for ensemble learning
What's stacking in ML?	\item Training an ensemble model by solving<div>\item $\hat w = \arg \min_w \sum_i L(y_i, \sum_m w_m \hat f_m^{-i}(x))$</div><div>\item where $\hat f^{-1}$ is the model trained without $(x_i, y_i)$</div>
What's the use of stacking in ML?	\item It's much more robust against overfitting than the naive approach which doesn't leave one input out
What's the error correcting output codes approach in ML?	\item A form of ensemble learning where the class labels are encoded with an ECC&nbsp;<div>\item then each bit is predicted using an individually-trained classifier</div>
What's BMA stand for in ML?	\item Bayes model averaging.
What's stochastic gradient boosting?	\item Gradient boosting but at each step, choose a different fraction (usually 80\%) of the data to use
What's a partial dependence plot?	\item A way of visualizing black-box models:<br /><div>\item pick a subset of variables $S$&nbsp;</div><div>\item plot $f(z_S) = \frac{1}{N} \sum_i f(x_i^\prime)$</div><div>\item where $x_i^\prime$ is $x_i$ with the variables in $S$ replaced with $z_S$</div><div>\item effectively averaging out all but the variables in $S$</div>
How can you determine the relative importance of predictor variables in ensembles of trees?	\item Calculate the fraction of nodes in which variable $j$ is used.
What's the joint distribution of a first order Markov model?	\item $p(X_{1:T}) = p(X_1)\prod p(X_t | X_{t-1})$
What's the transition function in a Markov model?	\item The $p(X_t|X_{t-1})$
What's a Markov chain?	\item Another name for a Markov model
What's a homogeneous Markov chain?	\item One whose transition function is independent of time
What're two other names for a homogeneous Markov chain?	\item Stationary<div>\item Time-invariant</div>
Conceptually, what's a stochastic process?	\item It's a generalization of probability distributions to the space of functions<br />
What's a finite-state Markov chain?	\item One where $X_t \in \{1, \dotsc, K\}$
What's the transition matrix of a discrete-state Markov chain?	\item The $A$ such that $A_{ij} = p(X_t = j| X_{t-1} = i)$
What's a stochastic automaton equivalent to?	\item A stationary, finite-state Markov chain
What's a left-to-right transition matrix?&nbsp;	\item An upper triangular transition matrix&nbsp;<div>\item that corresponds to a Markov chain where the states can be numbered left-to-right and no transition ever goes left</div>
What're the Chapman-Kolmogorov equations?	\item $A(m+n) = A(m)A(n)$<div>\item for a homogeneous discrete-state Markov chain</div>
What's $A(m)$ denote in the context of a Markov chain?	\item The $m$-step transition matrix,<div>\item $A_{ij}(m) = p(X_{t+m}=i| X_t = j)$</div>
What's a $k$th order Markov model?	\item One where the transitions consider the last $k$ states
What's an $n$-gram model?	\item An $n$th order Markov chain whose state space is all words
What's the MLE for an bigram model?	\item Let $N_j^1$ be the count of the number of times a sentance starts with $j$<div>\item Let $N_{jk}$ be the number of times $j$ is followed by $k$</div><div>\item Then</div><div>\item $\hat \pi_j \propto N^1_j$</div><div>\item $\hat A_{jk} \propto N_{jk}$</div>
What's $\pi$ represent in the context of Markov models?	\item Some kind of distribution over the states of the model<div>\item usually the initial one or a stationary one</div>
When is the zero-count problem particularly noticeable with $n$-gram models?	\item Whenever the number of states $K$ or the order $n$ is particularly large,&nbsp;<div>\item since $n$-gram models have $O(K^n)$ states&nbsp;</div>
What's deleted interpolation in the context of $n$-gram models?	\item Avoiding the sparse data problem by interpolating between the unigram and bigram frequencies in the transition matrix:<div>\item $A_{ij} = (1-\lambda)f_{ij} + \lambda f_j$</div>
What're the unigram frequencies in an $n$-gram model?	\item $f_k = \frac{N_k}{N}$<div>\item where $N_k$ is the count of unigram $k$</div>
What're the bigram frequencies in a Markov model?	\item $f_{ij} = \frac{N_{ij}}{N_i}$
What's backoff smoothing in the context of $n$-gram models?	\item If a bigram frequency $f_{ij}$ is too small we `back off' to a more reliable estimate $f_j$&nbsp;
What's the Bayesian view of backoff smoothing?	\item Draw the $i$th row of the transition matrix $A_i$ from $\text{Dir}(\alpha_0 m)$<div>\item where $\alpha_0$ is the prior strength and $m$ are the prior means.</div><div>\item Then the posterior is $A_i \sim \text{Dir}(\alpha + N_i)$, where $N_i$ is composed of the transition counts $N_{ij}$</div><div>\item This model will back off to $m$ as the regularization is increased rather than $f_i$ though</div>
When using a Dirichlet distribution for the prior of a bigram model's transition matrix, how should the prior strength $\alpha_0$ and means $m$ be chosen?	\item Either empirical Bayes<div>\item or $m_k \propto |\{i : N_{ij} &gt; 0\}|$, ie $j$'s prior is proportional to the number of bigrams in which it occurs</div>
How do $n$-gram models usually handle novel words?	\item Every novel word in the input is replaced with `unk'
What's the stationary distribution of a Markov chain?	\item The $\pi$ such that<div>\item $\pi = \pi A$</div>
What're the global balance equations?	\item $\pi_i \sum_{j \neq i} A_{ij} = \sum_{j \neq i} \pi_j A_{ji}$<div>\item the probability of $i$ times the net flow out of $i$</div><div>\item is equal to</div><div>\item the probability of each $j$ times the probability of moving into $i$</div>
How can the stationary distribution be computed for positive transition matrices?	\item Find the eigenvectors of $A^T v = v$
How can the stationary distribution be computed for \emph{non-negative} transition matrices?	\item We've got $K+1$ constraints from $\pi = \pi A$ and $\pi\mb{1} = 1$, and $K$ free variables.<div>\item So replace the last column of $I - A$ with $\mb{1}$ to get the matrix $M$,&nbsp;</div><div>\item and let $r = [0, \dotsc, 0, 1]$</div><div>\item Then solve $\pi M = r$.</div>
What's an absorbing state in a Markov model?	\item One where once the model's entered the state it can't leave it
What's an irreducible Markov model?	\item One which is strongly connected
What's the limiting distribution of a Markov model?	\item $\pi_j = \lim_{n \rightarrow \infty} A_{ij}(n)$, if it exists
What's the period of a state in a Markov model?	\item $d(i) = \text{gcd} \{t : A_{ii}(t) &gt; 0 \}$
When is a state in a Markov model aperiodic?	\item When its period is 1
When is a Markov model aperiodic?	\item When all its states are aperiodic
What's the theorem concerning when a finite-state Markov model has a stationary distribution?	\item Every irreducible, aperiodic, finite-state Markov chain has a unique limiting distribution which is equal to its stationary distribution.
What's a regular Markov model?	\item One where for some $n$, $A_{ij}(n) &gt; 0$<div>\item ie every state is reachable from every other in bounded time</div>
What's the theorem concerning when an Markov model - finite or not - has a stationary distribution?	\item Every irreducible, ergodic Markov chain has a unique limiting distribution which is equal to its stationary distribution.
What's a recurrent state in a Markov model?	\item A state where the return probability is 1
What's a non-null recurrent state in a Markov chain?	\item It's a recurrent state where the return time is finite
What's a non-null Markov model?	\item One where every state is non-null recurrent
What's an ergodic state in a Markov model?	\item An aperiodic, non-null recurrent state
What's an ergodic Markov model?	\item A model where every state is ergodic
What's a time reversible Markov chain?	\item One satisfying the detailed balance equations
What're the detailed balance equations for a Markov model?	\item&nbsp;$\pi_i A_{ij} = \pi_j A_{ji}$
What's a weaker sufficient condition for identifying whether a Markov model has a stationary distribution than ergodicity?	\item If a Markov model is regular \&amp; satisfies the detailed balance equations with respect to $\pi$, then $\pi$ is a stationary distribution of the model
How can you modify a Markov chain to ensure its stationary distribution is unique?	\item Give each state a small but nonzero probability of transitioning to any other state,<div>\item $A^\prime = pA + \frac{1-p}{n}11^T$<br /><div>\item This makes the model aperiodic \&amp; regular</div></div>
What's an efficient method for finding the leading eigenvector of a large matrix?	\item The power method: repeatedly power the matrix then normalize it<br /><div>\item Or better, the Monte Carlo power method: construct the Markov model associated with the graph and count how many times each state is visited</div>
What's a Markov switching model?	\item Another name for a HMM
What's a HMM in ML?	\item Hidden Markov Model
What's the usual observation model for a HMM with discrete observations?&nbsp;	<div>\item A matrix:</div>\item $p(x_t = l | z_t = k) = B_{kl}$
What's the usual observation model for a HMM with continuous observations?&nbsp;	\item A Gaussian:<div>\item $x_t \sim \mc{N}(\mu_k, \Sigma_k)$</div>
What's the filtering task for HMMs?	\item Compute the belief state $p(z_t|x_{1:t})$ for each $t$<div>\item representing a streaming scenario</div>
What's the smoothing task for HMMs?	\item Compute $p(z_t|x_{1:T})$<div>\item represents an offline scenario</div>
What's the fixed lag smoothing task for HMMs?	\item Compute $p(z_{t-l}|x_{1:t})$, where $l &gt; 0$ is the lag<div>\item This adapts the filtering task by allowing you to model an accuracy vs delay tradeoff</div>
What's the prediction task for HMMs?	\item Compute $p(z_{t+h}|x_{1:t})$<div>\item where $h &gt; 0$ is the prediction horizon</div>
What's the Viterbi decoding task for HMMs?	\item Compute the joint MAP estimate of the hidden states $z_{1:T}$ given $x_{1:T}$
In the context of a HMM, what's the belief state at time $t$?	\item $\alpha_t = p(z_t|x_{1:t})$
What's the forwards algorithm for carrying out the filtering task on HMMs in terms of probabilities?	\item Compute the one-step-ahead predictive density:<div>\item $p(z_t = j |x_{1:t-1}) = \sum_i p(z_t = j|z_{t-1} = i)\alpha_{t-1}(i)$<div>\item This forms the prior for $z_t$.<br /><div>\item Use Bayes to update the belief state:</div></div><div>\item $\alpha_t = \frac{1}{Z_t}p(x_t|z_t = j)p(z_t = j | x_{1:t-1})$</div></div>
What's the forwards algorithm for the filtering task on HMMs in matrix notation?	<div>\item $\alpha_t = \psi_t \odot (\Psi^T\alpha_{t-1})$</div><div>\item where $\psi_t(j) = p(x_t| z_t = j)$ is the local evidence</div><div>\item and $\Psi$ is the transition matrix</div>
What's the local evidence in the context of HMMs?	\item&nbsp;&nbsp;$\psi_t(j) = p(x_t| z_t = j)$
What's the Hadamard product?	\item $u \odot v$, ie elementwise multiplication of two vectors/matrices
What's the forwards-backwards algorithm for the smoothing task on HMMs?	\item $\alpha_t(j) = p(z_t = j|x_{1:t})$, the filtered belief state<div>\item $\beta_t(j) = p(x_{t+1:T}|z_t = j)$, the conditional likelihood of future evidence</div><div>\item&nbsp;$\gamma_t(j) = p(z_t = j|x_{1:T})$, the posterior marginal</div><div>\item Let $\psi_t$ be the local evidence at time $t$ and $\Psi$ be the transition matrix</div><div>\item Compute the forward messages $\alpha_t \propto \psi_t \odot (\Psi^T\alpha_{t-1})$</div><div>\item Compute the backward messages &nbsp;$\beta_t = \Psi (\psi_{t+1} \odot \beta_{t+1})$</div><div><div>\item Then $\gamma_t \propto \alpha_t \odot \beta_t$</div></div>
What's a smoothed two-slice marginal in the context of HMMs?	\item $\xi_{t, t+1}(i, j) = p(z_t = i, z_{t+1} = j|x_{1:T})$
How can smoothed two slice marginals for a HMM be computed?	\item Using the forwards-backwards algorithm:<div>\item $\xi_{t, t+1} \propto \Psi \odot (\alpha_t(\psi_{t+1} \odot \beta_{t+1})^T)$</div>
What's the computational complexity of the forwards-backwards algorithm?	\item $O(K^2T)$ for dense transition matrices<div>\item $O(KT)$ for sparse transition matrices</div>
What's a trellis diagram for HMMs?	\item A visualization of a Markov model where each time is a column and each state is a row,&nbsp;<div>\item with edges weighted with the negative log-probability of a transition</div>
How can finding the MAP state of a HMM be interpreted in terms of trellis diagrams?	\item It's equivalent to finding the shortest path through the diagram
What's the MPM of a HMM?	\item Maximizer of posterior marginals,&nbsp;<div>\item the $\hat z$ such that each $\hat z_t$ maximizes $p(z_t|x_{1:T})$&nbsp;</div>
What's the Viterbi algorithm?	<div>\item Calculate forwards:</div>\item $\delta_t(j) = \max_z p(z_t = j, z_{1:t-1}|x_{1:t})$, the probability of ending up in $j$ at $t$ via the most probable path<div>\item $a_t(j) = \arg\max_i \delta_{t-1}(i)\Psi_{j,:}\psi_t$, the most likely previous state to $j$</div><div>\item Then we can carry out traceback: $z^*_t = a_{t+1}(z^*_{t+1})$</div><div>\item where&nbsp;$z^*$ is the MAP estimate of the joint state</div>
What's a useful trick when implementing the Viterbi algorithm?	\item $\max \ln = \ln \max$<div>\item so the arithmetic can be done in the log domain</div>
What property of a HMM does the forwards-backwards algorithm compute?	\item The MPM
What's the $N$-best list in the context of HMMs?	\item It's the list of the $N$ most probable paths through the hidden state space&nbsp;<div>\item usually obtained from a modification to the Viterbi algorithm</div>
What's the advantage of the $N$-best list vs the MAP for HMMs?	\item It allows some discriminitative method to apply global knowledge that isn't available to the HMM solver
What's the problem with generating $N$-best lists for HMMs?	\item The paths are often very similar, so no new knowledge is gained
What's the three-pass method to sample paths from the posterior distribution of a HMM?	\item Use forwards-backwards to compute the two-slice smoothed posteriors $p(z_{t-1}, z_t| x_{1:T})$<div>\item Normalize the posteriors get the conditionals $p(z_t|z_{t-1}, x_{1:T})$&nbsp;</div><div>\item Make a forwards pass to recursively construct the sample: $z^*_t \sim z_t | z^*_{t-1}, x_{1:T}$</div>
What's the two-pass method to sampling paths from the posterior distribution of a HMM?	\item Apply the forwards algorithm to compute the belief states $\alpha_t(j) = p(z_t = j |x_{1:t})$<div>\item Then $p(z_t = i | z_{t+1} = j, x_{1:t}) = \frac{\alpha_t(i)}{\alpha_{t+1}(j)} \Psi_{ij} \psi_{t+1}(j)$</div>
Intuitively, what's the Baum-Welch algorithm?	\item It's EM for HMMs
What's the EM algorithm for HMMs?	<div><div>\item The parameters are&nbsp;the initial state distribution $\pi$, the transition matrix $A$ and the observation parameters $B$ or $(\mu, \Sigma)$</div><div>\item E step: fix the parameters and use the forwards-backwards algorithm to calculate the node marginals $p(z_t|x_{i, 1:T_i},\theta)$ and the edge marginals $p(z_{t-1}, z_t|x_{i,1:T_i}, \theta)$.&nbsp;These can then be used to calculate</div><div>\item $\mbb{E}[N_k^1]$, the expected number of first nodes $z_1$ in state $k$,</div><div>\item $\mbb{E}[N_j]$, the expected number of nodes in state $j$,&nbsp;</div><div>\item $\mbb{E}[N_{jk}]$, the expected number of transitions from state $j$ to $k$.</div><div>\item M step: Use the expected counts to calculate the MLEs for the parameters.</div></div>
How are the parameters usually initialized when applying EM to HMMs?	\item Use fully-labelled data to get started<div>\item Ignore the Markov dependencies and estimate the observation parameters using mixture model estimation methods</div><div>\item Randomly initialize and use restarts</div>
What's Viterbi training in ML?	\item Approximating the posterior over paths through a HMM using the MAP path<div>\item then using that to get the EM alg for training a HMM started</div><div>\item This isn't very reliable though as the initial parameters will be poorly estimated</div>
How are HMMs usually used for classification?&nbsp;	\item They're used as the class-conditional densities inside a generative classifier<div>\item and are trained separately (since EM can't be applied to the whole model), then tuned discriminatively.</div>
When selecting a HMM to use, how is the number of hidden states usually chosen?	\item Grid search<div>\item Variational Bayes</div><div>\item Use an infinite HMM</div>
What's structure learning in the context of HMMs?	\item Learning a sparse transition matrix
What's the minimum entropy prior?	\item $p(a) \propto \exp(-\mbb{H}(a))$<div>\item where $a$ is a vector</div>
What's the usual way to do structure learning with HMMs?	\item Enforce a minimum entropy prior on the rows of the transition matrix<div>\item Take the MAP estimate using EM</div>
What's a common problem with structure learning methods for HMMs?	\item They can sometimes prune out all the incoming connections to a state
What's a semi-Markov model?	\item A generalization of a Markov model that allows transitions to depend on how long the model's been in its current state for
What's a HSMM in ML?	\item Hidden semi-Markov model<div>\item ie a semi-Markov model where the state space isn't observed directly</div>
What're two other names for HSMMs?	\item Variable duration HMM<div>\item Explicit duration HMM</div>
What's the main use of HSMMs?	<div>\item Modelling</div><div>\item $p(x_{t:t+l}|z_t = k, d_t = l)$</div><div>\item ie the result of $l$ correlated obserations when the model's in state $k$ for $l$ timesteps</div><div>\item This is good for data that shows local trends (like piecewise linear models)</div>
How can HSMMs be thought of as augmented HMMs?	<div>\item Can be thought of as a high-order HMM:</div>\item Create `duration counter' states $D_t \in \{0, \dotsc, D\}$<div>\item When the model enters a new state $j$, it immediately transitions to one of the duration states</div><div>\item which it `counts down' through</div><div>\item Then it can transition to another state $k$, conditional on $j$&nbsp;</div>
What's a simple way to introduce non-geometric wait times into a HMM without having to use a HSMM?	\item Replace each state with $n$ states with a chain of $n$ states which have the same emission probabilities<div>\item By tuning $n$ and the self-loop probabilities, a wide range of wait time distributions can be achieved</div>
What's HHMM stand for in ML?	\item Hierarchical hidden Markov model
How do HHMMs compare to HMMs?	\item A HHMM can always be flattened out to a HMM<div>\item but HHMMs are easier to interpret and fit</div>
What's a hierarchical hidden Markov model in ML?	\item A transition between two states $i, j$ can be replaced with a whole HMM<div>\item where the model only transitions back to $j$ when the sub-model reaches its termination state.</div>
What's an input-output HMM?	\item A HMM where the hidden states are conditional on some control signal $u_t$
How are continuous inputs usually coupled into a IO-HMM?	\item $z_t | x_t, z_{t-1}&nbsp;\sim \text{Cat}(\mc{S}(W_{z_{t-1}}u_t))$<div>\item ie a logistic regression model whose parameters depend on the previous state</div>
What's an auto-regressive HMM?	\item A HMM where the observations aren't conditionally independent given the hidden states
How are continuous observations usually coupled in auto-regressive HMMs?	\item $x_t | x_{t-1}, z_t \sim \mc{N}(W_{z_t}x_{t-1}, \Sigma_{z_t})$<div>\item ie a linear regression model where the parameters depend on the previous hidden state</div>
What's a regieme-switching HMM?	\item Another name for an auto-regressive HMM
How can AR-HMMs be interpreted in terms of regular HMMs?	\item They're effectively two Markov chains:<div>\item One on the hidden variables to capture long-range dependencies</div><div>\item and another on the observed variables to capture short-range dependencies</div>
What're buried Markov models?	\item An extension of AR-HMMs which allow the dependency structure between observed nodes to change depending on the hidden state
What's AR-HMM stand for in ML?	\item Auto-regressive hidden Markov model
What's a dynamic Bayesian multi-net?	\item Another name for a buried Markov model<div>\item since it's a mixture of different networks</div>
What's a factorial HMM?	\item A HMM that uses a distributed encoding of the hidden state:&nbsp;<div>\item states $\{1, \dotsc, K\}$ can be encoded as $\lg K$ coupled states, each representing a binary digit</div>
What's the problem with factorial HMMs?	\item Conditioned on the observations, all the hidden states are coupled.<div>\item Efficient approximate inference algorithms still exist though</div>
What's a coupled HMM?	\item A sequence of HMMs where transitions in one chain depend on the states of the neighbouring chains<div>\item with all the HMMs sharing the same set of observed variables</div>
What's the influence model in ML?	\item A kind of coupled HMM that uses fewer parameters, but allows all chains to affect all others:&nbsp;<div>\item the joint conditional distribution $z_{ct}|z_{t-1}$ is a convex combination of pairwise transition matrices&nbsp;<br /></div>
What's a dynamic Bayesian network?	\item A DGM which relates variables to eachother over time<div>\item you provide the structure of the first time slice</div><div>\item the structure that takes one time slice to the next</div><div>\item and the structure that takes the hidden states to the evidence</div>
What's DBN stand for in ML?	\item Dynamic Bayesian network<div>\item Deep belief network</div>
What's the form of a state space model?	\item $z_t = g(u_t, z_{t-1}, \epsilon_t)$<div>\item $y_t = h(z_t, u_t, \delta_t)$</div><div>\item where&nbsp;</div><div>\item $u_t$ is the control signal</div><div>\item $z_t$ are the hidden states</div><div>\item $\epsilon_t, \delta_t$ are the system \&amp; observation noises</div><div>\item $g,h$ are the system \&amp; observation functions</div>
What're $g, h$ in the definition of a state space model?	\item $g$ is the transition model<div>\item $h$ is the observation model</div>
What're $\delta_t, \epsilon_t$ in the definition of a state space model?	\item $\delta_t$ is the observation noise<div>\item $\epsilon_t$ is the system noise</div>
What're $z_t, y_t$ in the definition of a SSM?	\item $z_t$ is the hidden state<div>\item $y_t$ is the observation</div>
What's $u_t$ in the definition of a SSM?	\item The control signal
What's SSM stand for in ML?	\item State space model
What's a linear dynamical system?	\item A SSM with linear-Gaussian transition \&amp; observation models<div>\item $z_t \sim \mc{N}(A_t z_{t-1} + B_t u_t, Q_t)$</div><div>\item $y_t \sim \mc{N}(C_t z_t + D_t u_t, R_t)$&nbsp;</div>
What's another name for a linear-Gaussian SSM?	\item A linear dynamical system
What's LG-SSM stand for in ML?	\item Linear-Gaussian state space model
What's the advantage of the LG-SSM over more general SSMs?	\item LG-SSMs support exact inference<div>\item and if the initial belief state $z_1$ is Gaussian, so are all subsequent belief states</div>
In the context of LG-SSMs, what does $\mu_{t|\tau}$ denote?	\item $\mbb{E}[z_t|y_{1:\tau}]$
What's $\mu_t$ denote in the context of SSMs?	\item $\mu_t = \mu_{t|t}$<div>\item ie the posterior belief state of the mean</div>
What's the SLAM problem in ML?	\item Simultaneous location and mapping<div>\item ie the problem of a robot traversing an unknown world</div>
What's the recursive least squares algorithm?	\item Use a LG-SSM to model a linear regression model<div>\item by defining the hidden state to be the parameters, which are fixed over time</div><div>\item and the observations to be the input vector</div><div>\item and then applying a Kalman filter to solve the system.&nbsp;</div>
What's RLS stand for in ML?	\item Recursive least squares algorithm
How does RLS compare to LMS?	\item LMS falls out of RLS if you approximate the covariance term $\frac{1}{\sigma^2}\sum_{t|t-1}$ in the RLS update rule with $\eta_t I$, where $\eta_t$ is the step size<div>\item So an advantage of RLS is it sets the step size automatically</div><div>\item It also converges in a single pass over the data</div>
What's LMS stand for in ML?	\item Least mean squares algorithm
What's ARMA stand for in ML?	\item Auto-regressive moving average
What's an auto-regressive moving average model in ML?	\item A type of SSM<div>\item where $x_t$ is formed from linear combination of the $p$ previous $x_{t^\prime}$ plus a linear combination of the previous $q$ noise terms $w_{t^\prime}$</div>
What're ARMA models commonly used for?	\item Time series predictions
What's a structural time series model?	\item A kind of SSM which assumes some generative model for some time-series data&nbsp;<div>\item then marginalizes out the hidden variables to make predictions</div>
What's the use of the Kalman filter?	\item It solves the filtering problem exactly for LG-SSMs in a Bayesian manner, giving the full posterior
What's the analogue of the Kalman filter for HMMs?	\item The forwards algorithm
What's the prediction step of the Kalman filter?	<div>\item $z_t|y_{1:t-1}, u_{1:t} \sim \mc{N}(\mu_{t|t-1}, \Sigma_{t|t-1})$<br /></div>\item $\mu_{t|t-1} = A_t\mu_{t-1} + B_t u_t$<div>\item $\Sigma_{t|t-1} = A_t\Sigma_{t-1} A^T_t + Q_t$</div>
What's the measurement step in the Kalman filter?	\item $z_t | y_{1:t}, u_t \sim \mc{N}(\mu_t, \Sigma_t)$<div>\item $\mu_t = (I - K_t C_t) \mu_{t|t-1} + K_t y_t$</div><div>\item $\Sigma_t = (I - K_t C_t)\Sigma_{t|t-1}$</div><div>\item where</div><div>\item $y_t$ is the observation</div><div>\item $K_t$ is the Kalman gain matrix</div>
What's the residual $r_t$ in the Kalman filter?&nbsp;	\item $r_t = y_t - \hat y_t$<div>\item where&nbsp;</div><div>\item $\hat y_t = C_t \mu_{t|t-1} + D_tu_t$</div>
What's the Kalman gain matrix $K_t$?	\item $K_t = \Sigma_{t|t-1}C^T_t S^{-1}_t$<div>\item where $S_t$ is the covariance of the residual given the observations,&nbsp;</div><div>\item $S_t = C_t \Sigma_{t|t-1} C^T_t + R_t$</div>
When there are many more observations than latent states, what optimization can be made to the Kalman filter?	\item $K_t$ can be precomputed, since it doesn't depend on the actual observations.
What's the computational complexity of the vanilla Kalman filter?&nbsp;	\item $O(|y|^3)$ to compute the gain matrix<div>\item $O(|z|^2)$ to compute the covariance</div><div>\item so its overall complexity is determined by whether $|z|$ is much larger than $|y|$&nbsp;</div>
What are some more numerically stable alternatives to the Kalman filter?	\item The information filter, which updates the information parameters of the Gaussian rather than the moment params<div>\item The square root filter, which works with the Cholesky decomposition of the variance</div>
What's the analogue of the Kalman smoother for HMMs?	\item The forwards-backwards algorithm
What's the advantage of the Kalman smoother over the Kalman filter?	\item Since the smoothing task is offline, we can condition on all the data and significantly reduce our uncertainty
What's the RTS algorithm?	\item Another name for the Kalman smoothing algorithm
What's the Kalman smoothing algorithm?	\item Use the Kalman filter to compute $\mu_{T|T}$ and $\Sigma_{T|T}$<div>\item Then work backwards:<br /><div>\item $z_t | y_{1:T} \sim \mc{N}(\mu_{t|T}, \Sigma_{t|T})$</div><div><div>\item $\mu_{t|T} = \mu_{t|t} + J_t(\mu_{t+1|T} - \mu_{t+1|t})$</div></div><div>\item $\Sigma_{t|T} = \Sigma_{t|t} + J_t(\Sigma_{t+1|T} - \Sigma_{t+1|t})J^T_t$</div></div><div>\item where $J_t$ is the backwards Kalman gain matrix</div><div><br /></div>
What's the backwards Kalman gain matrix?	\item $J_t = \Sigma_{t|t} A^T_{t+1} \Sigma^{-1}_{t+1|t}$
What's a neat feature of the backwards pass of the Kalman smoothing algorithm?	\item It doesn't need the data!
What's the biggest difference between the Kalman smoothing algorithm and the forwards-backwards algorithm for HMMs?	\item The backwards pass needs all the data from the forwards pass<div>\item and while the updates can be rewritten to be independent of the forwards pass, it has several disadvantages:&nbsp;</div><div>\item it introduces a dependence on the data</div><div>\item the backward message is a likelihood rather than a posterior&nbsp;</div>
What's two-filter smoothing?	\item A Kalman smoothing variant that calculates<div>\item $z_t|y_{1:t}$ in the forward pass</div><div>\item $z_t|y_{t+1:T}$ in the backwards pass</div><div>\item and then combines them to calculate $z_t|y_{1:T}$</div>
What's systems identification in ML?	\item Estimating the parameters of a LG-SSM
What are some common constraints enforced when learning LG-SSMs?	\item Fixing the system noise $Q = I$, since its effect can be swallowed by $A$<div>\item Fixing the observation noise $R$ to be diagonal, since its effect can be swallowed by $C$</div><div>\item Limit the eigenvalues of $A$ to $&lt;1$, which stops $z_t$ from blowing up (noise stops the system from collapsing)</div>
How is EM applied to LG-SSMs?	\item Similarly to the Baum-Welch algorithm for HMMs<div>\item but using Kalman smoothing rather than forwards-backwards in the E step</div>
What's the advantage of the subspace method over EM for learning LG-SSMs?	\item EM can be very sensitive to the initial parameters<div><br /></div>
If a LG-SSM is fully observed, how can you train it?	\item By solving a linear regression problem<div>\item where the datapoints are the pairs $(z_{t-1}, z_t)$ and $(z_t, y_t)$</div>
What's the intuition behind the subspace method for training LG-SSMs?	\item Assume there was no observation or system noise.<div>\item Then $z_t = Az_{t-1}$ and $y_t = Cz_t$</div><div>\item so $y_t = CA^{t-1}z_1$</div><div>\item Hence all observations must be generated from a $\dim(z_t)$-dimensional manifold</div><div>\item which can be estimated using PCA.</div><div>\item Once we've got estimates for all the $z_t$, the model can be fit as though it were fully observed</div>
Given a $Y = f(X)$, where $X$ is Gaussian, what are the two main ways to approximate $Y$?	\item Use a first-order approximation of $f$, so $Y$ is Gaussian<div>\item Use $f$ exactly, but project $Y$ onto the space of Gaussians by moment matching</div>
What's a nonlinear Gaussian dynamical system?	\item A SSM with possibly-nonlinear transition \&amp; observation functions $g, h$<div>\item but with Gaussian noise</div>
What's the idea behind the extended Kalman filter algorithm?	\item Given a nonlinear Gaussian dynamical system<div>\item linearize $g, h$ around the previous state estimate using a first-order Taylor series</div><div>\item then apply the standard Kalman filter equations</div><div>\item This effectively converts a stationary nonlinear system to a nonstationary linear system</div>
When does EKF work poorly?	\item When the prior covariance is large, so probability mass ends up a long way from where the function is linearized<div>\item When the function is highly nonlinear near the current mean</div>
What's EKF stand for in ML?	\item Extended Kalman Filter
What's the idea in the unscented Kalman filter?	\item It's a modification of the extended Kalman filter<div>\item but rather than trying to linearly approximate a function</div><div>\item it passes a set of points through the function and tries to fit a Gaussian to them afterwards</div>
What's the idea in assumed density filtering?	<div>\item Given a SSM, at step $t$</div>\item suppose we have an approximate prior $q_{t-1} \in \mc{Q}$ such that $q_{t-1}(\theta_{t-1}) \approx p_{t-1}(\theta_{t-1}|y_{1:t-1})$<div>\item Predict: the predictive distribution is $q_{t|t-1}(\theta_t) = \int p(\theta_t|\theta_{t-1})q_{t-1}(\theta_{t-1})d\theta_{t-1}$<br /></div><div>\item Update: the posterior is $\hat p_t(\theta_t) \propto p_{t-1}(y_t|\theta_t)q_{t|t-1}(\theta_t)$</div><div>\item Project: $q_t(\theta_t) = \arg\min_q \mbb{KL}(\hat p_t(\theta_t)||q(\theta_t))$</div>
How can the project step in assumed density filtering be done with $q$ in the exponential family?	\item By moment matching
What's the Boyer-Koller algorithm?	\item It's assumed density filtering applied to discrete dynamic Bayes nets<div>\item with an approximation of the form $q(\theta_t) = \prod_j \text{Cat}(\theta_{tj}|\pi_{tj})$</div><div>\item where the $\pi_{tj}$ are set by moment matching, $\pi_{tjk} = \hat p(\theta_{tj} = k)$</div>
What's a hybrid system?	\item A system with both discrete \&amp; continuous variables
What's a switching linear dynamical system?	\item A combination of HMM and LG-SSM<div>\item where $q_t$ evolves as a discrete HMM</div><div>\item and $z_t, y_t$ evolve as a LG-SSM, with the conditional distributions being additionally conditional on the state of $q_t$</div>
Why is exact inference intractable on SLDSs?	\item Because the discrete variables induce an exponential explosion in the number of modes the posterior has
What's SLDS stand for in ML?	\item Switched linear dynamical system
What're some other names for SLDSs?	\item Jump Markov linear system<div>\item Switching state space model</div>
What's multiple hypothesis tracking in ML?	\item An approach to approximate inference for hybrid systems<div>\item where low probability trajectories in the discrete tree are pruned off</div>
What's the idea in a Gaussian sum filter?	\item It's an approach to modelling switching SSMs. If there are $K$ possible states for the switch<div>\item then model the belief state at each step as a mixture of $K$ Gaussians</div><div>\item and pass them through the update by running $K^2$ Kalman filters in parallel</div><div>\item then projecting back to $K$ Gaussians</div>
What's the optimal way to approximate a mixture of Gaussians with a single Gaussian?	\item The solution that minimizes the KL divergence is<div>\item $\mu = \sum \pi_k \mu_k$</div><div>\item $\Sigma = \sum \pi_k (\Sigma_k + (\mu_k - \mu)(\mu_k - \mu)^T)$</div>
What's the data association problem in ML?	\item You're given a series of observations $y_{tk}$ and a set of objects $z_{tj}$<div>\item There may be more or fewer observations than objects at any time slice, but the number of objects is fixed<br /><div>\item Find a consistent matching of objects to observations</div></div>
What's multi-target tracking in ML?	\item It's the data association problem with a variable number of objects at each time slice
How do you give a raw string literal in Python?&nbsp;	\item \ttt{s = r'string'}
What're pandas's primary classes?	\item Series - 1D array<div>\item Timeseries - 1D array indexed w/ times</div><div>\item DataFrame - 2D labelled, columnar structure</div><div>\item Panel - 3D labelled structure</div>
What're the two kinds of input to a clustering algorithm?	\item Similarity-based clustering, using a dissimilarity matrix $D$<div>\item Feature-based clustering, using a design matrix $X$</div>
What's a design matrix?	\item The $X$ of input variables which has each datapoint as a row
What are the two kinds of output of a clustering algorithm?	\item Partitional clustering, which returns a partition<div>\item Hierarchical clustering, which returns a tree</div>
What's the usual computational complexity of a clustering algorithm?	\item $O(ND)$ for partitional clustering<div>\item $O(N^2\lg N)$ for hierarchical clustering</div>
What's a dissimilarity matrix?	\item A nonnegative matrix $D$ with a zero diagonal<div>\item with $d_{ij}$ representing the `distance' between $i$ and $j$</div><div>\item Doesn't acutally have to be a distance though!</div>
How are similarity matrices $S$ usually converted to dissimilarity matrices?	\item $D = \max(S) - S$<div>\item though any monotonic decreasing function will do</div>
What are common dissimilarity measures for real-valued features?	\item $l_2$ distance<div>\item $l_1$ distance</div><div>\item Negated correlation coeff&nbsp;</div>
What's the usual dissimilarity metric for ordinal data (like low, med, high)?	\item Encode them as equally-spaced reals in $[0, 1]$<div>\item eg low is $1/3$, med is $2/3$, high is $3/3$</div><div>\item then apply any dissimilarity function over the reals</div>
What's the usual dissimilarity function for vectors of categorical variables (like red, green, blue)?	\item Hamming distance.&nbsp;
What's the purity of a cluster in ML?	\item Given class-labelled data,<div>\item $N_i$ is the number of objects in cluster $i$<br /><div>\item $p_{ic}$ is the fraction of cluster $i$ which is class $c$,</div><div>\item $p_i = \max p_{ic}$ is the purity of cluster $i$</div><div>\item $\text{purity} = \sum \frac{N_i}{N}p_i$ is the purity of the clustering&nbsp;</div></div>
What's the problem with purity as a measure of the performance of a clustering algorithm?	\item It doesn't penalize putting every object in its own cluster
What's the Rand index of a clustering?	\item Given a reference clustering $U$ and a computed clustering $V$<br /><div>\item let $TP$ be the number of pairs in the same cluster in $U$ that are also in the same cluster in $V$</div><div>\item let $TN$ be the number of pairs in different clusters in $U$ that are also in the same cluster in $V$</div><div>\item let $N_\text{pair}$ be the total number of pairs&nbsp;</div><div>\item Then $R = \frac{TP + TN}{N_\text{pair}}$</div>
What's the adjusted Rand index?	<div>\item Assuming a distribution of clusters based on the hyper-geometric distribution,&nbsp;</div>\item $AR = \frac{\text{index} - \text{expected index}}{\text{max index} - \text{expected index}}$
What's the normalized mutual information of two clusterings $U, V$?	\item Define $p_U, p_V$ to be the distribution of randomly-selected items over clusters in $U, V$&nbsp;<div>\item Define $p_{UV}$ to be the distribution of randomly-selected items over $U \times V$</div><div>\item $\text{NMI}(U,V) = \frac{2\mbb{I}(U,V)}{\mbb{H}(U) + \mbb{H}(V)}$</div>
What's finite model based clustering?	\item Fitting a finite mixture model&nbsp;<div>\item and assigning items to the model whose weight is highest&nbsp;</div>
Intuitively, why is fitting a mixture model based on a Dirichlet process often faster than fitting models for different $K$?	\item When fitting the DP-based model, the appropriate values of $K$ are determined long before the parameters are estimated<div>\item whereas when fitting models for different $K$, the parameters must be estimated for each value that's tried &nbsp;</div>
What's the definition of a Dirichlet process $\text{DP}(\alpha, H)$?	\item It's a distribution over probability measures $G\colon \Theta \rightarrow \mbb{R}^+$, implicitly defined by the fact that<div>\item $(G(T_1), \dotsc, G(T_K)) \sim \text{Dir}(\alpha H(T_1), \dotsc, \alpha H(T_K))$</div><div>\item for any finite partition $(T_1, \dotsc, T_K)$ of the space $\Theta$</div>
What're the parameters of a Dirichlet process?	\item $\alpha$, the concentration parameter<div>\item $H$, the base measure</div>
How can a Dirichlet process be thought of in terms of conjugate priors?	\item $\text{Dir}(\alpha)$ is a conjugate prior for the categorical distribution<div>\item and if a sample is observed of type $k$, the posterior is Dirichlet distribution with $k$th parameter $\alpha_k + 1$</div><div>\item A DP generalizes this in that an observation is of type $k$ if it falls in partition $T_k$, and the prior probability of this happening is given by $\alpha H(T_k)$</div><div>\item so $\alpha$ is effectively the prior sample size</div>
What's a \text{GEM} distribution?	<div>\item Let $\pi$ be an infinite sequence, generated by</div><div>\item $\beta_k \sim \text{Beta}(1, \alpha)$</div><div>\item $\pi_k = \beta_k \prod_1^{k-1}(1 - \beta_l)$</div><div>\item Then</div><div>\item $\pi \sim \text{GEM}(\alpha)$</div>
How do DPs relate to the GEM distribution?	<div>\item $\pi \sim \text{GEM}(\alpha)$,&nbsp;</div><div>\item $\theta_k \sim H$</div><div>\item If we define &nbsp;</div>\item $G(\theta) = \sum \pi_k \delta_{\theta_k}(\theta)$<div>\item Then $G \sim \text{DP}(\alpha, H)$</div>
What's DP stand for in ML?	\item Dirichlet process
What's the consequence of the relationship between DPs and the GEM distribution?	\item Samples $G \sim \text{DP}(\alpha, H)$ are discrete with probability 1:<div>\item if you keep sampling from it, you'll eventually just keep getting repetitions of values you've seen already</div>
What's the behaviour of the GEM distribution?	\item The weights will always go to zero eventually<div>\item although how long that takes increases with $\alpha$</div>
What's the definition of a Chinese restaurant process?	\item $p(z_{N+1} = z|z_{1:N}, \alpha) = \frac{\alpha}{\alpha + N}$ if $z$ has not yet appeared<div>\item&nbsp;$p(z_{N+1} = z|z_{1:N}, \alpha) = \frac{N_k}{\alpha + N}$ if $z$ has appeared $N_k$ times</div>
What's the intuition behind a Chinese restaurant process?	\item When a person enters the restaurant, she may choose to join table $k$ with probability proportional to the number of people sitting there already, $N_k$<div>\item or she might sit at a new table with probability $\alpha$</div>
What's the Blackwell-MacQueen sampling scheme?	\item Another name for the modified Polya urn which corresponds to a DP
What's the asymptotic behaviour of the Chinese restaurant process?&nbsp;	\item The number of distinct values approaches $\alpha \ln N$
How is a DP used to build a generative cluster model?&nbsp;	\item $G \sim \text{DP}(\alpha, H)$ is a distribution over the possible cluster parameters<div>\item $\theta_i \sim G$ are the parameters for generating $i$<br /><div>\item $x_i \sim F(\theta_i)$ for some distribution $F$&nbsp;</div></div>
What's the Polya urn sampling scheme for a Dirichlet process?	\item Start with an urn with $\alpha$ black balls.<div>\item If we draw a black ball, pick a new color according to $H$ and drop it into the urn along with the black ball.</div><div>\item If we draw a non-black ball, return it and another ball of the same color into the urn.</div>
What's the idea in affinity clustering?	\item Each data point must choose another data point as it's exemplar<div>\item (possibly choosing itself)</div><div>\item and each resulting tree forms a cluster</div>
What's the usual objective in affinity clustering?	<div>\item Maximize</div>\item $S(c) = \sum s(i, c_i) + \sum \delta_k(c)$<div>\item where&nbsp;</div><div>\item $s(i, c_i)$ measures the similarity between $i$ and the centroid it's chosen $c_i$</div><div>\item $\delta_k(c)$ is a penalty for some $i$ choosing $k$ as it's centroid when $k$ hasn't chosen itself</div>
What algorithm's usually used to fit DPMMs?	\item A collapsed Gibbs sampler&nbsp;
What algorithm is usually used to fit an affinity clustering model?	\item Loopy belief propagation
What's the normalized cut cost of a cut $A$?	\item $\text{ncut}(A_1, \dotsc, A_K) = \frac{1}{2} \sum \frac{\text{cut}(A_k, \bar A_k)}{\text{vol}(A_k)}$<div>\item where $\text{vol}(A_k) = \sum_{i \in A_k} d_i$</div><div>\item and $d_i$ is the weighted degree of $i$</div>
What's the weighted degree of a node in a graph?	\item $d_i = \sum w_{ij}$
What's the cost of a cut $A$ of a graph?	\item $\text{cut}(A_1, \dotsc, A_K) = \frac{1}{2} W(A_k, \bar A_k)$<div>\item where $W(A_j,A_k)$ is the total weight of edges going from $A_j$ to $A_k$</div>
Conceptually, what's spectral clustering?	\item The problem of minimizing the normalized cut cost $\text{ncut}(A_1, \dotsc, A_K)$ of a clustering $A$<div>\item can be thought of as an optimization problem over binary vectors $c_i$ such that $c_{ik} = 1$ if point $i$ belongs to cluster $A_k$</div><div>\item This is NP-hard.</div><div>\item If we replace `binary' with `real' though, we get an eigenvector problem</div><div>\item and solving it gives you a spectral clustering of the graph</div>
How do you get a $k$-regular sparse graph from a similarity matrix?	<div>\item Use the $K$ most similar objects to $i$ as the neighbours of $i$&nbsp;</div>\item and use the similarities as edge weights<div><br /></div>
How's the graph Laplacian defined?	\item Let $D$ be the diagonal matrix of weighted degrees<div>\item Then $L = D - W$</div>
What's the theorem relating the eigenvalues of a graph's Laplacian to its connected components?	\item The set of eigenvectors of $L$ with eigenvalue 0<div>\item is spanned by the indicator vectors $1_{A_1}, \dotsc, 1_{A_k}$</div><div>\item where the $A_k$ are the $K$ connected components of the graph</div>
What're two versions of &nbsp;the normalized graph Laplacian?	<div>\item $L_\text{rw} = D^{-1}L$, the random walk version</div><div>\item $L_\text{sym} = D^{-\frac{1}{2}}LD^{-\frac{1}{2}}$, the symmetric version</div>
What's the connection between the random walk Laplacian $L_\text{rw}$&nbsp;and random walks?	\item $P = I - L_\text{rw}$ is the transition matrix of a walk on the graph<br />
How can the normalized cut cost be interpreted in terms of random walks?	<div>\item If the graph is connected and bipartite, then</div>\item for a binary cut $\text{ncut}(A, \bar A)$ is the probability of the stationary distribution making a step across the boundary of $A$
What's the advantage of the normalized graph Laplacian over the graph Laplacian?	\item It accounts for the fact that some nodes are more highly connected than others
Conceptually, what's the algorithm used in spectral graph clustering?	\item Construct a graph from the similarity matrix<div>\item Compute the Laplacian $L$ (or normalized Laplacian)</div><div>\item Find $K$ eigenvectors with zero eigenvalue, $u_k$</div><div>\item Form $U$ using the $u_k$ as columns</div><div>\item Let $y_i$ be the rows of $U$</div><div>\item Apply K-means clustering to the $y_i$</div><div>\item then assign $i$ to cluster $k$ iff $y_i$ was assigned to cluster $k$</div>
What are the two main approaches to hierarchical clustering?	\item Agglomerative clustering<div>\item Divisive clustering</div>
What's the problem with standard hierarchical clustering techniques?	\item They're just heuristics, they don't optimize any well-defined objective<div>\item which means it's hard to assess the quality of the hierarchy</div><div>\item and they'll happily build a hierarchy out of noise</div>
What's a dendrogram?	\item A binary tree that represents a hierarchical clustering
Conceptually, how does agglomerative clustering work?	\item Each item starts in its own cluster<div>\item Then the two `most similar' clusters are repeatedly merged</div>
What's single-link clustering?	\item An agglomerative clustering technique<div>\item which defines cluster similarity as the distance between the two closest members of each group&nbsp;</div>
What kind of tree is produced by single-link clustering?	\item A MST
What's complete link clustering?	\item An agglomerative clustering algorithm<div>\item where the distance between clusters is the distance between the most distant two points</div>
What's the problem with single-link clustering?	\item The clusters violate the compactness property
What does it mean for a clustering to be compact?	\item Every point within a cluster is similar to every other point in that cluster&nbsp;
What's the diameter of a cluster $d_G$?	\item It's the greatest dissimilarity between two members of the cluster<br />
What kind of clusters will the complete link clustering algorithm create?&nbsp;	\item Ones with low diameter
What's furthest neighbour clustering?	\item Another name for complete link clustering
What's average link clustering?	\item An agglomerative clustering algorithm<div>\item where the distance between clusters is defined as the average distance between pairs</div>
What's the problem with average link clustering?	\item The clusters produced are sensitive to the measurement scale
What kind of clusters will average link clustering produce?	\item Clusters that are more compact than single link's clusters<div>\item but further apart than complete link's clusters</div>
Which of the common agglomerative clustering heuristics is usually used?	\item Average link clustering
What's the bisecting K-means algorithm?	\item A divisive clustering algorithm<div>\item where the split is chosen using K means with $K =2$</div>
What's the divisive clustering equivalent to single-link clustering?	\item Form the MST of the graph<div>\item then repeatedly break the link corresponding to the greatest dissimilarity</div>
What's the dissimilarity analysis algorithm?	\item It's a divisive clustering algorithm<div>\item where clusters are broken by splitting off the element with the greatest average dissimilarity from all other elements</div><div>\item and then moving across any other element which is more similar on average to the members of the new cluster than the old cluster,</div><div>\item in order of greatest difference in similarity</div>
What's the advantage of divisive clustering over agglomerative clustering?	\item It can be faster to build $L$-level hierarchies, as the algorithm can terminate early<div>\item Splitting decisions are made in the context of seeing all the data</div>
Given a hierarchical clustering, how can the `correct' number of clusters be determined?	\item Hopefully by observing a `jump' in the length of the links of the dendrogram<div>\item representing the merging of an `unnatural' cluster with a `natural' cluster</div>
Conceptually, what's Bayesian hierarchical clustering?	\item It's similar to agglomerative clustering<div>\item but it uses Bayesian hypothesis tests to decide which clusters to merge</div><div>\item with the tests based on a Dirichlet Process model</div>
What're the variables used in Bayesian hierarchical clustering algorithm?	<div>\item Let $\mc{D}_i$ be the data in the leaves of the tree $\mc{T}_i$</div><div>\item Suppose we're deciding whether to merge $\mc{T}_i, \mc{T}_j$</div><div>\item Then let $\mc{D}_{ij}$ be their merged data \item and $M_{ij}$ be an indicator variable determining whether to merge them or not.</div>
What's the probability of a merge in the Bayesian hierarchical clustering algorithm?	<div>\item $r_{ij} \propto p(\mc{D}_{ij}|M_{ij} = 1)p(M_{ij} = 1)$</div><div>\item where $p(M_{ij} = 1)$ is the prior probability of a merge</div>
How's the likelihood of the data defined in the Bayesian hierarchical clustering algorithm?	\item If the data should be merged,<div>\item $p(\mc{D}_{ij}| M_{ij} = 1) = \int \left[ \prod_{\mc{D}_{ij}} p(x_n|\theta)\right] p(\theta|\lambda)d\theta$</div><div>\item If the data shouldn't be merged,</div><div>\item&nbsp;$p(\mc{D}_{ij}| M_{ij} = 0) = p(\mc{D}_i|T_i)p(\mc{D}_j|T_j)$</div><div>\item where the terms on the RHS have already been calculated, since this is a bottom-up algorithm</div>
At a high level, what are the steps in the Bayesian hierarchical clustering algorithm?	\item Start with each datapoint in its own tree.&nbsp;<div>\item Then at each step merge the&nbsp;pair of clusters $\mc{D}_i, \mc{D}_j$ with the greatest merge probability $r_{ij}$<div>\item When there's only one cluster remaining, delete any edge with $r_{ij} &lt; 0.5$.</div></div>
What's a DPMM in ML?	\item Dirichlet process mixture model
How is the prior probability of a merge at node $k$, $\pi_k$, on trees $\mc{T}_i, \mc{T}_j$, calculated in Bayesian hierarchical clustering?	\item Initialize $d_i = \alpha$, $\pi_i = 1$<div>\item Then in a bottom-up fashion, the node $k$ with children $i, j$ has</div><div>\item $d_k = \alpha\Gamma(n_k) + d_i d_j$</div><div>\item $\pi_k = &nbsp;\frac{1}{d_k}\alpha\Gamma(n_k)$</div><div>\item where $n_k$ is the number of points in $\mc{D}_k$, which is the union of $\mc{D}_j, \mc{D}_k$</div>
What's the intuition behind the Bayesian hierarchical clustering algorithm's calculation of the prior probability of a merge, $p(M_{ij} = 1)$?	<div>\item Assume the clusters are generated by a DPMM with concentration $\alpha$. Then&nbsp;</div>\item $\alpha \Gamma(n_k)$ represents $\mc{D}_k$ being a cluster drawn from the DPMM<div>\item $\alpha \Gamma(n_k) + d_id_j$ represents all the other partitions of $\mc{D}_k$ consistent with the current tree&nbsp;</div>
How are the parameters $\lambda$ of the prior $p(\theta)$ and the DPMM parameter $\alpha$ fit in the hierarchical Bayesian clustering algorithm?	\item The gradients $\frac{\partial}{\partial \lambda} p(\mc{D}_k|\mc{T}_k)$ (\&amp; the same wrt $\alpha$) can be back-propagated through the tree<div>\item allowing empirical Bayes estimates of the hyperparameters to be done</div>
What's biclustering in ML?	\item Clustering the features as well as the samples
What's coclustering in ML?	\item Another name for biclustering
What's a simple Bayesian approach to coclustering?	\item Associate a latent clustering indicator $r_i \in \{1, \dotsc, K_r\}, c_j \in \{1, \dotsc, K_c\}$ with each datapoint $i$ and feature $j$.<div>\item Assume the data are iid across samples and features within each cluster</div><div>\item $p(x|\theta) = \prod_{i,j} p(x_{ij}|\theta_{r_i, c_j})$</div><div>\item and draw the $\theta$ from a DP.</div>
What's multi-view clustering?	\item A generalization of biclustering<div><div>\item The features $j$ are clustered into views: $c_j \in \{1, \dotsc, V\}$, with $c \sim \text{DP}(\alpha)$</div><div>\item Then the datapoints $i$ in each view $v$ are clustered: $r_{vi} \in \{1, \dotsc, K(v)\}$, with $r_v \sim \text{DP}(\alpha)$</div><div>\item and then the data is generated using these subclusters</div></div>
What's the main advantage of multi-view clustering over biclustering?	\item It's robust to irrelevant features, as they'll be farmed off in their own feature cluster
What's the stick-breaking process interpretation of a GEM distribution?	<div>\item At the $k$th step, break off $\beta_k$ fraction of the remaining stick.</div><div>\item $\pi_k$ is the length of the broken off piece.</div>
What's multiple hypothesis testing?	\item Make multiple binary decisions of the form $p(y_i &nbsp;= 1|\mc{D}) \geq \tau$<div>\item (note we're conditioning on all the data!)&nbsp;</div>
What's the false discovery rate in multiple hypothesis testing?	<div>\item Let $p_i = p(y_i = 1|\mc{D})$ be the probability of a discovery. Then&nbsp;</div>\item $\text{FD}(\tau, \mc{D}) = \sum (1-p_i)\mbb{I}(p_i \geq \tau)$ &nbsp;is the number of false discoveries<div>\item $\text{N}(\tau, \mc{D}) = \sum&nbsp;\mbb{I}(p_i \geq \tau)$ is the number of discoveries<br /><div>\item and the false discovery rate is</div><div>\item $\text{FDR}(\tau, \mc{D}) = \frac{\text{FD}(\tau, \mc{D})}{\text{N}(\tau, \mc{D})}$</div></div>
What's the direct posterior probability approach to multiple hypothesis testing?	\item Set an acceptible false discovery rate $\alpha$ (usually $\alpha = 0.05$)<div>\item Model the distribution of the discovery rates $p_i$&nbsp;</div><div>\item Model the distribution of the FDR</div><div>\item Minimize $\tau$ subject to $\text{FDR}(\tau, \mc{D}) &lt; \alpha$</div>
What's the usual import alias for pandas?	\item \ttt{import pandas as pd}&nbsp;
What's the basic tenet of pandas?	\item Data alignment is intrinsic
What's the index of a pandas series?	\item The collective name for the&nbsp;keys used&nbsp;to label the data
What's pandas's approach to non-unique index values?	\item They're allowed<div>\item but operations which don't support non-unique indexes will throw an exception</div>
What's the standard missing data marker in pandas?	\item NaN
How do you create a series in pandas?	\item \ttt{Series(data, index=index)}<div>\item where the default \ttt{index} is the first \ttt{|data|} natural numbers</div>
Which NumPy object do pandas Series correspond to?&nbsp;	\item A 1D ndarray
What's the main difference between a pandas Series and a NumPy ndarray?	\item Operations that combine Series elementwise will automatically align the data based on the labels<div>\item with missing elements being substituted by NaN</div>
How do you select a column in a pandas DataFrame?	\item \ttt{df['colname']}<div>\item \ttt{df.colname}</div>
What's the best way to think of the structure of a pandas DataFrame?	\item As a dict of columns.&nbsp;<div>\item So whole columns can be inserted, del'd, etc</div>
How do you select a row by label from a pandas DataFrame?	\item \ttt{df.loc['rowname']}
How do you select a row by index from a pandas DataFrame?	\item \ttt{df.iloc[5]}
What does pandas do when two Series with disjoint labels are combined elementwise?	\item The union of the labels is taken<div>\item with missing data filled in by Na*</div>
What's pandas default behaviour for combining DataFrames and Series elementwise?	\item The Series is aligned on the DataFrame's columns<div>\item and the operation is broadcast down the rows</div>
What's pandas default behaviour for combining DataFrames and TimeSeries elementwise?	\item If the DataFrame index contains dates,<div>\item the TimeSeries will be aligned with the DataFrame's rows</div><div>\item and the operation broadcast columnwise</div>
How do you transpose a pandas DataFrame?	\item \ttt{df.T}
How do you get a text summary of the structure of a pandas DataFrame?&nbsp;	\item \ttt{df.info()}
What're the axes of a pandas Panel?	\item \ttt{items}, axis 0, which indexes the DataFrames<div>\item \ttt{major\_axis}, axis 1, which is the index/rows of each of the DataFrames</div><div>\item \ttt{minor\_axis}, axis 2, which is the columns of each of the DataFrames&nbsp;</div>
What's panel data?	\item Records of multiple phenomena (the columns)<div>\item over multiple subjects (the rows)</div><div>\item over multiple observations/times</div>
How do you get one of the DataFrame items from a pandas Panel?	\item \ttt{wp['itemname']}
How do you get a row from a pandas Panel?	\item \ttt{wp.major\_axis['rowname']}
What does the \ttt{squeeze} operation do in pandas?	\item Removes length-1 dimensions from the shape of the object<div>\item So \ttt{[[[x], [y]]} becomes \ttt{[x, y]}&nbsp;</div>
How does pandas support higher-dimensional data?	\item Via Panel4D and panelnd
How do you get a small sample of a pandas Series?	\item \ttt{s.head()}<div>\item \ttt{s.tail()}</div><div>\item Default number of items returned is 5</div>
What's the \ttt{shape} of a pandas object?	\item It's an array of integers giving how many labels there are along each dimension
When you assign to the index/columns/items of a pandas object, how is data migrated from the old index/columns/items?	\item Data under the first old label is moved to the first new label<div>\item Data under the second old label is moved to the second new label</div><div>\item etc</div>
How do you get an array of the data in a pandas object?	\item \ttt{df.values}
Which libraries are commonly used by pandas to accelerate calculations?	\item \ttt{numexpr}, for general calculations<div>\item \ttt{bottleneck}, for calculations involving arrays with NaNs</div>
What's the preferred way to conduct elementwise arithmetic on a pandas DataFrame?	<div>\item \ttt{df.sub},&nbsp;\ttt{df.add},&nbsp;\ttt{df.mul},&nbsp;\ttt{df.div}</div>
What's a common confusion when applying elementwise arithmetic to pandas DataFrames and Panels?	\item \ttt{df.sub(x, axis='columns')} specifies that \ttt{x} should be aligned with \ttt{df} on the columns<div>\item \ttt{wp.sub(x, axis='columns')} specifies that the operation should be broadcast over the columns</div>
What's broadcasting in pandas?	\item If you conduct an elementwise operation with say a pandas dataframe and a scalar<div>\item the scalar will be `broadcast' over every element of the dataframe&nbsp;</div>
How do you specify the default value for an elementwise operation in pandas?	\item \ttt{df.add(df2, fill\_value=x)}<div>\item which will be used in place of Na*</div>
How do you conduct elementwise numeric comparisons in Pandas?	\item \ttt{df.gt(df2)}, \ttt{df.lt(df2)}&nbsp;<div>\item \ttt{df.ge(df2)}, \ttt{df.le(df2)}&nbsp;</div><div>\item \ttt{df.eq(df2)}, \ttt{df.ne(df2)}&nbsp;</div>
What are the Boolean reductions for collections of bools in&nbsp;pandas?	\item \ttt{df.any()}<div>\item \ttt{df.all()}</div>
What does \ttt{df.bool()} do in pandas?	\item If \ttt{df} has a single element which is a Boolean, it returns it
How should you compare pandas objects for equivalence?	\item \ttt{df.equals(df2)}<div>\item since this'll consider Na*s in the same location to be equal</div>
How can you arbitrarily combine the data from two pandas DataFrames with the same columns?&nbsp;	\item \ttt{df1.combine(df2, combiner)}<div>\item where \ttt{combiner} takes two Series, one from each DataFrame</div>
What's pandas \ttt{combine\_first} method?	\item \ttt{df1.combine\_first(df2)} replaces any Na*s in \ttt{df1} with the data from the same location in \ttt{df2}
How do you compute summary statistics over a pandas DataFrame?	\item \ttt{df.sum(i)}<div>\item or similar, where \ttt{i} specifies the axis to summarize over</div><div>\item \ttt{i = 0}, index, is the default</div><div>\item \ttt{i = 1}, columns</div>
How do you compute summary statistics (like the sum per row) over a Pandas panel?	\item \ttt{df.sum(i)}<div>\item or similar, where \ttt{i} specifies the axis to summarize over</div><div>\item \ttt{i = 0}, items</div><div>\item \ttt{i = 1}, major,&nbsp;is the default</div><div>\item \ttt{i = 2}, minor</div>
How can you handle missing data in pandas when computing summary statistics?	\item Pass \ttt{df.sum(skipna=True)} to ignore Na* data
What's a common mistake when using axis-dependent methods in pandas?	\item Mixing up which functions have \ttt{axis} attributes that set the axis to match on<div>\item and which have \ttt{axis} attributes that set the axis to broadcast over</div>
What's pandas' \ttt{describe()}?	\item \ttt{df.describe()} gives the common summary stats of an object<br />
How can you get the index of the minimum value in a pandas object?	\item \ttt{ds.idxmin()}
How do you get the number of each unique value in a pandas object?	\item \ttt{s.value\_counts()}
How can you bin the data in a pandas series into $k$ equally-sized ranges?	\item \ttt{cut(s, k)}
How can you bin the values of a pandas object into $k$&nbsp;quantiles?	\item \ttt{qcut(s, k)}
How's infinity represented in Python?	\item \ttt{sp.inf}
How do you apply a function along an axis of a pandas object?	\item \ttt{df.apply(f, axis=i)}<div>\item \ttt{f} can return an object of the same dimension as the one it consumed, or a smaller one</div>
How can you apply a function to the scalars of a pandas object?&nbsp;	\item \ttt{df.applymap(f)}
How do you apply a lookup table to the scalars of a pandas object?	\item Represent the lookup table as a Series \ttt{s}<div>\item \ttt{df.applymap(s)}</div>
How can an axis be specified in pandas?	\item Either with an index&nbsp;<div>\item or with it's name (\ttt{index}, \ttt{columns}, \ttt{items})</div>
At a high level, what does \ttt{df.reindex(idx)} do in pandas?	\item Reorders the data to match the new index<div>\item Throws away data for which there's no corresponding new label</div><div>\item Fills labels for which there's no data</div>
How are indexes passed in pandas?	\item BY REFERENCE
What's the relevance of reindexing to performance in pandas?	\item Operations on aligned data are much faster than operations that have to implicitly realign the data first
How can you reindex a pandas object to match another pandas object's axes?	\item \ttt{df1.reindex\_like(df2)}
What's the best way to align two objects to eachother in pandas?	\item \ttt{df1.align(df2)}<div>\item and optionally the alignment strategy can be specified</div>
When reindexing a pandas object, how can you specify how missing values should be dealt with?	\item \ttt{df1.reindex(idx, method='ffill')} copies in the previous non-missing value<div>\item \ttt{df1.reindex(idx, method='bfill')} copies in the next non-missing value</div>
How can you remove labels from a pandas axis?	\item \ttt{df.drop([label1, label2])}
How can you update the labels of a pandas object?	\item \ttt{df.rename(f)}&nbsp;where \ttt{f} is a total function on \ttt{df}'s labels<div>\item \ttt{df.rename(l)} where \ttt{l} is a lookup table (series or dict) on some subset of \ttt{df}'s labels</div>
What do you get when you iterate over a pandas object?	<div>\item Series: the values</div><div>\item DataFrame: the column labels</div><div>\item Panel: the item labels&nbsp;</div>
How can you iterate through the rows of a pandas DataFrame?	\item \ttt{for (i, r) in df.iterrows()}
How can you iterate through the key-value pairs of a pandas object?	\item \ttt{for (col, series) in df.iteritems()}
How do you perform string transformations on the values of a pandas Series?	\item Use the methods in \ttt{s.str}
How can you convert categorical data, represented as strings, into indicator variables in pandas?	\item \ttt{get\_dummies}
How do you sort a DataFrame by a specified column in pandas?	\item \ttt{df.sort\_index(by='colname')}
How do you sort a pandas Series by value?	\item \ttt{s.order()}<div>\item Note that \ttt{s.sort()} does it in place!</div>
How do you get the $k$ largest elements in a pandas Series?	\item \ttt{s.nlargest(k)}<div>\item Equivalent to sorting by value and then calling \ttt{head(k)}, but faster</div>
What's a multi-index in pandas?	\item A hierarchical index<div>\item with labels given by tuples \ttt{('top level label', 'second level label')}</div>
What's pandas's policy on mutator methods?	\item None of pandas's methods automatically modify data in place<div>\item They'll only do it when you explicitly specify so</div>
How can you get the type of the objects stored in a Pandas DataFrame?	\item \ttt{df.dtypes} will return a Series of the datatypes stored in different columns<div>\item If a column holds more than one datatype, it'll return their most recent common ancestor&nbsp;</div>
What's the default integer type size in pandas?&nbsp;	\item 64 bit, on all platforms
How do you upcast the elements in a pandas object?	\item \ttt{df.astype('typename')}
What's a common gotcha concerning selection operations over columns of integers in pandas?	\item If the column contains a NaN<div>\item then everything in the column will be cast to a float</div>
How can you downcast the objects in a pandas object?	\item \ttt{df.convert\_objects()}<br />
How can you select columns from a pandas DataFrame contingent on their type?	\item \ttt{df.select\_dtypes(include=[bool])}
What's the advantage of specialized indexing methods over subscripting and attribute access to an object in pandas?	\item The type of the object isn't known in advance when subscripting or using attributes<div>\item so certain optimizations can't be made</div>
What're valid arguments to \ttt{loc()} in pandas?	\item A single label \ttt{'a'}<div>\item A list/array of labels \ttt{['a', 'b', 'c']}</div><div>\item A slice object \ttt{'a':'f'} - note both endpoints are included!</div><div>\item A boolean array \ttt{[True, False, False]}</div>
What're valid arguments to \ttt{iloc()} in pandas?	\item An integer \ttt{5}<div>\item A list/array of integers \ttt{[1, 2, 3]}</div><div>\item A slice object with ints \ttt{1:7}</div>
What's \ttt{ix()} in pandas?	\item The most general form of indexing:<div>\item it's primarily label-based access (ie \ttt{loc}) but will fall back to positional access (ie \ttt{iloc})</div><div>\item It also supports floating-point access</div>
How do \ttt{loc, iloc, ix} select the axes to use on a multidimensional pandas object?	\item All indices should be supplied: \ttt{df.loc[row\_idxr, col\_idxr]}<div>\item but any of them can be replaced with the null slice \ttt{:}</div><div>\item and any indexers are left out completely are assumed to be \ttt{:}&nbsp;</div>
What happens if you try and create a new column on a pandas DataFrame using attribute access?	\item It fails silently, creating a new attribute rather than a new column
What's a common gotcha with subscripting on a pandas DataFrame?	\item While in general subscripting operates over columns<div>\item subscripting with a slice operates over rows!</div>
What's a common mistake with slicing with indexes in pandas?	\item Forgetting that the ranges are \emph{inclusive}
How does pandas deal with out-of-bounds slice arguments?	\item It'll truncate them to the length of the object
What's the purpose of \ttt{at} in pandas?	<div>\item It's for getting/setting the scalar at a location in an object without the overhead that \ttt{loc} has to do to sort out indexes/slices/etc&nbsp;</div>\item \ttt{df.at['rowname', 'colname']}
What's pandas \ttt{isin} method do on DataFrames?	\item \ttt{df.isin(arr)} returns a Boolean DataFrame indicating which values were in the array<div>\item \ttt{df.isin(dict)} does the same, but uses the dict to look up an array for each column label</div>
What's the difference between subscripting with a Boolean vector and using the \ttt{where} method in&nbsp;pandas?&nbsp;	\item \ttt{where} preserves the shape of the data, replacing values that failed the condition with some fill value
What's the inverse of \ttt{where} in pandas?	\item \ttt{mask}, which replaces each value satisfying the condition with a fill value
What's pandas' \ttt{query} method?	\item \ttt{df.query()} takes a string like \ttt{'(a &lt; b) \&amp; (b &lt; c)'}<div>\item substitutes each dummy variable with the matching column, getting \ttt{(df.a &lt; df.b) \&amp; (df.b &lt; df.c)}</div><div>\item then uses it as a Boolean vector indexing \ttt{df[(df.a &lt; df.b) \&amp; (df.b &lt; df.c)]}</div>
In a pandas query expression, how do you reference the index on a DataFrame?	\item \ttt{df.query('index &gt; 2')}
How do you refer to the components of a multi-index in a pandas query expression?	\item \ttt{df.query('ilevel\_0 &gt; 2')} to get the 0th level of the index, etc
What's pandas' \ttt{take} method?	\item \ttt{df.take([1, 2, 3])} gets the items at indices 1, 2, 3&nbsp;<div>\item and since it's intended for just integer indices, it's a lot faster than subscripting</div>
How can you find duplicated rows in a pandas DataFrame?	\item \ttt{df.duplicated(['a', 'b'])}<div>\item where the array indicates which columns to use to checking equality</div><div>\item By default, the first appearance of a row is assumed to be the unique one</div>
How can you drop duplicate rows from a pandas DataFrame?	\item \ttt{df.drop\_duplicated(['a', 'b'])}<div>\item where the array indicates which columns to use to checking equality</div><div>\item By default, the first appearance of a row is assumed to be the unique one</div>
How can you get a copy of a slice from a pandas object?	\item Use the \ttt{truncate} method
How can you get an arbitrary intersection of rows and columns in pandas?&nbsp;	\item \ttt{df.lookup(rows, columns)}
What's a float index in pandas?	\item An index whose labels are floats<div>\item Subscripting can use a slice of floats to select a range</div>
What's chained indexing in pandas?	\item \ttt{df['colname']['rowname']}<div>\item which causes a copy of the column to be made, then the scalar indexed from the copied column</div><div>\item which means assignment will be to the copied column, not to the DataFrame!</div><div>\item Better to use \ttt{loc['colname', 'rowname']}</div>
How do you take the intersection of two indexes in pandas?	\item \ttt{index1 \&amp; index2}<div>\item They're effectively multisets</div>
In what ways can you create a multi-index in pandas?	\item Pass a list of tuples using \ttt{MultiIndex.from\_tuples}<div>\item Pass two lists to be product'd together \ttt{MultiIndex.from\_product}</div><div>\item Pass an array of lists of the same length straight to the \ttt{index} argument of \ttt{Series}</div>
What happens in pandas if you pass a list of tuples to an \ttt{index} argument of a constructor? &nbsp;	\item It uses the tuples as atomic values for the index<div>\item It does \emph{not} create a hierarchical index</div>
How can you get the labels for a particular level of a pandas multiindex?	\item \ttt{index.get\_level\_values(i)}<div>\item where \ttt{i} can be an integer index or a name</div>
How do you subscript into a multiindexed pandas object?	\item \ttt{df['levelzero', 'levelone']} (preferred)<div>\item \ttt{df['levelzero']['levelone']}</div>
What're the two ways to slice a multiindex in pandas?	\item Provide one or more tuples: \ttt{df[('start0', 'start1'):end1]}<div>\item Use a slice object: \ttt{df[(slice('start0', 'end0'), slice('start1', 'end1')), :]}</div>
What's the universal slice object in pandas?	\item \ttt{slice(None)}
What's a common mistake with using slice objects for multiindexing in pandas?&nbsp;	\item You should specify \ttt{:} for any axis you don't want sliced!<div>\item otherwise the slice might be misinterpreted as being intended for all axes</div>
What's a prerequisite for slicing an axis in pandas?	\item The axis must be lexsorted
How can you easily create multiple slice objects in pandas?	\item \ttt{idx = pd.IndexSlice}<div>\item Then \ttt{idx[:, ['start1', 'end1']]} will create the corresponding slice objects</div>
What's the easiest way to select data at a particular level of a multiindex?	\item \ttt{df.xs('label', level=2)}
How can you sort an index with respect to a level in pandas?	\item \ttt{s.sortlevel(i)}
What's the catch about sorting and multiindexes in pandas?	\item Multi-indexes don't implicitly enforce an ordering on the index<div>\item but many of the methods on them require the data to be sorted</div><div>\item and others will return a copy rather than a view if it isn't!</div>
What're the two ways to permute the levels of a multi-index?	\item \ttt{df.swaplevel()}<div>\item \ttt{df.reorder\_levels()}</div>
How can you test whether a value is null in pandas?	\item \ttt{isnull()}<div>\item \ttt{notnull()}</div><div>\item Covers both None/NaN/NaT/etc</div>
How are Na* values usually filled in pandas?	\item \ttt{df.fillna()}<div>\item with either a default value,</div><div>\item a fill method (\ttt{ffill}, \ttt{bfill})</div><div>\item or a lookup on the column labels</div>
How can you drop the labels from a pandas axis which correspond to null data?	\item \ttt{df.dropna()}
What's an alternative to filling missing values in pandas?	\item Interpolating them with \ttt{df.interpolate()}
What's the NaN literal in pandas?	\item \ttt{np.nan}
How can you replace all instances of some set of values in a pandas object?	\item \ttt{df.replace()}<div>\item This has a lot of overloads, inc for regex</div>
What's a groupby object in pandas?	\item It's a proxy object for a grouping<div>\item Note that the actual grouping operation is lazy!</div>
How do you group the rows of a DataFrame by their values in two columns?	\item \ttt{df.groupby(['colname1', 'colname2'])}
What do you get when you iterate over a groupby object?	\item \ttt{(key, group)} pair&nbsp;
How do you apply an arbitrary scalar-valued function to the groups of a pandas groupby object?	\item \ttt{grouped.aggregate(f)}<div>\item Collections of functions can also be passed</div>
How can you apply an arbitrary size-preserving function to the groups of a pandas groupby object?	\item \ttt{grouped.transform(f)}<div>\item where \ttt{f} takes and returns the entire group</div>
How can you select the groups in a pandas grouping satisfying some condition?	\item \ttt{grouped.filter(f)}
What's dispatching in pandas groupings?	\item If a member function is called on the grouping<div>\item which doens't correspond to an actual member function</div><div>\item it'll instead be dispatched to each individual group to execute</div>
How can you apply an arbitrary function to the groups in a pandas grouping?	\item \ttt{df.apply(f)}<br />
What's a common gotcha with calling \ttt{apply} on pandas groupings?	\item It'll be called twice on the first group, so it can decide whether to take a fast or slow code path<div>\item So don't pass a function which has side effects!</div>
How does pandas' groupby handle Na* keys?	\item It doesn't - they'll be discarded
How can you see where each row appears in a pandas group?	\item Use \ttt{grouped.cumcount()}
What does \ttt{stack()} do in pandas?	\item Converts the lowest level of the column index to a new innermost level of the row's multiindex
How do you join two pandas objects along an axis?&nbsp;	\item \ttt{concat(df1, df2)}
What does pandas' \ttt{concat} do with the axes other than the one being joined along?	\item Depends on the arguments it's passed<div>\item Most commonly, \ttt{join='inner'} to take the intersection of the axes labels</div><div>\item \ttt{join='outer'} to take the union of the axes labels</div>
What's a shortcut for concatenating the rows of two different pandas objects?	\item \ttt{df1.append(df2)}<br />
What's the default behaviour of pandas' \ttt{append} concerning the rows' labels?	\item The indices must be disjoint unless \ttt{ignore\_index=True} is passed
How do you carry out full-on SQL-esque joins in pandas?	\item Use \ttt{merge} and its million arguments
What's the shorthand for concatenating two pandas DataFrames by column?	\item \ttt{df1.join(df2)}
How can you conduct SQL-style joins on ordered data in pandas?&nbsp;	\item \ttt{ordered\_merge}
What's pandas' \ttt{update} method?	<div>\item \ttt{df1.update(df2)}</div><div>\item replaces the values in \ttt{df1} corresponding to non-NA values in \ttt{df2} with those values</div>
How do you use the pivot function in pandas?	\item \ttt{df.pivot(index='colA', columns='colB', values='colC')}<div>\item will create a table with&nbsp;</div><div>\item rows given by the values in \ttt{colA}</div><div>\item columns given by the values in \ttt{colB}</div><div>\item and values given by \ttt{colC}</div>
What happens if you omit the \ttt{values} argument to pivot in pandas?	\item You'll get a hierarchical column index<div>\item where each column that wasn't specified by the \ttt{index} or \ttt{columns} arguments to pivot</div><div>\item forms the bottom level of the hierarchy</div>
What does \ttt{unstack()} do in pandas?	\item Converts the innermost level of the row index to a new innermost level of the column index
What does \ttt{melt} do in pandas?	\item It `unpivots' to the row axis all but the columns specified by the \ttt{id\_vars} argument&nbsp;<div>\item leaving two non-identifier columns: \ttt{variable} and \ttt{value}</div>
What does \ttt{pivot\_table} do in pandas?	\item Can specify which column(s) to use with \ttt{values},&nbsp;\ttt{index},&nbsp;\ttt{columns}<div>\item and an aggregation function \ttt{aggfunc}, defaulting to the mean</div>
How can you construct detailed grouping heuristics in a reusable way in pandas?	\item Create a \ttt{Grouper}
What's \ttt{crosstab()} do in pandas?	\item It calculations a crosstab/contingency table between two objects<div>\item defaulting to a frequency table</div>
How can you encode 1D values as an enumerated type in pandas?	\item \ttt{labels, uniques = factorize(x)}<div>\item where \ttt{uniques} is an index of the distinct values in \ttt{x}</div><div>\item and \ttt{labels} gives the index for each element of \ttt{x} in uniques</div>
What's an Andrews curves plot?	\item Many timeseries samples from each class are plotted as curves<div>\item with each class being colored differently</div>
What's the use of a hexagonal bin plot?	\item They're intended for data which is too dense for a scatterplot to be effective&nbsp;
What's a scatter matrix plot?	\item Given samples $x_i$ over features $j$<div>\item a scatter matrix plot is a grid of plots, where the $j,k$th plot is a scatterplot of $j$ vs $k$</div><div>\item while the $j,j$th plot is a density plot of $j$</div>
What's a parallel coordinate plot?	<div>\item Meant for data where the features have some ordering to them</div>\item The features are represented as equally-spaced vertical lines<div>\item and points are represented as piecewise linear curves between them&nbsp;</div>
What's a lag plot?	\item A way to check whether a series is random: plot $x_i$ vs $x_{i+l}$<div>\item where $l$ is some `lag'</div>
What's an autocorrelation plot?	\item A plot of the correlations between $x_{i}$ and $x_{i+l}$ as $l$ varies<div>\item Used for checking for randomness</div>
How do you plot each series in a pandas DataFrame on its own subplot?	\item \ttt{df.plot(subplots=True)}<br />
What's trellis plotting in pandas?	\item A way to arrange data in a rectangular grid of plots by values of specified attributes&nbsp;
When does a pandas subscripting return a view and when does it return a copy?	\item Subscripting with a list of indices or a collection of Booleans will return a copy<div>\item Subscripting with a slice or a single value will return a view</div>
What's a causal MRF?	\item Another name for a Markov mesh
What's a Markov mesh?	\item The grid version of a Markov chain<div>\item where causality flows down and to the right</div>
What's a MRF in ML?	\item A Markov Random Field
What's a Markov Random Field?	\item A graphical model whose edges are undirected
What's a Markov network?	\item Another name for a Markov random field
What's an undirected graphical model another name for in ML?	\item A Markov random field
What's UGM stand for in ML?	\item Undirected graphical model
At a high level, what're the advantages of UGMs over DGMs?	\item They're symmetric<div>\item Conditional UGMs work better than conditional DGMs</div>
What're the disadvantages of UGMs compared to DGMs?	\item The parameters are harder to interpret<div>\item The parameters are less modular<div>\item Parameter estimation is more expensive</div></div>
What's the global Markov property for UGMs?	\item Nodes $A$ are independent of nodes $B$ conditional on nodes $C$&nbsp;<div>\item if $C$ separates $A$ from $B$</div>
What's the shorthand for the Markov blanket of a node $t$?	\item $\text{mb}(t)$
What's the closure of a node in a UGM?	\item $\text{cl}(t) = \text{mb}(t) \cup \{t\}$
What's the undirected local Markov property for UGMs?	\item The Markov blanket of a node is its immediate neighbours
What's the pairwise Markov property for UGMs?	\item Two nodes are independent in a UGM if they don't share an edge
How do the local, global and pairwise Markov properties relate on a UGM?	\item If the distribution is positive, then they're equivalent<div>\item (if the distribution is zero anywhere, that induces independences that aren't captured in the graph)</div>
What's moralization?	\item A process for converting DGMs to UGMs<div>\item Coparents are connected then directions are dropped</div><div>\item This loses some CI information though!</div>
How can you use UGMs to determine whether $A \perp B | C$ in a DGM?	\item Extract the ancestral graph of $A \cup B \cup C$<div>\item Moralize it</div><div>\item See if $C$ separates $A, B$</div>
What's the ancestral graph of a set of nodes in a digraph?	\item The subgraph on the nodes which are in the set or ancestors of the nodes in the set
What's a perfect map of a distribution $p$ with respect to graphical models?	\item A graph $G$ such that&nbsp;<div>\item $G$ is an I-map of $p$ and</div><div>\item $I(G) = I(p)$</div><div>\item ie $G$ captures exact the CI properties of the distribution</div>
What's a CI relationship that can be represented by a DGM but not by a UGM?	<div>\item A non-monotonic one:</div>\item $A \perp B$ but $A \not \perp B |C$<div>\item represented in a DGM as $A \rightarrow C \leftarrow B$</div>
What's a CI property that can be represented by a UGM but not by a DGM?	\item A cyclic one
What's a monotonic CI property?	\item One such that if $A \perp B|C$ then $A \perp B|C,D$
What's a chordal graph?	\item A graph in which every length-4-or-greater cycle<div>\item has a chord, an edge between two non-adjacent nodes</div>
What's a decomposable graph?	\item A graph such that moralization (with respect to some ordering of the variables) adds no edges
What's the special property of chordal graphs with respect to graphical models?	\item They can be perfectly modeled as either DGMs or UGMs
What's a factor of a UGM?	\item A potential function $\psi_c(y_c|\theta_c)$ of a clique $c$
What's the Hammersley-Clifford theorem?	\item A positive distribution $p(y) &gt; 0$ satisfies the CI properties of an undirected $G$ iff&nbsp;<div>\item $p(y|\theta) = \frac{1}{Z(\theta)}\prod_c \psi_c(y_c|\theta_c)$ &nbsp;</div><div>\item where $c$ are the maximal cliques of the graph</div><div>\item and $Z(\theta)$ is the partition function</div>
What's the Gibbs distribution?	\item $p(y|\theta) = \frac{1}{Z(\theta)} \exp\left(-\sum_c E(y_c|\theta_c)\right)$<div>\item where $E$ is the energy function</div>
What's the maxent distribution strongly resemble?	\item The Gibbs distribution
How can a Gibbs distribution be converted to a UGM?	\item Define factors<div>\item $\psi_c(y_c|\theta_c) = \exp(-E(y_c|\theta_c))$</div>
What's a pairwise MRF?	\item A MRF which is written as a product over the edges of the graph<div>\item $p(y|\theta) \propto \prod_{s\sim t}\psi(y_s, y_t)$</div>
What do the potentials in a MRF represent?	\item The `compatibility' of the variable assignment<div>\item They're not probabilities!</div>
What's a maximum entropy MRF?	\item One where the log-potentials are linear in the parameters:<div>\item $\ln \psi_c(y_c|\theta_c) = \phi_c(y_c) \cdot \theta_c$</div><div>\item where $\phi_c$ are the feature functions</div>
What's an associative Markov network?	\item A discrete MRF with potentials that encourage the states of each variable in a clique to match
What's the Ising model?	\item A pairwise MRF such that<div>\item $\psi_{st}(y_s, y_t) = \begin{pmatrix} e^{w_{st}} &amp; e^{-w_{st}} \\ e^{-w_{st}} &amp; e^{w_{st}} \end{pmatrix}$</div><div>\item where $y_s \in \{-1, +1\}$</div>
What're the two most common cases of the Ising model?	\item The same weight is set for all edges, $w_{st} = J$<div>\item and if $J &gt; 0$ then we get an associative Markov network</div><div>\item and if $J &lt; 0$ we get a frustrated system</div>
What's a frustrated system?	\item One in which all the constraints can't be satisfied simultaneously
What's the computational complexity of computing the partition function for MRFs?	\item In general it's NP-hard<div>\item but it's polynomial time for associative Markov networks</div>
In an Ising model, what's an external field?	\item An energy term which biases the spins, of the form<br /><div>\item $\ln p(y) = \dotsb + b^Ty$</div><div>\item where $b$ is the bias term</div>
How does an Ising model relate to a GGM?	<div>\item If the Ising model has weights $W$ and bias $b$,</div><div>\item $\Lambda\mu = b$</div>\item $\Lambda = W$<div>\item and the only difference is that the GGM has continuous parameters, while the Ising model uses bit-vectors</div>
What's a Hopfield network in terms of MRFs?	\item An Ising model on a complete graph with a symmetric weight matrix
What's the main use of Hopfield networks?	\item Associative memory:<div>\item train the network on fully observed bitvectors, corresponding to the patterns we want it to memory</div><div>\item and then present it with a partial bitvector and ask it to minimize the energy over the unknowns</div>
What's the iterative conditional modes algorithm?	\item It's an algorithm for solving Ising models<div>\item where at each step a node is set to its most likely state, given its neighbours</div>
What's the Potts model?	\item A generalization of the Ising model to $K$ states, using a matrix of the form<div>\item $\psi_{st}(y_s, y_t) = \begin{pmatrix} e^{w_{st}} &amp; 1 &amp; 1 \\ 1 &amp;&nbsp;e^{w_{st}} &amp; 1 \\ 1 &amp; 1 &amp;&nbsp;e^{w_{st}} \end{pmatrix}$&nbsp;</div>
What's the behaviour of the Potts model as the association strength $J$ varies?	\item $J &lt; 1.44$ gives small clusters<div>\item $J &gt; 1.44$ gives large clusters</div><div>\item $J = 1.44$ is the critical value which gives &nbsp;a mix of small and large clusters</div>
What's the use of the Potts model for image segmentation?	\item As a prior for image segmentation, since it encourages neighbouring pixels to have the same discrete label
What's a chain graph?	\item A combination of an undirected and a directed graph
What's the factor form of a Gaussian pairwise MRF?	\item It's a pairwise MRF with&nbsp;<div>\item $\ln \psi_{st}(y_s, y_t) = -\frac{1}{2}y_s \Lambda_{st} y_t$</div><div>\item $\ln \psi_t(y_t) = -\frac{1}{2}\Lambda_{tt} y_t^2 + \eta_t y_t$</div>
What's the distributional form of a Gaussian MRF?&nbsp;	\item It's a MVN in information form<br />
What're structural zeroes in a Gaussian MRF?	\item The zeros in the total precision matrix that correspond to absent edges in the MRF
What's a vector auto-regressive process?	\item $y_t|y_{1:t-1} \sim \mc{N}(\sum^L_1 A_l y_{t-l}, \Sigma)$<div>\item where $L$ is the order of the process</div>
How can a vector autoregressive process be represented as a graphical model?	<div>\item use directed edges to represent transitions between time slices</div><div>\item and if the precision is sparse, use undirected edges for the relationships within a time slice</div><div>\item or if the covariance is sparse, use bidirectional edges for the relationships within a time slice</div>
What's a bidirectional graph?	\item A way to represent sparse covariance matrices<br /><div>\item where an absence of an edge represents unconditional independence</div>
How can a bidirected graphical model be converted to a DAG?	\item Each edge $x \leftrightarrow y$ is replaced with $x \leftarrow z \rightarrow y$<div>\item where $z$ is a hidden `confounder' variable</div>
What's a directed mixed graphical model?	\item A graph which has both directed and bidirected edges
How can sparse covariance matrices be represented as graphical models?	\item Using covariance graphs, a kind of bidirected graph
What's probabilistic relational modelling?	\item A topic that tries to combine first order logic with probability theory
What's a Markov logic network?	\item First order logic represented as a MRF. Uses factors of the form<div>\item $\ln \psi_c(x_c) = w_c \phi(x_c)$</div><div>\item where $\phi(x_c)$ evaluates the Horn clause $c$ on variables $x$</div><div>\item and $w_c$ are the weights of the model</div>
In a Markov logic network, what's the intuitive interpretation of the weights?	\item $w_c$ represents the probability of a world where the clause is satisfied<div>\item relative to the probability of a world where it isn't.</div>
What's the open universe problem?	\item A logical question about the number or existance of some object or relation
What's a Horn clause in logic?	\item An OR clause with at most one positive literal
What's moment matching?	\item A method of fitting models that consists of finding parameters $\theta$ such that<div>\item $\mbb{E}_\text{emp}[y] = \mbb{E}_{p(y|\theta)}[y]$</div><div>\item where the left is the clamped term and the right is the unclamped/contrastive term</div>
How are maxent MRFs usually fitted?	\item Gradient descent
What's the problem with fitting maxent MRFs via gradient descent?	\item To compute the gradient at each step, the distribution of the variables needs to be inferred from the parameters<div>\item which is very slow on MRFs as there's no closed form</div>
What's a maxent MRF?	\item Another name for a log-linear MRF
What's the problem with training MRFs?	\item To do gradient-based optimization properly, you need to be able to calculate MAP/MLE estimates<div>\item which in general isn't possible with MRFs</div>
What's the pseudo-likelihood?	\item $l_{PL}(\theta) = \frac{1}{N}\sum_i \sum_d \ln p(y_{id}|y_{i, -d}, \theta)$<div>\item where $d$ denotes the dimension&nbsp;</div>
What's the use of the pseudo-likelihood for MRFs?	\item It can be used to approximate the MLE when training a MRF
What're the limitations of the pseudo-likelihood in the context of MRFs?	\item It's hard to apply to models with hidden variables<div>\item If a neighbour $j$ of a node $i$ s a perfect predictor of $i$, then the model will learn to rely completely on $j$, even if it means ignoring other useful evidence</div>
What's the stochastic maximum likelihood algorithm?	\item An algorithm for fitting MRFs<div>\item that uses stochastic gradient descent</div><div>\item and MCMC for generating samples</div><div>\item with the MCMC initialized at the start of each gradient step with its state at the end of the last gradient step &nbsp;</div>
What's SML stand for in ML?	\item Stochastic maximum likelihood
What's feature induction in ML?	\item A way to find good feature functions for models like maxent MRFs&nbsp;<div>\item Start with a base set of features, then continually create new feature combinations out of old ones,</div><div>\item greedily adding the best to the model and optimizing the new parameter</div>
What's the idea behind iterative proportional fitting?	\item When fitting a general MRF, at optimum it must be that<div>\item $p_\text{emp}(y_c) = p(y_c| \theta)$<div>\item and in chord graphs, this means that</div></div><div>\item $p_\text{emp}(y_c) = \psi_c(y_c|\theta_c)$</div><div>\item While this doesn't hold in general, we can imagine trying to enforce this condition.</div><div>\item IPF follows</div>
What's the iterative proportional fitting algorithm?	<div>\item A coordinate ascent algorithm for fitting discrete log-linear MRFs</div><div>\item using the update&nbsp;</div>\item $\psi^{t+1}_c (y_c) =&nbsp;\frac{p_\text{emp}(y_c)}{p(y_c|\psi^t)}\psi^t_c(y_c)$<div>\item where $\psi_c$ are vectors&nbsp;</div><div>\item and $y_c$ is a one-hot encoding of the clique $c$</div>
What's a conditional random field?	\item A MRF where the clique potentials condition on the input features<div>\item $p(y|w, w) = \frac{1}{Z(x,w)}\prod_c \psi_c(y_c|x,w)$</div>
What's CRF stand for in ML?	\item Conditional random field
What's a discriminative random field in ML?	\item Another name for conditional random fields
What's the form of a maximum entropy Markov model?	\item $p(y|x,w) = \prod_t p(y_t|y_{t-1}, x, w)$<div>\item where $x = (x_{1:T}, x_g)$<br /><div>\item and $x_t$ are the features specific to node $t$&nbsp;</div><div>\item and $x_g$ are the global features</div></div>
How do maximum entropy Markov models arise?	\item They're a discriminative version of a HMM<div>\item created by `reversing the arrows' in the observation model of the HMM</div><div>\item so that the hidden states are now the outputs</div>
What's MEMM stand for in ML?	\item Maximum entropy Markov model
What's the problem with MEMM models?	\item Label bias:<div>\item local features $x_t$ at time $t$ do not influence observations $y_{t-1}$ and all earlier&nbsp;</div><div>\item The root of this problem is that MEMMs are locally normalized, with each conditional probability distribution summing to 1</div>
What's a chain structured CRF?	\item A CRF whose hidden variables form a chain
Why are CRFs less useful for online tasks than DGMs?	\item Because CRFs are globally normalized by the partition function, which depends on all the nodes<br /><div>\item vs DGMs, which are locally-normalized conditional probability distributions</div>
What's the definition of the partition function for a MRF?	\item $Z(\theta) = \sum_y \prod_c \psi_c(y_c|\theta_c)$
How are CRFs used for handwriting recognition?	\item Each letter has a potential associated with it,&nbsp;calculated by a discriminative classifier (like a NN)<div>\item and neighbouring letters have edge potentials given by a language bigram model</div>
What's the form of a truncated Gaussian potential?	\item $\exp\left(-\frac{1}{2\sigma^2} \min(x^2, \delta_0^2)\right)$<div>\item where $\delta_0$ encodes the cutoff</div>
What's the use of the truncated Gaussian potential?	\item When $x = x_1 - x_2$,&nbsp;<div>\item it's a discontinuity-preserving potential<div>\item useful for things like image processing, where you don't want to smooth out edges&nbsp;</div></div>
What's a metric CRF?	<div>\item Inference is very hard on CRFs over continuous variables unless the model is jointly Gaussian</div><div>\item so a common trick is to discretize each variable</div><div>\item and if this is done with a pairwise CRF, the potentials often form a metric</div>
Why is training CRFs much slower than training MRFs?	\item The partition function in a CRF depends on the input $x_i$<div>\item so inference has to be done for every sample at every gradient step</div>
Why is training a MRF with hidden variables generally much harder than training a fully observed MRF?	\item When there are hidden variables, the objective can be non-convex
What's loss calibrated inference?	\item The Bayesian distinction between inference and decision making is only optimal if the exact posterior can be calculated<div>\item When it can't (ex: MRFs), it can make sense to take the loss function into account when fitting the model&nbsp;</div>
How can you bound a term of the form $\ln \sum_{y \in \mc{Y}} \exp(y)$?	\item $\max_{y \in \mc{Y}} y \leq \ln \sum_{y \in \mc{Y}} \exp(y) \leq \ln |\mc{Y}| +&nbsp;\max_{y \in \mc{Y}} y$
What's the additive form of big O notation?	\item $f \sim g$<div>\item is equivalent to $|f(x) - g(x)| \leq C$ for all $x$ and some $C$</div>
What's the loss function used by a SSVM?	\item $R_\text{SSVM} = \frac{1}{2}\|w\|^2 + C\sum \left[\max_y \{L(y_i, y) + w^T\phi(x_i, y)\} - w^T\phi(x_i, y_i)\right]$<div>\item where&nbsp;</div><div>\item $\phi$ is the feature vector</div><div>\item $L$ is the loss function</div><div>\item $C$ is the regularization parameter</div>
What's SSVM stand for in ML?	\item Structual support vector machine
How do SSVMs arise from a probabilistic standpoint?	\item Take a log-linear CRF and a Gibbs prior<div>\item and form the posterior expected loss for some loss function $L$</div><div>\item Then by upper bounding this, you can get the objective function for a SSVM&nbsp;</div>
How do SVMs relate to SSVMs?	\item SVMs fall out of SSVMs when you use<div>\item labels $\mc{Y} = \{-1, 1\}$</div><div>\item a 0-1 loss function</div><div>\item feature vectors of the form $\phi(x, y) = \frac{1}{2}yx$&nbsp;</div>
When using slack variables to form objective functions, what are two ways to penalize a large loss more than a small loss?	<div>\item Given constraint $c(w, y)$ and loss $L$,</div>\item Slack rescaling: $c(w, y) \geq 1 - \frac{\xi}{L(y)}$<div>\item Margin re-rescaling: $c(w, y) \geq L(y) - \xi$</div>
What's the frequentist perspective on how SSVMs arise?	\item Frequentists want to minimize the regularized empirical risk.<div>\item Given a log-linear CRF,&nbsp;</div><div>\item and a $l_2$ regularizer,</div><div>\item the&nbsp;objective of a SSVM is a convex upper bound on this</div>
What's the idea in the cutting plane approach to fitting SVMs?	\item Use the constraint-with-slacks interpretation of the objective function<div>\item Start with an initial guess $w, \xi$ and no constraints on any sample</div><div>\item Then for each sample in turn $i$, find the `most violated' constraint involving prediction $\hat y_i$</div><div>\item If the violation exceeds the current value of $\xi_i$ by more than $\epsilon$, add the constraint to the working set for $i$, $\mc{W}_i$</div><div>\item and solve the QP to find new $w, \xi$.</div><div>\item Keep repeating this until no sample's working set has changed in the last iteration</div>
Why does the cutting plane method for fitting SSVMs work so well?	\item Because only polynomially many constraints need to be added before convergence<div>\item and as soon as they are, the exponential number of other constraints are guaranteed to be satisfied within a tolerance of $\epsilon$</div>
What's the constraints interpretation of the objective of a SSVM?	\item $\min_{w, \xi} \frac{1}{2} \|w\|^2_2 + C|\xi|_1$<div>\item such that for each $i$ and each $y \in \mc{Y}\backslash y_i$</div><div>\item $w \cdot (\phi(x_i, y_i) - \phi(x_i, y)) \geq 1 - \frac{\xi_i}{L(y_i, y)}$</div>
How does the constraint interpretation of SSVMs arise?	\item We want the predictor $\arg\max_{y \in \mc{Y}}w^T\phi(x, y)$ to choose correctly on each test case $(y_i, x_i)$<div>\item which means that for all $i$ and $y \in \mc{Y}\backslash y_i$, we want</div><div>\item &nbsp;$w^T\phi(x_i, y_i) \geq w^T\phi(x_i, y)$</div><div>\item Add a $l_2$ regularization on the weights and some slack variables (which you then solve and sub out) and you get the objective for a SSVM</div>
What's the computational complexity of the cutting plane method for fitting SSVMs?	\item $O(1/\epsilon^2)$
What's the tricky part of the cutting plane method for fitting SSVMs?	\item Finding the most violated constraint at each step<div>\item The method for doing this is contingent on the loss function</div>
What's the structured perceptron algorithm?	\item An online algorithm for fitting SSVMs<div>\item On training sample $(y, x)$ calculate $\hat y = \arg\max p(y^\prime|x)$</div><div>\item then if $\hat y \neq y$, take a step</div><div>\item $w_{k+1} = w_k + \phi(y, x) - \phi(\hat y, x)$</div>
What's the idea in the stochastic subgradient descent algorithm for fitting SSVMs?	\item Calculate the subgradient of the SSVM objective function<br /><div>\item and then estimate the gradient using just one of the sample-dependent terms</div><div>\item Use this estimate to take steps, projecting $w$ back onto the unit ball after each one&nbsp;</div>
What's a latent CRF?	\item A CRF where the factors are allowed to rely on hidden variables
What's the concave-convex procedure?	\item An algorithm for optimizing a difference $f(w) - g(w)$ between convex functions $f, g$<div>\item which works by finding a linear upper bound $u$ on $-g$</div><div>\item then minimizing $f(w) + u(w)$</div>
What algorithm is usually used for solving latent SVMs?	\item The concave-convex procedure
In general, what kind of models can the forwards-backwards algorithm be applied to?	\item Any chain-structured graphical model
What's the sum-product algorithm?	\item Another name for belief propagation for trees
What're the phases of the belief propagation for trees algorithm?	\item Pick a root<div>\item Collect evidence: send messages from the leaves to the root</div><div>\item Distribute evidence: send messages from the root to the leaves</div>
What's the interpretation of the messages in the collect evidence phase of belief propagation for trees?	\item $m^-_{s\rightarrow t}(x_t) = p(x_t|v^-_{st})$<div>\item where $v^-$ is all the evidence from the `downstream' side of $s-t$, away from the root</div>
What's the definition of the belief state at $t$ after the collect evidence phase of the belief propagation on trees algorithm?	\item $\text{bel}^-_t(x_t) = \frac{1}{Z_t} \psi_t(x_t) \prod_{c\in \text{ch}(t)} m^-_{c\rightarrow t}(x_t)$<br />
What's the model underlying the belief propagation for trees algorithm?	\item A pairwise MRF with factors<div>\item $\psi_s(x_s)$ at each node indicating local evidence</div><div>\item $\psi_{st}(x_s, x_t)$ at each edge indicating the potential for edge $s-t$</div>
What's the definition of the messages in the collect evidence phase of belief propagation for trees?	\item $m^-_{s\rightarrow t}(x_t) = \sum_{x_s} \psi_{st}(x_s, x_t) \text{bel}_s^-(x_s)$
What's the interpretation of the belief state at $t$ after the collect evidence phase of the belief propagation algorithm?	\item $\text{bel}^-_t(x_t) = p(x_t|v_t^-)$<div>\item where $v_t^-$ is all the evidence from the `downstream' side of $t$, away from the root</div>
What's the equivalent of the belief propagation algorithm on tree graphical models for HMMs?	\item The forwards-backwards algorithm
When conducting belief propagation on trees, how can you calculate the probability of the evidence?	\item $p(v) = \prod_t Z_t$<div>\item where $Z_t$ is the normalization constant for node $t$ after the collect evidence phase</div>
What's the interpretation of the messages in the distribute evidence phase of belief propagation for trees?	\item $m^+_{s\rightarrow t}(x_t) = p(x_t|v^+_{st})$<div>\item where $v^+$ is all the evidence from the `upstream' side of $s-t$, towards the root</div>
What's the definition of the beliefs during the distribute evidence phase of the belief propagation algorithm for trees?	\item $\text{bel}_s(x_s) \propto \text{bel}^-_s(x_s) \prod_{t \in \text{pa}(s)} m^+_{t\rightarrow s}(x_s)$<br />
What's the definition of the messages during the distribute evidence phase of the belief propagation algorithm for trees?	\item $m^+_{t \rightarrow s}(x_s) = \sum_{x_t} \psi_{st}(x_s, x_t)\frac{\text{bel}_t(x_t)}{m^-_{s\rightarrow t}(x_t)}$
What's the interpretation of the beliefs after the distribute evidence phase of belief propagation for trees?	\item $\text{bel}_s(x_s) = p(x_s|v)$<div>\item where $v$ is all the evidence in the tree</div>
What's the difference between the belief updating and the sum-product forms of the belief propagation on trees algorithm?	\item Belief updating: the evidence distribution messages $m^+_{t \rightarrow s}$ are calculated by dividing out $m^-_{s \rightarrow t}$ from $\text{bel}_t$<div>\item Sum-product: the evidence distribution messages&nbsp;$m^+_{t \rightarrow s}$ are calculated without reference to $\text{bel}_t$, using the messages $m^+_{p \rightarrow t}$ directly instead</div>
What's a systolic array?	\item An algorithm architecture where each compute unit&nbsp;<div>\item receives messages from neighbours</div><div>\item does some work</div><div>\item sends messages to neighbours</div>
What's the parallel version of belief propagation on trees?	<div>\item All messages are initialized to all 1s</div>\item Each node receives and sends messages once per step<div>\item $D$ steps, where $D$ is the diameter of the graph, will result in convergence</div>
How can the joint and marginal distributions for a tree Gaussian pairwise MRF be calculated?	\item Using belief propagation,&nbsp;<div>\item where the messages and beliefs are Gaussians represented by their precision and precision-mean</div>
What's non-parameteric belief propagation?	\item Belief propagation applied to pairwise MRFs where the potentials aren't Gaussian<div>\item and so the integrals that show up when calculating the messages have to be approximated using sampling methods</div>
What happens when loopy belief propagation is applied to a Gaussian MRF which isn't a tree?	\item The posterior means are calculated exactly<div>\item but the precisions will usually be too small</div>
What's the max product algorithm?	\item A variant of BP where the sums are replaced with max's<div>\item and so it calculates the local MAP marginal of each node</div>
What's the problem with the max product algorithm?	\item The same as the problem with the Viterbi algorithm<div>\item ie the MAP for the marginal at a node might not be from the same minima that gave rise to the MAP at another node</div>
What's barren node removal in the context of DGMs?	\item Suppose we're given a partially-observed DGM where nodes $v$ are observed and we're asked to infer nodes $q$<div>\item If there's a node $b$ such that $\sum_{x_b} p(x_q|x_b) = 1$ for all $x_q$, then the node can be excised</div><div>\item and this can be done recursively to shrink the graph</div>
What's the idea in the variable elimination algorithm for UGMs?	\item Given locally-normalized factors $\psi_A(A)$ and $\psi_B(A, B)$<br /><div>\item suppose we want to calculate the marginal $p(A)$. This can be written</div><div>\item $p(A) = \sum_{A, B} \psi_A(A)\psi_B(A, B)$, taking $|A||B|$ multiplications</div><div>\item $p(A) = \sum_A \psi_A(A) \sum_B \psi_B(A, B)$, taking $|A|$ multiplications</div><div>\item This is variable elimination</div>
How can variable elimination be used to calculate conditionals?	\item Calculate the marginals $p(x_q, x_v), p(x_v)$<div>\item Then $p(x_q|x_v) = \frac{p(x_q, x_v)}{p(x_v)}$</div>
When can variable elimination be applied?	\item Whenever you're calculating an expression of the form $\sum_x \prod_c \psi_c(x_c)$<div>\item where $(+), (\times)$ are taken from a commutative semi-ring</div>
What's a commutative semi-ring?	\item A set $K$ with operations $(+), (\times)$ which are each associative, commutative, and have identities $0, 1$<div>\item and also such that $(\times)$ distributes over&nbsp;$(+)$</div>
What are some common commutative semirings?	\item $(+, \times)$, sum-product<div>\item $(\max, \times)$, max-product</div><div>\item $(\min, +)$, min-sum</div><div>\item $(\land,\lor)$, Boolean satisfiability</div>
"After inferring a linear model for the effect of covariates on your outcome, how can you use the values of the data points with those covariates ""removed""? "	via selecting the <i>residuals</i> of the regression result&nbsp;<div>&gt; e.g., resid(lm_obj) in R&nbsp;</div>
Whenever you assume that errors in a regression model follow a gaussian distribution, how should you check this graphically? 	via a q-q plot of your residuals versus a normal distribution with mean and variance derived from your residuals 
In variable elimination, what are fill-in edges?	\item When a variable $X$ is summed over<div>\item add an edge to the UGM between any $Y, Z$ that both share a factor with $X$</div>
What's the induced width of a variable ordering $(\prec)$ in variable elimination?	\item Start with the graph of the variables $G$&nbsp;<div>\item and eliminate variables according to $(\prec)$, adding the fill-in edges to $G$ that the eliminations imply</div><div>\item Then the induced width $w(\prec)$ is the size of the largest clique in the graph minus one.&nbsp;</div>
What's the intuitive reason for fill-in edges when visualizing variable elimination?	\item When you sum out a variable, you effectively form a clique over every variable it shared a factor with<div>\item The fill in edges represent these cliques</div>
What's the running time of variable elimination in terms of the induced width of the UGM?	\item If the variables each have $K$ states,<div>\item $O(K^{w(\prec) + 1})$</div><div>\item where $w(\prec)$ is the induced width of $G$ by $(\prec)$</div><div>\item so in general greedy heuristics are used</div>
What's the treewidth of a graph in terms of variable elimination?	\item $w = \min_{\prec} \max_{c \in \mc{C}(G(\prec))} |c| - 1$<div>\item where&nbsp;</div><div>\item $(\prec)$ is an ordering for variable elimination</div><div>\item $\mc{C}(G(\prec))$ is the set of cliques in the graph constructed by adding the fill-in edges produced by $(\prec)$ to $G$</div>
What's the computational complexity of finding an optimal variable elimination ordering?	\item NP-hard in general<div>\item since it reduces to finding the treewidth of a graph</div>
What's the treewidth of a $m \times n$ 2D lattice?	\item $O(\min\{m, n\})$
What're the problems with variable elimination?	\item Exponential dependence on treewidth<div>\item Computing a different marginal means re-eliminating all the variables from scratch</div>
How can BP on trees be used to efficiently calculate multiple marginals?	\item Store the messages generated each time<div>\item and re-use them where possible</div>
What's a junction tree?	\item A representation of the vertices of a graph $G$ as a tree $\mc{T}$ over sets of vertices<div>\item such that</div><div>\item every vertex appears in at least one set</div><div>\item for every edge $x-y$ in $G$ there's a set $S$ containing $x, y$</div><div>\item and the running intersection property holds&nbsp;</div>
What's the running intersection property of a junction tree?	\item Any set of nodes in the tree containing a given variable forms a connected subgraph
What's a tree decomposition?	\item Another name for a junction tree
How do chordal graphs relate to junction trees?	\item The maximal cliques of a chordal graph form the sets of a junction tree
How does the running intersection property of a junction tree relate to belief propagation?	\item BP applied to a tree with the running intersection property will return the exact values of $p(x_c|v)$ for each node $c$ in the tree
What're the separators of a junction tree?	\item For an edge $S\leftrightarrow T$ between two sets of variables, it's $S \cap T$
How does the junction tree algorithm correspond to a Kalman smoother?	\item JTA applied to a chain-structured Gaussian graphical model is equivalent to a Kalman smoother&nbsp;
What's the upper bound on the treewidth of a graph?	\item Linear in the number of nodes
What's the computational complexity of the junction tree algorithm?	\item $O(K^{w+1})$<div>\item where $w$ is the treewidth of the graph and $K$ is the number of states per variable</div>
What's the computational complexity of exact inference in general on graphical models?	\item \#P-hard<br />
In general, when is exact inference tractable on graphical models?	\item When the graph is a chain<div>\item a tree</div><div>\item or generally low-treewidth</div>
What are some problems that can be solved by &nbsp;generalizations of the junction tree algorithm?	\item Computing the MAP estimate<div>\item Computing the $N$ most probable configurations</div><div>\item Computing posterior samples</div>
What's the variational free energy?	\item Given a target distribution $p(x|\mc{D})$, it's<br /><div>\item $J(q) = \mbb{KL}(q||\tilde p)$, the reverse KL-divergence</div><div>\item where $\tilde p(x) = p(x, \mc{D})$ is the unnormalized target&nbsp;</div>
What's the Helmholtz free energy?	\item Another name for the variational free energy
How does the variational free energy relate to the likelihood of the evidence?	\item $e^{-J(q)} \leq p(\mc{D})$
How does the variational free energy relate to the energy?	\item $J(q) = - \mbb{H}(q) + \mbb{E}_q[E(x)]$
How does the variational free energy relate to the negative log likelihood?	\item $J(q) = \mbb{E}_q[\text{NLL}(x)] + \mbb{KL}(q(x)|p(x))$<div>\item where $p$ is the prior</div>
What's the difference between the forward and reverse KL divergences as objectives?	\item Given target $p$ and approximation $q$<div>\item Forward KL: $\mbb{KL}(p||q)$ is infinite if $p(x) &gt; 0$ but $q(x) = 0$, so it overestimates $p$'s support</div><div>\item Reverse KL: $\mbb{KL}(q||p)$ is infinite if $p(x) = 0$ but $q(x) &gt; 0$, so it underestimates $p$'s support</div>
Why's the reverse KL preferred as an objective over the forward KL?	\item Because the forward KL overestimates the support of the target distribution<div>\item on multimodal target distributions it'll have massively higher variance than it should</div><div>\item while the reverse KL will `lock on' to a single mode</div>
How can you interpolate between the properties of the forward and reverse KL divergences as an objective function?	\item Use the alpha divergence
What's the approximate posterior in the mean field approximation?	\item $q(x) = \prod_i q_i(x_i)$
What's the mean field update rule?	\item $\ln q_j(x_j) = \mbb{E}_{-q_j}[\ln p(x, \mc{D})] + C$<div>\item where the expectation is taken over all the variables except $j$</div><div>\item and $C$ is chosen to normalize the distribution</div>
What's the energy functional in variational inference?	\item $L(q) = -J(q)$<div>\item where $J$ is the variational free energy</div>
How does the mean field update equation arise?	\item Start with the variational free energy $J(q)$<div>\item If we ignore all but the $j$ terms, we get $L(q_j) = - \mbb{KL}(q_j||f_j) + C$</div><div>\item where $f_j(x) = \exp\left(\mbb{E}_{-q_j}[\ln p(x, \mc{D})]\right)$</div><div>\item This can be minimized by setting $q_j \propto f_j$</div><div>\item and the update equation follows</div>
What's the structured mean field approach?	\item Sometimes assuming that the variables in the posterior are independent is too strong of an assumption<div>\item Instead, group variables into `mega-variables'</div><div>\item such that each group has some substructure that allows inference to be performed efficiently on it</div><div>\item and then apply the vanilla mean field approach</div>
At a high level, how is the mean field algorithm run?	\item At each step, pick a variable $j$<div>\item and apply the mean field update rule to replace a $q_j$ with its expectation.</div><div><div>\item averaging over just the variables involved in the Markov blanket of $j$</div></div>
How is the structured mean field approach applied to factorial HMMs?	\item Since the observed $y_t$ is influenced by $x_{tk}$ for $1 \leq k \leq \lg K$<div>\item and since for each fixed $k$, the $x_{tk}$ form a chain</div><div>\item pick the mega-variables to be $\{x_{tk}\}_t$</div><div>\item and conduct inference on them using the forwards-backwards algorithm</div><div>\item Then perform inference between chains using the mean field approach</div>
What's the idea in variational Bayes?	\item Apply a mean field approximation to the posterior<div>\item $p(\theta|\mc{D})$ with $\prod_k q_k(\theta_k)$</div>
What's a useful fact when debugging VB algorithms?	\item The variational free energy $J(q)$ must always decrease at each step
What kind of problems is variational Bayes EM suited to?	\item Models with both latent variables and parameters
Why does EM distinguish parameters from latent variables?	\item The posterior uncertainty in the parameters is usually much less than in the latent variables<div>\item since $\theta$ is influenced by all the data cases, while $z_i$ is only influenced by $x_i$</div><div>\item so taking a MAP estimate of $\theta$ is much more reasonable than a MAP estimate of the $z$</div>
What's VB stand for in ML?	\item Variational Bayes
What's VBEM stand for in ML?	\item Variational Bayes Expectation Maximization
What's the idea in VBEM?	\item Approximate the posterior $p(\theta, z|\mc{D})$ with $q(\theta)\prod q(z_i)$<div>\item E step: take the posterior mean $\bar \theta$ and calcuate $p(z_i|\mc{D}, \bar \theta)$ using standard methods.</div><div>\item M step: use the expected sufficient statistics to update the hyperparameters.</div>
What's the main advantage of VBEM over EM?	\item By marginalizing out the parameters, a lower bound on the marginal likelihood can be calculated<div>\item which can be used for model selection</div>
What's variational message passing?	\item A generalization of VBEM&nbsp;<div>\item which can be applied to any DGM&nbsp;</div><div>\item whose conditional distributions are in the exponential family</div><div>\item and whose parent nodes all have conjugate distributions</div>
What's local variational approximation?	\item Where a specific term in the joint distribution is replaced with a simpler function<div>\item so as to make the posterior easier to compute</div>
What kind of problem are variational techniques best suited for?	\item Ones in which one or more of the hidden nodes are continuous<div>\item If they're all discrete, LBP is preferred</div>
What's the log-sum-exp function?	\item $\text{lse}(\eta_i) = \ln \left(1 + \sum_{m=1}^M e^{\eta_{im}}\right)$
What's the usual use of variational bounds on the log-sum-exp function?	\item Approximating the posterior that results from applying a Gaussian prior to a multinomial likelihood
What's the loopy belief propagation algorithm?	\item Initialize all the messages to $m_{s\rightarrow t}(x_t) = 1$<div>\item Initialize all the beliefs to $\text{bel}_s(x_s) = 1$</div><div>\item Repeatedly:</div><div>\item Update the messages</div><div>\item Update the beliefs</div><div>\item until the beliefs stop changing significantly</div>
What's a factor graph?	\item An undirected bipartite graph, with round nodes and square nodes<div>\item Round nodes represent variables</div><div>\item Square nodes represent factors</div><div>\item Edges represent which variables appear in which factors</div>
How are the messages defined for belief propagation on factor graphs?	\item $m_{x \rightarrow f}(x) = \prod_{h \in \text{nbr}(x) \backslash f} m_{h \rightarrow x}(x)$<div>\item $m_{f \rightarrow x}(x) = \sum_y f(x, y) \prod_{y \in \text{nbr}(f) \backslash x}m_{y \rightarrow f}(y)$</div>
How're the beliefs defined in belief propagation on factor graphs?	\item $\text{bel}(x) = \prod_{f \in \text{nbr}(x)} m_{f \rightarrow x}(x)$
What's a computation tree in the context of belief propagation?	\item It's a visualization of the genesis of the messages received by a node after $K$ iterations of belief propagation<div>\item In particular it's a $K+1$ height tree where the edges at height $k$ represent the messages passed in round $k$ that eventually contributed to the root's state after round $K$<br /><div><br /></div></div>
How are computation trees used to model the convergence of LBP?	\item $K$ rounds of LBP on a graph are equivalent to a height $K+1$ computation tree<div>\item and if the strength of the edges is sufficiently weak then the root's value will converge as $K$ increases</div>
What's damping in the context of belief propagation?	\item Using messages<div>\item $\tilde m^k_{st} = \lambda m_{st} + (1-\lambda)\tilde m_{st}^{k-1}$</div><div>\item at iteration $k$</div><div>\item Values of $\lambda \approx 0.5$ can drastically improve convergence</div>
From the outside, what's double loop belief propagation?	\item A variant of BP that is guaranteed to converge to a local minima of the objective that LBP is minimizing<div>\item but which is rather slow, complicated and gives marginal gain</div>
What's the tree reparameterization heuristic for LBP?	\item Rather than updating the messages at all nodes synchronously<div>\item pick a set of spanning trees</div><div>\item and perform an up-down sweep on one of them at a time</div>
What's the residual belief propagation heuristic for LBP?	\item Rather than update all the messages synchronously<div>\item update them one at a time, prioritising the message which is most different from its previous value</div>
Which of the scheduling heuristics for LBP works best?	\item Residual belief propagation
What's the cost of computing a message in vanilla BP?	\item $O(K^f)$<div>\item where $K$ is the number of states and $f$ is the size of the largest factor</div>
How can BP be sped up when the potentials have the form $\psi(x_s, x_t) = \psi(x_s - x_t)$?	\item In this case, message computation is just convolution over $x_s$<div>\item so it can be accelerated using the FFT</div>
What's the multi-scale method for BP?	\item If you're computing BP over a self-similar structure (like a grid)<div>\item then construct a coarse grid, solve it using BP</div><div>\item the use the results to initialize BP on the fine grid</div>
What's a computational cascade in the context of ML?	\item When working in a high-dimensional state space<div>\item a filtering step can be used to prune away improbable states, making the remaining problem easier to solve</div><div>\item By applying the filtering repeatedly, a hierarchy of models can be built that trade off accuracy for speed.&nbsp;</div><div>\item This is a computational cascade</div>
What're the mean parameters of a model in ML?	\item $\mu = \mbb{E}[\phi(x)]$<div>\item wherer $\phi(x)$ are some sufficient statistics of the model</div>
What's the marginal polytope of a graphical model $G$?	\item $\mbb{M}(G)$, the set of mean parameters for the model that're generated by a valid probability distribution:<div>\item $\mbb{M}(G) = \{ \mu : \mu = \mbb{E}_p[\phi] \text{ for some distribution } p\}$</div><div>\item where $\phi$ are some sufficient statistics for $G$</div>
How can the geometric form of the marginal polytope be characterized?	\item It's a convex hull over the feature set:&nbsp;<div>\item $\mbb{M}(G) = \text{conv}\{\phi_d(x)\}_d$</div>
How does the marginal polytope relate to the likelihood of the data?	\item We can write the variational free energy in terms of the mean parameters of the model to get that<div>\item $\max_{\mu \in \mbb{M}(G)} \theta^T \mu + \mbb{H}(\mu) = \ln Z(\theta)$</div><div>\item and $\theta$ are the canonical parameters</div><div>\item and $Z(\theta) = p(\mc{D})$ is the partition function</div><div><div>\item and where equality is achieved when $\mu = \mbb{E}_p [\phi(x)]$, with $p$ being the true distribution</div></div>
Why is it hard to optimize over the marginal polytope?	\item Because while it's convex, it's got an exponential number of faces
Given a graphical model $G$ and a subgraph $F \subset G$, what's the inner approximation to the marginal polytope of $G$?	\item $\mbb{M}_F(G) = \{\mu : \mu = \mbb{E}[\phi(x)] \text{ for some } \theta \in \Omega(F)\}$<div>\item where $\Omega(F)$ is the parameter space for the submodel</div>
Given a graphical model $G$ and a subgraph $F \subset G$, what's the canonical parameter space of the submodel?	\item If $\Omega$ is the parameter space for $G$, then<div>\item $\Omega(F) = \{ \theta \in \Omega : \theta_\alpha = 0 \text{ for $\alpha$ outside of } \mc{I}(F)\}$</div><div>\item where $\mc{I}(F)$ is the subset of sufficient statistics associated with the cliques of $F$</div>
Given graphical models $F \subseteq G$, what does the inner approximation $\mbb{M}_F(G)$ to the marginal polytope of $G$ look like geometrically?	\item It's a non-convex volume<div>\item nested inside $\mbb{M}(G)$</div>
What're the local consistency constraints for a pairwise MRF?	\item $\sum_{x_s} \tau_s(x_s) = 1$, the normalization constraint<div>\item $\sum_{x_t} \tau_{st}(x_s, x_t) = \tau_s(x_s)$, the marginalization constraint</div>
What's the outer approximation to the marginal polytope of a graphical model $G$?	\item $\mbb{L}(G) = \{\tau \geq 0 : \tau \text{ the local consistency constraints are satisfied} \}$
What does the outer approximation $\mbb{L}(G)$ of the marginal polytope of $G$ look like?	\item It's a convex polytope with linear number of faces<div>\item that contains $\mbb{M}(G)$</div>
When is the outer approximation to the marginal polytope equal to the marginal polytope?	\item When the graph's a tree
What're the components of $\tau \in \mbb{L}(G)$ called?	\item Pseudo-marginals, since they might not correspond to any valid probability distribution
What's the Bethe approximation to the entropy of a pairwise MRF?	\item $\mbb{H}_\text{Bethe}(\mu) = \sum_V H_s(\mu_s) - \sum_E I_{st}(\mu_{st})$<div>\item where $I_{st}$ is the mutual information of $\mu_s, \mu_t$</div>
How can the joint distribution over a pairwise tree-structure MRF be written in terms of its marginals?	\item $p(x) = \prod_V p_s(x_s) \prod_E \frac{p_{st}(x_s, x_t)}{p_s(x_s)p_t(x_t)}$
When's the Bethe approximation to the entropy exact?	<div>\item When the graph is a tree</div>
What's the Bethe free energy?	\item $F_\text{Bethe}(\tau) = -[\theta^T\tau + \mbb{H}_\text{Bethe}(\tau)]$<div>\item where $\tau$ is a pseudo-distribution over the model&nbsp;</div><div>\item and $\theta$ are its canonical parameters</div>
What's the Bethe variational problem?	\item $\min_{\tau \in \mbb{L}(G)} F_\text{Bethe}(\tau)$<div>\item ie minimize the Bethe free energy over the outer approximation to $G$'s marginal polytope</div>
What's the relevance of the Bethe variational problem to loopy belief propagation?	\item Any fixed point of LBP is a stationary point of the Bethe variational energy<div>\item In particular, if $\lambda_{ts}$ is the Lagrangian multiplier for the marginalization local consistency constraint</div><div>\item then at convergence, $m_{t \rightarrow s}(x_s) = \exp(\lambda_{ts}(x_s))$</div>
What's the main advantage of LBP over MF?	\item The mean field objective has many more local optima than the LBP objective<div>\item which means that LBP often performs much better</div>
What're the main advantages of MF over LBP?	\item It lower-bounds the likelihood of the evidence, which is very useful for model selection<div>\item It extends easily to non-discrete distributions<br /><div><br /></div></div>
Why is the Bethe variational problem non-convex?	\item Because although $\mbb{L}(G)$ is a convex set<div>\item $F_\text{Bethe}(\tau)$ is not a convex objective</div>
What's the cluster variational method?	\item Cluster together nodes that form a tight loop, forming a hypergraph<div>\item Apply generalized belief propagation to the hypergraph</div>
What's the variational problem that generalized belief propagation minimizes?	\item It minimizes the Kikuchi free energy<div>\item over an outer approximation to the valid distributions on the hypergraph</div>
How does generalized belief propagation compare to belief propagation?	\item It's more complicated<div>\item and has a higher computational complexity</div><div>\item but gives more accurate results than LBP</div>
In what scenario would you want to use a linear vs logistic regression?&nbsp;	<div>1) Use linear regression when your outcome&nbsp;is <i>continuous&nbsp;</i></div><div>2) Use logistic regression when your outcome is <i>binary</i></div>&gt;&nbsp;http://stats.stackexchange.com/questions/7701/adjusting-for-confounding-variables<br /><div>&gt;&nbsp;Aha, that makes things a little different. The difference between linear and logistic regression stems from nature of your outcome. If the outcome is continuous and distributed reasonably normally, OLS may apply. If the outcome is binary, logistic regression may apply. (I'm not coming down definitely in either case because there can be many other factors worth taking into account when picking a model). Both logistic and OLS models can accommodate binary, categorical, ordinal and continuous covariates. – &nbsp;ashaw Feb 28 '11 at 14:23</div><div><br /></div>
What's the convex entropy of a distribution $\mu$ over a graphical model $G$ with respect to a set of submodels $\mc{F}$?	\item $\mbb{H}(\mu, \rho) = \sum_{F \in \mc{F}} \rho(F)\mbb{H}_F(\mu)$<div>\item where $\rho$ are the coefficients of a convex combination over $\mc{F}$</div>
What's the objective optimized by convex belief propagation?	\item $\max_{\tau \in \mbb{L}(G; \mc{F})} \tau^T \theta + \mbb{H}(\tau, \rho)$<div>\item where</div><div>\item $\mc{F}$ is a set of tractable submodels of $G$ (like trees)</div><div>\item $\mbb{L}(G; \mc{F})$ is the intersection of the marginal polytopes for each $\mc{F}$</div><div>\item $\mbb{H}(\tau, \rho)$ is the convex entropy</div>
What's the most common kind of convex belief propagation?	\item Tree reweighted belief propagation
What's the form of the entropy in tree reweighted belief propagation?	\item $\mbb{H}(\mu) = \sum_V H_s(\mu_s) - \sum_E \rho_{st}I_{st}(\mu_{st})$<div>\item where</div><div>\item $I_{st}$ is the mutual information between $s$ and $t$</div><div>\item $\rho_{st}$ is the probability of edge $s-t$ appearing in the distribution over trees used by the algorithm</div>
What's the idea in tree-reweighted belief propagation?	\item It's belief propagation<div>\item but the message $t \rightarrow s$ is conditioned by the probability that the edge $t \rightarrow s$ exists</div><div>\item in a tree randomly selected from the set of spanning trees of the graph</div>
What's one of the main advantages of tree-reweighted belief propagation over vanilla loopy belief propagation?	\item If TRBP converges, its objective is a lower bound on the likelihood of the evidence
What's expectation propagation a generalization of?	\item Assumed density filtering<div>\item but while assumed density filtering is online, expectation propagation is offline</div>
What's the clutter problem?	\item Suppose we have two superimposed Gaussians, one at $x$ and one at $0$<div>\item Infer $x$.</div>
What's the inverse probability transform?	\item If a distribution has cdf $F$<div>\item and $U \sim U(0, 1)$<br /><div>\item then $F^{-1}(U) \sim F$</div></div>
What's the Box-Muller method?	\item Sample $z_1, z_2 \sim U(0,1)$<div>\item Discard pairs that don't lie in the unit disc</div><div>\item Define</div><div>\item $x_i = 2\frac{\sqrt{-\ln r}}{r}z_i$ where $r = \|z\|$</div><div>\item Then $x \sim \mc{N}(0, I)$</div>
What's the use of the Box-Muller method?	\item Sampling pairs of independent, standard, normally distributed random numbers<div>\item using a uniformly-distributed source</div>
How is the Box-Muller method used to sample from a multivariate Gaussian $\mc{N}(\mu, \Sigma)$?	\item Compute the Cholesky decomposition $\Sigma = LL^T$<div>\item Sample $x \sim \mc{N}(0, I)$ using Box-Muller</div><div>\item Compute $y = Lx + \mu$</div>
How do you perform rejection sampling on a distribution $p(x)$?	\item Pick a proposal distribution $q(x)$ such that $Mq(x) \geq \tilde p(x)$,&nbsp;<div>\item where $M$ is a constant and $\tilde p(x)$ is the nonnormalized version of $p$</div><div>\item Sample $x \sim q$ and $y \sim U(0,1)$</div><div>\item If $u \leq \frac{\tilde p(x)}{Mq(x)}$, accept, else reject.<br /></div>
What's the probability of acceptance in rejection sampling?	\item $p(\text{accept}) = \frac{1}{M} \int \tilde p(x) dx$
How is rejection sampling often applied to a posterior distribution?	\item Set the proposal distribution to the prior $q(\theta) = p(\theta)$<div>\item Set $M$ to the probability of the MLE, $M = p(\mc{D}|\hat \theta)$</div><div>\item This is only reasonable when the prior isn't vague</div>
What's the idea in adaptive rejection sampling?	\item Given a log-concave density $p(x)$<div>\item construct a piecewise linear upper bound on it</div><div>\item and iteratively add linear pieces at any point $x$ where a sample is rejected</div>
What's rejection sampling particularly bad at?	\item High dimensions.
What's the use of importance sampling?	\item Approximating&nbsp;$\mbb{E}[f]$
What's a super efficient importance sampler?	\item One which needs to draw fewer samples to approximate $\mbb{E}[f]$ to a given level of accuracy<div>\item than a sampler which only worked with $p(x)$ would need</div>
What's importance sampling for a function $f$?	\item Given a proposal distribution $q$ to a target $p$<div>\item take samples $x^s$ from $q$. Then<br /><div>\item $\mbb{E}_p[f] \approx \frac{1}{S} \sum_s w_s f(x^s)$</div><div>\item where $w_s$ are the importance weights $w_s = \frac{p(x^s)}{q(x^s)}$</div></div>
How should the proposal distribution for importance sampling be chosen?	\item To minimize the variance of the estimator
What's the optimal proposal distribution for importance sampling?	\item $q^*(x) = \frac{|f(x)|p(x)}{\int |f(x^\prime)|p(x^\prime)dx^\prime}$<div>\item Though computing this can obviously be tricky.</div>
How can importance sampling be applied when only a non-normalized proposal $\tilde q$ and a non-normalized target $\tilde p$ can be computed?	\item $\frac{Z_p}{Z_q} \approx \frac{1}{S} \sum \tilde w_s$&nbsp;<div>\item so</div><div>\item $\mbb{E}_p[f] \approx \frac{1}{\sum \tilde w_s} \sum \tilde w_s f(x^s)$</div><div>\item This is biased but asymptotically unbiased</div>
What's ancestral sampling?	\item To sample from the joint of a DGM with no evidence<div>\item sample from the root</div><div>\item then its children</div><div>\item then it's grandchildren</div><div>\item etc</div>
What's logic sampling?	\item To sample from the joint of a DGM with evidence (ie with some nodes clamped to specific values)<div>\item conduct ancestral sampling</div><div>\item but throw the sample out and start again if a value is encountered which is inconsistent with the observed value</div>
What's likelihood weighting for sampling DGMs?	\item It's an improvement over logic sampling for DGMs<div>\item Rather than throw a sample away when a sample from an observed node contradicts the evidence</div><div>\item instead just don't sample observed nodes, and weight the entire sample as</div><div>\item $w(x) = \prod_{t \in E} p(x_t|x_\text{pa}(t))$</div><div>\item where $E$ is the set of observed nodes</div>
What's sampling importance resampling?	\item Use importance sampling with a proposal $q$ to construct a distribution<div>\item $p(x) \approx \sum_1^S w_s\delta_{x^s}(x)$</div><div>\item where $w_s$ are the importance weights.</div><div>\item Then sample with replacement from the above to get an unweighted distribution</div><div>\item $p(x) \approx \frac{1}{S^\prime} \sum^{S^\prime}_1 \delta_{x^s}(x)$</div><div>\item where $S^\prime \ll S$</div>
How are the weights calculated in sequential importance sampling?	<div>\item Given a proposal $q$ and target $p$,</div>\item $w_t \propto w_{t-1} \frac{p(z_{1:t}|y_{1:t})}{q(z_{1:t}|y_{1:t})}$<div>\item where various Markov assumptions can be applied to $p$ and $q$ to make computing the posteriors tractable</div>
What's sequential importance sampling?	\item Approximate the belief state of an entire trajectory $z_{1:t}$ using a weighted set of particle trajectories $\{z^s_t\}_s$:<div>\item $p(z_{1:t}| y_{1:t}) \approx \sum_s \tilde w^s_t \delta_{z^s_{t-1}}(z_{1:t})$</div><div>\item where $\tilde w_s^t$ is the normalized weight of particle $s$ at time $t$</div>
What's the main problem with sequential importance sampling?	\item The degeneracy problem: the state space is growing by a factor of $|\mc{Z}|$ at every step<div>\item while a constant number of samples are being used</div>
What's the effective sample size of a set of particles?	\item $S_\text{eff} = \frac{S}{1 + \text{var}[w^{*s}_t]}$<div>\item where $w^{*s}_t$ is the true weight of particle $s$ at time $t$, ie the weight as calculated without any Markov assumptions applied to $p$</div>
How is the effective sample size of a set of particles usually approximated?	\item $\hat S_\text{eff} = \frac{1}{\sum_s (w_t^s)^2}$
What's the resampling step in particle filtering?	\item Whenever the (approximate) effective sample size of the particle set drops below a threshold,<div>\item particles with low weight are culled&nbsp;</div><div>\item and the population is rejuvenated by sampling from</div><div>\item $p(z_t|y_{1:t}) \approx \sum_s \hat w_s^t \delta_{z^s_t}(z_t)$</div>
What's multinomial sampling in particle sampling?	\item Rejuvenating a population by computing<div>\item $K \sim \text{Multi}(S, w_t)$</div><div>\item and making $K_s$ copies of $z^s_t$</div>
What's sample impoverishment?	\item When resampling, it's where a few high-weight samples get replicated to the exclusion of all others
What's a regularized particle filter?	\item A particle filtering algorithm that uses a kernel density estimate for rejuvenation<div>\item which helps with the sample impoverishment problem</div>
What proposal distribution is most commonly used in particle filtering?	\item The prior<div>\item though when this is uninformative, it can be very wasteful</div>
What's the name of the vanilla particle filtering algorithm?&nbsp;	\item Sequential importance sampling
What are two common distance metrics for histograms?	\item The Bhattacharya distance<div>\item Earth mover distance</div>
What's Rao-Blackwellised particle filtering?	\item In some models there are hidden variables $z_t$ that can be analytically integrated out provided we know the values of $q_t$<div>\item So each particle $s$ represents a value $q^s_{1:t}$ and a distribution $p(z_t|y_{1:t}, q_{1:t}^s)$</div><div>\item These are distributional particles and the associated technique is Rao-Blackwellised particle filtering</div>
What model is Rao-Blackwellised particle filtering most commonly applied to?	\item Switching linear Gaussian state space models
What's the idea in Gibbs sampling?	\item Given a sample $x^s$, generate $x^{s+1}$ by sampling each feature in turn using the previously sampled features for the other components<br />
What's the full conditional for a feature?	\item $p(x_i|x_{-i})$
What's MCMC stand for in ML?	\item Monte Carlo Markov Chain
What's the idea in MCMC?	\item Construct a Markov chain on the state space $\mc{X}$ whose stationary distribution is the target density $p^*(x)$<div>\item Then draw samples from the chain to perform Monte Carlo integration with respect to $p^*(x)$</div>
What's the main problem with Gibbs sampling?	\item Label switching/unidentifiability:<br /><div>\item different samples may be drawing their parameters from different clusters</div><div>\item so you can't just take the Monte Carlo average of the samples to compute the posterior means</div>
What's the usual solution to the label switching problem in Gibbs sampling?	\item Only ask questions that are invariant with respect to labelling<div>\item ie rather than `does point $i$ belong to cluster $k$'</div><div>\item ask `do points $i, j$ belong to the same cluster'</div>
What's a collapsed Gibbs sampler?	\item Gibbs sampling using Rao-Blackwellisation to marginalize out some of the parameters first
What's the Rao-Blackwell theorem?	<div>\item For any variables $z, \theta$ and scalar function $f$,</div>\item $\text{var}_{z,\theta}[f(z, \theta)] \geq \text{var}_z[\mbb{E}_\theta[f(z, \theta)|z]]$
What's the intuitive interpretation of the Rao-Blackwell theorem?	\item The variance of the estimate created by integrating out $\theta$ will never be higher than the variance of a direct MC estimate
How do collapsed Gibbs samplers generally perform compared to vanilla Gibbs samplers?	\item Their average performance is better<div>\item but they'll still get stuck in poor local modes from time to time</div>
What's the imputation posterior algorithm?	\item A MCMC version of EM, where variables are split into hidden variables and parameters
What's data augmentation in ML?&nbsp;	\item Adding auxiliary variables to make computing the posterior easier
How does the mixing time of a Gibbs sampler correspond to the variance of the conditional distributions?	\item If the variance along dimension $i$ is $l$<div>\item and the distribution has a $L$-sized support in that dimension</div><div>\item then $O((L/l)^2)$ steps are needed to get independent samples</div>
What's blocked Gibbs sampling?	\item Sometimes there are groups of variables which can all be efficiently sampled at once<div>\item This allows greater steps through the state space and accelerates mixing</div>
What're the high-level steps&nbsp;in the Metropolis Hastings algorithm?	<div>\item Let $q$ be the proposal distribution</div><div>\item At each step, given state $x$, sample $x^\prime \sim q(x)$</div><div>\item Then either accept $x^\prime$, in which case the new state is $x^\prime$</div><div>\item or reject it, in which case the new state is $x$&nbsp;</div>
What's a random walk Metropolis algorithm?	\item MH with a symmetric Gaussian proposal centered on the current state&nbsp;
What's MH stand for in ML?	\item Metropolis Hastings
What's an independence sampler?	\item MH with a proposal that's independent of the current state
What's the probability of accepting a proposal in MH with a symmetric proposal distribution?	\item $r = \min(1, \frac{p^*(x^\prime)}{p^*(x)})$<br /><div>\item where $p^*$ is the target distribution</div>
What's a symmetric proposal distribution in MH?	\item A $q$ such that $q(x^\prime|x) = q(x|x^\prime)$
What's the Hastings correction?&nbsp;	\item It's the probability of accepting a move in MH when the proposal distribution isn't symmetric<div>\item $r = \min(1, \alpha)$</div><div>\item $\alpha = \frac{p^*(x^\prime)}{p^*(x)}/\frac{q(x^\prime|x)}{q(x|x^\prime)}$</div><div>\item This corrects for the fact that the proposal distribution (rather than the target distribution) might favour certain states</div>
How can MH be applied when the target distributon can only be calculated in non-normalized form?	\item The same way as it is for the normalized form<div>\item because the normalization constant for the target $p^*$ cancels out in the calculation for the acceptance probability&nbsp;</div>
How does Gibbs sampling relate to MH?	\item It's MH with a proposal of the form<div>\item $q(x^\prime|x) = p(x^\prime_i|x_{-i})\mbb{I}(x^\prime_{-i} = x_{-i})$</div><div>\item which has an acceptance rate of 1</div>
Intuitively, what's the effect of the way proposals are accepted/rejected in MH?	<div>\item The acceptance probability is chosen so that the time spent in state $x$ is proportional to $p^*(x)$</div><div>\item because it'll always move to a higher-probability proposal,&nbsp;</div><div>\item and to a lower probability proposal with probability proportional to how much worse the proposal is than the current state</div>
What proposals are considered valid for MH?	<div>\item For target $p^*$, it's any $q$ such that&nbsp;</div>\item $\text{supp}(p^*) \subseteq \cup_x \text{supp}(q(\cdot|x))$
If you're exploring a bimodal target using random walk MH, what's the effect of altering the variance of the proposal?	\item Too low variance: only one of the modes will be explored<div>\item Just right variance: both modes are efficiently explored</div><div>\item Too high variance: a `sticky' chain with a high rejection rate that spends too long in single states</div>
What's a sticky Markov chain in the context of MH?	\item It's when proposals have a high rejection rate, so the chain spends a long time in each state
What's a pilot run in the context of MH?	\item Short runs used to calibrate the parameters of the proposal
As a rule of thumb, what acceptance rate should you aim for in MH?	\item $25\%$ to $40\%$
How should the variance of the proposal be set in random-walk MH?	\item Compute the Hessian $H$ at some point on the target<div>\item then use $\Sigma = s^2H^{-1}$</div><div>\item where $s^2$ is some scaling parameter chosen to accelerate mixing</div>
When applying random walk MH to a Gaussian posterior, what's the optimal variance scaling parameter $s$ to choose?&nbsp;	\item $s^2 \approx \frac{2.38^2}{D}$, where $D$ is the number of dimensions&nbsp;
What's a data-driven MCMC?	\item A MCMC algorithm where the proposal distribution depends on the data, $q(x^\prime|x, \mc{D})$
How are proposals for data-driven MCMC usually created?	\item By sampling pairs $(x, \mc{D})$ from the forwards model<div>\item and training a discriminative classifier to predict $p(x_S|D)$ for some subset of the variables $S$</div><div>\item with a standard data-independent proposal used to predict $x_{S^\prime}$</div>
What's adaptive MCMC?	\item MCMC where the proposal parameters change over the life of the chain<div>\item but the parameters shouldn't depend on the whole life of the chain, or it'd violate the Markov property!</div>
At a high level, why does MH work?	\item MH constructs a transition function $p(x^\prime|x)$ such that $p^*(x)$ satisfies the detailed balance equations<div>\item And with a valid proposal distribution, the chain is also irreducible and ergodic</div><div>\item So $p^*(x)$ is its unique limiting distribution</div>
What's trans-dimensional MCMC?	\item MCMC that can handle with moving between models with different parameter spaces<div>\item such as in mixture models where the number of components is unknown</div>
What's reversible jump MCMC?	\item A kind of trans-dimensional MCMC<div>\item that corrects the problem with computing acceptance probabilities by augmenting the low-dimensional models with extra random variables</div>
What's the problem with vanilla trans-dimensional MCMC?	\item When computing acceptance probabilities, you're comparing densities defined in different measure spaces<div>\item which is meaningless</div>
What's burn-in in the context of MCMC?	\item All the samples that are thrown away until the chain has reached its stationary distribution
How's the mixing time of a MCMC defined?	<div>\item Given transition function $T$</div>\item $\tau_\epsilon = \max_{x_0} \min_t \{t : \|T^t(\delta_{x_0}(x)) - p^*\|_1 \leq \epsilon\}$<br />
For a discrete MCMC, how can the mixing time be bounded in terms of the eigenvalues of the transition matrix?	\item $\tau_\epsilon = O(\frac{1}{\lambda_1 - \lambda_2}\ln \frac{n}{\epsilon})$<div>\item where</div><div>\item $\lambda_1, \lambda_2$ are the two largest eigenvalues of the transition matrix</div><div>\item $n$ is the number of states</div>
What's the eigengap of a transition matrix?	\item $\gamma = \lambda_1 - \lambda_2$<div>\item where $\lambda_1, \lambda_2$ are the two largest eigenvalues of the matrix</div>
For a discrete MCMC, how can the mixing time be bounded in terms of conductance?	\item $\tau_\epsilon = O(\frac{1}{\phi^2}\ln\frac{n}{\epsilon})$<div>\item where</div><div>\item $\phi$ is the conductance of the chain</div><div>\item $n$ is the number of states</div>
What's the conductance of a discrete Markov chain?	\item $\phi = \min_{S \colon p^*(S) \leq 0.5} \frac{1}{p^*(S)} \sum_{x \in S, y \in S^\prime} p(y|x)$<div>\item ie it's the least probability of moving from some set to its compliment&nbsp;</div>
What kinds of distributions usually lead to MCMCs with high mixing times?	\item Ones with well-separated modes
What's a trace plot in the context of MCMCs?	\item A way to evaluate burn-in time:<div>\item run multiple chains from overdispersed starting points and plot the traces of some variables of interest</div><div>\item The chains have mixed when they've forgotten where they started from, and their traces converge to the same dsitribution</div>
How is the estimated potential scale reduction of a MCMC defined?	\item Take $S$ samples $y$ from $C$ chains<div>\item Calculate the between-sequence variance $B$ and within-sequence variance $W$</div><div>\item Define $\hat V = \frac{S-1}{S}W + \frac{1}{S}B$,&nbsp;</div><div>\item which is an unbiased estimator of $\text{var}[y]$ under stationarity</div><div>\item Define the EPSR, $\hat R = \sqrt{\hat V / W}$</div>
How is the estimated potential scale reduction of a MCMC interpreted?	\item It's the degree to which the posterior variance would drop as $S \rightarrow \infty$<div>\item If $\hat R \approx 1$ for a feature, the estimate is not unreliable.</div>
What's the autocorrelation function?	\item Given ordered samples $x_s$,<div>\item $\rho(t) = \frac{\text{cov}[x_s, x_{s+t}]}{\text{var}[x_s]}$</div>
What's the problem with autocorrelation with respect to MCMCs?	\item Because the samples produced by MCMC are autocorrelated, their information content is reduced relative to independent samples.<div>\item This can be quantified by plotting the autocorrelation $\rho(t)$ of a set of samples.</div>
What's thinning in the context of MCMCs?	\item Only keep every $k$th sample, to reduce autocorrelation<div>\item This doesn't improve the efficiency of the sampler, but it does reduce the number of highly correlated samples that have to be stored</div>
As a rule of thumb, how many chains, steps, and burn-in samples should be used with MCMC?	\item Three chains and 100,000 steps each, half of which is burn-in.&nbsp;
What's the idea in auxiliary variable MCMC?	\item Replace the distribution $p(x)$ with a distribution with some additional variables $p(x,z)$<div>\item such that $\sum_z p(x, z) = p(x)$</div><div>\item and $p(x, z)$ is easier to sample from than $p(x)$</div>
What's the pdf of a logistic distribution in terms of exponentials?	\item $p(x) = \frac{e^{-x}}{s(1+e^{-x})^2}$
How can auxiliary variable MCMC be used to sample from a Student distribution?	\item Use the scale mixture parameterization of the Student distribution<div>\item and add the mixture coefficients as the auxiliary variables of the MCMC</div>
What's the idea in slice sampling?	<div>\item It's a kind of auxiliary variable MCMC, with joint</div>\item $p(x, u) \propto 1$ if $0 \leq u \leq p(x)$<div>\item $p(x, u) = 0$ otherwise.</div><div>\item Effectively:</div><div>\item $u$ is selected from the vertical slice of $p$ through $x$.</div><div>\item $x^\prime$ is selected from the horizontal slice of $p$ through $u$</div>
How are the slices calculated in slice sampling?	\item By stepping out:<div>\item construct a range $x_L \leq x \leq x_R$ and extend $x_L, x_R$ until they're no longer in the slice through the distribution</div>
How is slice sampling applied to multivariate distributions?	\item By using an extra auxiliary variable for each dimension
What's the main advantage of slice sampling over MH?	\item The user doesn't have to specify a proposal distribution, just the width of the stepping out interval
What's the main advantage of slice sampling over Gibbs?	\item It doesn't need a specification of the full conditionals, just the unnormalized joint
What's the Swendsen-Wang model?	\item An auxiliary MCMC sampler for Ising models<div>\item where an auxiliary bond variable $\in \{0, 1\}$ is added for each edge that indicates whether the bond is `active'</div>
What's &nbsp;Hamiltonian MCMC?	<div>\item MCMC for continuous state spaces where the log-posterior can be calculated.</div>\item Think of the parameters of the model as a particle<div>\item and use auxiliary variables to represent the `momentum' of the particle.</div>
What's the effect of reducing the temperature of the Boltzmann distribution?	\item The mass concentrates at the minimum-energy (most probable) state
What's simulated annealing?	<div>\item Let $f$ be the energy of the system</div><div>\item For each temperature $T$, starting at $T_0$, repeatedly:</div>\item take old state $x$ and sample a new state $x^\prime$<br /><div>\item and calculate $\alpha = \exp\left(\frac{f(x) - f(x^\prime)}{T}\right)$</div><div>\item Then accept the new state with probability $\min(1, \alpha)$</div><div>\item After a large number of steps has been taken, decrease the temperature</div>
What cooling schedule is generally used in simulated annealing?	<div>\item An exponential one:</div>\item $T_0 \approx 1$<div>\item $C \approx 0.8$<br /><div>\item $T_k \approx T_k C^k$</div></div>
What's the tradeoff in selecting the speed of the cooling schedule in simulated annealing?	\item Too fast a cooling schedule will leave you stuck in a local maximum<div>\item Too slow a cooling schedule just wastes time</div>
What's the idea in annealed importance sampling?	\item Given an easy distribution to sample from $f_n(x)$ and a distribution that's difficult to sample from $f_0(x)$,<div>\item construct a sequence between them $f_j(x) = f_0(x)^{\beta_j}f_n(x)^{1-\beta_j}$</div><div>\item and a Markov chain $T_j$ for each that leaves $p_j \propto f_j$ invariant.&nbsp;</div><div>\item Then sample $z_{n-1} \sim p_n$ and $z_k \sim T_{k+1}(z_{k+1})$ for each $k$</div><div>\item and output $x = z_0$ with weight</div><div>\item $w = \prod \frac{f_k(z_k)}{f_{k+1}(z_k)}$</div>
What's parallel tempering?	\item A simulated annealing variant<div>\item where multiple chains are run at different temperatures</div><div>\item and each chain can sample from another chain at a neighbouring temperature</div><div>\item This way high temp chains can make large moves through the parameter space, and have this influence on lower temperature chains</div>
What's the candidate method in ML?	\item It's a way to approximate the marginal likelihood. Write it as&nbsp;<div>\item $p(\mc{D}|M) = \frac{p(\mc{D}|\theta, M) p(\theta|M)}{p(\theta|\mc{D}, M)}$</div><div>\item for some $\theta$</div><div>\item Then $p(\mc{D}|\theta, M)$ and $p(\theta|M)$ are easy to compute</div><div>\item and $p(\theta|\mc{D}, M)$ can be approximated with MCMC</div>
What's the problem with the candidate method in ML?	\item $p(\theta|\mc{D}, M)$ must be approximated by marginalizing over all the modes in the posterior<div>\item If this isn't done, the approximation of the marginal likelihood will be poor</div>
What's the harmonic mean estimate in ML?	\item Approximating the marginal likelihood using<div>\item $\frac{1}{p(\mc{D})} \approx \frac{1}{S}\sum \frac{1}{p(\mc{D}|\theta^s)}$</div><div>\item where $\theta^s \sim p(\theta|\mc{D})$ are samples from the posterior</div>
What's the problem with the harmonic mean estimate in ML?	<div>\item It works very poorly in practice</div>\item The samples used to generate it are drawn from the posterior, which can be very insensitive to the prior<div>\item but the marginal likelihood can be very sensitive to the prior</div>
What's the annealed importance sampling approach to approximating the marginal likelihood?	\item Apply annealed importance sampling to the target $p_0$ with easy distribution $p_n$. Then<div>\item $\frac{Z_0}{Z_n} \approx \frac{1}{S}\sum w_s$</div><div>\item where $w_s$ are the annealed importance weights.</div><div>\item So if $Z_n = p_n(\mc{D})$ can be computed, so can $Z_0 = p_0(\mc{D})$</div>
What's the preferred method for estimating the marginal likelihood using MCMC?	\item The annealed importance sampling approach
When you use a linear model, what assumptions must you test? (3)&nbsp;	"1) Normally distributed errors (usu via q-q plot inspection; and mi, no correlated error terms)&nbsp;<div>2) Constant error variance (usu via inspecting studentized residualss vs fitted responses)&nbsp;</div><div>3) Model linearity (inspected via residual plots; ideally, the residual plot will show no discernible pattern)&nbsp;</div><div><img src=""paste-8229157339522.jpg"" /></div><div><img src=""paste-8370891260299.jpg"" /></div><div><img src=""paste-8478265442856.jpg"" /></div><div><img src=""paste-8740258447728.jpg"" /></div><div>&gt;&nbsp;Another important assumption of the linear regression model is that the error terms have a constant variance, Var(i) = σ2. The standard errors, confidence intervals, and hypothesis tests associated with the linear model rely upon this assumption. Unfortunately, it is often the case that the variances of the error terms are non-constant. For instance, the variances of the error terms may increase with the value of the response. One can identify non-constant variances in the errors, or heteroscedasticity, from the presence of a funnel shape in heterosceda- the residual plot.</div><div>&gt;&nbsp;If the residual plot indicates that there are non-linear associations in the data, then a simple approach is to use non-linear transformations of the predictors, such as log X, √X, and X2, in the regression model.</div><div>&gt; from&nbsp;http://www.nature.com/nmeth/journal/v8/n11/full/nmeth.1710.html</div><div>&gt;&nbsp;Compliance with three assumptions of linear least-squares fitting was investigated: normally distributed errors, constant error variance and linearity. Error distributions were deemed to be normal by comparing the sample distribution of studentized residuals with quantiles of the normal distribution (quantile-quantile plot), for a large number of fitted probe sets. Similarly, we examined studentized residuals versus fitted responses for a large number of expression models. Most probe sets had constant error variance. A minority showed increasing error variance with increasing fitted expression values. This increase was modest and was deemed not to compromise ordinary least-squares-based coefficient estimation. Finally, model linearity was checked by looking at partial residual plots14. The vast majority of fitted probe sets did not reveal clear nonlinearity.</div><div><br /></div><div>&gt; from&nbsp;</div>"
define precision (statistics)&nbsp;	the inverse of the variance<br /><div>&gt; original term Gauss used</div>
What does \ttt{pyplot.plot()} return?	\item A tuple of objects representing the lines that have been plotted
What're the arguments to \ttt{pyplot.plot()}?	\item \ttt{pyplot.plot(xs1, ys1, style1, xs2, ys2, style2)}<br /><div>\item etc</div><div>\item where \ttt{style1, style2} are strings describing the style for that line</div>
How can you get the figure that pyplot considers current?	\item \ttt{pyplot.gcf()}
What's \ttt{pyplot}?	\item A module of \ttt{matplotlib} that emulates MATLAB's plotting capabilities<div>\item ie plots are created in an extremely stateful way&nbsp;</div>
How do you get the current axes from pyplot?	\item \ttt{gca()}
How do you select which figure should be active in pyplot?	\item \ttt{figure(i)}
How do you set the currently active axes to a sub-plot in pyplot?	\item \ttt{subplot(no\_of\_rows, no\_of\_cols, subplot\_no)}<div>\item where \ttt{subplot\_no} indexes 1 through \ttt{no\_of\_rows*no\_of\_cols}, top to bottom \&amp; left to right</div>
What's a common shorthand for pyplot's \ttt{subplot()}?	\item If the number of rows, columns and the subplot index are all less than 10 then<div>\item \ttt{subplot(i, j, k)} is the same as \ttt{subplot(ijk)}</div>
How do you free the memory associated with a plot in pyplot?	\item \ttt{close()}
How do you clear the current figure in pyplot?	\item \ttt{clf()}<br />
How do you clear the current axes in pyplot?	\item \ttt{cla()}
How do you annotate a point on a plot using pyplot?	\item \ttt{annotate()}
What's a \ttt{suptitle} in pyplot?	\item The title for the whole figure; \ttt{title} is for subplots
How do you display an image as a plot in pyplot?	\item \ttt{imshow(img)}<div>\item where \ttt{img} is a numpy array</div>
What's an artist in matplotlib?	\item An object that knows how to use a renderer to paint onto canvas
What's an \ttt{axes} in matplotlib?	\item The object which sets the coordinate system and contains most of a figure's elements
What's a \ttt{FigureCanvas} in matplotlib?	\item It's the area onto which the figure is drawn
What's a \ttt{Renderer} in matplotlib?	\item It's the object which knows how to draw onto a \ttt{FigureCanvas}
What are the two kinds of artist in matplotlib?	\item Primatives<div>\item Containers</div>
What's the main type of object in matplotlib?&nbsp;	\item \ttt{axis}
How can you autoadjust plots in matplotlib to prevent elements from intersecting?	\item \ttt{tight\_layout()}
How do you place subplots on an arbitrarily-shaped grid in pyplot?	\item Use \ttt{GridSpec}
What are the four main coordinate systems in matplotlib?	\item \ttt{data}<div>\item \ttt{axes}, which goes $(0, 0)$ to $(1, 1)$</div><div>\item \ttt{figure}, which goes $(0, 0)$ to $(1, 1)$</div><div>\item \ttt{display}, which goes $(0, 0)$ to $(\text{width}, \text{height})$</div>
define quantile	"the data value marking a boundary between consecutive subsets equally dividing data (usually into ""q"" parts)&nbsp;<br /><div>&gt; vs quintile, which refers to a q-quantile where q = 5</div>"
define hyperparameter	a parameter in a model about the probability of another parameter
What is the typical formula for the expected value of a continuous variable x?&nbsp;	<div>∫&nbsp;dx p(x) x</div>
What's the Fisher-Neyman factorization theorem?	\item $T(x)$ is a sufficient statistic for a parameter $\theta$ of $p(x|\theta)$ if and only if there are $g, h$ such that<div>\item $p(x|\theta) = h(x) g(T(x), \theta)$</div>
What's a minimally sufficient statistic?	\item $S$ is minimally sufficient iff<div>\item $S$ is sufficient</div><div>\item If $T$ is sufficient, there's a $f$ such that $S = f \circ T$</div>
What's a useful characterization of minimally sufficient statistics?	\item $S$ is minimally sufficient for $\theta$ and $p_\theta$ iff<div>\item $\frac{p_\theta(x)}{p_\theta(y)}$ is independent of $\theta$ iff $S(x) = S(y)$</div>
continuous (infinite number of values) or discrete (non-negative whole numbers)	numerical variable
ordinal (ordered) or non-ordinal (unordered)	categorical variable
variables that show some relationship with one another; the relationship will have a positive or negative association	dependent variable
a variable that is not influenced by another and influences the value of the dependent variable	independent variable
in a pair of variables, it is the variable suspected of affecting the other; even if there is a correlation, it does not guarantee causation	explanatory variable
a study where data are collected only by monitoring what occurs; only correlations can be concluded; two types of observational studies: *prospective* (identifies individuals and collects information as events unfold) and *retrospective* (collect data after events have taken place, e.g. researchers may review past events)	observational study
a study where researchers assign treatments to cases; causality can be concluded	experimental study
1. *Control* - Compare treatment of interest to a control group. 2. *Randomize* - Randomly assign subjects to treatments. 3. *Replicate* - Collect a sufficiently large sample, or replicate the entire study. 4. *Block* - Block for variables known or suspected to affect the outcome.	principles of experimental design
AKA lurking variable, confounder; a variable correlated with both the explanatory and response variables	confounding variable
when a statistic is influenced by external factors in such a way that it is systematically different from the population parameter of interest; types of bias: measurement, selection, volunteer, nonresponse	bias
Each subject in the population is equally likely to be selected.	simple random sampling (SRS)
First divide the population into homogenous strata (subjects within each stratum are similar, across strata are different), then randomly sample from within each strata.	stratified random sampling
First divide the population into clusters (subjects within each cluster are non-homogenous, but clusters are similar to each other), then randomly sample a few clusters, and then randomly sample from within each cluster.	cluster sampling
experimental units don't know which group (control or treatment) they're in	blinding
Both the experimental units and the researchers don't know the group assignment.	double blinding
"each point in a dataset is defined by two values (x, y) plotted on a pair of axes; relationships between the two variables can be described by direction (positive or negative), form (linear or non-linear), strength (strong to weak), outliers         <div><img src=""cOo85F.2MOIuWWifD9.ZfQ_m.png"" /></div>         "	scatterplot
a statistic (such as mean) that represents a single point on the number line; point estimate and sample statistic are synonymous	point estimate
mean (the arithmetic average), median (the midpoint), mode (the most frequent observation)	measures of central tendency
measure of center; arithmetic average; two kinds of means - sample (x̄), population (µ); R cmd: mean(VECTOR)	mean
midpoint of the distribution; 50th percentile; R cmd: median(VECTOR)	median
most frequent observation	mode
standard deviation (variability around the mean), range (max-min), interquartile range (middle 50% of the distribution)	measures of spread (dispersion)
roughly the average deviation around the mean, and has the same units as the data; sample sd = s, population sd = σ; R cmd: sd(VECTOR)	standard deviation
roughly the average squared deviation from the mean; sample variance = s², population variance = σ²	variance
"Datasets that show roughly equal trailing off in both directions; mean ≈ median.         <div><img src=""6f7rzhtnb1xinsRqmG50hQ_m.png"" /></div>         "	symmetric distribution
"Datasets where data points trail off to the left; order of centers: mean, median, mode         <div><img src=""ITHXG0Ak.FiPggET4kHP1Q_m.png"" /></div>         "	left-skewed distribution
"Datasets where data points trail off to the right; order of centers: mode, median, mean         <div><img src=""Hpv8z-MwKp8OOx7FZHSMMQ_m.png"" /></div>         "	right-skewed distribution
"Graphic display of continuous data that provides a view of data density; higher bars represent where data are relatively more common; bins touch one another; x-axis represents a scale rather than a series of labels; R cmd: hist(COLUMN, breaks=N)         <div><img src=""8193703647_968a4a5029_m.jpg"" /></div>         "	histogram
"graphic display that summarizes a data set using five statistics while also plotting unusual observations; R cmd: boxplot(COLUMN, data=DF)         <div><img src=""6812795585_7af0b63dde_m.jpg"" /></div>         "	boxplot
"graphic display where colors are used to show higher and lower values of a variable         <div><img src=""zXfiscTIrhgczrd-AzH0RA_m.png"" /></div>         "	intensity map
a statistic (e.g., median, IQR) that is not heavily affected by skewness and extreme outliers	robust statistic
rescaling of the data using a function (e.g., log, square root, inverse) that can make the distribution of data more symmetric, and hence easier to model	transformation
"a table for a single variable; R cmd: table(DF$COLUMN)         <div><img src=""A60S59MdGFRub9yAGgbWtw_m.png"" /></div>         "	frequency table
"a table that summarizes data for two categorical variables; R cmd: table(DF$COLUMN_A, DF$COLUMN_B)         <div><img src=""Q1ttk8ifmjdemzJGb6zGlQ_m.png"" /></div>         "	contingency table
"graphical display of contingency table information (two categorical variables); R cmd: barplot(CTABLE, col=c(""COLOR1"",""COLOR2""), legend = rownames(CTABLE))         <div><img src=""JA1fFVEh41plPGB.yQon6Q_m.png"" /></div>         "	segmented bar plot
"graphical display of contingency table information that is similar to a bar plot for one variable or a segmented bar plot when using two variables; R cmd: mosaicplot(TABLE)         <div><img src=""2o1-P2Hu52BBvrl8sVMjxw_m.png"" /></div>         "	mosaic plot
a method of statistical inference using data from a scientific study to derive a conclusion between a null hypothesis (status quo) or alternative hypothesis. A result is called statistically significant if it has been predicted as unlikely to have occurred by chance alone, according to a pre-determined threshold probability, the significance level.	hypothesis test
(H0) often represents either a skeptical perspective or a claim to be tested	null hypothesis
(HA) represents an alternative claim under consideration and is often represented by a range of possible parameter values	alternative hypothesis
"a distribution that has one prominent mode (or peak in a histogram)         <div><img src=""sMjbutDZWVVBhp0kYlSZQw_m.png"" /></div>         "	unimodal distribution
"a distribution that has two prominent modes (or peaks in a histogram)         <div><img src=""2e8iVN8wRVgG-E0Sph.8zA_m.png"" /></div>         "	bimodal distribution
"a distribution that has no prominent modes (or peaks in a histogram)         <div><img src=""fhEOMiw8u4Xb3X8WQsLN.g_m.png"" /></div> "	uniform distribution
"a distribution that has more than two prominent modes (or peaks in a histogram)         <div><img src=""c3vNJXwjKonGXSJkoqFZ.A_m.png"" /></div>         "	multimodal distribution
probability (of an outcome)	the proportion of times the outcome would occur if we observed the random process that gives rise to it an infinite number of times
law of large numbers	As more observations are collected, the proportion p̂n of occurrences with a particular outcome converges to the probability p of that outcome.
disjoint (mutually exclusive) events<br><br>disjoint events are always dependent since if one event occurs, the other cannot	events that cannot both happen at the same time; P(A and B) = 0; P(A or B) = P(A) + P(B); 
independent events	the outcome of one event does not influence the outcome of another; for example, if A and B are independent, then having information on A does not tell us anything about B (and vice versa)
non-disjoint events	events that can happen at the same time; P(A or B) = P(A) + P(B) - P(A and B)
sample space	collection of all possible outcomes of a trial
probability distribution	a list of the possible outcomes with corresponding probabilities that satisfies three rules: 1. The outcomes listed must be disjoint. 2. Each probability must be between 0 and 1. 3. The probabilities must total 1.
union of events (A or B)	Calculate the probability of union of events using the (general) addition rule: - If A and B are not mutually exclusive, P(A or B) = P(A) + P(B) − P(A and B) - If A and B are mutually exclusive, P(A or B) = P(A) + P(B), since for mutually exclusive events P(A and B) = 0
intersection of events (A and B)	Calculate the probability of intersection of independent events using the multiplication rule: - If A and B are independent, P(A and B) = P(A) × P(B)  - If A and B are dependent, P(A and B) = P(A|B) × P(B)
marginal probabilities	probabilities based on a single variable without conditioning on any other variables
joint probability	probability of outcomes for two or more variables or processes
conditional probability	"probability based on a condition; there are two parts: the outcome of interest and the condition; notation: P(outcome of interest | condition), or P(A | B), = P(A and B)/P(B); ""|"" means ""given"""
tree diagram	"a tool to organize outcomes and probabilities around the structure of the data; they are most useful when two or more processes occur in a sequence and each process is conditioned on its predecessors; first branch is called primary branch, other branches are called secondary         <div><img src=""rAorjW5qPzdtJveffhW3eQ_m.png"" /></div> "
Z score<br><br> the Z score of an observation is defined as the number of standard deviations it falls above or below the mean; R cmd: scale(x, mean, sd)	"a normalized score for comparing data of different scales;<br>        <div><img src=""c7LmwBmpk4sHpTEairjj0Q_m.png"" /></div><br>        "
For various distributions (normal, left-skewed, right-skewed), state whether the Z score of the median is negative, positive, or zero.	- normal: zero - left-skewed: positive - right-skewed: negative
binomial distribution<br><br>r cmd: dbinom(k, size=n, prob=p)	"the probability of having exactly k successes in n independent Bernoulli trials with probability of a success p; conditions: <br>1. The trials must be independent<br>2. The number of trials, n, must be fixed.<br>3. Each trial outcome must be classified as a success or failure.<br>4. The probability of success, p, must be the same for each trial.<br><br>        <div><img src=""bPTE3MPlC5Dc3G3fGwO4nA_m.png"" /></div><br>        "
Bernoulli random variable (AKA binomial variable)	when an individual trial has only two possible outcomes
expected value (mean) of binomial distribution	µ = np
standard deviation of binomial distribution	σ = √np(1-p)
success-failure rule of binomial distribution	A binomial distribution with at least 10 expected successes and 10 expected failures closely follows a normal distribution. - np >= 10 - n(1-p) >= 10
What is the relationship between the p-value of a correlation evaluated using cor.test and the sample size used to generate it?&nbsp;	"in general, larger sample size -&gt; more likely to be significant, even at a smaller correlation value<div><img src=""paste-16750372455324.jpg"" /></div><div>&gt;&nbsp;http://stats.stackexchange.com/questions/17371/example-of-strong-correlation-coefficient-with-a-high-p-value<br /><div>&gt; based on the chi-square distribution, because based on the t-distribution&nbsp;</div></div>"
At a high level, how do you construct a model in PyMC?	\item Instantiate \ttt{Node} objects,&nbsp;<div>\item passing the other distributions a \ttt{Node} depends on as initializer parameters.</div>
How can you deal with missing data in PyMC?	\item Pass a numpy masked array of the data instead of a standard array<div>\item It'll construct predictive distributions for the masked values</div>
What's a sensible first thing to try to deal with poorly-mixing models in PyMC?	\item If there are highly-correlated variables involved, set the step method to \ttt{AdaptiveMetropolis}
At a high level, how do you train a model in PyMC?	\item Having instantiated a collection of \ttt{Variables}<div>\item instantiate a \ttt{MCMC} object using the collection</div><div>\item then call \ttt{mcmc.sample()}&nbsp;</div>
What are the basic model component classes in PyMC?	\item \ttt{Stochastic} and \ttt{Deterministic}, which are subclasses of \ttt{Variable}<div>\item \ttt{Potential} and \ttt{Variable}, which are subclasses of \ttt{Node}</div>
What are the primary attributes of a PyMC \ttt{Stochastic} object?	\item \ttt{value}<div>\item \ttt{logp}</div>
What's the \ttt{extended\_children} attribute of a PyMC \ttt{Stochastic} object?	\item It's the set of all the variables which deterministically depend on the object's \ttt{value}<div>\item ie they're all the variables that need to have their log-probabilities recomputed when \ttt{value} changes</div>
What's the purpose of the \ttt{dtype} attribute of a PyMC \ttt{Stochastic} object?	\item It specifies the variable's value to fitting methods
What are the three main ways of creating \ttt{Stochastic} objects in PyMC?	\item Use the built-in distributions<div>\item Use the \ttt{@stochastic} decorator on an appropriate function</div><div>\item Instantiate \ttt{Stochastic} directly, passing everything it needs to the initializer&nbsp;</div>
What's the \emph{simple} way to use the \ttt{@stochastic} decorator in PyMC?	\item Define a function \ttt{f} which&nbsp;<div>\item has a \ttt{value=initial\_val} parameter</div><div>\item has \ttt{parent\_name=ParentVar} parameters that specify the variable's parents</div><div>\item and which returns a log-probability</div><div>\item Then decorate \ttt{f} with \ttt{\@stochastic(args)}, passing in any options that'd usually go to the \ttt{Stochastic} initializer</div>
What's the advanced way to use the \ttt{@stochastic} decorator in PyMC?	\item It's similar to the common way, but rather than applying it to a \ttt{f} that returns a log probability<div>\item apply it to an \ttt{f} that contains two functions,</div><div>\item \ttt{logp}, which takes the same parameters as \ttt{f} and returns the log-probability</div><div>\item \ttt{random}, which takes the parents specified in \ttt{f} and returns a random sample</div>
How should you update the \ttt{value} of a \ttt{Stochastic} object in PyMC?	\item Only using simple assignment, \ttt{x.value = y}<div>\item Anything else (like \ttt{(+=)} or setting \ttt{x.value.attr}) will confuse PyMC's caching!</div>
How is data represented in PyMC?	\item As \ttt{Stochastic} objects with the initializer parameter \ttt{observed=True}
How is a Dirichlet variable represented in PyMC?	\item As a \ttt{dirichlet\_like} stochastic variable which gives the log-probability of the first \ttt{k-1} elements<div>\item and a \ttt{CompletedDirichlet} deterministic variable which wraps it and gives the last element</div>
How can you convert a lambda to a deterministic variable in \ttt{PyMC}?	\item Use the \ttt{Lambda} deterministic variable
What're implicit deterministic variables in PyMC?	\item Certain elementary operations (like \ttt{+, []}, etc) on \ttt{Variables} return a \ttt{Deterministic} variable representing their value automatically&nbsp;
What are the four main ways of creating deterministic variables in PyMC?	\item Use the built-in variables<div>\item Apply elementary operations to other variables</div><div>\item Use the \ttt{\@deterministic} decorator</div><div>\item Instantiate a \ttt{Deterministic} object directly</div>
How is the \ttt{@deterministic} decorator used in PyMC?	\item Define a function \ttt{f} which&nbsp;<br /><div>\item has \ttt{parent\_name=ParentVar} parameters that specify the variable's parents</div><div>\item and returns a value</div><div>\item Then decorate \ttt{f} with \ttt{@deterministic(args)}, passing in any options that'd usually go to the \ttt{Deterministic} initializer</div>
What's PyMC's \ttt{@observed} decorator?	\item It's sugar for \ttt{@stochastic(observed=True)}
What're \ttt{Container}s in PyMC?	\item If you pass a collection as the parent of a \ttt{Variable}, you'll silently get a \ttt{Container} back<div>\item which has a copy of the \ttt{Variable} for each item in the collection</div><div>\item and will attempt to act like the contained \ttt{Variables}</div>
How is the \ttt{@potential} decorator used in PyMC?	\item Define a function \ttt{f} which&nbsp;<br /><div>\item has \ttt{parent\_name=ParentVar} parameters that specify the variable's parents</div><div>\item and returns a log potential</div><div>\item Then decorate \ttt{f} with \ttt{@potential(args)}, passing in any options that'd usually go to the \ttt{Potential} initializer</div>
How can you visualize the structure of a PyMC model?	\item Using the \ttt{pymc.graph.dag()} function to draw a graphical representation of the model&nbsp;
What caching is done in PyMC?	\item \ttt{logp} methods are wrapped in a \ttt{LazyFunction}&nbsp;<div>\item which by default keeps a depth-2 cache that matches by reference against \ttt{logp}'s arguments</div>
What are the important classes in PyMC's model fitting hierarchy?&nbsp;	\item \ttt{MCMC} and \ttt{NormalApprox} both extend \ttt{Sampler}<div>\item \ttt{MAP}, \ttt{MCMC} and&nbsp;\ttt{NormalApprox} all&nbsp;extend \ttt{Model}</div>
What can be passed to PyMC's fitting methods as \ttt{input}?	\item A collection or nested collections of nodes<div>\item A dictionary of nodes or collections of nodes&nbsp;</div><div>\item A module containing the node definitions</div>
What's the advantage of passing a dictionary to a PyMC fitting method's \ttt{input}?	\item The entries will be exposed as attributes on the produced model<div>\item which is useful when you want collections of variables exposed as a single attribute, instead of the normal behaviour of exposing every variable as its own attribute</div>
What's the \ttt{model.draw\_from\_prior()} method in PyMC?	\item It sets all stochastic variables to new random values<div>\item which is effectively a sample from the joint distribution if all data and potentials log-probabilities returned zero</div>
What's the \ttt{model.seed()} method in PyMC?	\item It sets all the stochastic variables whose \ttt{rseed} attribute is not \ttt{None} to new randomly-chosen values
At a high level, what's the \ttt{MAP} model class in PyMC?	\item It uses continuous optimization methods from SciPy to find the MAP of continuous-variable-only models.
What's the \ttt{NormalApprox}&nbsp;model class in PyMC?	\item An extension of the \ttt{MAP} class which uses the Hessian at the MAP to compute a normal approximation to the joint, which can then be sampled from
What's the \ttt{model.isample()} method in PyMC?	\item An interactive version of \ttt{model.sample()}, which allows the sampling to be interrupted at any time<div>\item then later resumed with \ttt{model.icontinue()}</div>
What's the \ttt{method} class in PyMC?	\item Instantiations of a \ttt{method} subclass deal with updating one or more variables during MCMC execution
How do you set the step method used for a variable in PyMC?	\item \ttt{model.use\_step\_method(MethodClassObj, variable, initializerArgs)}<div>\item where \ttt{initializerArgs} will be used to instantiate \ttt{MethodClassObj}</div>
What must be done to implement a Metropolis-Hastings step method in PyMC?	\item Subclass \ttt{Metropolis}<div>\item Override \ttt{propose()}, which should set the values of the variables to proposed values</div><div>\item Override \ttt{reject()}, which should reset the values of the variables to what they were before \ttt{propose()} was called.</div><div>\item For non-symmetric random walks, override \ttt{hastings\_factor}</div>
What's tuning in PyMC?	\item During a MCMC run with a Gaussian proposal<div>\item the standard deviation of the proposal is automatically adjusted to keep the acceptence ratio in the desired range</div>
What's the \ttt{AdaptiveMetropolis} step method in PyMC?	\item It's MH but updates the variables in blocks using a multivariate jump proposal<div>\item with the covariance of the proposal being tuned during sampling</div>
What're the standard step methods in PyMC?	\item \ttt{Metropolis} and its discrete \&amp; adaptive variants<div>\item \ttt{Slicer}, which implements slice sampling</div><div>\item \ttt{Gibbs}, which (kinda) implements Gibbs sampling&nbsp;</div>
How are step methods chosen by the \ttt{MCMC} in PyMC?	<div>\item For each stochastic variable \ttt{v}</div>\item and for each method in the \ttt{StepMethodRegistry}<div>\item \ttt{sm.competence(v)} is called<br /><div>\item and the \ttt{sm} with the highest result is used</div></div>
How can you get a collection of all the samples accepted for a variable in a PyMC \ttt{MCMC} run?	\item \ttt{M.trace(var)}
How do you get summary statistics for a variable in a \ttt{MCMC} run in PyMC?	\item \ttt{model.varname.summary()}
How can you add a function whose values should be recorded during a MCMC run in PyMC?	\item Add the function (with no args) to the \ttt{model.\_funs\_to\_tally} dictionary.<div>\item The tallied values can later be retrieved via \ttt{model.trace['name\_in\_dict']}</div>
How can you save the current state of a \ttt{MCMC} object in PyMC?	\item \ttt{model.save\_state()}, which will store it in the chosen backend
How do you roll back the state of a \ttt{MCMC} object to a particular previous iteration of the chain?	\item \ttt{model.remember(idx)} will restore the variables' values to the state given at index \ttt{idx} in the database
Which database is used by default in PyMC?	\item \ttt{ram}, which stores everything in RAM
What's a relevance network in ML?	\item Given a set of random variables,&nbsp;to generate edges<div>\item calculate the pairwise mutual information and threshold it at a fraction of maximum MI</div>
What's a covariance graph another name for?	\item A relevance network
What distinguishes a relevance network from a graphical model?	\item Relevance networks represent conditional dependence<div>\item Graphical models represent conditional independence (usually a lot sparser)</div>
What's a dependency network?	\item A way to identify structure<div>\item by fitting a full, sparse CPD $p(x_t|x_{-t})$ to each variable $x_t$</div>
What's a common catch when constructing a dependency network?	\item Some of the relationships represented in the sparse CPDs might be strong \emph{anti}correlations
What're the most common uses for dependency networks?	\item Quick and easy way to visualize structure<div>\item Somewhat useful for data imputation&nbsp;</div><div>\item Can be used to initialized more advanced methods</div>
When should directed or undirected trees be preferred for representing tree structures?	\item Undirected is generally better for structure learning<div>\item Directed is generally better for parameter learning</div>
Are undirected and directed graphical models of trees equivalent?	\item Yup
What're the steps in the Chow-Liu algorithm?	\item Construct a complete graph on the variables where the edge weights are the mutual informations<br /><div>\item Find a maximum spanning tree over this graph</div><div>\item This MST maximizes the likelihood of the data over the set of possible tree topologies</div>
How is the Chow-Liu algorithm derived?	\item Start with the equation for the $p(\mc{D}|\theta, T)$ of a tree $T$-structured MRF<div>\item Assume the edge and node distributions are given by the empirical distribution</div><div>\item Throw away the node terms because they're indepedent of $T$</div><div>\item Notice that the edge terms are given by the mutual information, assuming the empirical distribution</div>
What's the use of a mixture of trees in structure learning?	\item It's a half-way house between trying to represent a model's structure as a tree and representing it as a general graph.
Intuitively, what's Markov equivalence?	\item Two graphical models are Markov equivalent if they encode the same set of independence assumptions
How can Markov equivalence in DGMs be characterized?	\item Two DGMs are Markov equivalent if they have the same undirected structure and the same set of v-structures
What's an essential graph?	\item It's a partially directed DAG which represents a class of Markov-equivalent graphs
In the essential graph of a class of DGMs, what're the compelled edges?	\item The directed edges, which, if their direction was changed, would no longer be equivalent to the DGMs in the equivalence class
What's a PDAG in ML?	\item Partially-directed acyclic graph
What's global prior parameter indpendence in structure learning?	\item That if $\theta_t$ are the parameters for $t$'s CPD,<div>\item $p(\theta) = \prod_t p(\theta_t)$</div>
What's local prior parameter independence for tabular CPDs in structure learning?	\item That if $\theta_{tc}$ are the parameters for $t$'s CPD when its parents are in state $c$,<div>\item $p(\theta_t) = \prod_c p(\theta_{tc})$</div>
What's a consequence of global \&amp; local prior parameter independence for tabular CPDs in structure learning?	<div>\item That if $\theta_{tc}$ are the parameters for $t$'s CPD when its parents are in state $c$,</div>\item $\theta_{tc} \sim \text{Dir}(\alpha_{tc})$
When defining the marginal likelihood for a particular graph structure $G$, what's the $\text{score}$ function?	<div>\item If $N_{tc}$ is a vector of the counts of each state of $t$ given its parents are in state $c$,&nbsp;</div><div>\item $\text{score}(N_{t, \text{pa}(t)}) = \prod_c \frac{B(N_{tc} + \alpha_{tc})}{B(\alpha_{tc})}$</div>
What's the marginal likelihood for a particular graph structure $G$ in structure learning?	<div>\item If $N_{tc}$ is a vector of the counts of each state of $t$ given its parents are in state $c$, and &nbsp;$N_{t,\text{pa}(t)}$ is a vector of all such $N_{tc}$</div>\item $p(\mc{D}|G) = \prod_t \text{score}(N_{t,\text{pa}(t)})$
What's likelihood equivalence in structure learning?	\item If two graphs are Markov equivalent, they should have the same marginal likelihood
What's the definition of the BDe prior?	\item $\alpha_{tck} = \alpha p_0(x_t = k, x_\text{pa}(t) = c)$<div>\item where $\alpha$ is the equivalent sample size&nbsp;</div><div>\item and $p_0$ is some prior joint probability distribution</div>
What's BDe stand for in structure learning?	\item Bayesian Dirichlet likelihood equivalent prior
What's special about the BDe prior in structure learning?	\item It's the only prior on complete graphs which satisfies<div>\item global prior parameter independence</div><div>\item local prior parameter independence</div><div>\item likelihood equivalence</div>
What's parameter modularity in structure learning?	\item If $t$ has the same parents in $G$ and $H$, then $p(\theta_t|G_1) = p(\theta_t|H)$
How are prior parameters $\alpha_t$ usually derived from the BDe for a graph in structure learning?	<div>\item Construct the prior for the complete graph</div>\item then assume parameter modularity and so marginalize out any irrelevant parameters for the graph in question&nbsp;
What's the definition of the BDeu prior?	\item It's the BDe prior with a uniformity assumption, so<div>\item $\alpha_{tck} = \frac{\alpha}{K_t C_t}$</div><div>\item where&nbsp;</div><div>\item $\alpha_{tck}$ is the prior probability of $t$ being in state $k$ when it's parents are in state $c$</div><div>\item $K_t$ is the number of states $t$ can be in</div><div>\item $C_t$ is the number of states its parents can be in</div>
What does BDeu stand for in structure learning?	\item Bayesian Dirichlet likelihood-equivalent uniform
At a high level, what's the K2 algorithm for structure learning?	\item If a total ordering of the nodes is known<div>\item then the distribution over the parents of each node can be evaluated independently without risking introducing any cycles</div><div>\item The K2 algorithm is to return the locally most probable set of parents for each node.</div>
What's the main problem with doing structure learning exactly?	\item The huge number of DAGs for even a small number of nodes
At a high level, how can the MAP DAG be found for $&lt;16$ nodes?	\item Using dynamic programming
What's the computational complexity of finding the MAP DAG for a set of nodes?	\item NP-complete
At a high level, how is the MAP DAG for a set of nodes usually found in practice?	\item Using greedy hill climbing<div>\item with steps involving reversing/adding/removing an edge</div>
How are summaries of the posterior distribution of graphs for a set of nodes other than the MAP usually calculated in structure learning?	\item By sampling DAGs from the posterior via MCMC and computing estimates of the summary using the samples
How does the BIC usually compare to the actual marginal likelihood?	\item It usually severely underestimates it, leading to too-simple models being chosen
What's the Cheeseman-Stutz approximation?	\item Given a graphical model with hidden parameters, estimate the marginal likelihood of a structure $G$ as<div>\item $\ln p(\mc{D}|G) \approx \ln p(\bar D|G) + \ln p(\mc{D}|\hat \theta, G) - \ln p(\bar D|\hat \theta, G)$</div><div>\item where</div><div>\item $\hat \theta$ is the MAP</div><div>\item $\bar D$ is the expected sufficient statistics of the data (ie with the hidden variables replaced by their expectation)</div>
What's CS stand for in ML?	\item Cheeseman-Stutz approximation
How do variational bounds, CS and BIC approximations to the marginal likelihood compare?	\item Variational bounds are always better than CS<div>\item CS is always better than BIC</div>
What's the problem with using the marginal likelihood to assess model quality when there are hidden variables?	\item The marginal likelihood doesn't decompose when there's missing data
Conceptually, how does the structural EM algorithm work?	\item Under the current structure, estimate the hidden variables<div>\item Then use the estimates to assess the marginal likelihood of all neighbouring structures</div><div>\item and move to the most likely one</div>
What metric does structural EM usually use to assess the quality of a model?	\item $\text{score}_\text{BIC}(G, \mc{D}) = \ln p(\mc{D}|\hat \theta, G) - \frac{\ln N}{2} \text{dim}(G) + \ln p(G) + \ln p(\hat \theta| G)$
What's a structural signature in structure learning?	\item It's a cluster of densely connected nodes that can be taken to indicate the presence of a latent variable
What's an idiom for structure learning in neuroscience?	\item ``Nodes that fire together should wire together''
What's the causal Markov assumption?	\item If a DGM has an edge $a \rightarrow b$, then this means that `$a$ directly causes $b$'
What's the causal sufficiency assumption?	\item That all the variables relevant to a causal DAG are included in the model<div>\item aka there are no confounders &nbsp;</div>
What's a perfect intervention?	\item It's a representation of fixing a variable in a causal DAG to a specific value
What's the do-calculus notation for a perfect intervention?	\item $\text{do}(X_i = x_i)$<br />
What's graph surgery?	\item It's representing a perfect intervention by cutting the edges coming into any node set by the intervention
How can you perform inference about the effects of an intervention on a causal DAG?	\item Implement the intervention using graph surgery<div>\item Apply standard probabilistic inference to the mutilated graph&nbsp;</div>
What's a fat hand intervention?	\item An intervention which affects multiple nodes simultaneously
What does it mean for a distribution $p$ to be faithful to a graphical model $G$?	\item All the conditional independence assumptions of $p$ are captured by $G$
What's a stable distribution another name for?	\item A faithful distribution
Given a multivariate normal, how can the likelihood of the precision be written in terms of the determinant and trace?	\item $l(\Lambda) = \ln \det \Lambda - \text{tr}(S\Lambda)$<div>\item where $S = \frac{1}{N} \sum_i (x_i - \bar x)(x_i - \bar x)^T$ is the empirical covariance matrix</div>
Given a multivariate normal, what's the gradient of the likelihood of the precision?	\item $\nabla l(\Lambda) = \Sigma - S$<div>\item where $S = \frac{1}{N} \sum_i (x_i - \bar x)(x_i - \bar x)^T$ is the empirical covariance matrix</div>
What's a matrix completion of an empirical covaraince matrix $S$ in the context of GRF structure learning?	\item It's a covariance matrix $\Sigma$ which retains as many entries of $S$ as possible while preserving a specified sparsity pattern on $\Sigma^{-1}$
What's the objective in graphical lasso?	\item $J(\Lambda) = -\ln \det \Lambda + \text{tr}(S\Lambda) + \lambda \|\Lambda\|_1$<div>\item where $\|\Lambda\|_1 = \sum |\Lambda_{jk}|$</div><div>\item and $\lambda$ controls the regularization strength</div>
What's a nonparanormal distribution?	\item A distribution $X$ such that there exists a set of monotonic $f_j$, one for each $X_j$,<div>\item such that $(f_j(X_j))_j$ is jointly Gaussian</div>
What's the relevance of nonparanormal distributions to structure learning?	\item Structure learning on UGMs whose distribution is jointly nonparanormal&nbsp;<div>\item can be done by transforming the distribution to jointly Gaussian</div><div>\item and carrying out glasso.&nbsp;</div><div>\item This is a consistent estimator of the graph's structure.</div>
Why is learning structure for UGMs with discrete variables much harder than learning structure for Gaussian UGMs?	\item Computing the partition function for a Gaussian UGM is equivalent to computing the determinant<div>\item Computing the partition function for a discrete UGM is equivalent to computing the permanent</div>
What's the relevance of circuit complexity to structure learning?	\item Models with low circuit complexity can have high treewidth while also permitting fast exact inference
What's sample complexity?	\item The number of samples an approximation needs to be within some $\epsilon$ of the true value with high probability
explanatory variable	independent variable (predictor)
response variable	dependent variable (predicted)
linear regression model	y = β₀ + β₁x β₀ : intercept β₁ : slope * point estimates: b₀ and b₁, respectively
What are the three ways to describe the association between two numerical variables?	1. *direction*: positive (x↑, y↑), negative (x↓, y↑) 2. *form*: linear or not 3. *strength*: determined by the scatter around the underlying relationship
correlation	*linear* association between two numerical variables; note that a relationship that is nonlinear is simply called an association
correlation coefficient	R, also called Pearson's R, has the following properties: - magnitude (absolute value) of R = strength of linear association - sign (positive or negative) indicates direction of association - always between -1 (perfect negative linear association) and +1 (perfect positive linear association); 0 indicates no linear relationship) - unitless, so not affected by changes in center or scale of either variable, such as unit conversions) - correlation of X with Y = Y with X - sensitive to outliers
residual (e)	"difference between observed (y) and predicted (ŷ) values of the response variable         <div><img src=""ljOC19medI0cuelEtazI3w_m.png"" /></div>         "
least squares line	minimizes the sum of the squared residuals; always passes through the average of the response and explanatory variables (x mean, y mean); conditions necessary for fitting such line: 1. linearity 2. nearly normal residuals  3. constant variability
indicator variable	binary explanatory variable (with two levels)
estimate for the slope (b₁)	"R is the correlation coefficient, sy is the standard deviation of the response variable, and sx is the standard deviation of the explanatory variable         <div><img src=""vsWKcbQZsgZuwUrRSPOpqA_m.png"" /></div>         "
How can the slope be interpreted?	"1. When x is numerical: ""For each unit increase in x, we would expect y to be lower/higher on average by |b1| units."" 2. When x is categorical: ""The value of the response variable is predicted to be |b₁| units higher/lower between the baseline level and the other level of the explanatory variable."" - Note that whether the response variable increases or decreases is determined by the sign of b₁."
estimate for the intercept (b₀)	"b1 is the slope, y ̄ is the average of the response variable, and x ̄ is the average of explanatory variable         <div><img src=""Zr8eXj5lqPtvHRGk75kWwA_m.png"" /></div>         "
How can the intercept be interpreted?	"1. ""When x = 0, we would expect y to equal, on average, b₀"" when x is numerical. 2. ""The expected average value of the response variable for the reference level of the ex- planatory variable is b₀"" when x is categorical."
How can you predict the value of the response variable for a given value of the explanatory variable, x*?	"- Only predict for values of x* that are in the range of the observed data. - Do not extrapolate beyond the range of the data, unless you are confident that the linear pattern continues.         <div><img src=""F5n4FHG1oQFG4CHJQ4F5AA_m.png"" /></div>         "
R²	variability in the response variable explained by the the explanatory variable - For a good model, we would like this number to be as close to 100% as possible. - This value is calculated as the square of the correlation coefficient.
leverage point	a point that lies away from the center of the data in the horizontal direction
influential point	a point that influences (changes) the slope of the regression line; This is usually a leverage point that is away from the trajectory of the rest of the data
What is the null hypothesis (H₀) set to for testing the significance of the predictor?	H₀ : β₁ = 0 - β₁ = 0 means the regression line is horizontal, hence suggesting that there is no relationship between the explanatory and response variables.
T score for the hypothesis test	"- df = n − 2 - Note that the T score has n - 2 degrees of freedom since we lose one degree of freedom for each parameter we estimate, and in this case we estimate the intercept and the slope.         <div><img src=""u2IQ3mPqRf25fLrYQ8Q0ZA_m.png"" /></div>         "
Why is a hypothesis test for the intercept irrelevant?	It's usually out of the range of the data, and hence it is usually an extrapolation.
confidence interval for the slope	"- df = n − 2 and t*df is the critical score associated with the given confidence level at the desired degrees of freedom. - Note that the standard error of the slope estimate SEb1 can be found on the regression output         <div><img src=""FYe1rOAzAGgLgCSCZfoIlA_m.png"" /></div>         "
What's the trick for doing RDA when $D &gt; N$?	\item Let $X = UDV^T$ be the thin SVD of $X$, so $D$ is $N \times N$.<div>\item Then we can define $Z = UX$ to be the design matrix in the smaller $N$-dimensional space</div><div>\item so $\Sigma_x = V\Sigma_z V^T$</div><div>\item and we can regularize $\Sigma_z$, then map it back to $\Sigma_x$&nbsp;</div>
What's the posterior mean given a NIW prior?	\item It's a NIW with parameters<div>\item $\kappa_N = \kappa_0 + N$</div><div>\item $m_N = \frac{\kappa_0}{\kappa_N} m_0 + \frac{N}{\kappa_N} \bar x$</div>
What's the posterior scale matrix given a NIW prior?	<div>\item $\kappa_N = \kappa_0 + N$</div><div>\item $S_N = S_0 + S_{\bar x} + \frac{\kappa_0 N}{\kappa_N}(\bar x - m_0)(\bar x - m_0)^T$</div>
What's the form of the predictive distribution given a NIW prior?	\item It's a Student T distribution<div>\item (the T distribution has wider tails, which account for the fact $\Sigma$ is unknown)</div>
When writing a Student's T distribution as a mixture of Gaussians, what distribution are the component coefficients drawn from?	\item An inverse Wishart distribution
What's the form of the posterior marginals of $\mu$ and $\Sigma$ given a NIW prior?	\item $\Sigma \sim \text{IW}$<div>\item $\mu \sim \mathcal{T}$</div>
How does the sample standard deviation arise from a Bayesian perspective?	\item If you apply an uninformative NIX (ie NIW) prior to a Gaussian, the posterior varaince is found to be<div>\item $s^2 = \frac{N}{N-1}\hat \sigma_{\text{mle}}$</div>
What's a simple approximation to the 95\% credible interval for the mean given an uninformative NIX (ie NIW) prior?	\item $I_{.95}(\mu | \mc{D}) = \bar x \pm 2\frac{s}{\sqrt{N}}$<div>\item where $s$ is the sample standard deviation</div>
How do T tests arise from a Bayesian perspective?	\item An uninformative NIX (NIW) prior on a Gaussian gives rise to a $\mc{T}$-distributed posterior mean
Is it covariance or precision matrices that are drawn from a Wishart distribution?	\item Precision<br />
What's a semi-conjugate prior?	\item One in which each term is individually conjugate, but the whole thing isn't
How can the posterior predictive distribution be written given a conjugate prior?	\item Given new data $\mc{D}^\prime$ and posterior hyperparameters $\alpha^\prime$<div>\item it's the marginal likelihood $p(\mc{D}^\prime|\alpha^\prime)$</div>
What's the distribution of the product of two Gaussians?	\item $\mc{N}(\Lambda_1\mu_1 + \Lambda_2\mu_2, \Lambda_1 + \Lambda_2)$
What's a reject option in ML?	\item It's the ability to refuse to make a prediction<div>\item which can be useful if mispredictions are very expensive</div>
What's type II maximum likelihood another name for?	\item Empirical Bayes
What's the second moment of a Gaussian?	\item $\mbb{E}[X^2] = \mu^2 + \sigma^2$
What are some basic facts about the optimal solution set of $\min\|x\|_1$ s.t. $b = Ax$, where $A$ is a $n\times m$ matrix?	\item It's bounded<div>\item It's convex</div><div>\item It has a solution $x$ with $n$ nonzero entries&nbsp;</div>
How can you convert a&nbsp;$\min\|x\|_1$ s.t. $b = Ax$ problem to a LP?	\item Write $x = u - v$ for positive vectors $u, v$<div>\item Write $z = \left[\begin{smallmatrix} u \\ v \end{smallmatrix}\right]$</div><div>\item Then</div><div>\item $\min \sum z_i$ s.t. $b = [A, -A]z$, $z \geq 0$</div>
What's dangerous about $p$-norms with $p&lt;1$?	\item They're not actually norms - they don't satisfy the triangle inequality
For $q &lt; p$, what're the $x$ with minimum $q$ norm when $\|x\|_p = 1$?	\item The $x$ with only one non-zero entry, which is 1<div>\item So the smaller the $r$, the sparser the $r$ norm</div>
Geometrically, why is the $q$ norm sparser than the $p$ norm when $q &lt; p$?	\item Imagine the $p$ norm surface<div>\item and blow up a $q$ norm `balloon' inside it.</div><div>\item The first intersection of the two occurs on the axes<br /></div>
What's the weak $l_p$ norm?	\item $\|x\|^p_{wl_p} = \sup_{\epsilon &gt; 0} [N(\epsilon, x)\cdot \epsilon^p]$<div>\item where $N(\epsilon, x)$ counts the number of elements of $|x|$ larger than $\epsilon$</div>
What are the necessary properties of $\rho$ in a function $J(x) = \sum \rho(x_i)$ to promote sparsity?	\item $\rho(x)$ is symmetric<div>\item $\rho(x)$ is non-decreasing for $x \geq 0$</div><div>\item $\rho^\prime(x)$ is non-increasing for $x \geq 0$</div>
What's the danger in the $l_0$ norm?	\item It isn't homogeneous<br />
What does $P_J$ stand for in the sparsity literature?	<div>\item The problem</div>\item $\min\|x\|_J$ s.t. $Ax = b$
What's the uncertainty principle for Fourier-conjugate functions?	\item If $f, F$ are a function and its Fourier transform,&nbsp;<div>\item with $f$ scaled and the transform defined so $\|f\|_2, \|F\|_2 = 1$&nbsp;<div>\item then&nbsp;</div><div>\item $D_0(f) \cdot D_0(F) \geq \frac{1}{2}$</div></div><div>\item where $D_0$ is the dispersion about zero</div>
What's the mutual coherence of two bases $\Psi, \Phi$?&nbsp;	\item $\mu([\Psi, \Phi]) = \max_{i, j} |\psi_i \cdot \phi_j|$
What's the range of the mutual coherence of two orthogonal bases $\Phi, \Psi$?	\item $\frac{1}{\sqrt{n}} \leq \mu([\Phi, \Psi]) \leq 1$
What's the first uncertainty principle for orthogonal bases $\Psi, \Phi$?	\item Given a nontrivial $b = \Psi \alpha = \Phi \beta$,<div>\item $\|\alpha\|_0\|\beta\|_0 \geq \frac{1}{\mu([\Psi, \Phi])^2}$</div><div>\item This holds for the $l_1$ norm too</div>
What's a useful inequality relating geometric and algebraic means?	\item $\sqrt{ab} \leq \frac{a+b}{2}$
What's the dispersion about zero in Fourier analysis?	\item $D_0(f) = \int x^2 |f(x)|^2 dx$
What's the uncertainty of redundant solutions principle for orthogonal bases $\Psi, \Phi$?	\item Given a nontrivial $b$ and solutions $x_1, x_2$ to $[\Psi, \Phi]x = b$,<div>\item $\frac{\|x_1\|_0 + \|x_2\|_0}{2} \geq \frac{1}{\mu([\Psi, \Phi])^2}$</div>
What's the uniqueness consequence of the uncertainty of redundant solutions?	\item Given orthonormal bases $\Psi, Phi$ and nontrivial $b$<div>\item if $[\Psi, \Phi]x = b$ has fewer than $\frac{1}{\mu(A)}$ nonzeros</div><div>\item then it is the sparsest one possible</div>
What's the spark of a matrix $A$?	\item The smallest number of columns that are linearly dependent
What's the uniqueness result for the spark of $A$?	\item If $x$ solves $Ax = b$<div>\item and&nbsp;$\|x\|_0 &lt; \frac{1}{2}\text{spark}(A)$</div><div>\item then $x$ is the sparsest solution possible</div>
What's the range of the spark of a matrix?	<div>\item For a $n \times m$ matrix A,</div>\item $2 \leq \text{spark}(A) \leq n + 1$<div>\item It can be $1$ if one of the columns of $A$ is zero, but this is considered an edge case</div>
What's the Gram matrix of $A$?	\item $A^TA$<div>\item ie the matrix of inner products of the columns of $A$</div>
What's the mutual coherence of a matrix $A$?	\item $\mu(A) = \max_{i \neq j} \frac{|\bar a_i \cdot \bar a_j|}{\|a_i\|_2\|a_j\|_2}$<div>\item ie the maximum normalized inner product between two columns</div>
What's the lower bound on the mutual coherence for general $n \times m$ matrices $A$?	\item $\mu(A) \geq \sqrt{\frac{m-n}{n(m-1)}}$
Which operators satisfy the lower bound on the mutual coherence?	\item Grassmannian frames
How is the spark of a matrix related to its mutual coherence?	\item $\text{spark}(A) \geq 1 + \frac{1}{\mu(A)}$
What's the Gershgorin disc theorem?	\item Let $A$ be a $n \times n$ matrix,&nbsp;<div>\item Let $R_i$ be the sum of the nondiagonal entries in row $i$ of $|A|$</div><div>\item Then every eigenvalue of $A$ lies in one of the discs $D(a_{ii}, R_i)$&nbsp;</div>
What's the intuitive interpretation of the Gershgorin circle theorem?	\item If the off-diagonal entries of $A$ are small, then the eigenvalues must be close to the eigenvalues of $\text{diag}(A)$,&nbsp;<div>\item so they must be close to $\{a_{ii}\}_i$</div>
What's the uniqueness result for the mutual coherence of $A$?	\item If $x$ solves $Ax = b$<div>\item and&nbsp;$\|x\|_0 &lt; \frac{1}{2}(1 + \frac{1}{\mu(A)})$</div><div>\item then $x$ is the sparsest solution possible</div>
What's the Babel function?	\item For a matrix $A$ with normalized columns,<div>\item $\mu_1(p) = \max_{|\Lambda| = p} \max_{j \not \in \Lambda} \sum_{\Lambda} |\bar a_i \cdot \bar a_j|$</div>
What's the behaviour of the Babel function?	\item $\mu_1(1)$ is the mutual coherence<div>\item It's non-decreasing</div><div>\item $\mu_1(p) &lt; p \mu(A)$</div>
How can the Babel function be calculated efficiently?	\item Compute the Gram matrix $G$ of the column-normalized $A$<div>\item Sort each row of $|G|$ in descending order to get $G_S$.</div><div>\item Then&nbsp;</div><div>\item $\mu_1(p) = \max_i \sum_{j=2}^{p+1} |G_S(i, j)|$</div>
How does the Babel function lower bound the spark?	\item If $p$ is the smallest such that $\mu_1(p) \geq 1$<div>\item then $\text{spark}(A) \geq p + 1$</div>
How can the spark of a matrix be upper bounded?	\item For each $i$, solve<div>\item $z^{i} = \arg \min_x \|x\|_1$ s.t. $Ax = 0$ and $x_i =1$</div><div>\item Then&nbsp;</div><div>\item $\text{spark}(A) \leq \min_i \|z^i\|_0$</div>
How well does the $l_1$-derived upper bound on the spark work in practice?&nbsp;	\item It's usually very tight
What's a Grassmannian matrix?	\item It's a $A$ of size $n \times m$ with normalized columns such that its Gram matrix $G$ satisfies<div>\item $|G_{ij}| = \sqrt{\frac{m-n}{n(m-1)}}$</div><div>\item for all $i \neq j$</div>
What's the intuitive interpretation of a Grassmannian matrix?	\item All the columns are at the same angle to eachother, and the angle is maximal
What are the two strategies for solving $l_0$ optimization problems?	\item Search over possible supports<div>\item Smooth the penalty function</div>
What's the difference between matching pursuit and orthogonal matching pursuit?	\item In OMP, the residual is re-evaluated after each selection using all the selected vectors<div>\item In MP, the residual simply has the component along the newly selected vector removed</div>
What's the idea in LS-OMP?	\item Rather than testing each candidate against the residual<div>\item a full least-squares fit with the candidate and all currently selected vectors is done&nbsp;</div>
What's the weak matching pursuit algorithm?	\item Rather than picking the optimal vector in each step<div>\item the first vector within a factor of $t$ of $\|r\|_2$ is chosen, where $r$ is the residual</div><div>\item or the optimal vector if there is no such weak choice&nbsp;</div>
What's the decay factor of a column normalized matrix $A$ wrt a normalized vector $v$?	\item $\delta(A, v) = \max_j |\bar a_j \cdot v|$
What's the universal decay factor of a matrix?	\item $\delta(A) = \inf_v \delta(A, v)$&nbsp;<div>\item where $\delta(A, v)$ is the decay factor wrt $v$</div>
What's the intuitive interpretation of the decay factor of a matrix?	\item It's the (arccos of) the maximum angle any vector can be from a column of the matrix
How can the universal decay of a matrix be used to analyze the progress of matching pursuits?	<div>\item When solving the system $Ax = b$, the $k$th residual is bounded by</div>\item $\|r_k\|^2_2 \leq (1 - \delta(A))^k \|b\|_2^2$
What's the universal decay factor of an orthogonal matrix $A$?	\item $\delta(A) = \frac{1}{n}$
What's the thresholding algorithm for $l_0$ optimization?	\item Pick the normalized columns with the $k$ largest inner products with the target.
What are some common sparsity-promoting regularizers other than the $l_p$-norms?	\item $\sum \ln(1+\alpha x_j^2)$<div>\item $\sum \frac{x_j^2}{\alpha + x_j}$</div><div>\item $\sum (1 - \exp(-\alpha x_j^2))$</div>
What's the idea in the FOCUSS algorithm for $l_0$ optimization?	\item Apply IRLS with weights that emulate the $l_\epsilon$ norm using the $l_2$ norm<div>\item where $\epsilon$ is very close to 0</div>
How does the FOCUSS algorithm approximate the $l_\epsilon$ norm?	\item Let $x^+_{j} = x_j^{\epsilon-1}$ if $x_j$ is nonzero, and 0 otherwise.<div>\item Then $\|x^+ \odot x\|^2_2$ is equal to $\|x\|^\epsilon_\epsilon$</div>
What path do the intermediary solutions of the FOCUSS algorithm describe?	\item A descent on $\prod |x_i|$
How should the FOCUSS algorithm be initialized?	\item With an all-nonzero vector, since once an iteration zeros a component, it'll remain zerod
What's the basis pursuit problem?	\item $\min\|x\|_1$ s.t. $Ax = b$<div>\item ie LASSO with an exact constraint</div>
In terms of the mutual coherence, when is OMP guaranteed to find the optimal-sparsity solution to $Ax = b$?	\item When a solution exists with<div>\item $\|x\|_0 &lt; \frac{1}{2}(1 + \frac{1}{\mu(A)})$</div>
In terms of the mutual coherence, when is the thresholding algorithm guaranteed to find the&nbsp;optimal-sparsity&nbsp;solution to $Ax = b$?	\item When a solution exists with<div>\item $\|x\|_0 &lt; \frac{1}{2}(1 + \frac{|x_\text{min}|}{|x_\text{max}|}\frac{1}{\mu(A)})$</div><div>\item where the min \&amp; max are taken over the nonzero elements of $x$</div>
In terms of the mutual coherence, when is solving the basis pursuit problem guaranteed to find the&nbsp;optimal-sparsity&nbsp;solution to $Ax = b$?	\item When a solution exists with<div>\item $\|x\|_0 &lt; \frac{1}{2}(1 + \frac{1}{\mu(A)})$</div>
Which of OMP and BP generally performs better in practice?	\item Basis pursuit
What's the exact recovery condition for a matrix $A$ and target support $\mc{S}$?	\item $\text{ERC}(A, \mc{S})$: $\max_{i \not \in \mc{S}} \|A^+_\mc{S}\bar a_i\|_1 &lt; 1$<div>\item where $A_\mc{S}$ is $A$ with its columns restricted to the set $\mc{S}$</div><div>\item and $A^+$ is the pseudoinverse</div>
What's the relevance of the exact recovery condition to BP and OMP?	\item If $Ax = b$ has a solution $x$ over support $\mc{S}$ such that $\text{ERC}(A, \mc{S})$ is met<div>\item then both OMP and BP will recover $x$</div>
What are the two general approaches to interpolating functions?	\item Restrict the set of functions that could explain the data<div>\item Pick a prior distribution over the functions that could explain the data</div>
What are the two main views on what a GP represents?	\item As a distribution over weights in a high-dimensional feature space<div>\item As a distribution over the function space</div>
What's the formal definition of a Gaussian process?	\item A collection of random variables such that any finite subset have a joint Gaussian distribution
What's the consistency requirement of GPs?	\item If you consider the distribution of $(y_1, y_2) \sim GP$, then marginalizing $y_2$ must lead to $y_1 \sim GP$
How's the kernel of a GP relate to its covariance?	<div>\item $k(x_p, x_q) = \text{cov}(f(x_p), f(x_q))$</div><div>\item So the kernel describes the covariance of the outputs in terms of the inputs</div>
How are GPs used for prediction?	\item By constructing the joint distribution on the training \&amp; test inputs<div>\item and then conditioning on the observed training outputs</div>
Given a feature map $\phi(x)$ and a prior on the weights $w \sim N(0, \Sigma_p)$, what's the corresponding GP kernel?	\item $k(x_i, x_j) = \langle \phi(x_i), \phi(x_j) \rangle_{\Sigma_p}$
In the GP literature, what do $K$ and $K_*$ signify?	\item $K = K(X,X)$, the kernel matrix of the training inputs<div>\item $K_* = K(X, X_*)$, the kernel matrix between the training \&amp; test inputs</div>
In the GP literature, what does $k_*$ signify?	\item The vector of covariances between the training inputs and the test input $x_*$
What's the covariance of the predictive distribution of &nbsp;GP?	\item $\Sigma = K_{**} - K_*^T[K + \sigma^2 I]^{-1} K_*$
What's SMSE stand for in ML?	\item Standardized mean square error
What's MSLL stand for in ML?	\item Mean standardized log loss
What's the standardized loss?	\item A loss function rescaled by the loss that'd occur under a trivial model
What's the standardized error in ML?	\item The error divided by the standard deviation
How should the MSLL be interpreted?	\item Trivial predictive methods will have a MSLL around 0<div>\item Better methods will have a more negative MSLL</div>
How can the predictive mean of a GP be written in terms of the eigenvectors of the kernel?	\item $\bar f = \sum \frac{\lambda_i}{\lambda_i + \sigma^2_n} (u_i \cdot y) u_i$<div>\item where $u_i$ is the $i$th eigenvector of the kernel evaluated on the training set</div>
What's the effective number of degrees of freedom of a GP?	\item $\sum \frac{\lambda_i}{\lambda_i + \sigma_n^2}$<div>\item where $\lambda_i$ are the eigenvalues of the kernel evaluated on the test data, $K$</div>
What's the weight function of a linear smoother?	\item The $h(x_*)$ such that $\bar f(x_*) = h(x_*) \cdot y$
What's the weight function for a GP when interpreted as a linear smoother?	\item $h(x_*) = (K + \sigma^2_n I)^{-1}k(x_*)$
What's a least-squares classifier?	\item One in which the target classes are interpreted as real values (like $-1, 1$) and least-squares regression is applied to them<br />
What's a response function in ML?	\item Another name for the mean function of a GLM
What's the function used in calculating the log odds ratio?	\item The logit function
What are the two main methods for building discriminative classifiers from GPs?	\item Normal approximations to the posterior<div>\item Expectation propagation</div>
How is the mean of normal approximation fit to the posterior of a GP classifier?	<div>\item Given labels $y$ and a latent function $f$ such that $p(y=+1|x) = \sigma(f(x))$</div>\item analytically derive the gradient of the unnormalized posterior, &nbsp;$\nabla \Phi(f)$<div>\item and use Newton's method to find the MAP, $\hat f$</div><div>\item This is the mean of the approximation.</div>
How does the logistic function correspond to the logistic distribution?	\item The logistic function is the cdf of the logisitic distribution
In a binary classifier with a Gaussian latent posterior, what's a simple alternative to predicting class labels by integrating over the posterior?	\item Point prediction using the MAP parameters<div>\item These are equivalent because the Gaussian is symmetric while the response function (usually $\sigma$) is commonly antisymmetric</div>
What's the use of a latent variable in a discriminative classifier?	\item The latent variable can be assumed to be continous over say $\mbb{R}$<div>\item and transformed to a class probability using a response function like $\sigma$</div>
What's jitter in the context of numerical computation?	\item Replacing a badly-conditioned matrix $K$ with $K + \epsilon I$ for some small $\epsilon$
What's the core approximation in EP for GP discriminative classifiers?	\item Approximate the label likelihood as<div>\item $p(y_i|f_i) \approx \tilde Z_i \mc{N}(f_i|\tilde \mu_i, \tilde \sigma^2_i)$</div>
What're the parameters of the approximation to the posterior $p(f|X,y)$ in the EP approach to GP classifiers?	\item If $\tilde \Lambda, \tilde \Lambda \tilde \mu$ are the parameters for the approximation to the likelihood $p(y|f)$<div>\item then the parameters for the posterior approximation are</div><div>\item $\Lambda = K^{-1} + \tilde \Lambda$</div><div>\item $\Lambda \mu = \tilde \Lambda \tilde \mu$</div>
What are the steps in an iteration of EP for GPCs?	\item Take the current approximate posterior $q(f|X,y)$<div>\item Leave out one of the approximate likelihood terms $q_i(y_i|f_i)$ to get the cavity distribution $q_{-i}(f_i)$</div><div>\item Combine the cavity distribution with the exact likelihood $p(y_i|f_i)$ to get a non-Gaussian marginal $\hat q(f_i)$</div><div>\item Find the parameters such that $q_i(y_i|f_i)$ minimize the reverse KL divergence from $\hat q(f_i)$</div><div>\item Replace the old approximation of&nbsp;$q_i(y_i|f_i)$ with the new one.</div>
What's the information score of a model?	\item The KL divergence of the model from the empirical distribution
How do MCMC, EP and the normal approximation compare for constructing GPCs?	\item MCMC usually performs the best<div>\item with EP close behind</div><div>\item while the normal approximation often suffers from an inability to represent skew distributions</div>
What's a stationary covariance function?	\item A translation-invariant one
What's the Gram matrix of a covariance function?	\item The $K$ such that $K_{ij} = k(x_i, x_j)$ for some inputs $\{x_i\}$
Given a one dimensional Gaussian with zero mean and kernel $k$, what's the expected number of upcrossings on the unit interval?	\item $\mbb{E}[N_u] = \frac{1}{2\pi} \sqrt{-\frac{k^{\prime \prime}(0)}{k(0)}} \exp\left(-\frac{u^2}{2k(0)}\right)$
What's it mean for a function $f$ to be continuous in mean square at a point $x_*$?&nbsp;	\item For every sequence $x_k$ such that $|x_k - x_*| \rightarrow 0$,<div>\item $\mbb{E}[|f(x_k) - f(x_*)|^2] \rightarrow 0$</div>
What does it mean for a random field to be continuous in mean square at a point $x_*$?	\item The covariance function $k(x, x^\prime)$ is continuous in &nbsp;MS at $x = x^\prime = x_*$
What's the use of the mean square limit in the context of stationary processes?	<div>\item If $k$ is the kernel and derivatives are taken using the mean square limit,</div>\item then if the $2m$th order partial derivatives of $k$ exists at $0$<div>\item then the $m$th order partial derivatives of $k$ exist everywhere in $\mbb{R}^D$</div>
What's a stationary statistical process?	\item One with a stationary kernel
What's Bochner's theorem?	\item A complex-valued $k$ is the covariance function of a stationary mean-square continuous random process&nbsp;<div>\item if and only if&nbsp;</div><div>\item it's the Fourier transform of a positive finite measure</div>
What's the Wiener-Khintchine theorem?	\item If a stationary mean-square continuous covariance function $k$ has a corresponding power spectrum $S$<div>\item then $k$ and $S$ are Fourier duals</div>
What's the power spectrum of a covariance function $k$?	\item Given a stationary mean-square continuous random process with covariance $k$<div>\item if the corresponding positive finite measure in the Fourier domain, $\mu$, has a density $S$</div><div>\item then $S$ is the power spectrum of $k$</div>
What's the infinite network construction of the squared exponential kernel?	\item The SE kernel can be obtained by expanding an input $x$ over a dense grid of spherical Gaussians
What happens to the Matern kernel when $\nu \rightarrow \infty$?	\item The SE kernel is recovered
When is the Matern kernel $k$ times MS differentiable?	\item When $\nu &gt; k$
What's the general form of the Matern kernel when $\nu = p+ \frac{1}{2}$ for an integer $p$?	\item It's the product of an exponential, and a polynomial of order $p$
For what values of $\nu$ are Matern kernels of interest to ML?	\item $\frac{3}{2}$ and $\frac{5}{2}$<div>\item below which it becomes too rough and above which it becomes indistinguishable from a SE kernel</div>
What does MS differentiable mean in ML?	\item Mean square differentiable;&nbsp;<div>\item ie the function is differentiable when the limits are taken in the mean-square</div>
What's the most general representation of an isotropic kernel?	\item A scale mixture of Gaussians
Which kernel functions are usually used for a GP's covariance if compact support is needed?	\item Piecewise polynomial ones
What kind of problems are polynomial kernels usually suited to?	\item High-dimensional image classification
How can a `neural network' covariance function be constructed?	\item Define $f(x) = b + \sum v_j h(x \cdot u_j)$ for some transfer function $h$ and hidden weights $u_j$<div>\item Distribute $b, v_j, u_j$ as independent Gaussians&nbsp;</div><div>\item Then $\mbb{E}[f(x)f(x^\prime)]$ can be interpreted as a covariance function</div>
When constructing a neural network covariance function, what transfer function is usually used?	\item $h(x) = \text{erf}(x \cdot u_j)$
What's warping in the context of GPs?	\item Constructing a nonstationary kernel by applying a nonlinear map $u(x)$, then evaluating it against a stationary kernel
Given two random processes $f_1(x), f_2(x)$, what's the kernel of $f_1 + f_2$?	\item $k_1 + k_2$
Given two random processes $f_1(x), f_2(x)$, what's the kernel of $f_1f_2$?	\item $k_1(x, x^\prime)k_2(x, x^\prime)$
Given random process $f(x)$ and function $a(x)$, what's the kernel of $a(x)f(x)$?	\item $a(x)k(x, x^\prime)a(x^\prime)$
Given a random process $f$ and a kernel $h$, what's the kernel of $\int h(x,z)f(z)dz$?	\item $\int h(x,z)k(z, z^\prime)h(x^\prime, z^\prime)dzdz^\prime$
What's an eigenfunction of a kernel?	\item A $\phi$ satisfying<div>\item $\int k(x, x^\prime)\phi(x)d\mu(x) = \lambda \phi(x)$</div><div>\item with respect to a given measure $\mu(x)$</div>
What's Mercer's theorem?	\item If $k$ is a positive definite kernel on a finite measure space with normalized eigenfunctions $\{\phi_i\}_i$<div>\item then $\{\lambda_i\}_i$ are absolutely summable</div><div>\item and $k(x, x^\prime) = \sum \lambda_i \phi_i(x) \cdot \phi_i(x^\prime)$ almost everywhere</div>
What's a degenerate kernel?	\item A kernel with only a finite number of nonzero eigenvalues
How are the eigenfunctions of a kernel usually approximated computationally?	\item By approximating the integral that defines them with a sum,&nbsp;<div>\item with the points of the sum being sampled according to the measure</div><div>\item and solving the matrix eigenproblem that results</div>
When training a GP with a SE kernel, what are the hyperparameters?	\item $\sigma_f$, the signal variance<div>\item $\sigma_n$, the noise variance</div><div>\item $M$, the precision matrix of the kernel</div>
What are common forms for the precision matrix of a SE kernel?	\item $\frac{1}{l^2}I$<div>\item $\text{diag}(l^2)^{-2}$</div><div>\item $\Lambda\Lambda^T + \text{diag}(l^2)^{-2}$</div>
What does the characteristic length scale represent?	\item How far you need to move before the function becomes uncorrelated
Why is LOOCV cheap for GPs?	\item Because the expensive part of inverting the kernel only need be done once<div>\item then the inverse-with-a-row-missed-out needed for each LOO case can be computed using block inversion formulae</div>
When visualizing the tensor dot product of two matrices $A, B$ along their row axis, how should you orient the components?	\item As three faces of a cube:<div>\item with the output on the front face</div><div>\item $A$ on the left</div><div>\item $B$ on the top</div><div>\item the axis you're summing over heading away from you</div><div>\item and the origins for $A, B$ in the top-left corner</div>
In an equation such as Y&nbsp;≈ mX + b, what does the&nbsp;≈ refer to?&nbsp;	"""is approximately modeled as""&nbsp;"
Why is the irreducible error for a function in making a prediction almost always greater than zero? 	because you havent measured all of the relevant variables <br />&gt; or because it is unmeasurable, but this is more philisophical IMO 
What is a parametric model? how is a non parametric model different? 	makes an assumption about the functional form of the model and thereby reduces the problem to estimating that functions parameters; makes no assumption about the functional form of the model 
What defines unsupervised statistics, vs supervised statistics? classic example? 	unsupervised refers to when you want to make sense of your measurement variables but lack a response variable to predict; cluster analysis 
define semi-supervised learning	a situation where you have access to response variable measurements for only a subset of the data points<br />&gt; so you have some measurements which are not associated with response variables, but you still want to try to use them to make sense of your data 
As the flexibility in a statistical model increases, what happens to training Mean Squared Error (MSE)? test MSE? 	"monotonic decrease; typically it is a U shaped curve, as it decreases as the function approxs the true model, then once again increases as the model overfits the data <br />&gt; Figure 2.9 from ""An Introduction to Statistical Learning"";&nbsp;http://www-bcf.usc.edu/~gareth/ISL/getbook.html<div><img src=""paste-62289910694898.jpg"" /></div>"
define bias (statistics) 	error that is introduced by approximating a complicated real world problem by a simple model <br />&gt; so typically model underspecification
define variance of a function (statistical modeling) 	the amount that a function would change if you estimated it with a different training data set<div>&gt; higher levels of this cause more generalization error </div><div>&gt; ISL&nbsp;</div>
How does k nearest neighbor classification work? (3 steps)&nbsp;	1) For each data point in the test set, it finds the k nearest points in the training set based on measurement similairty<br />2) It assigns conditional proabilities to each response outcome based on the frequency of each outcome in this set of neighbors<br />3) It chooses the response outcome with the highest probaility as the prediction <br />&gt; ISL&nbsp;
define residual sum of squares (RSS)	in a regression model, the sum of the squared deviations of the predicted from the actual values
"What phenomenon does this plot demonstrate?&nbsp;<div><img src=""paste-5634997092940.jpg"" /></div>"	"<div>a representation of the<i> trade-off</i> between flexibility and interpretability in using different statistical learning methods</div><div>&gt; In general, as the flexibility&nbsp;of a method increases, its interpretability decreases.</div><div>&gt; Figure from ""An Introduction to Statistical Learning"" by James et al;&nbsp;http://www-bcf.usc.edu/~gareth/ISL/getbook.html</div>"
"In these contour plots measuring RSS as a function of two variables on some data set, what do the red dots represent?&nbsp;<div><img src=""paste-3264175145212.jpg"" /></div>"	"the least squares estimates that minimize the RSS&nbsp;<div>&gt; Figure from ""An Introduction to Statistical Learning"";&nbsp;http://www-bcf.usc.edu/~gareth/ISL/getbook.html</div>"
In the context of a multiple regression, how do you interpret the meaning of the Bj regression coefficient where Xj represents the jth predictor variable?&nbsp;	as the average effect on Y of a one unit increase in Xj, <i>holding all other predictors fixed&nbsp;</i><div>&gt; ISL&nbsp;</div>
When you are asking the following question, what is a good model to use?&nbsp;<div>&gt;&nbsp;Do all the predictors help to explain Y, or is only a subset of the&nbsp;predictors useful?</div>	multiple regression&nbsp;<div>&gt; for example, multiple linear regression&nbsp;<div>&gt; ISL chapter 3</div></div>
In a multiple regression, if there are p variables to consider, then how many possible models are there?&nbsp;	2<sup>p</sup>&nbsp;<div>&gt; so 4 (2^2) for 2 variables, and 8 (2^3) for 3 variables</div>
What are the steps for forward model selection in a linear regression? (3 steps)&nbsp;	1) Begin with a null model that contains an intercept but no predictors<div>2) Choose the variable to add to the regression that results in the lowest RSS</div><div>3) Continue until some stopping rule is satisfied</div><div><div>&gt; in backward selection,&nbsp;start with all variables in the model, and backward</div></div><div>&gt; note that this is a <i>greedy</i> approach that might include variables early that later become redundant</div><div>&gt; ISL&nbsp;</div>
<div>In linear regression, what happens to r-squared on the testing data set when more variables are added to the model? why?&nbsp;</div>	<div>it <i>always </i>increases;&nbsp;adding another variable to the least squares equations must allow us to better fit the training data (though&nbsp;not necessarily the testing data) more accurately</div><div>&gt; ISL&nbsp;</div>
Accd to the James textbook, what are the two most important assumptions of a linear regression model?&nbsp;	"1) Linear relationship, i.e. the effect of changing one unit in Xj is constant, irrespective of the value of Xj<div>2) Additive relationship, i.e. the effect of changes in a predictor X on the response Y is independent of the values of the other predictors (vs synergy or an interaction)</div><div>&gt; from ""An Introduction to Statistical Learning"" (ISL); http://www-bcf.usc.edu/~gareth/ISL/getbook.html</div>"
define interaction term (regression)&nbsp;	"describes a situation in which the simultaneous influence of two variables on a third is not additive<div>&gt; W:&nbsp;The notion of ""interaction"" is closely related to that of ""moderation"" that is common in social and health science research: the interaction between an explanatory variable and an environmental variable suggests that the effect of the explanatory variable has been moderated or modified by the environmental variable.</div>"
"What is likely the simplest extension to linear regression, which is seen here?&nbsp;<div><img src=""paste-7499012899095.jpg"" /></div>"	"polynomial regression&nbsp;<div>&gt; still a linear model, so can still be solved using standard multiple linear regression software</div><div>&gt; Figure from ""An Introduction to Statistical Learning""; http://www-bcf.usc.edu/~gareth/ISL/getbook.html</div>"
define studentized residual (regression)	"the result of dividing a residual by its estimated standard error<div>&gt; necessary bc points can have different standard errors so comparing their deviations, eg when looking for outliers, can be perilous ow</div><div>&gt; ISL:&nbsp;Observations whose studentized residuals are greater than 3 in absolute value are possible outliers</div><div>&gt; Figure from ""An Introduction to Statistical Learning""; http://www-bcf.usc.edu/~gareth/ISL/getbook.html</div><div>&gt;&nbsp;<img src=""paste-8877697401123.jpg"" /><br /><div>&gt; W:&nbsp;Typically the standard deviations of residuals in a sample vary greatly from one data point to another even when the errors all have the same standard deviation, particularly in regression analysis; thus it does not make sense to compare residuals at different data points without first studentizing. It is a form of a Student's t-statistic, with the estimate of error varying between points.&nbsp;This is an important technique in the detection of outliers.&nbsp;&nbsp;It is named in honor of William Sealey Gosset, who wrote under the pseudonym Student, and dividing by an estimate of scale is called studentizing, in analogy with standardizing and normalizing: see Studentization.</div></div>"
"In a regression setting, what is the name of the problem with the data set on the right? why is this a problem?&nbsp;<div><img src=""paste-9040906158384.jpg"" /></div>"	"as predictor variables, rating and limit have high <i>collinearity</i>; it can be difficult to separate out the individual&nbsp;effects of highly collinear variables on the response variable<div>&gt; Figure from ""An Introduction to Statistical Learning""; http://www-bcf.usc.edu/~gareth/ISL/getbook.html</div>"
define collinearity&nbsp;	an exact or approximate linear relationship between two explanatory variables<div>&gt; which is considered a problem beacuse it is difficult to separate out the individual&nbsp;effects of highly collinear variables on the response variable</div>
What's the definition of the error in numerical analysis?	\item $e_{(i)} = x_{(i)} - x_*$
What's the definition of the residual in numerical analysis?	\item $r_{(i)} = y_{(i)} - y_*$
What's the quadratic minimization problem associated with solving $Ax = b$ for a symmetric, positive-definite $A$?	\item $\min \frac{1}{2}x^TAx - bx$<div>\item Gradient of the quadratic problem gives the linear system</div>
In the CG method for solving a linear system $Ax = b$, what are two alternative interpretations of the residual?	\item The error transformed into the same space as the steps, $r_{(i)} = -Ae_{(i)}$<div>\item The direction of steepest descent in the quadratic problem, $r_{(i)} = -f^\prime(x_{(i)})$</div>
What're the steps in the Jacobi method for solving a linear system $Ax = b$?	\item Split $A = D+E$, where $D = \text{diag}(A)$<div>\item Then iterate $x = Bx+z$, where</div><div>\item $B = -D^{-1}E$</div><div>\item $z = D^{-1}b$</div>
What's the idea in the Jacobi method for solving a linear system $Ax=b$?	\item Hopefully $B = -D^{-1}E$ will have a smaller spectral radius than $A$, leading to faster convergence
In the Jacobi method for solving a linear system, why does $B$ having a small spectral radius speed convergence?&nbsp;	\item Write $x = x_* + e$<br /><div>\item Then the error updates as $e^\prime = Be$</div><div>\item so the smaller the spectral radius, the faster the error shrinks<br /></div>
Is the Jacobi method guaranteed to converge?	\item Nope.
What're roughers and smoothers in the context of numerical analysis?	\item Smoothers shrink every component of the error at each step<div>\item Roughers only shrink some components</div>
How fast does steepest descent converge in terms of $A$'s condition number?	\item $\frac{\|e_i\|_A}{\|e_0\|_A} \leq \left(\frac{\kappa-1}{\kappa+1}\right)^i$
When are two vectors $x, y$ conjugate with respect to $A$?	\item When $x^TAy = 0$
What's the intuition behind two vectors being conjugate wrt a positive-definite symmetric $A$?	\item $x, y$ are conjugate wrt $A$&nbsp;<div>\item if when the space is rescaled so the ellipses described by $A$ are circles</div><div>\item then $x, y$ are orthogonal</div>
What's the useful property of the search directions chosen in the CG method?	\item The direction $d_i$ at a step $i$ is chosen to be $A$-conjugate wrt the directions chosen previously
What's the property of the optimality of the error term in CG?&nbsp;	\item At step $i$, CG has minimized $\|e_i\|_A$ over the subspace $e_0 + \text{span}(\{d_k\}_k)$&nbsp;
Given a positive definite matrix $A$, what's the definition of the energy norm $\|x\|_A$?	\item $\|x\|_A = \sqrt{\langle A x, x \rangle}$
Intuitively, what's the consequence of how the search direction is generated in CG?	\item $d_i$ is&nbsp;the $i$th residual with the components of all previous search directions removed
What's a Krylov subspace?	\item The direct sum over&nbsp;&nbsp;$0 \leq i &lt; n$ of the subspaces generated by $A^ix$
What's the definition of the step size in CG?	\item $\alpha^\prime = \frac{\|r\|^2}{\|d\|^2_A}$
What's the definition of the the Gram-Schmidt constants generated in CG?	\item $\beta^\prime = \frac{\|r^\prime\|^2}{\|r\|^2}$
What's the definition of the search direction in CG?	\item $d^\prime = r^\prime + \beta^\prime d$
What's the definition of the residual in CG?	\item $r^\prime = r - \alpha A d$
What's the definition of the location $x$ in CG?	\item $x^\prime = x + \alpha d$
What's the convergence rate of CG in terms of the condition number?	\item $\frac{\|e_i\|_A}{\|e_0\|_A} \leq \left(\frac{\sqrt{\kappa}-1}{\sqrt{\kappa}+1}\right)^i$
What's a Boltzmann machine?	\item A pairwise MRF with both hidden and observed nodes
In Galton's height data, parents with height 1 inch above the mean tend to have children with height different from the mean by how many inches? why?&nbsp;	0.66 inches; regression to the mean<br /><div>&gt; from Swirl</div>
In a regression, how do you visually tell how much effect an outlier has?&nbsp;	"by seeing how much the regression line changes when the outlier is included vs when it is not<div>&gt; this is called ""influence"" or ""leverage"" or ""hat""<br /></div><div>&gt; can measure this for a regression via&nbsp;View(hatvalues(fit))</div><div>&gt; Figure from ""An Introduction to Statistical Learning""; http://www-bcf.usc.edu/~gareth/ISL/getbook.html</div><div><img src=""paste-4544075400400.jpg"" /></div>"
"Is this regression diagnostic indicative of a good fit? why?&nbsp;<div><img src=""paste-67418101646516.jpg"" /></div>"	yes; residuals are uncorrelated with the fitted values&nbsp;<div>&gt; and have mean zero and approx iid&nbsp;</div><div>&gt; one of the standard plots when you plot an lmfit object in R via&nbsp;plot(lmobj); this was generated from randomized data&nbsp;</div>
What's the smoothness prior in the context of ML?	\item If you're trying to approximate a function $f$<div>\item it's the idea that if $x$ is close to $x^\prime$</div><div>\item then $f(x)$ is close to $f(x^\prime)$</div>
What's representation learning?	\item Where you learn not only the mapping from some representation to the output, but the representation itself
What's the basic idea in deep learning?	\item That good representations are built from other, simpler representations
What's the `program' view of deep learning?	\item Networks encode a program<div>\item and deep networks can encode programs with longer sequential paths</div>
What's the consequence of the program view of deep learning when interpreting layers' representations?	\item A layer's representation may not always encode the factors of variation that explain the input<div>\item It might encode some program state that's useful in making sense of the input instead</div>
What's capacity in ML?	\item It's the number of examples that the model could always learn perfectly<div>\item Relates to underfitting \&amp; overfitting</div>
Conceptually, how does the information content of an event relate to the likelihood of an event?	\item Likely events should have low information content<div>\item Unlikely events should have high information content</div>
What's the self information of an event $x \sim X$?	\item $I(x) = -\log p_X(x)$
What's a nat in ML?	\item It's the equivalent of a bit, but for base $e$
How's the entropy of a distribution defined in terms of the self-information?	\item $H(X) = \mbb{E}_X[I(x)]$
How does the multinouilli distribution relate to the multinomial distribution?	\item Multinouilli is a multinomial for a single case
What's the definition of the softplus function?	\item $\zeta(x) = \ln (1+\exp(x))$
When measuring the information content of a random variable, what happens when you measure it in different bases?	\item The result is rescaled
Given a scalar $x$, what does $x^+$ denote in deep learning?	\item $x^+ = \max(0, x)$
How can the Hessian be defined in terms of the Jacobian?	\item The Hessian is the Jacobian of the gradient
What's the Lagrangian equivalent to minimizing $f$ subject to $g(x) = 0, h(x) \leq 0$, where $g, h$ are vectors of functions?	\item $L(x, \lambda, \alpha) = f(x) + \lambda \cdot g(x) + \alpha \cdot h(x)$<div>\item $\min_x \max_\lambda \max_{\alpha \geq 0} L(x, \lambda, \alpha)$<br /><div><br /></div></div>
What does the Lagrangian of an optimization problem evaluate to at a $x$ where the constraints are all satisfied?	\item $\max_\lambda \max_{\alpha \geq 0} L(x, \lambda, \alpha) = f(x)$<div>\item because the $g$ associated with $\lambda$ are all $g(x) = 0$</div><div>\item and the $h$ associated with $\alpha$ are all $h(x) \leq 0$</div>
What does the Lagrangian $L(x, \lambda, \alpha)$ of an optimization problem evaluate to at a $x$ where one of the constraints is violated?	\item $\max_\lambda \max_{\alpha \geq 0} L(x, \lambda, \alpha) = \infty$<div>\item because one of the $g$ associated with $\lambda$ is nonzero</div><div>\item or one of the $h$ associated with $\alpha$ is positive</div>
What are the Karush-Kuhn-Tucker conditions?	\item $\nabla L(x^*, \lambda^*, \alpha^*) = 0$<div>\item Constraints are all satisfied at $x^*$</div><div>\item $\alpha \cdot h(x^*) = 0$</div><div><br /></div>
What's the use of the Karush-Kuhn-Tucker conditions?	\item They're first-order necessary conditions for a point to be an optima of a constrained problem
What's KKT stand for in optimization?	\item Karush-Kuhn-Tucker conditions
What's anomaly detection in ML?	\item A task identifying inputs that are not like the others
What's active learning?	\item A type of learning where the model can request specific additional training examples
What's the intuitive interpretation of regularization?	\item It's an imposition of a preferred set of functions<div>\item which is why it's often exchangeable with some prior distribution&nbsp;</div>
What's the definition of the VC dimension of a model?	\item It's the cardinality of the largest set of points that the model can shatter
What's it mean for a model to shatter a dataset?	\item It means that for every assignment of labels to the points in the dataset<div>\item some setting of the model parameters will lead to perfect classification</div>
What's optimism in ML?	\item $\text{generalization error}&nbsp;- \text{training error}$
How can underfitting be diagnosed in terms of capacity?	\item If generalization error drops when the capacity of the model increases<div>\item then the model is underfitting</div>
What's the use of the VC dimension?	\item It's a measure of a model's capacity
What's the theoretical prediction of how optimism responds to changes in capacity?	\item $\text{Optimism} \propto \frac{\text{capacity}}{\text{training set size}}$
What are three typical interpretations of a `simple representation' in ML?	\item Low-dimensional<div>\item Sparse</div><div>\item Independent</div>
Which are the most common examples of ML models that exploit the smoothness prior?	\item Kernel methods
When do smoothness-prior-based models work well?	\item When the data covers the variations in the target function
What's the key idea to nonlocal generalization in ML?	\item $O(N)$ samples can define $O(2^N)$ regions as long as dependencies are allowed between regions
What's a maxout unit in NNs?	\item It's a nonlinear function<div>\item $\max_i(w_i x)$</div>
How's the softplus relate to the ReLU?	\item The softplus is a smoothed version of the ReLU
What's lateral inhibition in the context of NNs?	\item Excited biological neurons often inhibit their neighbours
What're the two usual artificial equivalents of lateral inhibition?	\item Softmax layers and similar `competitive' functions<div>\item Local response normalization</div>
How can neural networks be trained to mimic a conditional distribution?	\item Let $P(Y|f(X))$ be a conditional distribution of the class labels<div>\item Then get the neural network to learn $f$, using the NLL as the loss function</div>
What are the three kinds of optimization method typically used for training NNs?	\item SGD variants on small minibatches<div>\item Second-order methods on large minibatches</div><div>\item Natural gradient methods</div>
What's the minimum depth needed for a neural network to be a universal approximator?	\item 2. One hidden layer and one output layer.
Which of smooth and rectifying nonlinearities generally give better image classification performance when used in NNs?	\item Rectifying nonlinearities
What're the advantages of ReLU nonlinearities over smooth ones in NNs?	\item Smooth nonlinearities tend to saturate \&amp; discard information, hindering both forward \&amp; backpropagation&nbsp;<div>\item Backpropagation with ReLUs is piecewise linear</div><div>\item Changes in parameters result in a linear change in the network's activity until the point it causes some ReLU&nbsp;to change pieces</div>
What're the problems with ReLU nonlinearities compared to smooth nonlinearities?	\item They can't learn via gradient methods on examples where their activation is zero
What's an alternative to ReLU nonlinearity that doesn't suffer the no-training problem?	\item Maxout units<div>\item Each piece of the maxout response has its own weight vector, so it can always learn</div>
What are the main types of difficulty with gradient optimization of NNs?	\item Local minima<div>\item Saddle points<br /><div>\item Plateaus/vanishing gradients</div><div>\item Cliffs/exploding gradients</div></div>
How do gradient-based optimizers for NNs usually deal with exploding gradients?	\item By limiting the size of the step that can be taken
Why are the gradients at the output of a deep NN typically very large or very small?	\item Because the Jacobian of each layer is $DW$, where $W$ is the weights matrix and $D$ are the derivatives of the nonlinearity<div>\item Successive layers are likely to have similar Jacobians, so by the final layer some eigenvectors will be far larger than others</div>
As a rule of thumb, to avoid overfitting how many examples are needed per parameter in a model?	\item Ten examples per parameter
What's an energy-based model in ML?	\item A MRF whose overall probability distribution can be written as $p(x) = \frac{1}{Z}\exp(-E(x))$
Why is the choice of domain from which values are drawn so important when analyzing MRFs?	\item Because it can determine whether the partition function exists.<div>\item Example: a MRF with potentials $\exp(b_ix_i)$ is well-defined when $x_i &nbsp;\in \{0,1\}$, but not when $x_i \in \mbb{R}$</div>
What's harmony in ML?	\item Another name for the negative energy
What does `d-separation' stand for?	\item Dependence separation
What's a harmonium in ML?	\item Another name for an RBM
What are the two categories of autoencoders?	\item Undercomplete, where the bottleneck is enforced through architecture<div>\item Overcomplete, where the bottleneck is enforced through regularization</div>
What's a contractive autoencoder?	\item One where $\left\| \frac{\partial h}{\partial x} \right\|^2$ is penalised<div>\item which encourages only a few hidden units to take part in encoding local changes to $x$</div>
In terms of its derivative, what's a contractive function?	\item One where $\|f^\prime(x)\| &lt; 1$ everywhere
What are denoising autoencoders strongly related to?	\item Contractive autoencoders
What's a stochastic autoencoder?	\item An autoencoder where the variables are assumed to be taken from CRDs:<div>\item $h \sim Q(h|x)$ is the encoding distribution</div><div>\item $x \sim P(x|h)$ is the decoding distribution</div>
What's greedy unsupervised pre-training for NNs?	\item Given the outputs of a network<div>\item train a one-layer autoencoder to reproduce the output of the network</div><div>\item then stack the autoencoder on top of the existing network and repeat</div>
What are the two most popular interpretations of the effect of unsupervised pre-training?	\item As a form of parameter initialization<div>\item As a regularization strategy</div>
Why is pre-training called pre-training?	\item Because it's expected that once the pretraining is done and the full network is constructed<div>\item the network will be fine-tuned for a specific problem using traditional supervised approaches</div>
What's concept drift?	\item When gradual changes in the input distribution occur over time
What's zero shot learning?	\item A kind of transfer learning where structure learnt on one domain $X$ is `mapped onto' another domain $Y$&nbsp;<div>\item and used to solve tasks for which no training data has been provided</div>
What's multi-modal learning?	\item A transfer learning variant where the representations of related domains $X, Y$ are learnt, as well as the map between those concepts
What's a feature map in the context of a convolution?	\item The output of the convolution
What's the form of the matrix corresponding to a 2D convolution?&nbsp;	\item A doubly-block circulant matrix
When are functions $f, g$ equivariant?	\item When $f \circ g = g \circ f$
What's the equivariance property of convolution?	\item It's equivariant wrt translation
What's the prior convolution enforces on the function learnt by a layer?	\item The function must be local and equivariant wrt small translations
What are the three typical stages in a convolution layer?&nbsp;	\item Convolution<div>\item Detection<br />\item Pooling</div>
What's the detection stage in a convolution layer?	\item The application of an activation function
What are some typical pooling functions in NNs?	\item Max<div>\item Average</div><div>\item Distance-from-center weighted average</div><div>\item L2 norm</div>
What's the prior that a pooling layer enforces on the function the layer learns?	\item The function should be invariant wrt the transformations the inputs to the pooling layer represent<br />
How can pooling be used to induce invariance to some general transformation?	\item By pooling over separately-parameterized convolutions<div>\item ie pooling over convolutions that respond to different rotations of an object would induce invariance wrt rotation</div>
How is pooling usually combined with downsampling?	\item If the pooling is over a width $k$ window, then often only $n_\text{previous}/k$ pooling nodes are needed
How are pooling layers usually used to accomodate varying input sizes?	\item By fixing the number of pooling nodes, irrespective of how large the previous layer was
What's the main advantage of convolution over correlation?	\item Convolution is commutative<div>\item This is much more useful in theory work than in practice, where correlation is often called convolution</div>
What's the stride of a convolution?	\item The distance between the centers of the receptive fields of neighbouring neurons
What's a same convoluton?	\item Adding enough zeros to each edge of the input to prevent convolution from shrinking it<br />
What's a valid convolution?	\item One that doesn't zero-pad the input, causing the output to shrink
What's a full convolution?	\item Where enough zeros are added to each edge of the input that each pixel will appear in each position within the kernel&nbsp;
Between valid, same and full convolutions, which amount of padding usually performs best?	\item Some amount of padding between valid and same
When do locally connected layers have an advantage over convolution layers?	\item When the feature to be learnt is local, but has no reason to occur across the whole input space
What's a tiled convolution layer?	\item One where the kernel used in the convolution cycles as you move through the input
When are tiled convolution layers usually used?	\item When you need a compromise between straight convolution and a locally-connected layer
What three operations need to be implemented for a convolutional layer in a NN?	\item Convolution<div>\item Backprop from outputs to weights</div><div>\item Backprop from outputs to inputs</div>
Why do convolution layers sometimes allow the bias to vary across the image?	\item Because it allows the model to account for differences in image statistics across the image<div>\item for example, detectors at the edge receive less total input so should get larger biases</div>
What's a seperable kernel?	\item A kernel which can be written as the outer product of some lower-dimensional kernels<br />
What's the traditional approach to manifold learning?	\item Construct a nearest neighbour graph from the samples and use each neighbourhood to approximate the tangent plane at that point on the manifold
What's the problem with the traditional approach to manifold learning?	\item If the manifold has strong curvature, you need a lot of examples to cover it well<div>\item and if you don't, you can't reason about parts of the manifold that haven't been covered&nbsp;</div>
When do manifolds in ML tend to have high curvature?	\item When transformations that we consider trivial significantly change many coordinates<div>\item ie translation of an image&nbsp;</div>
What's the relation between autoencoders and manifold learning?	\item An autoencoder effectively tries to learn to be very sensitive to changes along the manifold, which minimizes reconstruction error<div>\item but insensitive to changes orthogonal to the manifold, which minimizes the regularization penalty</div>
What's the probabilistic interpretation of the loss function of an autoencoder?	\item The loss function should represent the negative log-likelihood of the reconstruction,&nbsp;<div>\item $L(x) = -\ln p(x|(\text{dec}\circ \text{enc})(x))$</div>
How are denoising autoencoders implemented?	\item By corrupting the input, passing it to an autoencoder, and asking it to reconstruct the uncorrupted input
What's the vector field of interest associated with a denoising autoencoder?	\item $(\text{dec} \circ \text{enc})(x) - x$<div>\item which approximates $\frac{\partial \ln Q(x)}{\partial x}$, where $Q$ is the data generating distribution</div>
How can denoising autoencoders be used to approximate the data generation distribution?	\item By turning them into a Markov chain:<div>\item Corrupt the current step, then encode/decode it to get the next step.</div>
What's the practical advantage of using ReLU units over traditional nonlinearities?	\item Training is much faster
Where are LRN layers most commonly used?	\item Following detector layers like ReLUs
Why do traditional NN nonlinearities require that their input be normalized?	\item Because if it isn't, the nonlinearities are likely to saturate
In NNs, what's the advantage to having the neighbourhoods for a pooling layer overlap?	\item It can help reduce overfitting
How are variable-sized image inputs typically adapted to fixed-size NNs?	\item By scaling along one axis then cropping along the other
When enlarging a NN training set by transforming natural input, what are the usual transformations?	\item Extract patches from the image<div>\item Mirror them horizontally</div><div>\item Find the principle RGB components across the set and add small random multiples of them to the image</div>
What's the idea behind the RGB-PCA image corruption technique?	\item Object identity is invariant to changes in intensity and color
What happens in NN dropout?	\item Suppress the output of each neuron with probability $\approx 0.5$ during training,<div>\item ignoring it during both the forward and backward pass</div><div>\item Then at test time, multiply all neuron outputs by $0.5$</div>
What's the purpose of&nbsp;using NN dropout?	\item It prevents neurons from relying on the presence of other neurons, forcing more robust features to be learnt
What's the effect of dropout on training time?	\item Roughly doubles it
What's the use in having different channels in a convolutional layer of a CNN?	\item Different channels can learn different functions of the input
How should NN layers using ReLUs be initialized?	\item With positive biases<br /><div>\item which ensures that that ReLU neurons will learn from the beginning</div>
When working with documents, what does $y_{il}$ usually denote?	\item The identity of the $l$th word in document $i$
When working with documents in ML, what does $V$ denote?	\item The size of the vocabulary
When working with documents in ML, what does $n_{iv}$ usually denote?	\item The number of times word $v$ appears in document $i$
When working with documents in ML, what does $L_i$ usually denote?	\item The length of document $i$
When working with documents in ML, what does $R$ typically denote?	\item The number of channels/responses
In a mixture model for documents, what're topics?	\item The latent cluster-identification variable $q_i$
What's latent semantic analysis?	\item Applying PCA to a token-count design matrix
What's the model used in exponential family PCA?	\item A discrete model of the form<div>\item $y_{il} \sim \text{Cat}(\mc{S}(Wz_i)), z_i \sim \mc{N}(\mu, \Sigma)$</div><div>\item or similarly for multinomial or Poisson distributions&nbsp;</div>
What's the usual use of ePCA techniques?	\item Simple alternative to mixture models for modelling documents
What's ePCA stand for in ML?	\item Exponential family PCA
What's the model used in multinomial PCA?	\item $n_i|\pi_i \sim \text{Mu}(L_i, B\pi_i)$<div>\item $\pi_i \sim \text{Dir}(\alpha)$</div><div>\item where $B$ is a left-stochastic matrix</div>
What's the model used in latent Dirichlet allocation?	\item $y_{il}|q_{il} = k, b_k \sim \text{Cat}(b_k)$<div>\item $q_{il} \sim \text{Cat}(\pi_i)$</div><div>\item $\pi_i \sim \text{Dir}(\alpha 1_K)$</div>\item $b_k \sim \text{Dir}(\gamma 1_V)$&nbsp;<div>\item where $q_{il}$ is the topic for word $y_{il}$</div>
What's the main advantage of LDA over latent semantic analysis?	\item The latent quantities $\pi_{ik}$ are nonnegative and sum to 1, making them much easier to interpret
What's the distribution used in the GaP model?	\item $n_{iv}|z^+_i \sim \text{Poi}(b_v \cdot z_i^+)$<div>\item $z^+_{ik} \sim \text{Ga}(\alpha_k, \beta_k)$</div>
What's the use of the GaP model?	\item To model documents whose length is not known
What does mPCA stand for in ML?	\item Multinomial PCA
What prior is often put on the matrix $B$ in LDA?	\item $\bar b_k \sim \text{Dir}(\gamma1_V)$<br />
What's the topic interpretation of LDA?	\item Every word $l$ in document $i$ is assigned a topic $q_{il} \in \{1, \dotsc, K\}$<div>\item and these topics are drawn from a document-specific distribution $\pi_i$</div>
What's the geometric interpretation of LDA?	\item Documents are represented by a convex combination of topics<div>\item So LDA projects the $V$-simplex of document count vectors onto the $K$-simplex of topics</div>
How can LDA be used to infer the meaning of a word?	\item By fitting an LDA model then finding the topic $k$ which maximizes $p(q_{il} = k|y_i, \theta)$<br /><div>\item The topic distribution $\pi_i$ that has been chosen for document $i$ helps disambiguate $q_{il}$</div>
What's labelled LDA?	\item Vanilla LDA has a problem with unidentifiability<div>\item which labelled LDA fixes by forcing the topics to correspond to ground truth tags</div>
What's the perplexity of two distributions?	\item $\text{perplexity}(p,q) = 2^{\mbb{H}(p,q)}$
What's the cross entropy between two stochastic processes?	\item $H(p,q) = \lim_{N\rightarrow \infty} -\frac{1}{N}\sum_{y_{1:N}} p(y_{1:N})\ln q(y_{1:N})$
What's the perplexity of $p$ against the empirical distribution?	\item $\text{perplexity}(p_\text{emp}, q) = \exp\left( - \frac{1}{N} \sum \ln q(y_i | y_{1:i-1}) \right)$<br />
What's the perplexity of a uniformly random distribution $U$ against the empirical distribution?	\item $\text{perplexity}(p_\text{emp}, U) = V$<div>\item where $V$ is the number of tokens</div>
What's the intuitive interpretation of the perplexity?	\item It's the probabilistically-weighted average `branching factor' of the model's predictive distribution<div>\item If some symbols are (correctly) predicted to be more likely than others, the perplexity drops</div>
What's the range of the perplexity vs the empirical distribution?	\item $H(p_\text{emp}) \leq \text{perplexity}(p_\text{emp}, q) \leq V$<br />
Which variables are usually collapsed in a Gibbs sampler for LDA?	\item Everything but the topics $q_{il}$
How is the performance of language models usually evaluated?	\item Perplexity vs the empirical distribution
How is a latent Dirichlet analysis model usually fit?	\item Collapsed Gibbs sampling<div>\item Variational EM&nbsp;</div>
How is the number of topics $K$ in a LDA model usually determined?	\item By model selection techniques;<div>\item Annealed importance sampling</div><div>\item Cross validation</div><div>\item Variational lower bound on the evidence</div>
What's the correlated topic model?	\item LDA but with<div>\item $\pi_i | z_i = \mc{S}(z_i)$</div><div>\item $z_i \sim&nbsp;&nbsp;\mc{N}(\mu, \Sigma)$</div>
What's the difference between the correlated topic model and categorical PCA?	\item CTM: $y_{il} \sim \text{Cat}(B\mc{S}(z_i))$<div>\item catPCA: $y_{il} \sim \text{Cat}(\mc{S}(Wz_i))$</div>
What's the advantage of the correlated topic model over LDA?	\item LDA has trouble with topics which are strongly correlated<div>\item like the `business' and `finance' topics</div>
How can you visualize a correlated topic model?	\item By sparsifying the precision matrix $\Sigma^{-1}$ and interpreting it as a Gaussian graphical model
What's the model used in a dynamic topic model?	\item The same as a LDA but with the weights at time $t$ being<div>\item $b^t_k|b^{t-1}_k \sim \mc{N}(b^t_{k-1}, \sigma^2 1_V)$</div><div>\item $y^t_{il}|q^t_{il} = k, b^t_k \sim \text{Cat}(\mc{S}(b^t_k))$</div>
What's the use of a dynamic topic model?	\item It allows the distributions of words in each topic to evolve over time
What's the structure used in LDA-HMM?	\item For each document, create a HMM model with states $z_{il} \in \{1, \dotsc, C\}$ to represent syntax<div>\item&nbsp;and a LDA model to represent semantics</div><div>\item If $z_{il} = 0$ then generate word $y_{il}$ using the LDA</div><div>\item else generate it from the HMM</div>
What's the advantage of the LDA-HMM over LDA?	\item It helps prevent the LDA from being polluted by stop words<div>\item and can help distinguish when a word is being used syntactically or semantically</div>
What's the model used in supervised LDA?	\item LDA with the class labels generated by<div>\item $c_i | \bar{q}_i \sim \text{Ber}(\text{sigm}(w^T\bar{q}_i))$</div><div>\item where $\bar{q}_{ik} = \frac{1}{L_i} \sum q_{ilk}$ is the empirical topic distribution for document $i$</div>
What's the problem that supervised LDA aims to solve?	\item Predicting class labels $c_i$ for documents via their topic distribution<div>\item as in sentiment analysis</div>
What's the model used in discriminative LDA?	\item Same as LDA except the topic prior is label-dependent:<div>\item $q_{il}| c_i = c, \pi_i, A_c \sim \text{Cat}(A_c \pi)$</div>
What's the difference between discriminative and supervised LDA?	\item They solve the same problem but one is generative while the other is discriminative
What's a conditional topic random field?	\item Similar to LDA but with the topic variables $q_{il}$ drawn from a conditional MRF<br />
Which model does a conditional topic random field extend?	\item A correlated topic model
What's the model used in Dirichlet multinomial regression LDA?	\item Similar to LDA but with<div>\item $\pi_i \sim \text{Dir}(\text{exp}(Wx_i))$</div>
What's the use of&nbsp;Dirichlet multinomial regression LDA?	\item It allows the topic distribution for a document to depend on some tag input $x_i$
What's the model used in discriminative categorical PCA?	\item $y_{il}|z_i \sim \text{Cat}(\mc{S}(Wz_i))$<div>\item $z_i|x_i \sim \mc{N}(Vx_i, \Sigma)$</div><div>\item ie a NN with one hidden layer and categorical outputs</div>
What's the model used in the stochatic block model?	<div>\item $R_{ij}|q_i = a, q_j = b \sim \text{Ber}(\eta_{ab})$</div>\item $q_i \sim \text{Cat}(\pi)$
In LVMs for graph-structured data, what do $q_i$ denote?	\item The latent variable (like a block) associated with node $i$
In LVMs for graph-structured data, what do $R_{ij}$ denote?	\item Whether edge $ij$ exists
What's the difference between the clustering induced by a stochastic block model and traditional communities?	\item Clusters in a SBM are formed of nodes that connect to similar nodes,<div>\item rather than from nodes which connect to eachother</div>
What's the use of stochastic block models?	\item They're generative models of block-structured graphs
What's the intuitive purpose of a mixed-membership stochastic block model?	\item It's a SBM with the block membership variables $q_i$ replaced by $\pi_i \in S_K$<div>\item allowing different components of a node's behaviour to be explained by different blocks</div>
What's the model used in a mixed-membership stochastic block model?	\item $R_{ij}|q_{ij}=a, q_{ji}=b \sim \text{Ber}(\eta_{ab})$<div>\item $q_{ij} \sim \text{Cat}(\pi_i)$</div><div>\item $\pi_i \sim \text{Dir}(\alpha)$</div>
What's the model used in the relational topic model?	<div>\item It's similar to supervised LDA but with&nbsp;</div>\item $R_{ij} | \bar{q}_i, \bar{q}_j \sim \text{Ber}(\text{sigm}(w^T(\bar{q}_i \otimes \bar{q}_j) + w_0))$<div>\item where $\bar{q}_i$ is the empirical topic distribution of document $i$</div>
What's the empirical topic distribution of a document?	\item&nbsp;$\bar{q}_{ik} = \frac{1}{L_i}\sum q_{ilk}$
What's the use of the relational topic model?	\item If each node in a graph has a document associated with it<div>\item the RTM creates edges between documents that share topics</div>
What's the advantage of the relational topic model over fitting an LDA then applying logistic regression to the empirical topic distributions?	\item RTM learns a latent space that's encouraged to be predictive of the graph's structure
What's the model used in the infinite relational model?	\item Give each item $i$ of type $t$ a latent variable $q^t_i \in \{1, \dotsc, K_t\}$. Then items $i_1$ through $i_m$ form a $m$-ary relation iff<div>\item $R_{i_1:i_m}|q^{t_1}_{i_1}, \dotsc,&nbsp;q^{t_m}_{i_m}&nbsp;\sim \text{Ber}(\eta_{i_1:i_m})$</div><div>\item $q^{t}_{i} \sim \text{DP}(\alpha_t, H_t)$</div>
Intuitively, what's an onotology?	\item An organisation of knowledge
How's an infinite relational model compare to a stochastic block model?	\item It generalizes a SBM from dyadic relations to $m$-adic relations<br />
How can an infinite relational model be used to learn an ontology?	<div>\item $R \colon T^\text{concepts} \times T^\text{concepts} \times T^\text{binary predicates} \rightarrow \{0,1\}$&nbsp;</div><div>\item describes when a predicate applies to a pair of concepts, and can be generated by an IRM</div>
How does the infinite relational model relate to biclustering?	<div>\item If the features are binary, then</div>\item $R \colon T^\text{items} \times T^\text{features} \times T^\text{clusters} \rightarrow \{0, 1\}$<div>\item can be generated by an IRM</div>
What's an IRM in ML?	\item Infinite relational model
What's the collaborative filtering problem?	\item Given a sparse matrix $R$ where $R_{ij}$ is the rating user $i$ gave to movie $j$<div>\item predict the blank entries of this matrix</div>
What's the model used in probabilistic matrix factorization?	<div>\item Approximate $R = UV$ as&nbsp;</div>\item $R_{ij}|u_i, v_j \sim \mc{N}(u_i \cdot \bar{v}_j, \sigma^2)$<div>\item $u_i \sim \mc{N}(\mu_u, \Sigma_u)$</div><div>\item $\bar{v}_j \sim \mc{N}(\mu_v, \Sigma_v)$</div>
What's PMF in ML?	<div>\item Probability mass function</div>\item Probabilistic matrix factorization
What was the most successful technique used in the Netflix ratings challenge?	\item Modelling ratings as a Gaussian variable and applying probabilistic matrix factorization
How does probabilistic matrix factorization relate to SVD?	\item PMF is equivalent to SVD if the data is complete
What's an impression log in ML?	\item It's side-information about the set of options displayed to a user
What's a restricted Boltzmann machine?	\item An RBM with its nodes arranged into a hidden and a visible layer<div>\item with no intralayer connections</div>
What's the product-of-experts interpretation of an RBM?	\item The potential function on each edge enforces an expert constraint<div>\item and taking their product creates `sharp' distributions which predict data that satisfy the constraint</div>
What's a localist encoding in ML?	\item One where a single hidden variable is used to generate the response vector
What's a distributed encoding in ML?	\item One where many hidden variables are used to generate the response vector
What's the advantage of RBMs over two-layer DGMs?	\item The hidden variables are conditionally independent given the visible variables<div>\item so the posterior of their states factorizes</div>
What's the problem with RBMs compared to two-layer DGMs?	\item RBMs are much harder to train
What are the most common kinds of RBM?	<div>\item Almost all have binary hidden variables and one of</div>\item binary visible variables<div>\item categorical&nbsp;visible variables</div><div>\item Gaussian&nbsp;visible variables</div>
What's the energy function for a binary-variable RBM?	\item $E(v, h) = -\langle v, Wh \rangle$
What's the posterior distribution for the hidden variables of a binary RBM?	\item A product of Bernouillis with mean<div>\item $\mbb{E}[h|v] = \text{sigm}(W^Tv)$</div>
In an binary-variable RBM, what are the generative and recognition weights?	\item $W$ are the generative weights<div>\item $W^T$ are the recognition weights</div>
What's the generative distribution for the visible variables of a binary RBM given the hidden variables?	\item A product of Bernouillis with mean<div>\item $\mbb{E}[v|h] = \text{sigm}(Wh)$</div>
Intuitively, when does a hidden node $h_k$ in a binary RBM activate?	\item When the inputs $v$ look like $\bar{w}_k$
What happens if you give an RBM Gaussian visible units \emph{and} hidden units?	\item You get a factor analysis model.
What's the gradient of the log likelihood for RBMs?	\item $\nabla_w l = \mbb{E}_{p_\text{emp}}[vh^t] - \mbb{E}_p[vh^t]$
What're the clamped and unclamped phases in the gradient of an RBM?	\item $\mbb{E}_{p_\text{emp}}[vh^t]$ is the clamped phase, since $v$ is held to the empirical distribution<div>\item $\mbb{E}_p[vh^t]$ is the unclamped phase, since $v$ is free</div>
How is Gibbs sampling conducted for an RBM?	\item Initialize the visible nodes to a data vector<div>\item Then repeatedly alternate between sampling $p(h|v)$ and $p(v|h)$</div>
What's the contrastive divergence algorithm?	\item It's SGD for RBMs<div>\item but with the unclamped phase of the gradient approximated using $K$ Gibbs sampling steps, for some small $K$&nbsp;</div>
What's persistant CD?	\item A variant of contrastive divergence that resembles SML for maxent models<br /><div>\item and improves the performance of CD's Gibbs sampling</div>
What's CD in ML?	\item Contrastive divergence
What's the replicated softmax model?	\item It's a categorical RBM for a bag-of-words document model
What's the problem with deep directed networks?	\item Inference is intractable because the hidden nodes are correlated due to explaining away
What's the problem with deep Boltzmann machines?	\item The partition function means training them is hard
What's a deep belief network?	\item A layered network which is directed in the bottom layers but undirected in the top layers
How should the partition of undirected/directed layers be interpreted in a DeeBN?	\item Undirected layers form an associative memory<div>\item Directed layers generate the output</div>
What's a complementary prior?	\item A complimentary prior for a likelihood<div>\item is one such that the posterior is fully factorized posterior</div>
What's the connection between RBMs and DeeBNs?	\item If you have a DeeBN with layers $v, h_1, h_2$<div>\item with weights $W_1, W_1^T$</div><div>\item then $h_1, v$ are distributed as a RBM</div>
What's the connection between complimentary priors and DeeBNs?	\item If you have a DeeBN with layers $v, h_1, h_2$<div>\item with weights $W_1, W_1^T$</div><div>\item then $h_1, v$ are distributed as a RBM, which implies $p(h_1|v)$ is fully factorized</div><div>\item So the undirected network between $h_1, h_2$ forms a complimentary prior for the directed network $v, h_1$</div>
What's the greedy layerwise algorithm for DeeBNs?	\item Given a visible layer $v_1$, fit a one-hidden-layer RBM $(v_1, h_1)$ with weights $W_1$<div>\item Approximate $v_2 = \mbb{E}[h_1|v_1, W_1]$</div><div>\item Convert $(v_1, h_1)$ to a directed network and repeat the process with $v_2$</div>
What's the up-down procedure?	\item Having constructed a DeeBN using greedy layerwise training,&nbsp;fine-tune it by<div>\item doing an upwards sampling pass</div><div>\item do a CD update to the top-level RBM parameters</div><div>\item do a downwards ancestral sampling pass</div><div>\item do a gradient-descent update to the directed network parameters</div>
What's the problem with the up-down procedure?	\item It's very slow
What's backfitting in ML?	\item Another name for the up-down procedure
What's the main advantage of probabilistic models compared to DNNs?	\item Probabilistic models are (usually) able to do top-down inference, which is useful when trying to interpret the signal
What's generative pre-training?	\item Initializing a DNN by training it as an auto-encoder
What's the useful effect of generative pre-training?	\item It's like a data-induced regularizer<div>\item and helps the backpropagation fine-tuning stage find minima with good generalization properties</div>
What's semantic hashing?	\item Train a deep auto-encoder with a binary code layer<div>\item then interpret the code layer as a hash for the input</div><div>\item So semantically similar items will have similar hashes, and a hash-table can be precomputed for fast use at search time&nbsp;</div>
What's one of the problems with pooling layers?	\item They throw away a lot of information, making top-down passes difficult
What's the signal-to-symbol divide?	\item The problem of converting a signal to a symbolic representation that can be manipulated and composited
define boosting (ML)&nbsp;	an ensemble ML method that builds the next classifier on the residuals of the former<div>&gt; thereby (in theory) gradually increasing accuracy by highlighting more and more subtle interactions for reducing bias in supervised machine learning</div><div>&gt;&nbsp;http://stats.stackexchange.com/questions/19224/combining-machine-learning-models</div>
What's lemmatization in NLP?	\item The transformation of a word to some base or canonical form
What's the difference between lemmatization and stemming in NLP?	\item A lemmatizer usually has some context about how a word was used, allowing it to discriminate between senses
What's a sense in NLP?	\item A way in which a word can be interpreted
What's chunking in NLP?	\item Breaking text up into phrases<div>\item ex: recognising `the Wall Street Journal' as a single noun phrase</div>
What's shallow parsing in NLP?	\item Another name for chunking
What's semantic role labelling in NLP?	\item Identifying the predicates of a sentance and their arguments<div>\item ex: given `Mary sold the book to John', identify `to sell' as the predicate, `Mary' as the seller, `the book' as the goods, and `John' as the buyer.</div>
What's named-entity recognition?	\item The NLP problem of extracting identifiers corresponding to people, organizations, etc from text
What's an unfolding recursive autoencoder?	\item The input (like a sentence) is structured as a binary tree<div>\item The encoding for each node is created from the encodings of its children<br /><div>\item and the objective is to reconstruct the contents of the tree using only its encoded root</div></div>
What's the shortcut for running a cell and jumping to the next cell in IPyNB?	\item Shift-enter
What's the shortcut for running a cell and keeping the cursor where it is in IPyNB?	\item Ctrl-enter
What's the shortcut for running a cell and creating a new cell below in IPyNB?	\item Alt-enter
How do you interrupt a computation in IPyNB?	\item \ttt{i} twice in command mode
How do you switch from edit to command mode in IPyNB?	\item Esc&nbsp;<div>\item Ctrl-m<br /></div>
How do you select the previous \&amp; next cells in IPyNB?	\item \ttt{k, j} in command mode
How do you move a cell up or down in IPyNB?	\item \ttt{Ctrl-k, Ctrl-j} in command mode
How do you create a cell above or below in IPyNB?	\item \ttt{a,b} in command mode
How do you merge two cells in IPyNB?	\item \ttt{Ctrl-m} on the top cell while in command mode
How do you split a cell in IPyNB?	\item \ttt{Ctrl-shift--} while in edit mode
How do you copy a cell in IPyNB?	\item \ttt{c} while in command mode
How do you paste a cell above or below the current cell in IPyNB?	\item \ttt{Shift-v, v}
How do you get a tooltip in IPyNB?	\item \ttt{Shift-tab}
How do you indent or unindent in IPyNB?	\item \ttt{Cmd-], Cmd-[}
How do you toggle output scrolling in IPyNB?	\item \ttt{Shift-o}
How do you restart the kernel in IPyNB?	\item \ttt{0} twice in command mode
What are the two ways to initialize BeautifulSoup?	\item \ttt{BeautifulSoup(html\_str)}<div>\item \ttt{BeautifulSoup(file\_handle)}</div>
What are the four types of objects most commonly found in BS's parse tree?	\item Tag<div>\item NavigableString</div><div>\item BeautifulSoup</div><div>\item Comment</div>
Given a tag object in BS, how do you get the kind of tag it is?	\item \ttt{tag.name}
Given a tag object in BS, how do you get the value of one of it's attributes?	\item \ttt{tag['attrname']}
How do you modify the attributes of a tag in BS?	\item By treating the tag object as a dictionary
How does BS represent multi-valued attributes?	\item As lists of strings
How do you get the text contents of a tag in BS?	\item \ttt{tag.string}
How do you change the text content of a BS tag?	\item \ttt{tag.string.replace\_with(new\_str)}
How do you get a Python string from a BS NavigableString?	\item \ttt{unicode(str)}
Why should you always apply \ttt{unicode} to the text content of a BS tag to a Python string before exporting it to another part of the program?	\item Because otherwise the \ttt{NavigableString} will carry a reference to the entire parse tree out with it
How's the \ttt{BeautifulSoup} object act in BS?	\item Like a tag, but without a name or attributes
How can you access the first child of a given name in BS?	\item \ttt{t.tag\_name}
How do you get a list of all the children of a tag in BS?	\item \ttt{tag.contents}
How do you get an enumerator over the children of a tag in BS?	\item \ttt{tag.children}
How do you enumerate all the descendents of a tag in BS?	\item \ttt{tag.descendents}
What's \ttt{tag.string} give you in BS?	\item If \ttt{tag} has a single child which is a navigable string, it gives you that string<div>\item If \ttt{tag} has a single child which has a \ttt{.string}, it gives you that string</div><div>\item Else it gives you \ttt{None}</div>
How do \ttt{\_\_repr\_\_} and \ttt{\_\_str\_\_} compare in Python?	\item&nbsp;\ttt{\_\_repr\_\_} is meant to unambiguously describe an object<div>\item \ttt{\_\_str\_\_}&nbsp;is meant to be readable</div>
When is&nbsp;\ttt{\_\_repr\_\_} used to print an object in Python?	\item \ttt{\%r} formatter<div>\item \ttt{repr(obj)}</div><div>\item A container's \ttt{\_\_str\_\_} uses the contained object's \ttt{\_\_repr\_\_}.</div>
When should&nbsp;\ttt{\_\_repr\_\_} and \ttt{\_\_str\_\_}&nbsp;be implemented?	\item Always implement&nbsp;\ttt{\_\_repr\_\_}&nbsp;<div>\item Implement \ttt{\_\_str\_\_}&nbsp;readability would&nbsp;be useful</div>
What are the two ways to enumerate over all the text descending from a tag in BS?	\item \ttt{tag.strings}<div>\item \ttt{tag.stripped\_strings}, which removes whitespace</div>
How can you get the parent of a tag in BS?	\item \ttt{tag.parent}
How can you get the ancestors of a tag in BS?	\item \ttt{tag.parents}
How can you move to the next or previous sibling of a tag in BS?	\item \ttt{tag.next\_sibling}, \ttt{tag.previous\_sibling}
How can you iterate over a tags' next or previous siblings?	\item \ttt{tag.next\_siblings}<div>\item \ttt{tag.previous\_siblings}</div>
How can you move to the in-order successor of a tag in BS?	\item \ttt{tag.next\_element}
How can you iterate over a tag's in-order successors in BS?	\item \ttt{tag.next\_elements}
How do you get \ttt{find\_all} to match against an exact string in BS?	\item \ttt{t.find\_all('str')}
How do you get \ttt{find\_all} to match against a regex in BS?	\item&nbsp;\ttt{find\_all(re.compile(pattern))}
How do you get&nbsp;\ttt{find\_all} to match against one of several strings in BS?	\item&nbsp;\ttt{find\_all([str1, str2, str3])}
How do you get&nbsp;\ttt{find\_all} to match against everything in BS?	\item&nbsp;\ttt{find\_all(True)}
How do you get&nbsp;\ttt{find\_all} to match against arbitrary criteria in BS?	\item&nbsp;\ttt{find\_all(f)}<div>\item where \ttt{f} is a function that takes a tag and returns a boolean</div>
How do you find all tags with a specific attribute in BS?	\item&nbsp;\ttt{find\_all(attr\_name=val)}
How do you find all tags with a specific set of attributes in BS?	\item \ttt{find\_all(attrs=\{attr\_name\_1: val\_1,&nbsp;attr\_name\_2: val\_2,&nbsp;attr\_name\_3: val\_3\})}
How do you find all tags with a specific class in BS?	\item \ttt{find\_all(class\_=class\_name)}<div>\item (since \ttt{class} is a reserved token in Python)</div>
How can you search for text matching a filter in BS?	\item \ttt{find\_all(text=filter\_name)}
How can you find the first $k$ elements matching a criteria in BS?	\item \ttt{find\_all(*args, limit=k)}
How can you search over only the direct children of a tag in BS?	\item \ttt{t.find\_all(*args, recursive=False)}
What's a shortcut for calling \ttt{t.find\_all(*args)} in BS?	\item \ttt{t(*args)}
What are the other methods related to \ttt{find\_all} in BS?	<div>\item Variants for finding</div>\item Parents<br /><div>\item Previous \&amp; next siblings</div><div>\item In order predecessors \&amp; successors</div>
How can you find just the first tag matching a filter in BS?	\item \ttt{find(*args)}
How do you search the descendents of a BS tag using a CSS selector?&nbsp;	"\item \ttt{t.select(""css\_selector\_string"")}"
How can you get BeautifulSoup to parse only some parts of a document?	\item Use the \ttt{SoupStrainer} class
What's an \ttt{Item} in Scrapy?	\item A container for scraped information<div>\item which works like a dict but with explicitly-declared entries</div>
How do you create a new Scrapy \ttt{Item} class?	\item Derive from \ttt{scrapy.Item}<div>\item Create some \ttt{scrapy.Field()} members with the names of the fields you want</div>
How do you create a Scrapy \ttt{Spider} class?	\item Derive from \ttt{scrapy.Spider} and define<div>\item \ttt{name}</div><div>\item \ttt{start\_urls}</div><div>\item \ttt{parse()}</div>
What's the job of the \ttt{parse()} method in Scrapy?	\item To consume a \ttt{Response} object and return an enumeration of&nbsp;<div>\item \ttt{Item}s containing scraped information</div><div>\item \ttt{Request}s containing new pages to scrape</div>
How do you run a Scrapy project from the terminal?	\item In the Scrapy project directory,<div>\item \ttt{scrapy crawl spider\_name}</div>
What are the two objects Scrapy uses to represent interactions with a website?	\item \ttt{Request}, which represents a website to be crawled<div>\item \ttt{Response}, which represents the contents of a crawled website</div>
What's the standard approach to extracting parts of scraped webpages in Scrapy?&nbsp;	\item Use the \ttt{Selector} object obtained via \ttt{response.selector}
What are the basic methods of a Scrapy \ttt{Selector}?	\item \ttt{xpath()}<div>\item \ttt{css()}</div><div>\item \ttt{re()}</div><div>\item \ttt{extract()}</div>
What do the \ttt{Selector.css(), Selector.xpath()} methods return in Scrapy?	\item A \ttt{SelectorList}, which has many of the methods of \ttt{Selector}<div>\item but broadcasts them over its contents</div>
What does \ttt{Selector.extract()} do in Scrapy?	\item Returns a unicode string of the material represented by the \ttt{Selector}
What's the best way to experiment with selectors in Scrapy?	"\item \ttt{scrapy shell ""url""}<div>\item The \ttt{Response} object will be in the \ttt{response} variable</div>"
What's a useful shortcut for selecting parts of a Scrapy \ttt{Response} using CSS \&amp; XPath?	\item \ttt{response.css()} calls \ttt{response.selector.css()}<div>\item \ttt{response.xpath()} calls \ttt{response.selector.xpath()}</div>
What are the two ways that items produced by a Scrapy spider are output?	\item Using a feed export that stores them directly as json or similar<div>\item Using a Pipeline to refine them first</div>
What's the definition of a Pipeline in Scrapy?	\item A class with a \ttt{process\_item(item, spider)} method<div>\item that either returns another \ttt{Item} for further processing</div><div>\item or raises a \ttt{DropItem} exception</div>
What's the use of a \ttt{scrapy.cfg} file?	\item It sits in the project's root directory and points to the Python module which defines the project settings
How do you create an empty Scrapy project?	\item \ttt{scrapy startproject projectname}
How can you instantiate a spider from a template in Scrapy?	\item Using the \ttt{scrapy genspider} command
What command line tools are useful in testing how a Scrapy project will treat a specific webpage?	\item \ttt{scrapy fetch} will print a url's contents as Scrapy sees it<div>\item \ttt{scrapy view} will show a url in the browser as Scrapy sees it</div><div>\item \ttt{scrapy parse} will print the things parsed from a url</div>
How can you run a scrapy spider without creating a project?	\item \ttt{scrapy runspider}
How can you define metadata for a \ttt{Field} in a Scrapy \ttt{Item}?	\item Create the field using \ttt{scrapy.Field(metadata\_name=metadata\_val)}
How do you copy the metadata of a Scrapy \ttt{Field} into a new \ttt{Field}?	<div>\item Use the field copy constructor:</div>\item \ttt{scrapy.Field(item.fields['oldfield'])}
How can you get a \ttt{Field} object from a Scrapy \ttt{Item} rather than just its value?	\item \ttt{item.fields['fieldname']}
How can you pass arguments to a Scrapy spider run from the command line?	\item Give the initializer keyword args<div>\item \ttt{scrapy crawl spidername -a param\_name=param\_val}</div>
How do you limit the domains that a Scrapy spider can crawl?	\item Define the \ttt{allowed\_domains} member
How can you create a request for a specific spider to crawl &nbsp;a URL in Scrapy?	\item \ttt{spider.make\_requests\_from\_url(url)}
How can you log a message from a Scrapy spider?	\item \ttt{spider.log(message)}
What are some of the standard spiders available in Scrapy?	\item \ttt{CrawlSpider}<div>\item \ttt{XMLFeedSpider}</div><div>\item \ttt{CSVFeedSpider}</div><div>\item \ttt{SitemapSpider}</div>
How does Scrapy's \ttt{CrawlSpider} work?	\item It has a set of \ttt{Rule}s.&nbsp;Each \ttt{Rule} takes a<div>\item \ttt{LinkExtractor} that returns a list of \ttt{Request}s</div><div>\item and a \ttt{callback} that will be called on the corresponding&nbsp;\ttt{Response}s&nbsp;</div>
How is the default \ttt{ItemLoader} used in Scrapy?	\item Create an \ttt{ItemLoader} with a given \ttt{Item} and \ttt{Response}<div>\item Make extraction calls of the form \ttt{loader.add\_xpath('fieldName', xpath)} (or similarly for CSS)</div><div>\item Get the item by calling \ttt{loader.load\_item()}</div>
What happens if a Scrapy default \ttt{ItemLoader} loads the same field twice?	\item The result of the second \ttt{add\_xpath} (or similar) call is appended to the first
How does a Scrapy \ttt{ItemLoader} work internally?	\item Calls of the form \ttt{loader.add\_css('fieldName', val)} call the input processor for \ttt{fieldName} and store the result internally<div>\item Calls of the form \ttt{loader.load\_item()} calls the output processor for \ttt{fieldName} and combines the results into a value to store in the \ttt{Item}</div>
How is \ttt{ItemLoader} subclassed in Scrapy?	\item Define a \ttt{fieldname\_in}&nbsp;attribute&nbsp;containing the input processor for \ttt{field\_name}<div>\item Define a \ttt{fieldname\_out}&nbsp;attribute&nbsp;containing the output processor for \ttt{field\_name}</div><div>\item Define \ttt{default\_input\_processor},&nbsp;\ttt{default\_output\_processor} for fields that don't have processors defined</div>
How can you define an \ttt{ItemLoader} at the same time you define an \ttt{Item} in Scrapy?	\item \ttt{scrapy.Field(default=val1, input\_processor=val2, output\_processor=val3)}
What's an item loader context in Scrapy?	\item If a processor takes a \ttt{loader\_context} argument<div>\item then the item loader will automatically pass a dict that the processors can use to communicate with eachother</div>
How can you manually analyze a response from within a Scrapy script?	\item \ttt{scrapy.shell.inspect\_response(response)}
How do you define which pipeline components a Scrapy project uses?	\item In the settings file, define<div>\item \ttt{ITEM\_PIPELINES = \{'component\_1': int\_1,&nbsp;'component\_2': int\_2\}}</div><div>\item where \ttt{int\_1, int\_2} are (typically) in $[0, 1000]$ and the flow is low-to-high</div>
How do you use the default feed exporters in Scrapy?	\item Define the settings<div>\item \ttt{FEED\_FORMAT='json'} or similar<div>\item \ttt{FEED\_URI='string\_with\_formatting\_params'}&nbsp;</div></div>
What're the formatting parameters that can be used with Scrapy's \ttt{FEED\_URI} setting?	\item \ttt{\%(time)s} will be replaced by the time the feed is created<div>\item \ttt{\%(name)s} will be replaced by the spider's name</div><div>\item \ttt{\%(attr\_name)s} will be replaced by \ttt{spider.attr\_name}'s value</div>
How do Scrapy's feed exporters and item exporters compare?	\item Feed exporters are the easy way to store scraped data<div>\item Item exporters allow advanced customization</div>
What's the definition of a \ttt{LinkExtractor} in Scrapy?	\item An object with a \ttt{extract\_links()} method&nbsp;<div>\item that takes a response</div><div>\item and returns a list of \ttt{Link}s&nbsp;</div>
How do you use the logging in Scrapy?	"\item Start the service with \ttt{scrapy.log.start()}<div>\item Log with \ttt{scrapy.log.msg(""message"", level=log.WARNING)}</div><div>\item or alternative with a spider's onboard \ttt{spider.log()} method</div>"
What are contracts in Scrapy?	\item A way to validate the behaviour of a spider's \ttt{parse()} method against a specific url<div>\item that's defined entirely in the method's docstring</div>
What's an easy way to validate that the calculation of some $f$ and $f^\prime$ is correct in Python?&nbsp;	\item Use \ttt{scipy.optimize.check\_grad}
What's a fundamental problem with debugging ML algorithms?&nbsp;	\item ML algorithms are designed to deal with noisy data<div>\item So often they can return useful results even while buggy</div>
When implementing ML algorithms, what high-level division should be maintained?	\item Clearly separate&nbsp;<div>\item The distributions</div><div>\item The model&nbsp;</div><div>\item The optimization algorithms</div>
When implementing a ML model, what's a good way to test a conditional probability distribution?	\item Check that&nbsp;<div>\item $\frac{p(y|\theta)}{p(x|\theta)} = \frac{p(y, \theta)}{p(x, \theta)}$</div>
When implementing ML algorithms, when should probabilities be used and when should log probabilities be used?	\item Always use log probabilities; use \ttt{lse} for addition
What's a Lipschitz continuous function?	\item A $f$ such that there exists a $K$ such that<div>\item $d(f(x), f(y)) \leq K\cdot d(x,y)$</div><div>\item for all $x, y$</div>
What's the sample complexity for learning a Lipschitz continuous function in $\mbb{R}^d$?	\item $\Omega(1/\varepsilon^d)$<div>\item where $\varepsilon$ is the excess risk</div>
What's the sample complexity for learning a linear function in $\mbb{R}^d$ with a Lipschitz continuous loss?	\item $\Omega(d/\varepsilon^2)$
How do the penalties in a deep contractive network improve performance?	\item They approximate a loss term $\frac{\partial y}{\partial x}$<div>\item encouraging the network to be insensitive to small changes in the input</div><div>\item which increases the minimal magnitude of adversarial distortion</div>
What are the penalties used in a deep contractive network?	\item $\lambda_i \left\|\frac{\partial h_i}{\partial h_{i-1}}\right\|_2$<div>\item for each layer $i$</div>
What's the group theory intuition for what greedy layerwise learning does?	<div>\item Each neuron (approximately) learns to identify some `figure' in the input space.</div><div>\item So for images, the first layer learns figures in $\mbb{R}^2$; the second layer learns figures-of-figures, etc.</div><div>\item And since a neuron stops learning as soon as it finds a stable figure, it learns figures with small orbits and large stabilizers</div>
When are default arguments for a function evaluated in Python?	\item At definition time!<div>\item *Not* when the function is called</div>
When are the values of variables used in a Python closure looked up?	\item When the inner function is called
What's the Lipschitz constant of a function?	\item The $K$ such that<div>\item $d(f(x), f(y)) \leq K \cdot d(x, y)$</div><div>\item if it exists</div>
How is PCA written in terms of matrices?	\item Write $\Sigma = U\Lambda U^T$<div>\item Then $W_\text{PCA} = \Lambda^{-\frac{1}{2}}U^T$</div>
How is ZCA written in terms of matrices?	\item Write $\Sigma = U\Lambda U^T$<div>\item Then $W_\text{ZCA} = U \Lambda^{-\frac{1}{2}}U^T$</div>
Intuitively, what does ZCA do?	\item It whitens the data while keeping it as close as possible to the original data
What does ZCA stand for in ML?	\item Zero-phase component analysis
What's the advantage of ZCA over PCA for image analysis?	\item On natural images, PCA components tend to be global<div>\item ZCA components tend to be local</div>
What's an extreme learning machine?	\item A NN with one very large hidden layer<div>\item where the input weights are randomly initialized and then fixed</div><div>\item and the output neurons are linear in the hidden layer</div>
What's the algorithmic probability of an object $x$?	\item Given models $\{S_i\}_i$ which use a TM $M$ to describe $x$ as $S_i(x)$,<div>\item $p_M(x) = \sum 2^{-|S_i(x)|}$</div>
What's the use of algorithmic probability?	\item It's a neat theoretical construct that allows the definition of a `universal prior'
What's a common mistake when using perplexity to evaluate a language model?	\item Reporting improvements in terms of percentage over a baseline<div>\item since a constant improvement over a varying baseline leads to a varying improvement in entropy&nbsp;</div>
What's the word error rate in NLP?	<div>\item $\text{WER} = \frac{d_L(\hat y, y)}{N}$</div>\item $d_L(\hat y, y)$ is the word-token Levehnstein distance of a predicted string from the actual string<div>\item $N$ is the number of words in the actual string</div>
What's the problem with the word-error rate as an evaluation metric?	\item It over-emphasizes uninformative words and errors which preserve sense
What's a Toeplitz matrix?	\item One with constant diagonals
What's a cache language model?	\item It caches the last few hundred words and forms a &nbsp;model from them<div>\item then interpolates it with a static model trained on a much larger corpus</div><div>\item This helps deal with `burstiness'</div>
What are the seven main classes of language models?	\item N-gram<div>\item Cache</div><div>\item Class-based</div><div>\item Structured</div><div>\item Decision trees</div><div>\item Maxent</div><div>\item Neural networks</div>
What's the use of vocabulary shortlists in NLP?	\item It's a better-performing alternative to vocab truncation for minimizing the size of a NN's output layer
What're vocabulary shortlists in NLP?	\item To keep complexity down, an advanced model can be applied to predict the probabilities of words in a shortlist of most common words<div>\item while an $n$-gram model is used for the rest</div>
What's a NNLM in ML?	\item Neural network language model
What's output factorization in NLP?	\item Grouping words and using one set of outputs to predict the group<div>\item and another set to predict which word from the group to output</div>
When using output factorization, how are words most commonly assigned to groups?	\item By unigram frequency binning<div>\item such that each group has roughly equal probability of occuring</div>
What's a dynamic NN?	\item One which is trained as it processes the test data
What's the typical size of the vocabulary of an English corpus in NLP?	\item Hundreds of thousands of words
Which of vocabulary reduction, shortlists and factorized output tends to work best?	\item Factorized output is best<div>\item Shortlists are better than vocab reduction</div>
When training a neural network using both in-domain and out-of-domain data, which should be fed through first?	\item The out of domain data, followed by the in-domain stuff
What's in-domain and out-of-domain training data?	\item In-domain data is specific to the problem<div>\item Out-of-domain data concerns other, related problems</div>
How can you sort a large NLP training set into chunks, going from furthest-out-of-domain to most-in-domain?	\item Chunk it randomly<div>\item Train a simple $n$-gram model on each chunk and evaluate its perplexity on the test set</div><div>\item Sort the chunks in order of decreasing perplexity</div>
What's incremental learning?	\item Training a NN to identify simple concepts first, then progressively more complex ones&nbsp;
What's a hash-based language model?	\item One where rather than keeping the entire tensor mapping $n$-grams to outputs, the inputs are hashed to an output<br /><div>\item This keeps memory down</div>
Why are collisions okay in hash-based maxent models?	\item Because during training, of the inputs that are mapped to a single output,<div>\item the most common inputs will dominate the way the output is trained</div>
What's the advantage to adding a maxent model to a RNN LM?	\item The maxent model can learn simple patterns and so save the RNN a lot of hidden variables
What's the high-level algorithm in the paragraph-vector framework?	\item Learn a vector for each paragraph in the corpus<div>\item such that the paragraph vector concatenated with a the vectors for a few consecutive words</div><div>\item can effectively predict the next word</div>
What's the point in learning a vector for each paragraph in the paragraph-vector framework?	\item The paragraph vector provides context that lets the predictor disambiguate what word should come next
In the paragraph vector framework, what's a good number of words to use when predicting the next word?	\item 5 to 12
What's the difference between memoization and DP?	\item Memoization is top-down and usually vulnerable to stack overflow<div>\item DP is bottom-up but takes a lot more thought to implement</div>
What's a RNN encoder-decoder?	\item A pair of RNNs,<div>\item the encoder takes a source sequence (like an English phrase) to a vector representation&nbsp;</div><div>\item and the decoder takes the vector to a target sequence (like a French phrase)</div>
If a NN puts out a vector, when can the vector be safely interpreted probabilistically?	\item When the NN has been trained to emulate a probability distribution<div>\item (like using it to predict the next word in a sentence)</div>
What's the difference between \ttt{@staticmethod} and \ttt{@classmethod} in Python?	<div>\item A method decorated with \ttt{@classmethod} is passed the class as it's first parameter</div>\item A method decorated with \ttt{@staticmethod} isn't passed anything as it's first parameter&nbsp;
What's the main use of \ttt{@classmethod} in Python?	\item \ttt{@classmethod}s can call other methods on the class<div>\item so they work well with inheritance&nbsp;</div>
How should you open a file in Python?	\item \ttt{with open(filename) as f:}
What's \ttt{\_\_slots\_\_} in Python?	\item It can be assigned a collection of strings that will be used as attribute names for the class<div>\item Assigning to it suppresses the generation of the usual \ttt{\_\_dict\_\_} that holds the attributes of most Python objects</div>
What's the functional difference between old- and new-style classes in Python?	\item Some magic names have been changed<div>\item Old-style use a DFS (kinda) for method resolution in a base class hierarchy. New use a BFS (kinda)&nbsp;</div>
What's \ttt{\_\_mro\_\_} in Python?	\item A magic name for viewing the method resolution order for a class<div>\item which lists the order in which the base class hierarchy will be searched&nbsp;</div>
What's a new-style class definition vs an old-style one in Python?	\item New style: \ttt{class ClassName(object):}<div>\item Old style: \ttt{class ClassName:}</div>
What's the most common use of \ttt{\_\_slots\_\_} in Python?	\item&nbsp;&nbsp;\ttt{\_\_slots\_\_ = ()} effective declares the class is stateless&nbsp;
What's \ttt{eval()} in Python?	\item A function that interprets a string as a code expression and returns the result
What's \ttt{raw\_input()} in Python?	\item&nbsp;\ttt{raw\_input(str)}&nbsp;will print \ttt{str} to the console, then wait for a new line to be entered, which it returns
What's \ttt{exec()} in Python?	\item A statement which interprets a string as code and executes it<div>\item Local and global variables can be supplied for use in the execution</div>
How can you index into a Python dictionary which uses tuples as keys?	\item \ttt{dictname[first, second]}, where the actual key is \ttt{(first, second)}
What's \ttt{\_\_new\_\_} in Python?	\item A magic name which is called when an object is created, and is responsible for returning an instance of the object
How can you set the value of a programmatically-chosen attribute in Python?	\item \ttt{setattr(obj, attrname, value)}
What are the siblings of the \ttt{setattr()} keyword in Python?	\item \ttt{getattr()}<div>\item \ttt{delattr()}</div><div>\item \ttt{hasattr()}</div>
How do you create a local variable with a programmatically-generated name in Python?	\item \ttt{locals()[varname] = value}
When nesting lambdas in Python, how can you make debugging them easier?	\item Give the lambdas names:<div>\item \ttt{lamb.\_\_name\_\_ = lambdaname}</div>
What's \ttt{\_\_class\_\_} in Python?	\item The magic name on an object of a new-style class that's used by \ttt{type} to get the object's class
What's the magic name behind \ttt{bool} in Python?	\item \ttt{\_\_nonzero\_\_()}
What're the magic names for the comparison operators in Python?	\item Preferentially \ttt{\_\_lt\_\_},&nbsp;\ttt{\_\_ge\_\_},&nbsp;\ttt{\_\_eq\_\_}, etc<div>\item but will default to \ttt{\_\_cmp\_\_} if those aren't available</div>
What's the magic name for an object's hash code in Python?	\item \ttt{\_\_hash\_\_()}
How can you get the unique identity of an object in Python?	\item \ttt{id(obj)}
How can you store state in a Python function such that it can be accessed call-to-call?	\item \ttt{def f(): f.storename = val}
What's the best way to implement a singleton in Python?	\item Store the singleton state in an attribute on a class or function
What's the magic method behind the \ttt{isinstance} keyword in Python?	<div>\item The class method</div>\item \ttt{\_\_instancecheck\_\_}
What's a chainmap in Python?	\item It's a dictionary which offers a composite view of a set of backing dictionaries
What's \ttt{\_\_dict\_\_} in Python?	\item The magic attribute which holds all the attributes of an object
What's the difference between a Python function starting with one underscore and one starting with two?	<div>\item One underscore indicates the function should &nbsp;be treated as private</div>\item Two underscores will have its name mangled by the classname
How is the bridge pattern usually implemented?	\item By passing an instance from the implementor hierarchy to the constructor of a class from the abstraction hierarchy
How do you make an object iterable in Python?	\item Implement the \ttt{\_\_iter\_\_()} method and have it return an iterator object
What does \ttt{iter()} do in Python?	<div>\item Iterator protocol: \ttt{iter(o)} will call \ttt{o.\_\_iter\_\_()} if it exists, else</div><div>\item Sequence protocol: \ttt{iter(o)} will call \ttt{o.\_\_getitem\_\_(i)} with increasing integers \ttt{i}, else</div><div>\item Iteration: \ttt{iter(o, sentinel)} will call \ttt{o.next()} until it returns something equal to \ttt{sentinel}</div>
How are iterator objects implemented in Python?	\item \ttt{o.\_\_iter\_\_()} should return \ttt{o}<div>\item \ttt{o.next()} should return the next item, or raise \ttt{StopIteration}</div>
How should \ttt{\_\_getitem\_\_()} be implemented in Python?	\item \ttt{\_\_getitem\_\_(key)} should<div>\item raise \ttt{TypeError} if the type of \ttt{key} is wrong</div><div>\item for sequence types, raise \ttt{IndexError} if the key is outside the valid range</div><div>\item for mapping types, raise \ttt{KeyError} if the key is missing</div><div>\item Else, return the requested item</div>
What's the difference between \ttt{dict.iteritems()} and \ttt{dict.items()} in Python 2.7?	\item \ttt{items()} returns a list of tuples<div>\item \ttt{iteritems()} returns a generator of tuples</div>
How can you get a view onto a dictionary in Python 2.7?	\item \ttt{dict.viewitems()}
What's an easy way to implement all the comparison operators for a class in Python?	\item Implement ($=, &lt;$)<div>\item Apply \ttt{@functools.total\_ordering} to the class</div>
How can you preserve the docstring and name of the wrapped function when writing your own decorators in Python?	\item Decorate the wrapper with \ttt{@functools.wraps(wrapped)}
How do you write a parameterized decorator in Python?	\item Write a function which takes some arguments<div>\item and returns another function that'll take the function-to-be-wrapped and returns the wrapped function</div>
Given getter, setter and deleter methods in Python, what are the two ways of creating a property?	\item Decorate them with \ttt{@property, @propname.setter, @propname.deleter}<div>\item Use \ttt{propname = property(getter, setter, deleter)}</div>
What's an elegant way to use class decorators to do field validation in Python?	\item Create an \ttt{Ensure} class that can hold a collection of validation rules<div>\item Define fields in the class as \ttt{fieldname = Ensure(validation\_rule)}</div><div>\item Have a class decorator \ttt{@do\_ensure} which takes each \ttt{Ensure} field and replaces it with a property that tests the associated rules</div>
When can Python class decorators be used instead of subclassing?	\item When the `inherited' methods and data aren't modified by the subclass
What're bound and unbound methods in Python?	\item A bound method is a method referenced through an object instance, so its \ttt{self} parameter has been `filled in'<div>\item An unbound method is a method referenced through the class instance, so its \ttt{self} parameter is still free</div>
What's the flyweight pattern?	\item A way to reduce memory use by deduplication; multiple objects have pointers to the same state
When should a \ttt{\_\_attrname} be used rather than a \ttt{\_attrname} in Python?	\item When you don't want subclasses to override the attribute
How can you alter what happens when attributes on a Python object are got \&amp; set?	\item By overridding \ttt{\_\_getattr\_\_} and \ttt{\_\_setattr\_\_}.
What's the most convenient way to get a list of the attributes of a Python object?	\item \ttt{dir(obj)}<div>\item although the list might not be rigorous or complete</div>
What's the best way to get the next item from a Python iterator?	\item \ttt{next(iterator[, default])}<div>\item where \ttt{default} is the value to return if the iterator is exhausted</div>
What's the difference between an iterator and generator in Python?	\item An iterator is anything with methods \ttt{\_\_iter\_\_()} and \ttt{next()}<div>\item A generator is the result of a call to a function containing a \ttt{yield} expression. The result is an iterator.</div>
What's send syntax in Python?	\item If you have a generator \ttt{g} which has yielded a value<div>\item then \ttt{g.send(x)} will cause the \ttt{yield} expression inside the generator to return with value \ttt{x}</div>
How can you create a Python generator when you're only concerned about \ttt{send}'ing values into them, not about getting yielded values?	<div>\item Use the expression</div>\item \ttt{sent\_value = (yield)}
What's the easiest way to implement coroutines in Python?	\item Use generators
What's the chain of responsibility pattern?	\item Each object in the chain takes an optional successor<div>\item and after it's done with an event, passes the event to its successor</div>
How can you make an object callable in Python?	\item Implement \ttt{\_\_call\_\_()}
How can you test if an object can be called in Python?	\item \ttt{callable(obj)}
What're the easiest ways to create anonymous objects in Python?	\item \ttt{type('', (), \{\})}<div>\item \ttt{object()}</div>
What's a default dictionary in Python?	\item It's a dictionary which you supply a \ttt{defaultfactory} to<div>\item and every time a missing key is requested, that key is added to the dictionary with a value specified by the \ttt{defaultfactory}</div>
What're the components of the mediator pattern?	\item \ttt{Mediator} defines the interface for communication between \ttt{Colleague}s
What's the use of the mediator pattern?	\item It decouples communicating objects from eachother
How do you implement coroutines using generators in Python?	\item Create a generator \ttt{g}<div>\item Call \ttt{next(g)} to advance it to its first \ttt{yield} statement</div><div>\item \ttt{g} is now ready to be used as a coroutine;&nbsp;send items into the coroutine using \ttt{g.send(obj)}</div>
What's the idea in the memento pattern?	\item The \ttt{Caretaker} requests an opaque \ttt{Memento} from the \ttt{Originator} which stores the \ttt{Originator}'s state<div>\item When the \ttt{Caretaker} wants to revert the \ttt{Originator} to it's previous state, it hands back the \ttt{Memento}</div>
How can you test whether a string is a valid Python name?	\item \ttt{s.isidentifier()}
What's the idea in the state pattern?	\item A \ttt{Context} object delegates requests to it to it's \ttt{State} property<div>\item Depending on what \ttt{ConcreteState} is inhabiting the \ttt{State} property, different behaviour will be obtained</div>
What's the use of the state pattern?	\item It replaces conditional logic in every state-dependent method with conditional logic only in the state-changing property
What's the easiest way to make another process to do some work in Python?	\item Create a \ttt{process = multiprocessing.Process(f, args)}<div>\item Then \ttt{process.start()}</div>
How can you ensure that processes created by \ttt{multiprocessing} in Python will be shut down when the parent process is?	\item By setting \ttt{process.daemon = True} on any process you create
How do you use a \ttt{JoinableQueue} as a work queue in Python?	\item Populate the joinable queue with jobs<div>\item Pass it to some other processes, which will take jobs from it then call \ttt{queue.task\_done()}</div><div>\item In the original process, call \ttt{queue.join()} to wait for the queue to be emptied</div>
How do you usually retrieve results from processes you create in Python?	\item By passing a \ttt{multiprocessing.queue} as an argument when you create the process<div>\item and having the other process store its results there</div>
How do you use futures to do multiprocess concurrency in Python?	<div>\item Within a \ttt{with ProcessPoolExecutor() as executor:} block</div><div>\item create futures using \ttt{future = executor.submit(f, args)}</div><div>\item and store them in some collection, \ttt{futures.add(future)}</div><div>\item Then outside the block, consume the futures as they complete using \ttt{for future in as\_completed(futures):}</div><div>\item and extract results using \ttt{future.result()}</div>
Where do errors thrown during the execution of a Python future emerge?	\item If any occured, they'll be returned by \ttt{future.exception()}
What penalized problem do AIC and BIC correspond to solving?	\item $\min_\theta l(\theta) + \lambda \|\theta\|_0$<div>\item where $\lambda$ depends in a complex manner on the criterion</div>
When is solving $\min \|y-Wx\|_2^2$ s.t. &nbsp;$\|x\|_0 \leq k$ tractable, and how is it solved?	\item When $W$ is orthonormal<div>\item and it's solved by hard-thresholding $W^Ty$</div>
What are three common formalizations of $l_1$ optimization?	<div>\item $\min \|y - Wx\|_2^2 + \lambda\|x\|_1$</div>\item $\min \|y - Wx\|_2^2$ s.t. $\|x\|_1 \leq \alpha$<br /><div>\item $\min \|x\|_1$ s.t. $\|y - Wx\|_2^2 \leq \epsilon$</div>
What's Tikhonov regularization?	\item Another name for $l_2$ regularization
What's the idea in structured sparsity?	\item It's an extension of group sparsity where the groups are allowed to intersect
What's the idea in hierarchical sparsity?	\item It's an extension of the idea of group sparsity that, given a tree of variables, encourages rooted subtrees to zero out
How is the idea of a sparse solution usually adapted to matrix-valued unknowns?	\item By asking for low-rank matrix solutions (equiv to $l_0$ norm)<div>\item which can be approximated by low-trace solutions (equiv to $l_1$ norm)</div>
What're two other names for the trace of a matrix?	\item Nuclear norm<div>\item Schatten norm</div>
Without using sparsity assumptions, approximately how many samples $n$ are needed to achieve a denoising error of $\epsilon$?	\item $n \approx \frac{p}{m} \cdot \frac{\sigma^2}{\epsilon^2}$<div>\item where</div><div>\item $p$ is the number of atoms</div><div>\item $m$ is the number of signal dimensions&nbsp;</div><div>\item $\sigma$ is the standard deviation of the noise</div><div>\item $\epsilon$ is the $l_2$ residual</div>
When using sparsity assumptions and a dictionary satisfying the RIP, approximately how many samples are needed to achieve a denoising error of $\epsilon$?	\item $n \approx \frac{k \ln p}{m} \cdot \frac{\sigma^2}{\epsilon^2}$<div>\item where</div><div>\item $k$ is the number of nonzeros in the truth</div><div>\item $p$ is the number of atoms</div><div>\item $m$ is the number of signal dimensions&nbsp;</div><div>\item $\sigma$ is the standard deviation of the noise</div><div>\item $\epsilon$ is the $l_2$ residual</div>
What's the restricted isometry property?	\item $W$ satisfies the RIP for signals with $k$-nonzero-element representations iff&nbsp;<div>\item all $k\times k$ submatrices of $W^TW$ have all their eigenvalues close to 1&nbsp;</div>
What's the relevance of the RIP to sparse coding?	\item If a dictionary satisfies the RIP for $k$-sparse signals, then the lasso algorithm behaves well and recovers the true support for $k$-sparse signals
What's RIP stand for in sparse coding?	\item Restricted isometry property
What's the main problem with the RIP?	\item There's no known way of testing whether a matrix satisfies it &nbsp;in polytime
Given a sparse denoising problem where the dictionary satisfies the RIP, what value of $\lambda$ are you generally recommended to use by the theory?	\item $\lambda \approx \sigma \sqrt{m \ln p}$<div>\item where</div><div>\item $\sigma$ is the standard deviation of the noise</div><div>\item $m$ is the number of signal dimensions</div><div>\item $p$ is the number of atoms&nbsp;</div>
Geometrically, what's the simplest way of dealing with sign-flip unidentifiability in dictionary learning?	\item By projecting the signal and the atoms onto the positive half-sphere<div>\item ie by considering them as points in the projective space $\mbb{P}^{m-1}$</div>
What is a good frequentist method to compare correlation coefficients? why is it necessary?&nbsp;	Fisher's z-transformation;&nbsp;the variance of r grows smaller as |ρ| gets closer to 1, and this provides a variance-stabillizing transformation so that they can be correctly compared&nbsp;<div>&gt; from Wikipedia</div>
What's the \ttt{ord} function in Python?	\item It gets the integer corresponding to an ASCII char
In Seaborn, how do you temporarily select a plot style?	\item \ttt{with axes\_style('whitegrid'):}
In Seaborn, how do you permanently set the plot style?	\item \ttt{sns.set\_style('white')}
What are the main styles in Seaborn?	\item \ttt{darkgrid} (default)<div>\item \ttt{whitegrid} (for large, blocky data elements)</div><div>\item \ttt{ticks} (for when values are less important)</div><div>\item \ttt{dark, white} (for when values aren't important)</div>
What's the usual way to control the position of a plot's axes border in Seaborn?	\item \ttt{sns.despine}
How can you override parts of a Seaborn style?	\item By passing a dictionary into the \ttt{rc} parameter of the \ttt{set\_style} or \ttt{axis\_style} methods
What's the division of aesthetic customization in Seaborn?	\item \ttt{set\_style} handles styling<div>\item \ttt{set\_context} handles scale</div>
How do you rescale components temporarily in Seaborn?	\item \ttt{with plotting\_context():}
How do you reset to the default parameters in Seaborn?	\item \ttt{sns.set()}
How can you set the scale of components permanently in Seaborn?	\item \ttt{set\_context()}
How do you set the color palette temporarily in Seaborn?	\item \ttt{with color\_palette():}
How can you set the color palette permanently in Seaborn?	\item \ttt{set\_palette()}
How can you examine a color palette in Seaborn?	\item \ttt{palplot(list\_of\_rgb\_tuples)}
What does \ttt{color\_palette()} return in Seaborn?	\item A list of RGB tuples
How can you draw a fixed number of qualitative colors in Seaborn?	\item \ttt{color\_palette('husl', 8)} for 8 colors
What are the two modifications to ColorBrewer palettes that can be applied in Seaborn?	\item \ttt{BuGn\_r} is the reversed version<div>\item \ttt{BuGn\_d} is the dark version</div>
What are the two ways to create a sequential color palette from a single color in Seaborn?	\item \ttt{light\_palette('blue')}<div>\item \ttt{dark\_palette('blue')}</div>
How do you make a custom diverging palette in Seaborn?	\item \ttt{diverging\_palette(hue\_angle\_1, hue\_angle\_2)}
What's a \ttt{jointplot} in Seaborn?	\item A hexbin plot with histogram on the top and right edges
What's a \ttt{rugplot} in Seaborn?&nbsp;	\item A plot of 1D data, with each datapoint represented as a short stick&nbsp;
What's Seaborn's \ttt{distplot}?	\item A way to combine KDE plots, rug plots and histograms
How can you adapt a violin plot in Seaborn to show how points change over several time intervals?	\item Passing \ttt{join\_rm=True} will use overlay a line plot to show how points move between each violin
What's the basic way to use \ttt{lmplot} in Seaborn?	\item \ttt{lmplot('x\_colname', 'y\_colname', dataframe)}
What's the basic tool for visualizing linear relationships in Seaborn?	\item \ttt{lmplot()}
When plotting a discrete axis using Seaborn's \ttt{lmplot}, what should you do?	\item Use the \ttt{x\_jitter} or \ttt{y\_jitter} arguments to spread the points out
What's the easiest way to plot multiple datasets in different colors on a Seaborn \ttt{lmplot}?	\item Pass \ttt{hue='colname'} to \ttt{lmplot}.&nbsp;<div>\item Each unique value in \ttt{colname} will be assigned a different color</div>
What's the easiest way to plot multiple datasets in different subplots on a Seaborn \ttt{lmplot}?	\item Pass \ttt{col='colname'} &nbsp;or \ttt{row='rowname'} to \ttt{lmplot}<div>\item Each unique value in \ttt{colname} will be assigned its own subplot</div>
How do you disable the linear regression in Seaborn's \ttt{lmplot}?	\item Pass the \ttt{fit\_reg=False} argument
What's the version of \ttt{lmplot} that can be passed a subplot to be drawn on in Seaborn?	\item \ttt{regplot}
What's the version of Seaborn's \ttt{lmplot} that can be passed array data rather than a dataframe?	\item \ttt{regplot}
What's Seaborn's variant of \ttt{lmplot} for 3D data?	\item \ttt{interactplot}
What's the easiest way to plot correlations in Seaborn?	\item \ttt{corrplot()}
How do you disable the significance test information in Seaborn's \ttt{corrplot}?	\item Pass the argument \ttt{sig\_stars=False}
What's the simplest way to use Seaborn's \ttt{factorplot}?	\item \ttt{factorplot('x\_col', 'y\_col', 'hue\_col', dataframe)}<div>\item where \ttt{x\_col} and \ttt{hue\_col} are categorical and \ttt{y\_col} is real</div>
What are the three arguments to \ttt{kind} in Seaborn's \ttt{factorplot}?	\item \ttt{point}, which plots a point-and-errorbar estimate of each category and connects hue categories into a line<div>\item \ttt{bar}, which plots bars for each hue category side-by-side</div><div>\item \ttt{box}, which plots boxes for each hue category side-by-side</div>
How can you use \ttt{factorplot} to show the counts in each category in Seaborn?	\item By omitting the \ttt{y} variable
What're the versions of Seaborn's \ttt{factorplot} that can be plotted onto a subplot?	\item \ttt{pointplot} and \ttt{barplot}
What're the versions of Seaborn's \ttt{factorplot} that'll accept array data?	\item \ttt{pointplot} and \ttt{barplot}
How do you easily create a heatmap in Seaborn?	\item \ttt{heatmap(dataframe)}
How do you easily plot a clustermap in Seaborn?	\item \ttt{clustermap(dataframe)}
How do you use matplotlib's \ttt{subplot2grid}?	\item \ttt{ax = subplot2grid((n\_rows, n\_cols), (top, left), colspan=width, rowspan=height)}
How do you use \ttt{GridSpec} in matplotlib to create arbitrary axes?	\item \ttt{gs = GridSpec(n\_rows, n\_cols)}<div>\item \ttt{ax = plt.subplot(gs[row\_range, col\_range])}</div>
How do you fine-tune the layout of axes created with a matplotlib \ttt{GridSpec}?	\item \ttt{gs.update()}
How do you create a \ttt{GridSpec} with non-square cells in matplotlib?	\item \ttt{GridSpec(n\_rows, n\_cols, width\_ratios=arr\_1, height\_ratios=arr\_2)}&nbsp;
What's the best way to plot time series in Seaborn?	\item \ttt{tsplot(ys)}
Which class implements Seaborn's support for trellis plotting?	\item \ttt{FacetGrid}
What's the simplest way to use Seaborn's \ttt{FacetGrid}?	\item \ttt{fg = FacetGrid(dataframe, row='row\_name', col='col\_name', hue='hue\_name')}<div>\item \ttt{fg.map(f, 'values\_name\_1', 'values\_name\_2', ...)}</div><div>\item where \ttt{f} takes some data and keyword args and draws a plot on the active axes</div>
How do you set the size of the figure when using Seaborn's \ttt{FacetPlot}?	\item Pass the arguments \ttt{size=height, aspect=ratio}
How can you wrap the column variable down rows when using Seaborn's \ttt{FacetGrid}?	\item Pass the argument \ttt{col\_wrap=width}
How do you alter the ordering of items when using Seaborn's \ttt{FacetGrid}?	\item Pass the arguments \ttt{col\_order, hue\_order, row\_order}
How do you set options on every subplot generated by a Seaborn \ttt{FacetGrid}?	\item \ttt{fg.set(xticks=list)}, and similar
How do you get a list of the axes generated by a Seaborn \ttt{FacetGrid}?	\item \ttt{fg.axes.flat}
Which Seaborn class supports scatter-matrix-esque functionality?	\item \ttt{PairGrid}
What's the difference between Seaborn's \ttt{FacetGrid} and \ttt{PairGrid}?	\item \ttt{FacetGrid} shows different facets of the relationship between a fixed set of variables<div>\item \ttt{PairGrid} shows a single facet of of the relationship between many different sets of variables</div>
What's the simplest way to use \ttt{PairGrid} in Seaborn?	\item \ttt{pg = PairGrid(dataframe)}<div>\item \ttt{pg.map(f)}<br />\item where \ttt{f} takes array \ttt{x, y} and keyword args and draws onto the currently active axes</div>
How do you make different kinds of plot on the diagonal of a Seaborn \ttt{PairGrid}?	\item \ttt{pg.map\_diag(f)}<div>\item \ttt{pg.map\_offdiag(g)}</div>
How can you plot multiple datasets in different colors when using a Seaborn \ttt{PairGrid}?	\item Create the \ttt{PairGrid} with a \ttt{hue='hue\_name'} argument
How do you limit which variables are used in a Seaborn \ttt{PairGrid}?	\item Pass the \ttt{vars=list\_of\_colnames} when you create the \ttt{PairGrid}
How do you create different plots in the upper and lower triangles of a Seaborn \ttt{PairGrid}?	\item \ttt{pg.map\_upper}<div>\item \ttt{pg.map\_lower}</div>
How do you specify different sets of variables for the x and y axes of a Seaborn \ttt{PairGrid}?	\item Pass the arguments \ttt{x\_vars=list\_A, y\_vars=list\_B} when creating the \ttt{PairGrid}
Which method implements scatter plot matrices in Seaborn?	\item \ttt{pairplot(dataframe)}<div>\item though this is much less customizable than \ttt{PairGrid}</div>
Which Seaborn class generalizes \ttt{jointplot}?	\item \ttt{JointGrid}
How is Seaborn's \ttt{JointGrid} used most simply?	\item \ttt{jg = JointGrid('x\_name', 'y\_name', dataframe)}<div>\item \ttt{jg.map(bivar\_f, univar\_f, summarize\_f)}</div><div>\item where</div><div>\item \ttt{bivar\_f} deals with the joint data</div><div>\item \ttt{univar\_f} deals with the marginals on each axis</div><div>\item \ttt{summarize\_f} returns a summary statistic string</div>
What's the more flexible way of using Seaborn's \ttt{JointGrid}?	\item \ttt{jg = JointGrid('x\_name', 'y\_name', dataframe)}<div>\item then</div><div>\item \ttt{jg.plot\_marginals(f)}</div><div>\item \ttt{jg.plot\_joint(g)}</div><div>\item \ttt{jg.annotate(h)}</div>
How do you scale the height of the marginal plots when using Seaborn's \ttt{JointGrid}?	\item Pass the \ttt{ratio=height\_ratio} argument when creating the \ttt{JointGrid}<div>\item Note the central plot is always square!</div>
How do you alter the spacing between the joint and marginal plots when using Seaborn's \ttt{JointGrid}?	\item Pass the \ttt{space=dist\_float} argument when creating the \ttt{JointGrid}
What's the problem with normalized mutual information for comparing clusterings?	\item The approximation $p(X) \approx \frac{n_X}{n}$ is only valid as $n \rightarrow \infty$<div>\item For finite $n$, this leads to the NMI being inflated</div>
What's relative normalized mutual information?	\item It's NMI minus the expected NMI of the reference partition against a completely random partition
What's Xavier's normalized initialization scheme?	\item Initialize layer $l$ with $\mc{N}\left(0, \frac{1}{n_l}\right)$<div><div>\item where $n_l$ is either</div><div>\item $n_l = k^2c$, with $k$ the kernel size and $c$ the number of input channels</div><div>\item $n_l = k^2d$, with $k$ the kernel size and $d$ the number of output channels</div></div>
What's the purpose of Xavier's normalized initialization scheme?	\item It attempts to keep the variance of the signals and gradients constant across layers of differing size
What's the variance of a uniform distribution on $[a,b]$?	\item $\frac{1}{12}(b-a)^2$
What are the constraints that Xavier's normalized initialization tries to fulfill?	\item The feedforward constraint, $\text{var}(W^i) = \frac{1}{n_i}$<div>\item The backprop constraint,&nbsp;$\text{var}(W^i) = \frac{1}{n_{i+1}}$</div>
What's the problem with using ReLU nonlinearities in a denoising autoencoder?	\item If they're used in the output layer, then when a zero is mistakenly reconstructed, the gradient generated by the error will be unable to flow back
How can a ReLU layer be modified to ensure that its mean activation is zero?	\item Multiply half the units by $-1$
How should the sparsity penalty generally be chosen when training ReLU networks?	\item So that about 50\%-80\% of the neurons are zero'd on any particular input
(Distribution?) X is the the math SAT score of one student chosen uniformly at random plus the verbal SAT score of a second student chosen uniformly at random.	close to normal  - two independent distributions added
(Distribution?) Y is the average of the two scores in part a.	close to normal, average of two normal distributions
(Distribution?) Z is the the math SAT score of one student chosen uniformly at random plus the verbal SAT score of the same student.	close to normal - addition of two normally distributed variables.
(Distribution?) W is the average of the two scores in part c. (math SAT score of student chosen uniformly at random, plus verbal SAT score of the same student).	close to normal - addition of two normally distributed variables, then scaled by a factor of 2.
(Distribution?) 200 dice are rolled.  X is the sum of the numbers on top of the first 100 dice plus the sum of the numbers on the bottom of the second 100 dice.	close to normal - all 200 independent numbers have equal probabilities
(Distribution?) 200 dice are rolled.  Y is the average of the numbers on top of the first 100 dice plus the average of the numbers on the bottom of the second 100 dice.	close to normal - all independent numbers have equal probabilities, then divided by 200.
(Distribution?) 100 dice are rolled.  Z is the sum of the numbers on top of the dice plus the sum of the numbers on the bottom of the dice.	normal distribution with average 7 and normal distribution 0.
(Distribution?) 100 dice are rolled.  W is the average of the numbers on top of the dice plus the average of the numbers on the bottom of the dice.	normal distribution - value is always 7.
Solve for a Median example	Ex. x0, x1,x2, x3. Median is n/2 = 4/2 = x2. (round up one)
Stat Quartiles example	x0, x1, x2, x3, x4, x5, x6, x7, x8. <br> Q1 = (x1+x2)/2 <br> Q2 = x4 <br> Q3 = (x6+x7)/2
Prob/CS definition of 1st Quartile of A	smallest number such that at least 25% of the elements of A are <= x.
Prob/CS definition of 3rd Quartile of A	smallest number that at least 75% of the elements of A are <= x
Prob/CS definition of nth Quartile of A	smallest number x such that at least n% of the elements of A are <= x.
Arithmetic Mean	average of x. <br> 1/n * summation from i=1 to n of xi. <br> Also written as x with a line on top of it.
Variance	"measures ""spread"" - how spread out your data is. <br> Var of xi, ... , xn is 1/(n-1) * summ_i=1 to n[(xi - mean)^2]"
Standard deviation	Standard Deviation = sqrt(variance)
Excel formulas for variance, standard deviation	var.s, stdev.s
Inclusion Exclusion rule	|A U B| = |A| + |B| - |A∩B| <br> P(A U B) = P(A) + P(B) - P(A U B)
De Morgan's Law	"<img src=""c07d19ba0c936ad1ee872e857662e5b0.png"" />"
Multiplying and Standard Deviation and Variance	Ex. If we multiply a set of numbers by 5: <br> Standard deviation is multiplied by 5. <br> Variance is multiplied by 5^2.
Getting at least 1 double in 3 rolls	D(D1 v D2 v D3 = 1-P(notD1 ^ notD2 ^ notD3) <br> = 1- (5/6)(5/6)(5/6) = 1-125/216.
Bayes Rule	"<img src=""bayes-rule.png"" />"
Law of Total Probability	ex. Probability of testing positive. S=uses steroids, P = tests positive <br> P(T) = P(S)P(T|S) + P(notS)P(T|notS)
Bayes Rule Final (Expanded)	"P(A|B) = P(B|A)P(A) / P(B|A)P(A) + P(notA)P(B|notA) <br /><br /><div><img src=""bayesFormula.gif"" /></div>"
Complement Rule	P(notA | B) = 1 - P(A|B) <br> P(C|T) =
Random variable	a real number you get from a random experiment. ex. Flip 10 fair coins. X = # of heads.
N choose K	(n k) =n!/( k!(n-k)! ) <br> Note: You'll use this for getting something like 7 3s in 10 dice rolls. <br> Pr(x=7) is 10choose3 * (1/6)^10
Binomial Distribution	"<img src=""binomial-distribution.jpg"" /><br /> *P^k (1-p) is the probability for a single sequence. <br /> Rememer that any yes/no (two result) experiment is a Binomial Distribution!"
Expected Value E[x]	E[x] = summation of all possible values for x times their probabilities. >>  aPr(x=a) <<  <br> The expected value often equals the average.
If x is Bin(n,p) distributed, E[x] equals?	E[x] = np.
If X is Bin(n,p) distributed, Var(x) = ?	Var(x) = np(1-p)
10 coin flips. Expected value and variance for either heads/tails	E[x] = 5 (10*.5) <br> Var = 10 * 0.5(1-0.5) = 2.5
P(E or F) (conditional) =	P(E) + P(F) - P(E and F)
Addition Rule (conditional):	P(E or F) =  P(E) + P(F) - P(E and F)
Special Addition Rule, when E and F are mutually exclusive:	P(E or F) = P(E) + P(E)
Subtraction Rule (conditional):	P(E) = 1-P(notE)
Multiplication Rule:	P(E and F) = P(E|F)P(F)
Special Multiplication Rule, when E and F are independent:	P(E and F) = P(E)P(F)
Bayes Theorem identifying events:	A: Patient has the disease. B: Patient tests positive <br> P(A|B) = P(A)P(B|A)/ [P(A)P(B|A) + P(notA)P(B|A)]
Make sure not to confuse a Probability Distribution Table with a normal Distribution Table	Probability Table - shows the prob that the random variable X has the value x. <br> y | 2 | 3 | 4 | 5 |6|... |12| <br> Pr(Y=y)| 1/36|2/36|3/36|4/36|...|1/36| <br> Distribution Table just shows all the outcomes.
Mean for Random Variables	μ is used for population mean, while x with bar on top is used for data mean. <br> μ = summation of xp(x) = E[x] = expected value of x.
Variance  of a random variable x:	it's the expected squared distance from the population mean. σ^2 = summation of (x-μ)^2 p(x)
Finding standard deviation for 2 coin tosses:	0 heads, p(x) = .25, (0-1)^2 * .25 = .25 <br> 1 head p(x) = 0.5, (1-1)^2 * .25 = 0 <br> 2 heads p(x) = .25, (2-1)^2 * .25 = .25 <br> .25+.25 = .5 = σ^2
Adding expected values rule:	E[ax + b] = aE[x] + b <br> σ^2 (ax + b) = a^2 o^2 (x) <br> E[x1 + x2] = E[x1] + E[x2]
Mean for Binomial Distributions	μ = np
Variance for Binomail Distributions	σ^2 = np(1-p)
Z-value formula	z = (x-μ) /σ    <br> Remember that σ is standard deviation
example: Probability of Y=7 with 9 coins flipped	Bin(9,0.5) <br> = (9 choose 7 ) * 0.5^9 <br> = (9*8)/2 * 0.5^9
When dealing with IQ values, add 0.5 to each IQ value	We do this because IQ values have to be whole numbers, and we have to compensate when an IQ is less than a certain number.
IQ example less than	IQ < 120 iff X <= 119, so use 119.5 as the x-value
IQ example between	between 90 and 140 inclusive. -> 89< x < 141 <br> values: 89.5, 140.5
IQ example exact value	IQ exactly 100. Use X-values 99.5, 100.5. <br> 0.5133-.4867 = 0.0266. <br> *Significant to know you have a low chance of having an exactly average IQ with our data from class.
Variance of an n-sided die	Var(z) = (n^2 - 1)/12
Bernouli System:	P and 1-P are the only results
p-hat = x/n	p-hat -number of successes x in the sample divided by the sample size n.
big P-hat = x/n	big P-hat - the random variable. little p-hat is the value for a particular sample.
Mean of P-hat equals	The expected value of p-hat. E[p-hat]
Standard deviation of p-hat:	"σ(P-hat) = sqrt(p(1-p)/n) or sqrt(p(p-1))/ sqrt(n) <br /><img src=""Tex2Img_1376793886.png"" />"
What IS the standard deviation of p-hat?	Sampling error measure. Increasing the sample size by a factor of n decreases  σ(P-hat) by a factor of sqrt(n)
iid means	Independent and identically distributed - no subset of the variables has any impact on another.
s.d of X1	is called  σ
Variance of a set Xn	= 1/n * Var(x1)
s.d. of a set Xn	σ(Xn) =  σ(x1)/sqrt(n) <br> = 1/sqrt(n) * sqrt(Var(x1))
Confidence Interval	(μ - moe, μ + moe) <br> μ = E[x]
Margin of Error (moe) =	moe = z-value * σ
Variance if sample size is large	σ^2 = p(1-p) ~=~ p-hat(1-p-hat)
Power of a Test, Condtionally Probability of a true positive	1-conditional probability of a false negative <br> = 1-Pr(test is negative | something is wrong)
Group that gets the placebo is	the control group <br> The test/experimental group gets the real product.
What's a parametric ReLU nonlinearity?	<div>\item $f(x) = x$ if $x &gt; 0$</div><div>\item $f(x) = ax$ if $x \leq 0$</div><div>\item where $a$ is channel-specific</div>
What's ReLU-Xavier initialization?	\item Initializing layer $l$ with variance $\frac{2}{(1+a^2)n_l}$ and zero bias<div>\item where $n_l$ is either</div><div>\item $n_l = k^2c$, with $k$ the kernel size and $c$ the number of input channels</div><div>\item $n_l = k^2d$, with $k$ the kernel size and $d$ the number of output channels</div><div>\item and $a$ is the PReLu coefficient, if it's being used</div>
What's the difference between Xavier and ReLU-Xavier initialization?&nbsp;	\item ReLU-Xavier takes the nonlinearity of the activation into account when setting the variance
Which layers is dropout usually used in?	\item All but the last fully-connected layer
What's a standard value for the weight decay in deep NNs?	\item 5E-4
What's the purpose of naming variables in Theano?	\item To help debugging; it's not strictly necessary
How can you print the graph behind a Theano variable?	\item \ttt{pp(x)} for brief output<div>\item \ttt{debugprint(x)} for detailed output</div>
Suppose you define a Theano expression \ttt{z = x + y}. How do you compile it?	\item \ttt{function([x, y], z)}
Suppose you define a Theano expression \ttt{z = x + y}. How do you execute it using \ttt{eval}?	\item \ttt{z.eval(\{x: 16.3, y: 12.1\})}
How does \ttt{eval} compare to \ttt{function} in Theano?	\item \ttt{eval} isn't as flexible<div>\item but it does cache the compiled code and can be cleaner</div>
What are the main groups of types available in Theano?	\item \ttt{scalar}<div>\item \ttt{vector}</div><div>\item \ttt{matrix}</div><div>\item \ttt{row}</div><div>\item \ttt{col}</div><div>\item \ttt{tensor3}</div><div>\item \ttt{tensor4}</div><div><br /></div>
What are the prefixes that can be used with Theano types?	\item \ttt{b}: byte<div>\item \ttt{w, i, l}: 16/32/64 bit integers</div><div>\item \ttt{f, d}: floats/doubles</div><div>\item \ttt{c}: complex</div>
How do you create a Theano expression that will evaluate multiple outputs?	\item \ttt{f = function([a, b], [a+b, a-b])}<div>\item Then \ttt{f(1, 3)} will return \ttt{[4, 2]}</div>
How can you create a Theano expression with a default argument?	\item \ttt{f = function([a, Param(b, default=val\_1)], a+b)}<div>\item Then \ttt{f} can be called as \ttt{f(5)} or \ttt{f(5, b=2)}</div>
How can you set the parameter name when creating a Theano expression with an argument that has a default value?	\item \ttt{f = function([a, Param(b, default=val\_1, name='bb')], a+b)}<div>\item Then \ttt{f} can be called as \ttt{f(5, bb=2)}</div>
How do you usually create a shared variable in Theano?	\item \ttt{shared(initial\_val)}<div>\item It'll iterate over the various \ttt{SharedVariable} subclasses until it finds one whose constructor will accept \ttt{initial\_val}</div>
How can you get and set the value of a shared variable in Theano?	\item \ttt{sv.get\_value()}<div>\item \ttt{sv.set\_value(new\_val)}</div>
How can you create a Theano function that updates a shared variable?	\item \ttt{function(args, f, updates=updater)}<div>\item where \ttt{updater} is either</div><div>\item a dict which maps shared variables to expressions representing their new value</div><div>\item an alist of \ttt{(shared\_var, new\_value\_expr)} pairs</div>
What's the use of shared variables in Theano?	\item They allow different functions to share state
What's the use of the \ttt{givens} parameter of \ttt{function} in Theano?	\item It allows arbitrary chunks of a formula to be replaced with other chunks<div>\item (as long as the new chunk is the same type and shape as the old one)<br /></div>
What's dangerous about the \ttt{givens} parameter to \ttt{function} in Theano?	\item The expressions that appear in \ttt{givens} should never be co-dependent, as the order of substitution is not defined
How are random variables created in Theano?	\item By creating a \ttt{rs = RandomStream}<div>\item then \ttt{rs.uniform(shape)} or similar</div>
How can you cause multiple calls to a Theano function to use the same random numbers?	\item By passing the \ttt{no\_default\_updates=True} argument to \ttt{function}
What's important to remember about the way random numbers are used in Theano?	\item A random variable is drawn from at most once during the evaluation of an expression<div>\item and if the variable appears more than once, the value will be reused!</div>
What's the use of a Theano \ttt{RandomStream}'s \ttt{state\_updates} attribute?	\item It keeps a list of the variables generated by the stream<div>\item which is useful for transferring random state between Theano functions</div>
What's an op node in Theano?	\item A node representing a computation, which takes some variables and returns others
What's an apply node in Theano?	\item A node in the computation graph which takes an op and applies it to some variables
What are the three kinds of nodes in a Theano graph?	\item variable nodes<div>\item op nodes</div><div>\item apply nodes</div>
Where is derivative information held in a Theano graph?	\item In the op nodes
Why will scalars frequently turn up as \ttt{InplaceDimShuffle}s or similar in Theano graphs?	\item Because the scalar has been broadcast to another shape in order to be compatible with some expression
How can you create a .png of a Theano computation graph?	\item \ttt{pydotprint(x)}
How do you calculate the gradient of an expression in Theano?	\item \ttt{T.grad(y, x)} will get the gradient of \ttt{y} in terms of {x}
What's \ttt{T} usually an import alias for when working with Theano?	\item \ttt{Tensor}
How do you calculate the Jacobian of a function in Theano?	\item Using \ttt{gradient.jacobian()}
What are \ttt{Rop, Lop} in Theano?	\item \ttt{Rop} is the R operator, $\frac{\partial f(x)}{\partial x}v$<div>\item \ttt{Lop} is the L operator, $v\frac{\partial f(x)}{\partial x}$</div>
What're the advantages of the R and L operators over computing the Hessian directly?	\item If you're able to use them, R and L are usually much faster
What's a mode in Theano?	\item A config setting that describes how functions should be compiled
How can you set the mode in Theano temporarily?	\item By passing the \ttt{mode} argument to \ttt{function}
How do you enable debug mode in Theano?	\item Pass \ttt{mode='DebugMode'} to \ttt{function}
What's the difference between \ttt{pickle} and \ttt{cPickle} in Python?	\item \ttt{cPickle} is much faster
When using \ttt{cPickle}, how can you ensure objects are stored efficiently?	\item By passing \ttt{protocol=cPickle.HIGHEST\_PROTOCOL} to \ttt{dump} when you write the file<div>\item Can make as much as an order of magnitude difference</div>
When writing Python pickles that'll be transferred across operating systems, what should you always do?	\item Open the pickle file in binary mode, \ttt{'b'}
How do you customize which parts of an object are saved and loaded by Python's \ttt{pickle}?	\item By implementing \ttt{\_\_getstate\_\_()}, \ttt{\_\_setstate\_\_()}
What're the differences between \ttt{IfElse} and \ttt{Switch} in Theano?	\item \ttt{IfElse} is lazy and takes a boolean<div>\item \ttt{Switch} is eager, takes a tensor and applies elementwise</div>
How do you implement loops in Theano?	\item Using \ttt{scan}
When using sparse matrices, when should \ttt{csr} or \ttt{csc} be preferred?	\item Use \ttt{csr} if there are more rows than columns
What do \ttt{csr} and \ttt{csc} stand for in Scipy?	\item Compressed sparse row and compressed sparse column formats, respectively
When running Theano code on the GPU, how can you suppress copies back to the host at the end of the computation?	\item Wrap the result in \ttt{gpu\_from\_host(x)}<div>\item which will be optimized away if \ttt{x} is already on the GPU</div>
Which Theano operations will be much faster on the GPU than the CPU?	\item Matrix mult<div>\item Convolution</div><div>\item Elementwise operations</div>
Which Theano operations will be no faster on the GPU than on the CPU?	\item Indexing<div>\item Dimension shuffling</div><div>\item Reshaping&nbsp;</div>
Which Theano operations will be a little slower on the GPU than on the CPU?	\item Summation over rows or columns
Why should you usually prefer \ttt{matrix, vector, scalar} constructors over \ttt{dmatrix, dvector, dscalar} in Theano?	\item The former will inherit their type from the \ttt{floatX} config setting<div>\item and so makes code easier to adapt to GPU</div>
How can you ensure that an often-accessed Theano variable is kept on the GPU?&nbsp;	\item By making it a \ttt{shared} variable, which are kept on the GPU by default
What's the effect of passing \ttt{borrow=True} to various methods in Theano?	\item It requests a reference be used rather than a copy<div>\item though there are circumstances - such as on the GPU - when it'll be ignored.</div>
What does it mean when you pass \ttt{borrow=True} to one of Theano's \ttt{In} or \ttt{Out} variables?	\item That Theano is allowed to overwrite than input/output
What's the effect of passing \ttt{return\_internal\_type=True} to various Theano methods?	\item Unlike \ttt{borrow=True}, it will \emph{always} return a reference to the variable<div>\item but the return type might change depending on circumstance!</div>
What's a common problem with shape computations in Theano?	\item Theano can frequently carry out optimizations that end up eliding checks that dimensions are compatible<div>\item This can be avoided by testing code in \ttt{DebugMode} or passing certain optimizer flags</div>
What's the best mode to set Theano's compiler in for iterative development?	\item \ttt{fast\_compile}
How can you print a debug statement from inside a Theano function?	\item \ttt{printing.Print('message')(variable)}<div>\item returns a wrapped variable which can be used as an ordinary variable</div><div>\item Might disable various optimizations however!</div>
How can you step through a compiled Theano function?	\item By using \ttt{MonitorMode}, which allows you to set callbacks that will be passed the inputs and outputs of every node
What config setting should always be used with Theano's \ttt{MonitorMode}?	\item \ttt{allow\_gc=False}, or the outputs to functions might be collected before the monitor gets to it
How do you profile Theano code?	\item By setting \ttt{config.profile=True}
"In the modified BNF used in the Python docs, what does \ttt{""a""...""z""} stand for?"	\item A choice of the characters `a' through `z'
In the modified BNF used in the Python docs, what does \ttt{&lt;text&gt;} denote?	\item A comment
What's the job of the lexical analyzer in Python?&nbsp;	\item To break a program into tokens, which will be fed to the parser
What are physical and logical lines in Python?	\item A physical line is some characters terminated by an end-of-line sequence<div>\item A logical line is one or more physical lines connected by line-joining rules</div>
How do you usually declare the character encoding in Python?	\item \ttt{\# -*- coding: utf-8 -*-}<br /><div>\item though this is emacs standard and there are other ways to do it, depending on the text editor</div>
What are the two line-joining rules in Python?	\item If the line ends with a backslash it'll be joined to the next one<div>\item If the line ends within a parenthesized/bracketed/braced expression, it'll be joined to the next one</div>
How does Python's lexical analyzer deal with tabs?	\item It replaces them left-to-right with the minimum number of spaces needed for the total number of characters to be a multiple of 8<div>\item (so if you've got space-tab, the tab will be replaced with 7 spaces)</div><div>\item (but for your sanity you shouldn't mix spaces and tabs)</div>
What does Python do when an invalid escape sequence appears in a string literal?	\item It leaves the sequence where it is
How does cPython deal with cyclically linked garbage?	\item It'll notice it eventually, but it isn't guaranteed to collect it promptly<div>\item This is why you shouldn't rely on finalization for freeing resources</div>
What are the two built-in mutable sequences in Python?	\item Lists<div>\item Byte arrays</div>
What does \ttt{b'string'} denote in Python 2.7?	\item The same as \ttt{'string'}; the \ttt{b} is only significant in Python 3, where it denotes a bytestring.<div>\item It's included in 2.7 for compatibility</div>
In Python, how do you get the module a function is in?	\item \ttt{f.\_\_module\_\_}
In Python, how do you get the default arguments for a function object?	\item \ttt{f.\_\_defaults\_\_}
In Python, how do you get the compiled code for a function?	\item \ttt{f.\_\_code\_\_}
In Python, how do you access the free variables of a function object?	\item \ttt{f.\_\_closure\_\_}
What are the \ttt{func\_name} etc attributes on function objects in Python 2.7?	\item They're old versions of \ttt{\_\_name\_\_} etc, which replaced them in Python 3 and have been backported to Python 2.7
How do you get the function object underlying a method in Python?	\item \ttt{m.\_\_func\_\_}
How do you get the \ttt{self} object of a bound method object in Python?	\item \ttt{m.\_\_self\_\_}
What's different about the implementation of unbound methods in Python 3 compared to Python 2?	\item In Python 3, they're just functions. Unbound methods don't exist.
In Python, what's a common problem with programmatically accessing the members of a module?	\item When the module \ttt{m} passes out of scope, the \ttt{m.\_\_dict\_\_} will be cleared even if the dict itself still has live references &nbsp;
What's a traceback in Python?	\item When an exception handler is entered, calling \ttt{sys.exc\_traceback} will return an item that allows you to navigate the stack that generated the exception
When will \ttt{\_\_getattr\_\_} be called in Python?	\item Only when the requested attribute can't be found through the normal mechanism
What's \ttt{\_\_getattribute\_\_} in Python?	\item An alternative to \ttt{\_\_getattr\_\_} for new-style classes which will \emph{always} be called
What are the methods of the descriptor protocol in Python?	\item \ttt{o.\_\_get\_\_(self, obj, type=None)}<div>\item \ttt{o.\_\_set\_\_(self, obj, value)}</div><div>\item \ttt{o.\_\_delete\_\_(self, obj)}</div>
What's the usual use of descriptors in Python?	\item To create reusable properties
How are descriptors used in Python?	\item By creating a class \ttt{Descriptor} which implements some part of the descriptor protocol<div>\item Then instantiating it as a field \ttt{desc = Desc()} at the class level of some object \ttt{o}</div><div>\item When \ttt{o.desc} is called, the descriptor protocol will go into action</div>
How can you use descriptors with unhashable objects in Python?	\item Have the descriptor initializer take and store a label equal to it's name in the owner's class<div>\item ie \ttt{x = Desc('x')}</div><div>\item then store any state associated with the owner under the label, ie \ttt{state['label'] = val}</div>
When using descriptors in Python, how can you access other methods on the descriptor?	\item By using the fact that when a descriptor attribute is accessed from the class level, the first argument to \ttt{\_\_get\_\_} is \ttt{None}<div>\item in which case you can redirect to \ttt{self}</div>
How do metaclasses intercept object construction in Python?	\item New-style classes are usually instantiated by calling \ttt{type.\_\_new\_\_()}<div>\item If a class defines \ttt{\_\_metaclass\_\_}, \ttt{\_\_metaclass\_\_.\_\_new\_\_()} will be called instead</div>
How can you intercept \ttt{issubclass} calls when using an ABC in Python?	\item By defining a \ttt{\_\_subclasshook\_\_} method in the ABC
When deriving from \ttt{dict} in Python, how can you define what should happen when a key is missing?	\item Implement \ttt{\_\_missing\_\_}
What are the magic methods behind the \ttt{in}/\ttt{not in} keywords in Python?	\item \ttt{\_\_contains\_\_}<div>\item or if it isn't defined, it'll try to iterate over the collection and see if any elements are equal</div>
How does scope work in Python?	\item The scope of a variable defined in a function block extends to any contained block<div>\item The scope of a variable defined in a class block is limited to the class block</div>
What are free variables in Python?	\item A variable is free in a block if it's used there but not defined there
What's a block's environment in Python?	\item The set of nearest enclosing scopes for each variable
If a name is defined at the module level in Python, what does it become automatically?	\item A global variable
What's the difference between a name and a binding in Python?&nbsp;	\item Names can be reused; in different scopes they may be bound to different values
Where is a name allowed to be used in a Python code block?	\item Anywhere in the block<div>\item (naming is different to binding! The name can be used before it's bound, it'll just throw an error)</div>
What's the effect of \ttt{global x} in Python?	\item It causes any uses of \ttt{x} within the same block, or from where the statement can be seen, to resolve to<div>\item the module namespace</div><div>\item the builtins namespace</div><div>\item the namespace of the module \ttt{\_\_builtin\_\_}</div>
How do you modify the builtin namespace in Python?	\item Import \ttt{\_\_builtin\_\_} and modify it's attributes<div>\item Do \emph{not} mess with \ttt{\_\_builtins\_\_}</div>
What's a generator expression in Python?	\item \ttt{(x for x in range(10))}<div>\item and it creates a generator</div>
What's a set comprehension in Python?	\item \ttt{\{x for x in range(10)\}}<div>\item which returns a set</div>
What's a string conversion in Python?	\item \ttt{`[x for x in range(10)]`}<div>\item which will evaluate the expression between the backticks and (attempt) to return a string that can then be passed to \ttt{eval} or \ttt{exec} as a valid Python expression</div><div>\item Only works for builtin types and builtin containers of builtin types</div>
What's the usual use of string conversions in Python?	\item It'll eat strings containing `funny' characters and return a string with them replaced with escape sequences that are safe to print
What's the difference between a Python generator and a coroutine?	\item Coroutines can dictate where execution should continue after it yields;&nbsp;<div>\item generators always yield to the caller</div>
What's the \ttt{throw} method of a Python generator do?	\item \ttt{throw(type)} will raise an exception of the specified \ttt{type} at the point where the generator was paused,&nbsp;<div>\item and returns the next value yielded by the generator&nbsp;</div>
What's the \ttt{close()} method of a Python generator do?	\item It'll raise a \ttt{GeneratorExit} exception at the point where the generator was paused<div>\item If the generator then raises a \ttt{StopIteration} or \ttt{GeneratorExit} in response, it'll be swallowed and \ttt{close} will return to the caller.</div>
What's the precendence of the power operator \ttt{(**)} in Python?	\item Higher than unary operators on its left; lower than that of unary operators on its right<div>\item Which means \ttt{2**-1} returns \ttt{0.5}<br /></div>
What's \ttt{//} in Python 3?	\item The floor division operator, which will round down a float result to an integer
How can you get the divisor and remainder of two numbers simultaneously in Python?	\item \ttt{divmod(a,b)}
How are left and right shifts defined in Python?	\item As divisions and multiplications by powers of 2
How are chained comparisons evaluated in Python?	\item \ttt{a &lt; b == c &gt;= d} is equivalent to \ttt{a &lt; b and b == c and c &gt;= d}<div>\item except that \ttt{a, b, c, d} are only evaluated once</div>
In Python, what order are the arguments to an assignment evaluated in?	\item Right hand side then left hand side
How do you run a Python module as a script from the commandline?	\item \ttt{python -m modulename}
How do you run pdb programmatically in Python?	\item \ttt{pdb.run('statement')}
How do you invoke pdb as a script from the commandline?	\item \ttt{python -m pdb scriptname.py}
How do you programmatically set a point to load the debugger when using pdb?	\item \verb|pdb.set_trace()|
How can you go into post-mortem debugging for the most recent traceback using pdb?	\item \ttt{pdb.pm()}
How can you specify the environment that a \ttt{pdb.run()} call should execute in?	\item \ttt{pdb.run(statement, globals, locals)}
Using pdb, how can you debug a function without having to write it as a string statement?	\item \ttt{pdb.runcall(f, args)}
How can you go into post-mortem debugging for any traceback in pdb?	\item \verb|pdb.post_mortem(traceback)|
How do you get the most recent traceback in Python?	\item \verb|sys.traceback|
How do you repeat the last command in pdb?	\item Enter a blank line
How can you enter multiple commands in a single line in pdb?	\item Seperate them with \verb|;;|<div>\item Note this isn't smart - it'll break at \verb|;;| in the middle of quoted strings!</div>
How can you execute a Python statement which shares a name with a pdb command when working in pdb?	\item \verb|!command|
How do you get help on a command in pdb?	\item \verb|h command|
How can you print a stacktrace when working in pdb?	\item \verb|w|<div>\item for `where'</div>
How can you move up or down the stack in pdb?	\item \verb|u, d|
How can you set a break at a certain line in the current file when working in pdb?&nbsp;	\item \verb|b 17|
How can you set a break at a certain line in another file when working in pdb?	\item \verb|b other_file.py:17|
How do you list the current breakpoints when working in pdb?	\item \verb|b|
How can you set a new conditional breakpoint when working in pdb's commandline?	\item \verb|b func, condition|
How can you set a break for a specific function when working in pdb's commandline?	\item \verb|b func|
How can you set a one-shot breakpoint when working in pdb's commandline?	\item \verb|tbreak 17|<div>\item standing for `temporary break'</div>
How do you permanently remove breakpoints when working from pdb's commandline?	\item Using \verb|cl|<div>\item for `clear'</div>
How do you enable or disable a breakpoint when working from pdb's commandline?	\item \verb|enable 3, disable 3|<div>\item to enable/disable breakpoint 3</div>
What's the ignore number of a breakpoint in pdb?	\item The number of times the breakpoint will be passed before activating<div>\item ie it'll activate when the ignore number is zero</div>
How do you set the ignore number of a breakpoint when working from pdb's commandline?	\item \verb|ignore 3 7|<div>\item will set breakpoint 3's ignore number to 7</div>
How do you set a condition on an already existing breakpoint when working in pdb's commandline?	\item \verb|condition 3 cond|<div>\item will set the conditon on breakpoint 3 to \verb|cond|</div>
How do you remove a condition from an already existing breakpoint when working from pdb's commandline?	\item \verb|condition 3|<div>\item will remove the condition from breakpoint 3</div>
How do you set up some commands to run every time a specific breakpoint is hit when working from pdb's commandline?	\item \verb|commands 3|<div>\item \verb|print some_variable|</div><div>\item \verb|end|</div><div>\item will print \verb|some_variable| every time breakpoint 3 is hit</div>
How do you move forward in pdb and stop at the first possible occasion?	\item \verb|s|<div>\item for `step'</div>
How do you move to the next line in the current function when working in pdb?	\item \verb|n|<div>\item for `next'</div>
When working in pdb, how can you run until you get to a strictly greater linenumber, or until you exit the frame?	\item \verb|unt|<div>\item for `until'&nbsp;</div>
When working in pdb, how can you run until the current function returns?	\item \verb|r|<div>\item for `return'</div>
When working in pdb, how can you run until the next breakpoint is reached?	\item \verb|c|<div>\item for `continue'</div>
When working in pdb, how can you jump forwards or backwards to a specified line number?	\item \verb|jump 17|<div>\item but this is only possible when you're at the bottom of the stack</div>
When working in pdb, how can you print the lines around the current line?	\item \verb|l|<div>\item for `list'</div>
When working in pdb, how can you list the arguments for the current function?	\item \verb|a|<div>\item for `args'</div>
When working in pdb, what are the two commands to print something?	\item \verb|p|, to print<div>\item \verb|pp|, to pretty-print</div>
How do you create an alias in pdb?	\item \verb|alias name command|<div>\item where command can contain \verb|%1, %2| to represent positional arguments</div><div>\item and \verb|%*| represents all arguments</div>
When working in pdb, how do you remove an alias?	\item \verb|unalias|
When using pdb to debug a script, how can you restart the program?	\item \verb|run|
When using pdb to debug a script, how can you restart the program with new arguments?	\item \verb|run args|
When working in pdb, how do you quit the debugger?	\item \verb|q|<div>\item for `quit'</div>
How can you put multiple statements on one line in Python?	\item \verb|s1; s2|
In a cProfile report, what does \verb|3/1| mean in the \verb|ncalls| column?&nbsp;	\item That the function recursed;<div>\item it made three total calls and one primative call</div>
At a high level, how do you use the \verb|pstats| module?	\item Profile some code and store the results in some file \verb|results|<div>\item Create \verb|p = pstats.Stats('results')|</div><div>\item Call various the methods of \verb|p|, then \verb|p.print_stats()|&nbsp;</div>
How can you get fine-tuned control over the profiler when using cProfile?	\item Create \verb|pr = cProfile.Profile()|<div>\item Call \verb|pr.enable()| to start collecting data</div><div>\item Call \verb|pr.disable()| to stop collecting data</div><div>\item Then call \verb|pr.print_stats()| to view the results</div>
How can you supply local and global variables to a profiled command when using cProfile?	\item \verb|cProfile.runctx(command, globals, locals)|
How can you get a list of all callers of the functions profiled in a cProfile \verb|Stats| object?	\item Use \verb|stats.print_callers()|
How can you get a list of all the functions called by some functions profiled in a cProfile \verb|Stats| object?	\item Use \verb|stats.print_callees()|
What's the difference between deterministic and statistical profiling?	\item Deterministic profiling monitors everything<div>\item Statistical profiling samples the instruction pointer</div>
What's the easiest way to programmatically time small chunks of code in Python?	\item \verb|timeit.timeit(command, number=num_of_repeats)|
When using Python's \verb|timeit| module, how can you initialize the environment before the timed code is run?	\item Pass a command via the \verb|setup| parameter
What are the main sections of a numpy-style docstring?	\item One-line summary<div>\item Extended summary of functionality</div><div>\item Parameters</div><div>\item Returns</div><div>\item Raises</div><div>\item Notes on implementation</div><div>\item Examples</div>
In a numpy-style docstring, how should parameters be formatted?	\item \verb|param_name : type| \\<div>\verb| &nbsp; &nbsp;Description, detailed if necessary|</div>
In the descriptions of a numpy-style docstring, how should programmatic names be denoted?	\item Using backticks: \verb|`x`|
What's a repository in Git?	\item A collection of commits
What's a commit in Git?	\item A snapshot of the working tree
What's the index in Git?	\item Where changes are registered before doing a commit<div>\item Also known as the staging area</div>
What's a working tree in Git?	\item A directory which has a repository, along with all the contained subfolders and files
How is the parent of a commit defined in Git?	\item It's the state of HEAD when the commit is made
What's a branch in Git?	\item A name for a commit (which commit it names might change)<br /><div>\item Also called a reference</div>
What's a tag in Git?	\item A name for a commit which doesn't change
What's \verb|**master**| in Git?	\item The branch on which mainline development is done. Typically \verb|default|
What's HEAD in Git?	\item It's a name which defines what's currently checked out<br />
What's HEAD when a branch is checked out in Git?	\item It's a symbolic reference to the branch<div>\item indicating the branch should be updated after the next commit operation</div>
What's a detached HEAD in Git?	\item It's what happens when you check out a specific commit rather than a branch<div>\item The HEAD then refers to that commit only</div>
What's an i-node in Unix?	\item An index node; a datastructure used to represent an object in a filesystem<div>\item Contains most of the metadata about the associated object (like size and modification date)</div>
What's a blob in Git?	\item How Git represents a file's contents<div>\item Identified by it's hash</div>
How can you get the hash of a file using Git?	\item \verb|git hash-object filename|
When passing a hash to Git, what's a useful time-saving idiom?	\item Only give the first 5-6 digits of the hash<div>\item That's all Git will need to find the object most of the time</div>
How can you get the type of a Git object?	\item \verb|git cat-file -t obj|
How can you list the objects in a tree in Git?	\item \verb|git ls-tree object|
How do trees relate to commits in Git?	\item Each commit holds a single tree
How do trees relate to blobs in Git?	\item Trees hold blobs
When are blobs created in Git?	\item When a novel file is added to the index
What are the steps that happen in the background when a Git commit is made?	\item The current index is used to make a tree<div>\item The tree is made into a commit</div><div>\item The branch is updated to refer to the new commit</div>
How does garbage collection work in Git?	\item Any commit not currently referred to,&nbsp;<div>\item and which isn't the child of a reachable commit</div><div>\item will be destroyed</div>
How can you refer to the parent of a commit in Git?	\item \verb|name^|
How can you refer to the second parent of a commit with multiple parents in Git?	\item \verb|name^2|
How can you refer to the 7th ancestor of a commit in Git?	\item \verb|name~7|
How can you refer to a file in a specific commit in Git?	\item \verb|commitname:filepath|
How can you refer to all commits reachable from \verb|name1| up to \verb|name2| in Git?	\item \verb|name1..name2|<div>\item The range is open on the right</div>
How can you refer to all commits reachable from the current head up to some commit \verb|name|?	\item \verb|..name|
How can you get all the commits unique to two branches \verb|name1, name2| in Git?	\item \verb|name1...name2|
How can you refer to all commits in the past two weeks in Git?	"\item \verb|-since=""2 weeks ago""|"
How can you refer to all commits matching a regexp of the commit message?	\item \verb|-grep=pattern|
Which way do the pointers run in a Git commit history?	\item From children to parents only!
What's a merge commit in Git?	\item A commit with more than one parent
How do you merge branches \verb|A, B| in Git so that \verb|A| points to the merge commit?	\item \verb|git checkout A|<div>\item \verb|git merge B|</div><div>\item \verb|A| will now point to the merge commit&nbsp;</div>
What's the base of two branches \verb|A, B| in Git?	\item The most recent commit they have in common
When should you rebase and when should you merge in Git?	\item Rebase when it's a local branch with no other branches off it<div>\item Merge in all other cases</div>
If you've got two Git branches \verb|B, C| with common parent \verb|A|, how can you rebase so that \verb|A-&gt;B-&gt;C|?	\item \verb|git checkout C|<div>\item \verb|git rebase B|</div>
What are the options when rebasing interactively in Git?	\item \ttt{pick}, apply the commit to its (rewritten) parent<div>\item \ttt{squash}, fold the commit into its parent</div><div>\item \ttt{edit}, return to the shell with the working tree set to reflect progess up to \&amp; including the commit</div><div>\item \ttt{(drop)}, throw away the commit permanently</div>
How do you rebase interactively in Git?	\item \verb|rebase -i branchname|<div>\item Then when you drop out to edit, resume later with \verb|rebase --continue|</div>
When should you use \verb|reset| in Git?	\item Almost never. Use the stash \&amp; branches instead.
What's the reflog in Git?	\item A chronological list of all the commits made in the past 30 days
What does \verb|stash| do in Git?	\item Creates a commit from the current working tree and adds it to the stash
How do you apply the 5th oldest stashed commit in Git?	\item \verb|git stash apply stash@{5}|
How can you list all the commits in the stash in Git?	\item \verb|git stash list|
What's a good habit to get into at the end of each day with Git?	\item Stashing your current working tree
What's the training objective of a skip-gram model?	\item To find word representations that are useful for predicting the surrounding words in a sentence or document
What's the usual problem with using a traditional logistic regression for NLP problems?	\item The number of possible words is huge, making the $O(m)$ calculation of its value or gradient very expensive&nbsp;
What's the hierarchical softmax?	\item Structure possible outputs as leaves of a tree<div>\item and define vectors $w_i$ for each node or leaf $i$ in the tree</div><div>\item Then given an input $x$, the probability of an output $y$ at the end of a path $L$ is</div><div>\item $p(y|x) = \prod_{i \in L} \text{sigm}(w_i \cdot x)$</div><div>\item where $v_x$ is the encoding of $x$</div>
What's the advantage of the hierarchical softmax?	\item Calculating its value or gradient needs only $O(\lg m)$ operations
How is the tree for hierarchical softmax usually constructed?	\item As a Huffman tree
What's negative sampling in NLP?	\item Trying to maximize the training objective&nbsp;<div>\item $\text{sigm}(w_i \cdot x_i) \cdot \prod_{j=1}^k \text{sigm}(-w^\prime_j \cdot x_i)$</div><div>\item where&nbsp;</div><div>\item $w$ is the correct output</div><div>\item $w^\prime_j \sim P$ are samples from the noise distribution $P$</div>
When implementing negative sampling in NLP, what's the usual noise distribution to use?	\item The unigram distribution with the frequencies taken to the power of $\frac{3}{4}$
What's an easy way to deal with too-frequent words when training a language model?	\item Discard word $w_i$ with probability&nbsp;<div>\item $p(w_i) = 1 - \sqrt{t/f(w_i)}$</div><div>\item where</div><div>\item $f(w_i)$ is the frequency of word $i$</div><div>\item $t$ is a threshold of $\approx 10^{-5}$</div>
How many negative samples are usually used when training language models?&nbsp;	\item $2$ to $20$, with fewer needed the larger the dataset is
What other technique does negative sampling approximate in NLP?	\item Noise contrastive estimation, which uses probabilities to refine the approximation of the noise distribution&nbsp;
What's a simple way to teach a NLP model phrases?	\item Score word pairs as<div>\item $\text{score}(w_i, w_j) = \frac{n_{ij} - \delta}{n_i n_j}$</div><div>\item where $\delta$ is a discounting coefficient to suppress infrequent words</div><div>\item and replace any pairs above the threshold with a unique token</div><div>\item Then train the model on the revised dataset</div>
What's internal covariate shift in neural networks?	\item The way in which the input distribution of a layer changes during training due to the weights of the previous layer shifting
What's a batch normalization layer in NNs?	\item It normalizes each input $x_i$ to the mean 0 and variance 1 $\hat x_i$ with respect to the minibatch<div>\item then outputs $\gamma \hat x_i + \beta$</div><div>\item where $\beta, \gamma$ are learnable parameters&nbsp;</div>
How are batch normalization layers used during inference?	\item The minibatch normalization is replaced with $\hat x = (x - E[x])/\sigma_x$<div>\item where the mean and variance are estimated from the population</div>
What steps usually go hand-in-hand with adding batch normalization layers to an existing network?	\item Increase the learning rate<div>\item Accelerate learning rate decay<br /><div>\item Remove dropout</div><div>\item Reduce weight regularization</div></div><div>\item Remove LRNs</div><div>\item Reduce input jittering</div>
What's the Johnson-Lindenstrauss lemma?	\item Given a set of $m$ points in $\mbb{R}^N$,&nbsp;<div>\item if $n &gt; 8\ln m/\epsilon^2$&nbsp;</div><div>\item then there's a linear embedding of the points into $\mbb{R}^n$ which $\epsilon$-preserves the distances between them</div>
How can the covariance be interpreted in terms of the multiplicativity of the expectation?	\item The covariance is the amount by which the multiplicitivity of the expectations fails
What's a good distance function for comparing histograms?&nbsp;	\item The earth-mover distance
What's saturation arithmetic in OpenCV?	\item The way in which a float intensity is taken to a (for example) 8-bit value by rounding it then clamping to $0$-$255$
How do you apply a lookup table to an array in OpenCV?	\item \verb|LUT(arr, lut)|
How do you calculate an arbitrary linear transformation of the colors of an image in OpenCV?	\item \verb|transform(src, transform_matrix)|&nbsp;
How do you usually deal with image boundary problems in OpenCV?	\item By using \verb|copyMakeBorder| to construct a mirrored/wrapped/etc border around an image
What's the idea in the bilateral filter?	\item Iteratively replace each pixel with a weighted mean of its locality<div>\item But weight pixels with `similar' intensities/colors more than ones with dissimilar intensities/colors&nbsp;<br /></div>
What's the use of the bilateral filter?	\item Edge-preserving noise reduction
What's a box filter?	\item A rectangular filter of constant value&nbsp;
What's a pyramid in image processing?	\item A technique where the image is repeatedly smoothed then scaled down
What's dilation in image processing?	\item Replacing each pixel in a greyscale image with the local maximum
What's erosion in image processing?	\item Replacing each pixel in a greyscale image with the local minimum
What's opening in image processing?	\item An application of erode-dilate, in that order&nbsp;<div>\item So named because it'll break apart regions which are thinly connected</div>
What's closing in image processing?	\item An application of dilate-erode, in that order<div>\item So named because it'll `close' small holes.</div>
What's the morphological gradient in image processing?	\item The dilated image minus the eroded image
What's the top hat operation in image processing?	\item The image minus the opened image
What's the black hat operation in image processing?	\item The closed image minus the source image
What's the use of the Scharr kernel?	\item It's the Sobel kernel adapted to have rotational symmetry<div>\item which makes it much better for optical flow</div>
What's matting in image processing?	\item Like masking, but real-valued<div>\item For use with hair/fluff/translucent images</div>
What's the mean-shift algorithm?	\item A way to find maxima of a density function<div>\item The position of each point is iteratively replaced with a weighted average of the positions of the points in its neighbourhood</div><div>\item until it's converged</div>
How is the meanshift algorithm usually applied to images?	\item Both color and position over the color/space neighbourhood are averaged<div>\item And the next iteration will use the position used by the last one as the center</div><div>\item At the end, the average color is mapped back to the original pixel</div>
How should geometric transformations be applied to images?	\item By calculating an inverse transformation from the destination pixels to source space first<div>\item then interpolating in the source space for non-existant locations<br /></div><div>\item This suppresses certain kinds of artifact that the naive forward transformation is prone to</div>
How do you implement arbitrary geometric transformations in OpenCV?	\item Using \verb|remap|
What's the geometric constraint on a projective transformation?	\item It must preserve straight lines
What are homogeneous coordinates?	\item Coordinates of points in projective space<div>\item $(kx, ky, k) \sim (x, y, 1)$, $k \neq 0$</div>
In homogeneous coordinates, what're the conventional points at infinity?	\item $(x, y, 0)$
In projective space, what's special about the points at infinity?	\item Nothing.
How's affine geometry defined in terms of projective geometry?	\item By selecting a distinguished line as the line at infinity
Geometrically, which projectivities are affinities?	\item The ones that preserve the distinguished line
What's the equation for a circle in homogeneous coordinates?	<div>\item A circle centered on $(a, b, 1)$ is the set of points $(x, y, w)$ that satisfy</div>\item $(x - aw)^2 + (y - bw)^2 = r^2w^2$
What are the circular points in 2D Euclidean homogeneous coordinates?	\item They're the points $(1, \pm i, 0)$ which every circle passes through
How's Euclidean geometry defined in terms of 2D projective geometry?	\item By selecting a line at infinity and two circular points on it
What's the absolute conic?	\item It's the equation $X^2 + Y^2 + Z^2 = 0, T = 0$ that any sphere in 3D projective geometry satisfies
How is 3D Euclidean geometry defined in terms of projective geometry?	\item By selecting a plane at infinity and an absolute conic
Conventionally, how does central projection map $\mbb{P}^3$ to $\mbb{P}^2$?	\item $(X, Y, Z, T) \rightarrow (X, Y, Z)$
What's the form of the camera matrix?	\item It's a $3 \times 4$ rank 3 matrix taking $\mbb{P}^3$ to $\mbb{P}^2$
When are different images related by a plane projective transformation?	\item When they share the same camera center<div>\item When the space points are coplanar</div>
What's the IAC in camera geometry?	\item Image of the absolute conic;<div>\item the curve induced on the image plane by the absolute conic</div>
In terms of camera geometry, when is a camera said to be calibrated?	\item When the location of the IAC in an image is known
Without calibration information, what ambiguity occurs in the reconstruction of space points from point correspondences in two images?	\item The space points are only unique up to a projective transformation<div>\item since for a camera matrix $P$ and point $X$, $PX = (PH^{-1})(HX)$ for any projective transformation $H$</div>
What's a projective reconstruction of a scene?	\item A reconstruction of the space points which is unique up to a projective ambiguity
In general, how many points are needed to create a projective reconstruction of a scene from point correspondances between two images?	\item Seven
At a high level, what's the fundamental matrix of two cameras?	\item The unique $3 \times 3$ matrix $F$ of rank 2&nbsp;<div>\item such that for all pairs of image points $x, x^\prime$,&nbsp;<div>\item $x^{\prime T} F x = 0$</div></div>
At a high level, what's the trifocal tensor of three cameras?	\item It's the $3 \times 3 \times 3$ tensor $\mc{T}^{jk}_i$<br /><div>\item such that for point $x$ in one camera and lines $l^\prime, l^{\prime\prime}$ in the other two</div><div>\item $\mc{T}_i^{jk}&nbsp;x^i l^\prime_j l^{\prime\prime}_k = 0$</div>
Are vectors covariant or contravariant?	\item Contravariant.
In Einstein notation, do upper indices indicate the components of covariant or contravariant vectors?	\item Contravariant vectors
In Einstein notation, do lower indices indicate the components of covariant or contravariant vectors?	\item Covariant vectors
What're the advantages of three-view reconstruction over two-view?	\item Three view allows a mixture of lines and points to be used<div>\item Three view reconstructions are more stable</div><div>\item Only six correspondances are needed</div>
Given a point correspondence in a three-view reconstruction problem, how do you find the lines that can be used with the trifocal tensor?	\item Any line that passes through one of the points will do
What's the internal constraint on the fundamental matrix in camera geometry?	\item $\det F = 0$
When is it permissible to use an affine camera rather than a projective camera?	\item When the distance between the front and back of the scene is negligible compared to the distance to the scene
What's the transfer problem in camera geometry?	\item Given the positions of a set of points in some images<div>\item find out where other points in one image map to in the others</div>
How are 2D lines represented in homogeneous coordinates?	\item $ax + by + c = 0$ becomes $(a, b, c)$
In homogeneous coordinates, when does a point $x$ lie on a line $l$?	\item When $x \cdot l = 0$
In homogeneous coordinates, how can you find the intersection between two 2D lines?	\item $x = l \times l^\prime$
In 2D homogeneous coordinates, how do you find the line through two points?&nbsp;	\item $l = x \times x^\prime$
What are the ideal points of a projective space?	\item The points with final coordinate $0$
What's the canonical line at infinity in 2D homogeneous coordinates?	\item $l_\infty = (0, 0, 1)$
What's the duality principle for 2D projective geometry?	\item Any theorem of 2D projective geometry still holds when the roles of lines and points are exchanged
What's the equation of a conic in homogeneous coordinates?	\item $\langle x, x \rangle_C = 0 $<br />
How many points define a conic?	\item Five<div>\item (the matrix $C$ has six parameters, minus one dof for scale)</div>
In homogeneous coordinates, what's the tangent line to a conic $C$ at $x$?	\item $l = x^TC^T$
Algebraically, what's the dual conic to $C$?	\item It's the adjoint $C^*$ for which every tangent line $l$ to $C$ satisfies $l^T C^* l = 0$
What's another name for the dual conic?	\item The conic envelope
In terms of its matrix, when is a conic degenerate?	\item When $C$ is not of full rank
What're three other names for projective transformations?	\item Projectivities<div>\item Homographies</div><div>\item Collineations</div>
Algebraically, when is a mapping a homography?	\item When there's a matrix $H$ that implements it over homogeneous coordinates
In terms of $\mbb{R}^3$ rays, how can a projectivity of $\mbb{P}^2$ be interpreted?	\item As a linear transformation of $\mbb{R}^3$
What's a perspectivity?	\item A projectivity that takes one Euclidean coordinate system to another
Under a projectivity with point transformation $x^\prime = Hx$, how are lines transformed?	\item $l^\prime = l H^{-1}$
Under a projectivity with point transformation $x^\prime = Hx$, how are conics transformed?	\item $C^\prime = (H^{-1})^T C H^{-1}$
What's a good example to show that vectors transform contravariantly?	\item Suppose your transformation is meters to centimeters, dividing the scale by 100<div>\item All the vector components are multiplied by 100</div>
When forming a basis out of vectors, are they usually stacked horizontally or vertically?	\item Horizontally: $B = [b_1, b_2, \cdots, b_n]$
How is $PL(n)$ defined in terms of $GL(n)$?	\item It's $GL(n)$ with matrices related by a scalar multiplication identified
In terms of transformation matrices, how is the affine group defined in terms of the projective linear group?	\item It consists of the members of the projective linear group whose last row is $(0, 0, \dotsc, 0, 1)$&nbsp;
How is the Euclidean group defined in terms of the affine group?	\item It consists of the members of the affine group for which the top-left submatrix is orthogonal
How is the oriented Euclidean group defined in terms of the Euclidean group?	\item It consists of the members of the Euclidean group whose top-left submatrix has determinant 1&nbsp;
How can a planar Euclidean transformation be written in terms of homogeneous coordinates?	\item $x^\prime = \left[ \begin{matrix} R &amp; t \\ 0 &amp; 1 \end{matrix} \right]$<div>\item where $R$ is an orthonormal matrix and $t$ is a translation</div>
Which group characterizes the isometries?&nbsp;	\item The Euclidean group
What are the usual invariants of the Euclidean group?	\item Length<div>\item Angle</div><div>\item Area</div>
What's a similarity transformation in camera geometry?	\item An isometry composed with an isotropic scaling
What's another name for similarity transformations in camera geometry?	\item Equi-form transformation&nbsp;<div>\item because it preserves form</div>
What are the usual invariants of similarity transformations in camera geometry?	\item Angles<div>\item Length ratios</div><div>\item Area ratios</div>
What's the phrase `metric structure' mean in camera geometry?	\item That the structure is defined up to a similarity transformation
How can a 2D affine transformation be written in terms of homogeneous coordinates?	\item $x^\prime = \left[ \begin{matrix} A &amp; t \\ 0 &amp; 1 \end{matrix} \right]$<div>\item where $A$ is nonsingular and $t$ is a translation</div>
What's a good way of interpreting the action of a linear transform in 2D?	\item Use the SVD to decompose it as<div>\item $A = R_\theta D R_{\phi}$&nbsp;</div><div>\item so it's a rotation, a scale along the axes, then a second rotation</div>
What are the invariants of an affine transform?	\item Parallel lines<div>\item Length ratios of parallel lines</div><div>\item Area ratios</div>
What's the result concerning how many functionally independent invariants a geometric transformation has?	\item There's at least as many functionally independent invariants<div>\item as the number of dof of the configuration of points</div><div>\item minus the number of dof of the transformation</div>
What're the three main invariants of a projective transformation?	\item The cross ratio<div>\item The order of contact&nbsp;</div><div>\item Straight lines</div>
What's the cross-ratio of four collinear points?	\item $(A, B; C, D) = \frac{AC \cdot BD}{BC \cdot AD}$<div>\item where $XY$ denotes the signed distance from $X$ to $Y$ along the line</div>
What are concurrent lines?	\item Lines passing through the same point
What're two popular realisations of the topology of $\mbb{P}^2$?	<div>\item A sphere with opposite points identified</div>\item A disk with opposite points on the boundary identified
When is the line at infinity preserved by a projective transformation?	\item Exactly when it's an affinity
Given an image distorted by a projectivity, how can you remove the projective part, leaving only an affine distortion?	\item Identify the line at infinity and find the transformation that takes it to $(0, 0, 1)$
What are the two usual ways to find the line at infinity in an image?	\item Find the intersections of two pairs of parallel lines<div>\item Use the length ratios of two triples of regularly-spaced collinear points</div>
Given a 2D image distorted by an affinity, geometrically, how can you remove the affine part, leaving only a similarity?	\item Identify the circular points and find the transformation that maps them to $(1, \pm i, 0)$
When are the circular points of an image fixed under a projectivity?	\item Exactly when the transformation is a similarity
What do $I, J$ usually denote in camera geometry?&nbsp;	\item The circular points<div>\item $I = (1, i, 0)$</div><div>\item $J = (1, -i, 0)$</div>
What's the conic dual to the canonical circular points in a Euclidean coordinate system?	\item $C_\infty^* = \left( \begin{matrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{matrix} \right)$
When is the dual conic fixed under a projective transformation?	\item Exactly when the transformation is a similarity
How does the line at infinity $l_\infty$ relate to the dual conic of the circular points, $C_\infty^*$?	<div>\item $l_\infty$ generates $C_\infty^*$'s nullspace</div>\item $C_\infty^* l_\infty = 0$
How do you calculate the angle between two lines $l, m$ in 2D that are subject to a perspective transform?	\item $\cos \theta = \frac{\langle l, m \rangle_{C_\infty^*}}{\|l\|_{C_\infty^*} \|m\|_{C_\infty^*}}$
Why's the black hat transform so named?	\item It returns an image containing objects which are smaller than the structuring element and darker than their surroundings
Why's the white hat transform so named?	\item It returns an image containing objects which are smaller than the structuring element and brighter than their surroundings
What's the white hat transform another name for?	\item The top hat transform
How does the dual conic transform under a point transformation $x^\prime = Hx$?	\item $C^{*\prime}_\infty = HC^*_\infty H^T$
When decomposing a 2D projectivity into three matrices, what's the similarity matrix $H_S$?	<div>\item $H_S = \left( \begin{matrix} sR &amp; \mb{t} \\ \mb{0}^T &amp; 1 \end{matrix} \right)$</div>
When decomposing a 2D projectivity into three matrices, what's the affinity matrix $H_A$?	<div>\item $H_A = \left( \begin{matrix} K &amp; \mb{0} \\ \mb{0}^T &amp; 1 \end{matrix} \right)$</div>
When decomposing a 2D projectivity into three matrices, what's the projection matrix $H_P$?	\item $H_P = \left( \begin{matrix} I &amp; \mb{0} \\ \mb{v}^T &amp; v \end{matrix} \right)$
Having decomposed a 2D projectivity into matrices $H_S, H_A, H_P$, how do you reconstruct the full matrix?	\item $H = \left( \begin{matrix} sRK + \mb{tv}^T &amp; \mb{t} \\ \mb{v}^T &amp; v \end{matrix} \right)$
Given the matrix of the dual conic, how do you recover the projective distortion that generated it?&nbsp;	\item Eigendecompose $C_\infty^*$.&nbsp;<br /><div>\item $\Lambda^{1/2}U$ is the matrix of the projectivity</div>
When are two projectively-distorted 2D lines orthogonal?	\item When $l^T C^*_\infty m = 0$<div>\item where $C^*_\infty$ is the dual conic of the projectivity</div>
Geometrically, what's the polar of a conic $C$ and point $x$?	\item The polar line $l$ intersects the conic at two points<div>\item The tangents to the conic at these points intersect at $x$</div>
Algebraically, how do you find the polar of a conic $C$ and point $x$?	\item $l = x^TC$<div>\item in homogeneous coordinates</div>
What's a correlation in projective geometry?	\item It's an invertible map between lines and points<div>\item represented in homogeneous coordinates by $l = x^TA^T$</div>
Algebraically, what are conjugate points in projective geometry?	\item Given a conic $C$, points $x, y$ are conjugate when $\langle x, C y \rangle = 0$
Geometrically, when are points $x, y$ conjugate with respect to conic $C$?	\item When $x$ is on the polar of $y$&nbsp;<div>\item or equivalently, when $y$ is on the polar of $x$</div>
How are conics classified according to the number of intersections they have with $l_\infty$?	\item Ellipses have no real intersections with $l_\infty$<div>\item Parabolas have one real intersection with $l_\infty$</div><div>\item Hyperbolas have two real intersections with $l_\infty$</div>
How are the fixed points and lines of a 2D projectivity characterized?	\item The fixed points ($x^\prime = Hx$) and fixed lines ($l^\prime = l^\prime H^T$) form a triangle<div>\item Note they may be complex</div>
What's $\pi_\infty$ denote in projective geometry?	\item The plane at infinity in $\mbb{P}^3$
What structure are points dual to in $\mbb{P}^3$?<br />	\item Planes
What structure are lines dual to in $\mbb{P}^3$?	\item Lines
When does a point $X$ lie on a plane $\pi$ in $\mbb{P}^3$?	\item When $\pi \cdot X = 0$
How can you test when a point $X$ lies on a plane defined by $X_1, X_2, X_3$ in $\mbb{P}^3$?	<div>\item Let $M =&nbsp;[X,&nbsp;X_1, X_2, X_3]$</div>\item When $X$ is on the plane, $\text{det} M = 0$&nbsp;<div>\item (in homogeneous coordinates)</div>
Under the point transformation $X^\prime = HX$, how does a plane $\pi$ of $\mbb{P}^3$ transform?	\item $\pi^\prime = \pi H^{-T}$
How is a line in $\mbb{P}^3$ defined in terms of the span of two points $A, B$?	\item Form $W = [A, B]$<div>\item Then the span of $W$ is the line connecting $A, B$</div>
How is a line in&nbsp;$\mbb{P}^3$ characterized in terms of the nullspace of two planes $P, Q$?	\item Form the matrix $W^* = \left[ \begin{matrix} P \\ Q \end{matrix} \right]$<div>\item Then the nullspace of $W$ is the line of intersection</div>
What's the Plucker matrix of two points $A, B$ in&nbsp;$\mbb{P}^3$?	\item $L = AB^T - BA^T$
What's the form of a Plucker matrix in $\mbb{P}^3$?	\item It's a skew-symmetric rank 2 matrix
What's the use of the Plucker matrix of two points $A, B$ in&nbsp;$\mbb{P}^3$?	\item It characterizes the line through $A, B$.
Given Plucker matrix $L$ of a line and a plane $\pi$, what does $L^T \pi^T$ describe?	\item The point of intersection between the line and the plane
What's the dual Plucker matrix of two planes $P, Q$ in&nbsp;$\mbb{P}^3$?	\item $L^* = P^TQ - Q^TP$
What's the use of the dual Plucker matrix of two planes $P, Q$ in&nbsp;$\mbb{P}^3$?	\item It characterizes the line of intersection between $P,Q$.
Given the dual Plucker matrix $L^*$ of a line, what does $X^T L^*$ describe?	\item The plane through the line and the point $X$
What are the Plucker coordinates of a line in&nbsp;$\mbb{P}^3$?	\item If the Plucker matrix of the line is $L$, then the Plucker coordinates are<div>\item $\mc{L} = [l_{12}, l_{13}, l_{14}, l_{23}, l_{42}, l_{34}]$</div><div>\item where $l_{42}$ is used instead of $l_{24}$ to suppress various negatives in common formulas</div>
When does a 6-vector $\mc{L}$ give the Plucker coordinates for a line in $\mbb{P}^3$?&nbsp;	\item When $( \mc{L} | \mc{L} ) = 0$<br />
In terms of Plucker coordinates, when are two lines in $\mbb{P}^3$&nbsp;coplanar?	\item When $( \mc{L}| \mc{\hat L}) = 0$
How is the inner product on Plucker coordiantes defined?	\item $(\mc{L}|\mc{\hat L}) = \begin{matrix} l_{12}\hat l_{34} + l_{13}\hat l_{42} + l_{14}\hat l_{23} \\<div>&nbsp; &nbsp;\hat l_{12} l_{34} + \hat l_{13} l_{42} + \hat l_{14} l_{23} \end{matrix}$</div><div>\item (follows from $(\mc{L}|\mc{\hat L}) = \det[A, B, \hat A, \hat B]$)</div>
Given a Plucker matrix $L$, how do you get the dual Plucker matrix $L^*$?	<div>\item Exchange the elements at coordinates</div>\item $12 \leftrightarrow 34$<div>\item $13 \leftrightarrow 42$</div><div>\item $14 \leftrightarrow 23$</div><div>\item ie replace coordinate $i, j$ with coordinates not-$i$, not-$j$</div>
What's the geometric interpretation of the Plucker coordinates of a line?	\item The Plucker coordinates for a line represent a point in $\mbb{P}^5$ on a 4-dimension surface called the Klein quadric&nbsp;
How many points define a quadric?	\item Nine
What's a quadric?	\item A co-dimension 1 surface defined by the roots of a quadratic
What's the polar of a point $X$ and a quadric $Q$ in $\mbb{P}^3$?	\item It's the plane $\pi = X^TQ$&nbsp;<div>\item such that the points of contact between $\pi$ and $Q$&nbsp;<div>\item are the same as points on $Q$ whose tangents pass through $X$</div></div>
Given a plane $\pi$ and quadric $Q$ in $\mbb{P}^3$, how do you characterize the points of intersection?	\item Pick a basis $M$ that takes points in the plane $x$ to points in the space $X = Mx$&nbsp;<div>\item Then the $x$ on the intersection are those satisfying $(Mx)^T Q (Mx) = 0$</div>
What's the dual of a quadric $Q$?	\item A quadric which is an equation on planes, defined by the adjoint $Q^*$&nbsp;
How are quadrics classified in terms of their matrix?	\item By the signs of the eigenvalues
How are conic curves in $\mbb{P}^2$ usually parameterized?	\item $x = A\left( \begin{matrix} 1 \\ \theta \\ \theta^2 \end{matrix} \right)$<div>\item for some non-singular matrix $A$</div>
How are twisted cubic curves in $\mbb{P}^3$ usually parameterized?<br />	\item $X = A\left( \begin{matrix} 1 \\ \theta \\ \theta^2 \\ \theta^3 \end{matrix} \right)$<div>\item for some non-singular matrix $A$</div>
Given two nondegenerate twisted cubics, what kind of transformation will take one to the other?	\item A projectivity
How do twisted cubics and planes interact?	\item They'll intersect at three points
What's the idea in the screw decomposition?	\item Any Euclidean transformation can be decomposed into a rotation around the `screw axis' and a translation along that axis
What's the canonical position of the plane at infinity in $\mbb{P}^3$?	\item $\pi_\infty = (0, 0, 0, 1)$
What do the circular points $I, J$ in&nbsp;$\mbb{P}^2$ correspond to in&nbsp;$\mbb{P}^3$?	\item The points at which the absolute conic $\Omega_\infty$ intersects any given circle
What's the geometric form of the absolute conic?	\item It's a conic of purely imaginary points lying in the plane at infinity
How do you measure the angle between two lines in&nbsp;$\mbb{P}^3$ if they're distorted by a projectivity?	\item Let $d_1, d_2$ be the intersections of the lines with $\pi_\infty$<div>\item Then&nbsp;</div><div>\item $\cos \theta = \frac{\langle d_1, d_2 \rangle_{\Omega_\infty}}{\|d_1\|_{\Omega_\infty}\|d_2\|_{\Omega_\infty}}$</div><div>\item where $\Omega_\infty$ is the absolute conic of the projectivity</div>
Geometrically, what's the absolute dual quadric $Q_\infty^*$ in $\mbb{P}^3$?	\item It's the quadric formed from the set of planes tangent to $\Omega_\infty$<br /><div>\item ie it's the rim quadric of $\Omega_\infty$</div>
When is a plane $\pi$ in the envelope defined by the absolute dual quadric?	\item When $\pi Q^*_\infty \pi^T = 0$
How can the absolute conic be viewed as a limit?	\item Consider the ellipsoids defined by $\text{diag}(1,1,1,k)$<div>\item As $k \rightarrow \infty$, the absolute conic is recovered</div>
What's the canonical form of the absolute dual quadric?	\item $Q^*_\infty = \text{diag}(1,1,1,0)$
What's the main advantage of the absolute dual quadric over the absolute conic?	\item The absolute dual quadric is defined by a single equation, whereas the absolute conic requires two
Which transformations fix the absolute dual quadric?	\item Exactly the similarities
What's the nullspace of $Q^*_\infty$?	\item The plane at infinity $\pi_\infty$
How many degrees of freedom does the absolute dual conic have?	\item Eight<div>\item equivalent to the eight dof needed to specify metric properties in a projective coordinate frame</div>
How can you calculate the angle between two planes that have been distorted by a projectivity?	<div>\item $\cos \theta = \frac{\langle \pi_1, \pi_2 \rangle_{Q^*_\infty}}{\|\pi_1\|_{Q^*_\infty}\|\pi_2\|_{Q^*_\infty}}$</div><div>\item where $Q^*_\infty$ is the dual absolute quadric of the projectivity</div>
How many point correspondances are needed to fully constrain a projectivity between two 2D images?&nbsp;	\item Four
What's the basis of the direct linear transformation algorithm?	\item Given correspondances $x_i^\prime \leftrightarrow x_i$<div>\item we want to find a $H$ such that $x^\prime_i \sim Hx_i$</div><div>\item Which can be done by solving $x_i^\prime \times Hx_i = 0$</div>
What's the purpose of the direct linear transformation algorithm?	\item To compute a homography between two images using four exact point correspondences
In the direct linear transformation algorithm, what's the form of the solution?	\item A one-dimensional subspace
When computing 2D homographies, what's the algebraic distance between two vectors $x, x^\prime$?	\item If the constraints imposed on the homography's elements $h$ by $x, x^\prime$ are described by $A\bar h = 0$<div>\item then $Ah = \epsilon$ gives the algebraic cost&nbsp;</div>
What're the advantages of the algebraic distance as a cost for computing 2D homographies?	\item It's cheap to compute
What're the problems with the algebraic distance as a cost for calculating 2D homographies?	\item It's not geometrically or statistically meaningful
In camera geometry, what do $x, \hat x, \bar x$ usually represent?	\item $x$ represents the measured value<div>\item $\hat x$ represents the estimated value</div><div>\item $\bar x$ represents the true value</div>
What's the symmetric transfer error when computing 2D homographies?	\item $d(x, H^{-1}x^\prime)^2 + d(Hx,&nbsp;x^\prime)^2$<div>\item where</div><div>\item $d$ is the Euclidean distance,&nbsp;</div><div>\item $H$ is the homography</div><div>\item $x, x^\prime$ are corresponding points</div>
What's the reprojection error when computing 2D homographies?&nbsp;	\item $d(x, \hat x)^2 + d(x^\prime, \hat x^\prime)^2$<div>\item where&nbsp;</div><div>\item $\hat x, \hat x^\prime$ are such that $\hat x^\prime = \hat H\hat x$ is exact for some homography $\hat H$</div>
What's the geometric intuition behind the reprojection error?	\item Optimizing it is effectively trying to minimize the distance of a variety in $\mbb{R}^4$ from the points $(x_i, x_i^\prime)$
What's a variety?	\item It's the set of roots of a multivariate polynomial
What's another name for the reprojection error?	\item The geometric error
What's the Sampson error in computing 2D homographies?	\item $d_S(x, x^\prime) = &nbsp;\|J^{-1} \epsilon\|^2$<div>\item where<br />\item $\epsilon = \mc{C}_H(X)$ is the distance of $H$'s variety from the point $X = (x, x^\prime)$<div>\item $J = \frac{\partial \mc{C}_H}{\partial X}$ is the gradient there</div></div>
How does the Sampson error arise?	\item By linearizing the geometric error
When is the Sampson error identical to the geometric error?	\item When the constraint violation cost $\mc{C}_H(X)$ is linear
define Cartesian product	"a mathematical operation which returns a product set from multiple sets<div>&gt; W: That is, for sets A and B, the Cartesian product A × B is the set of all ordered pairs (a, b) where a ∈ A and b ∈ B</div><div><img src=""paste-13915694039614.jpg"" /></div>"
What's the basis of the reprojection error in calculating a 2D homography?	\item It follows from an isotropic Gaussian error in the measurements
Which error does the direct linear transformation algorithm minimize for 2D homography?	\item The algebraic error
Which of algebraic and geometric errors are invariant to coordinate transformations?	\item Geometric
What normalization should be done before applying the DLT algorithm for 2D homography?	\item Translate so the mean of the correspondences in each image are zero<div>\item Scale isotropically so the average distance from the origin is $\sqrt{2}$</div>
What's the DLT in the context of 2D homographies?	\item The direct linear transformation algorithm
Why is normalizing the data so important for the DLT?	\item Because otherwise in homogeneous coordinates, the average point is likely to be $(100, 100, 1)$<div>\item which leads to a very large condition number</div>
When computing a 2D homography, what's the usual advantage to over-parameterizing the transformation?	\item It can lead to a much simpler cost function surface
What's the main advantage of the Sampson error over the reprojection error?	\item Sampson error requires only the parameters of the homography be optimized<div>\item Reprojection errors requires the parameters of the homography plus the parameters of all the ideal points be optimized&nbsp;</div>
How are iterative methods for finding homographies typically initialized?	\item By using the DLT to solve over a&nbsp;minimal subset of correspondences<div>\item (subset is usually selected so as not to contain outliers)</div>
What are the two most popular iteration schemes for solving 2D homography problems?	\item Levenberg-Marquardt<div>\item Newton's</div>
What's the gold standard error when calculating a 2D homography?	\item Another name for the reprojection error
When using RANSAC for calculating 2D homographies, what's the distance threshold usually used?&nbsp;	\item The error/distance is distributed as $\chi^2_m$, so threshold that at $5\%$ or whatever<div>\item where $m$ is the codimension of the object in question (1 for lines, 2 for points, etc)</div>
When using RANSAC for calculating 2D homographies, what're two common termination criteria?	\item A consensus set of at least $80\%$ of the points<div>\item An iteration threshold, picked so at least one iteration will be all inliers</div>
What's the adaptive RANSAC algorithm?	\item It's RANSAC with the termination threshold adaptively set by using the fact that if a consensus set of $(1-\epsilon)$ is found, then at most $\epsilon$ of the points can be outliers
What's the advantage of the adaptive RANSAC algorithm over regular RANSAC?	\item It means that the fraction of outliers doesn't have to be guessed beforehand
What's the polarization identity in linear algebra?	\item $|u \cdot v| = \frac{1}{2}(|u-v|^2 - |u|^2 - |v|^2)$
What's the Cauchy-Schwarz inequality in linear algebra?	\item $|u \cdot v| \leq |u||v|$
How's the vector space of oriented areas formed?	\item Associate each planar area of size $A$ with a vector perpendicular to it that has length $A$<br /><div>\item The orientation of the area corresponds to which side the vector points out of</div>
What are the fundamental properties of the wedge product?	\item $v \wedge v = 0$<div>\item Antisymmetric</div><div>\item Linear in the first</div>
In $\mbb{G}^3$, how can you write $u \wedge v$ in terms of basis vectors?	\item $u \wedge v = (u_1v_2 - u_2v_1)(e_1 \wedge e_2) + (u_1v_3 - u_3v_1)(e_1 \wedge e_3) + (u_2v_3 - u_3v_2)(e_2 \wedge e_3)$<div>\item Follows from the basic properties of outer product</div>
What's the geometric form of $u \wedge v$?	\item An oriented area corresponding to the parallelogram with sides $u, v$<br /><div>\item Note that oriented areas do \emph{not} have shape, only size and orientation</div>
In geometric algebra, what's the more common name for an oriented area?	\item A bivector
How's the vector space $\mbb{G}^3$ formed?	\item From multivectors of the form $M = v + B +T$<div>\item where</div><div>\item $v$ is a vector</div><div>\item $B$ is a bivector</div><div>\item $T$ is a trivector</div>
Algebraically, what's a bivector?	\item The result of the outer product of two vectors
What's $\mbb{G}^3$ denote?	\item The 3D geometric algebra
What's the fundamental identity of geometric algebra?	<div>\item It relates the geometric product to the inner \&amp; outer products</div>\item $uv = u \cdot v + u \wedge v$
What does the geometric product $uv$ reduce to when $u$ is parallel to $v$?	\item $uv = u \cdot v$
What does the geometric product $uv$ reduce to when $u$ is orthogonal to $v$?	\item $uv = u \wedge v$
How do you define the inner product in terms of the geometric product?	<div>\item If $A$ is a $j$-vector and $B$ is a $k$-vector</div>\item $A\cdot B = \langle AB \rangle_{k-j}$
How do you define the outer product in terms of the geometric product?	<div>\item If $A$ is a $k$-vector and $B$ is a $j$-vector</div>\item $A \wedge B = \langle AB \rangle_{j+k}$
What's $uv$ denote in geometric algebra?	\item The geometric product of $u,v$
What's the unit pseudoscalar for a plane in $\mbb{G}^3$?	\item If the plane has orthonormal basis $e_1, e_2$,&nbsp;<div>\item it's $i = e_1 \wedge e_2 = e_1e_2$</div>
What's the use of the unit pseudoscalar of a plane in geometric algebra?	\item It characterizes a plane
What's the square of the unit pseudoscalar?	\item $i^2 = -1$
What's the unit pseudoscalar for a volume in&nbsp;$\mbb{G}^3$?	\item $I = e_1e_2e_3$
What's the square of the unit pseudoscalar for a volume in&nbsp;$\mbb{G}^3$?	\item $I^2 = -1$
How do bivectors correspond to angles in&nbsp;$\mbb{G}^3$?	\item $i\theta$ corresponds to an angle of $\theta$ in the plane with unit pseudoscalar $i$
How are exponentials defined in&nbsp;$\mbb{G}^3$?	\item $e^{I\theta} = \cos \theta + I \sin \theta$<div>\item where $i$ is the unit pseudoscalar for a plane</div>
What's the polar form of $uv$ geometric algebra?	<div>\item $uv = re^{i\theta}$</div><div>\item where</div><div><div>\item $r = |u||v|$</div><div>\item $i\theta$ is the angle between $u, v$</div></div>
What's the Cartesian form of a generalized complex number $uv$ in geometric algebra?	\item $uv = a + bi$<div>\item where</div><div>\item $a = r \cos \theta$</div><div>\item $b = r \sin \theta$</div><div>\item $r = |u||v|$</div><div>\item $i\theta$ is the angle between $u, v$</div>
What're generalized complex numbers in geometric algebra?	\item A scalar plus a pseudoscalar
What's the geometric form of a generalized complex number in $\mbb{G}^2$?	\item $r e^{i\theta}$ is an oriented arc of radius $r$ and angle $\theta$ in the plane characterized by $i$
How is conjugation defined for generalized complex numbers?	\item If $uv = a + bi$<div>\item then $vu = a - bi$</div>
Does $e^{i_1\theta_1}e^{i_2\theta_2} =&nbsp;e^{i_1\theta_1 + i_2\theta_2}$ for generalized complex numbers?	\item Not unless $i_1 = i_2$
What's another name for a generalized complex number in $\mbb{G}^2$?	\item A complex number
What're two other names for a generalized complex number in $\mbb{G}^3$?	\item Quaternion<div>\item Spinor</div>
What's the conventional quaternion basis?	\item $i_1 = e_3 e_2$<div>\item $i_2 = e_1 e_3$</div><div>\item $i_3 = e_2 e_1$</div>
What are the basic identities for the quaternion basis?	\item $i_1^2 = i_2^2 = i_3^2 = -1$<div>\item $i_1i_2 = i_3$</div><div>\item $i_2i_3 = i_1$</div><div>\item $i_3i_1 = i_2$</div>
When are generalized complex numbers closed under the geometric product?	\item When they're complex numbers (ie in $\mbb{G}^2$) or quaternions (ie in $\mbb{G}^3$)
In $\mbb{G}^3$, which multivectors are generalized complex numbers?	\item The ones that can be written as a scalar plus a trivector
Why are generalized complex numbers referred to as complex numbers in&nbsp;&nbsp;$\mbb{G}^2$?	\item Because they have the same properties as regular complex numbers
Given quaternions $Z_1, Z_2$, what's $\overline{Z_1Z_2}$?	\item $\bar Z_2 \bar Z_1$
How are rotations represented by quaternions?	\item Let rotation by $\theta$ in the plane $i$ be represented by $r = e^{i\theta/2}$<div>\item so<br /><div>\item $R_{i\theta}(u) = \bar r u r$</div></div>
For a rotation in plane $i$ by $\theta$ in geometric algebra, what does a vector $u$ in the plane get taken to?	\item $v = u e^{i\theta}$
Are rotations closed under composition?	\item Only in 2 and 3 dimensions
Generally, what're the pseudoscalars of $\mbb{G}^n$?	\item The multiples of $e_1e_2\dotsb e_n$
What's a $k$-blade in geometric algebra?	\item Given a $k$-dim subspace of $\mbb{R}^n$ with basis $\{b_1, \dotsc, b_k\}$,<div>\item the blade for the subspace in $\mbb{G}^n$ is the subspace generated by $B = b_1b_2\dotsb b_k$</div>
What two things do blades in $\mbb{G}^n$ correspond to?	\item A $k$-blade $B = b_1 b_2 \dotsb b_k$ corresponds to<div>\item a $k$-dim subspace of $\mbb{R}^n$ generated by $\{b_1, \dotsc, b_k\}$</div><div>\item the sets in that subspace of size $|B|$</div>
How is the norm of a blade $B = b_1 b_2 \dotsb b_k$ defined?	\item $|B| = |b_1||b_2|\dotsb |b_k|$
How do the possible blades for a subspace relate?	\item They're all scalar multiples of eachother
How is the inverse of a blade defined?	\item If $B = b_1 b_2 \dotsb b_k$<div>\item then $B^{-1} = \frac{1}{|B|^2}b_k \dotsb b_2 b_1$</div>
How are vector inverses defined with respect to the geometric product?	\item $u^{-1} = \frac{1}{|u|^2} u$
What's the sign of the permutation that reverses $k$ elements?	\item $(-1)^{k(k-1)/2}$
What does $\langle A \rangle_j$ denote in geometric algebra?	\item The $j$-vector part of $A$
What's the grade of a blade?	\item The minimum number of vectors its formed from
Is the inner product of the geometric algebra commutative?	\item Only when the grades of the argument match
What's another name often used for the inner product in geometric algebra?	\item The left contraction<div>\item since there are actually several ways to construct an inner product on $\mbb{G}^n$</div>
When is the inner product of the geometric algebra commutative?	\item When the grades of the arguments are the same
How is the orientation of a basis of $\mbb{G}^n$ defined?	\item By the sign of the unit pseudoscalar of the basis,<div>\item $I = e_1 e_2 \dotsb e_n$</div>
Algebraically, what's the dual of a multivector?	\item $A^* = A/I$<div>\item where $I$ is the pseudoscalar</div>
When working with multivectors, what does $A/B$ usually denote?	\item $A/B = AB^{-1}$
Geometrically, what does the dual $A^*$ of a multivector $A$ represent?	\item The subspace orthogonal to the one represented by $A$
In the geometric algebra, what's $A^{**}$?	\item $A^{**} = (-1)^{n(n-1)/2}A$
How does the dual relate to the inner \&amp; outer products in geometric algebra?	<div>\item $(A \cdot B)^* = A \wedge B^*$</div>\item $(A \wedge B)^* = A \cdot B^*$
How does the exterior algebra relate to the geometric algebra?	\item The geometric algebra is a simplification of the exterior algebra
What's another name for the exterior algebra?	\item The Grassmann algebra
How is the cross product defined in the geometric algebra?	\item $u \times v = (u \wedge v)^*$
What does the dual in the geometric algebra correspond to in the exterior algebra?	\item The Hodge dual
What are the two main ways to construct a blade in geometric algebra?	\item As a geometric product of orthogonal vectors<div>\item As an outer product of linearly independent vectors</div>
What's an outermorphism?	\item A linear operator which preserves the outer product $(\wedge)$
What's the outermorphism extension theorem?	\item Every nonzero linear transformation $f \colon \mbb{R}^n \rightarrow \mbb{R}^m$ can be extended to a unique outermorphism&nbsp;$f \colon \mbb{G}^n \rightarrow \mbb{G}^m$&nbsp;<div>\item by setting $f(a_1 \wedge \dotsb \wedge a_k) =&nbsp;f(a_1) \wedge \dotsb \wedge f(a_k)$</div>
What's the defining property of the adjoint?	\item $u \cdot Av = A^*u \cdot v$
How is the determinant defined in the geometric algebra?	\item $\det f$ is such that<div>\item $f(I) = (\det f) I$</div><div>\item where $I$ is the pseudoscalar&nbsp;</div><div>\item and $f$ has been extended to an outermorphism</div>
What's the algebraic definition of a symmetric operator?	\item $f^* = f$
What's the algebraic definition of an orthogonal operator?	\item $f^* = f^{-1}$
What's the algebraic definition of a skew operator?	\item $f^* = -f$
What's the intuitive version of the Cartan-Dieudonne theorem in geometric algebra?	\item Every $n$-dimensional orthogonal transformation can be represented as $r \leq n$ reflections in hyperplanes
What's the algebraic version of the Cartan-Dieudonne theorem in geometric algebra?	\item Every orthogonal $f$ can be written<div>\item $f(v) = (-1)^r V v V^{-1}$</div><div>\item where $V$ is a geometric product of $r$ vectors, one perpendicular to each hyperplane a reflection occurs in</div>
What's the skew transformation representation theorem in geometric algebra?	\item Every skew $f$ can be written as<div>\item $f(v) = v \cdot \Omega$</div><div>\item for some unique bivector $\Omega$</div>
What's the theorem concerning the invariant subspaces of real linear transformations?	\item Every real linear transformation has a 1- or 2-dimensional subspace&nbsp;
What's the polar decomposition of a linear operator?	\item $f = op$<div>\item where</div><div>\item $o$ is orthogonal</div><div>\item $p$ is positive semidefinite</div>
When can the polar decomposition be applied?	\item Always
When is a linear operator positive definite?	\item When $f(v) \cdot v &gt; 0$ for all $v$
How'd you take the derivative of a geometric product?	\item Using the usual product rule
What's a sufficient condition for exchanging the order of differentiation?	\item When the second derivatives are all continuous
What does $\partial_i f(x)$ denote in geometric calculus?	\item $\frac{\partial f}{\partial x_i}$ evaluated at $x$
What's the differential of $f$ in geometric calculus?	\item It's the linear transformation<div>\item $f^\prime_x(h) = h_i (\partial_i f)(x)$</div>
Exactly when is a function differentiable in geometric calculus?	\item When&nbsp;<div>\item $f(x+h) = f(x) + f^\prime_x(h) + r(h)$</div><div>\item and</div><div>\item $\lim_{h \rightarrow 0} r(h)/|h| = 0$</div>
What's the usual sufficient condition for a function to be differentiable at $x$ in geometric calculus?	\item That all the partial derivatives exist in the neighbourhood of $x$<div>\item and are continuous at $x$</div>
What's the usual formula for the Jacobian determinant of a differential in geometric caculus?	\item $\det f_x^\prime$ is such that<div>\item $f^\prime_x(I) = (\det f^\prime_x) I$</div><div>\item using the outermorphism extension of $f$</div>
In geometric calculus, what are the uses of the differential and the gradient?	\item The differential gives tangents<div>\item The gradient gives rates of change</div>
What's the chain rule for differentials?	\item $(g \circ f)^\prime_x = g^\prime_{f(x)} f^\prime_x$
When it exists, what's the differential of an inverse function?	\item $(f^{-1})^\prime_{f(x)} = (f_x^\prime)^{-1}$
When does the differential of an inverse function exist?	\item When<div>\item $f$ is continuously differentiable</div><div>\item $f^\prime_x$ is invertible</div>
How is the directional derivative defined in terms of the differential?	\item $\partial_h f(x) = f^\prime_x(h)$
What's the inverse function theorem in geometric calculus?	\item If $f\colon \mbb{R}^n \rightarrow \mbb{R}^n$ is continuously differentiable around $x$<div>\item and $f^\prime_x$ exists and is invertible</div><div>\item then locally, $f^{-1}$ exists and is differentiable</div>
What's the implicit function theorem of geometric calculus?	\item If $f \colon \mbb{R}^{m \times n} \rightarrow \mbb{R}^n$ is continuously differentiable at $(a, b)$<div>\item and the Jacobian wrt $b$'s components is invertible</div><div>\item then there's a continuously differentiable $y(x)$ such that near $a$, $f(x, y(x)) = f(a, b)$</div>
What's a continuously differentiable function?	\item One whose derivatives are continuous
What's a common use of the implicit function theorem?	\item If $f(a, b) = c$ satisfies the theorem, it can be used to calculate how much $b$ has to change to keep $c$ constant when $a$ changes
What are the two usual constraints on manifold parameter functions?	\item They must be differentiable (so directional derivatives are equivalent to differentials)<div>\item The differentials must be bijective (so independent vectors map to independent vectors)</div>
If $x$ parameterizes a manifold $M$, what's the tangent space to $M$ at $p = x(q)$?	\item It's the $T_p$ generated by $x^\prime_q(w)$, where $w$ ranges over the same space as $q$
When does a mapping between manifolds extend to a mapping between tangent spaces?&nbsp;	\item When&nbsp;<div>\item the manifolds are of equal dimension<div>\item the map is bijective</div></div><div>\item the map is differentiable</div>
What's the gradient of a field $F$?	\item $\nabla F(x) = e_i \partial_i F(x)$
What's a field in geometric calculus?	\item A function $F$ that maps a manifold to $\mbb{G}^n$
What does $\dot \nabla F \dot G$ denote in geometric calculus?	\item $\dot \nabla F \dot G = e_i F \partial_i G$<div>\item So the dot denotes which part to take the derivative of, while keeping the $e_i$ in the same place</div>
What's the product rule for the gradient in geometric calculus?	\item $\nabla (FG) = \dot \nabla F \dot G + \dot \nabla \dot F G$
How is the directional derivative defined in terms of the gradient?	\item $\partial_h f(x) = h \cdot \nabla f (x)$
How do the divergence and curl arise from the gradient in geometric calculus?	<div>\item Using the fundamental identity for the geometric product</div><div>\item $\nabla F &nbsp;= e_i \partial_i F = e_i \cdot \partial_i F + e_i \wedge \partial_i F = \nabla \cdot F + \nabla \wedge F$</div>
How does the divergence affect the grade of it's argument?	\item It lowers it; $r$-vectors go to $r-1$ vectors
How does the curl affect the grade of it's argument?	\item It raises it; $r$-vectors go to $r+1$ vectors
What are the basic relations between gradient, divergence and curl in geometric calculus?	\item Curl of a curl is zero<div>\item Divergence of a divergence is zero<br /><div>\item Curl of a gradient of a scalar field is zero</div></div>
What's the difference between a blade and a multivector?	\item A blade is a simple product of $k$ vectors<div>\item A multivector is a sum of blades</div>
What's a common alternative to RANSAC?	\item Least median of squares<div>\item ie optimize the median of the square distances&nbsp;</div>
How does least median squares compare to RANSAC?	\item It doesn't need any distance thresholds setting<div>\item but it'll fail if more than 50\% of the points are outliers</div>
What're the three uses for local feature detectors?&nbsp;	\item For semantic information (ex: finding roads in satellite images)<div>\item For anchor points</div><div>\item For image representation</div>
What kind of region do corner detectors look for?	\item Regions with (in some sense) high curvature
What's the second-moment matrix for a 2D function $f$?	\item $S = w \star \left( \begin{matrix} f_x^2 &amp; f_x f_y \\ f_x f_y &amp; f_y^2 \end{matrix} \right)$<div>\item where $w$ is a windowing function</div>
How should the second-moment matrix of an image be interpreted?	\item It's eigendecomposition captures the gradient within the window<div>\item The eigenvector with the larger eigenvalue is maximally aligned with the gradient</div><div>\item and the eigenvalue gap indicates the anistropy of the gradient</div>
What's the idea in the Harris corner detector?	\item Use the second-moment matrix to capture the Gaussian-windowed gradient at each point<div>\item Average the results with another Gaussian</div><div>\item Look for points where both eigenvalues of the matrix are large, indicating large gradients in both directions</div>
What transformations is the Harris corner detector robust against?	\item Translation covariant<div>\item Rotation covariant</div><div>\item Robust against lighting changes</div>
What's repeatability in feature extraction?	\item That the same features can be extracted under many different transformations
What's the idea in the SUSAN feature detector?	\item Consider a small disk around each point<div>\item Partition the pixels of the disk according to whether they're similar to the point or not</div><div>\item Look for points with a small `similar' ratio</div>
How does the SUSAN detector compare to the HARRIS detector?	\item It tends to pick up a greater number of edges<div>\item It tends to be sensitive to noise</div>
What's the idea in the Harris-Laplace feature detector?	\item Induce scale invariance by calculating the Harris response at many different scales<div>\item Then at each point, pick the scale that maximizes the LoG of the Harris response</div>
What's the idea in the Harris-affine feature detector?	<div>\item For each point</div>\item Calculate an affine transform that'll take the second-moment matrix at the point to a spherical one<div>\item Normalize the local image with the transform \&amp; apply Harris-Laplace to extract normalized location \&amp; scale</div><div>\item &nbsp;If the new second-moment matrix isn't spherical, repeat.</div>
How's the Laplacian operator relate to the Hessian?	\item The Laplacian is the trace of the Hessian
What're the steps in the Hessian feature detector?	\item Compute the second-order Gaussian smoothed derivatives<div>\item Use them to calculate the determinant of the Hessian</div><div>\item Find the maxima of the Hessian</div>
What do Hessian feature detectors pick up?	\item Ridges and blobs whose scale matches that of the Gaussian kernel used to compute the second derivatives
What's the idea in the salient region feature detector?	\item Estimate the entropy at each point over a range of scales<div>\item Find the local maxima $H$ of the entropy</div><div>\item For each local maxima, calculate $Y$, the rate of change of the entropy with respect to scale</div><div>\item Find the maxima of $HY$</div>
What does the salient region feature detector look for?	\item Regions with high entropy<div>\item that are also self-dissimilar&nbsp;</div><div>\item (ie where the amount of entropy varies significantly as you move around)</div>
How do blobs and corners compare for feature detection?	\item Corners are easier to localize<div>\item Blobs give more scale information</div>
What's the idea in intensity-based region detectors?	\item Start with the intensity extrema of the image<div>\item Trace out rays in many directions</div><div>\item On each ray, look for a point where the intensity shifts most rapidly</div><div>\item Link these points into an irregular region</div><div>\item Replace the irregular boundary with an ellipse</div>
What's the Euler-Lagrange equation?	<div>\item If $q$ is a function of time</div><div>\item and $L$ is a function of time, position and velocity</div><div>\item then the corresponding Euler-Lagrange equation for $q$ is &nbsp;</div>\item $L_x(t, q, q^\prime) = \frac{d}{dt} L_v(t, q, q^\prime)$
define degrees of freedom 	the number of independent data points that go into an estimate minus the number of parameters used as intermediate steps in the estimation
Given a norm on vectors, how is a norm on operators usually induced?	\item $\|T\| = \max_x \|Tx\|/\|x\|$
What're the two fundamental properties of operator norms?&nbsp;	\item $\|Tx\| \leq \|T\|\|x\|$<div>\item $\|ST\| \leq \|S\|\|T\|$</div>
Given an induced operator norm, what's $\|T^{-1}\|$ equivalent to?	\item $\|T^{-1}\| = \frac{1}{\min_x\|Tx\|/\|x\|}$
When is a linear operator bounded?	\item Exactly when it's continuous
How is the $\ell_2$ norm of an operator defined in terms of eigenvalues?	\item $\|T\|_2 = \sqrt{\rho_{T^+T}}$<div>\item where $\rho$ is the spectral radius of $T^+ T$</div>
What does $e_\omega(t)$ denote in wavelet analysis?	\item $e_\omega(t) = \frac{1}{\sqrt{2\pi}} e^{iwt}$
In terms of norms, when is a projection orthogonal?	\item Exactly when $\|Px\| \leq \|x\|$ for every $x$
What's the closure of a set of vectors?	\item It's the set of all infinite sums of those vectors with coefficients in $\ell_2(\mbb{Z})$
What's the defining property of a reproducing kernel?	\item $x(t) = \langle K(t, t^\prime), x(t^\prime) \rangle$
In terms of the reproducing kernel, when is an orthonormal basis complete?	\item When&nbsp;<div>\item $K(t, t) = \sum \|\phi_n(t)\|^2$</div>
How does the Dirac delta relate to the reproducing kernel?	\item It acts like a generalized reproducing kernel for spaces not well-behaved enough to have actual reproducing kernels<div>\item (like $L_2(\mbb{R})$, whose functions are allowed to be unbounded on zero-measure sets)</div>
How is the Dirac delta written in terms of the evaluation functionals?	\item $\delta(t - t^\prime) = \langle t | t^\prime \rangle$<div>\item where $t$ on the RHS denotes the evaluation functional $e_t$</div>
What convention for the Fourier analysis \&amp; synthesis functions is used in these cards?	\item $x(t) = \int X(\omega) e_\omega(t) d\omega$<div>\item $X(\omega) = \int x(t) e_\omega^*(t) dt$</div>
If $X(\omega)$'s first $N$ derivatives all tend to zero, what follows?	\item That $x(t)$ is dominated by $\frac{1}{t^N}$&nbsp;
If $X(\omega)$ is dominated by $\frac{1}{\omega^N}$, what follows?	\item That $x(t)$'s first $N$ derivatives exist and<div>\item $\frac{d^n}{dt^n}x(t) = \int (i\omega)^n X(\omega) e_\omega(t) d\omega$</div>
What's the intuitive version of the relation between $X(\omega)$'s rate of decay and $x(t)$'s differentiability?	\item The faster $X(\omega)$ decays<div>\item the smoother $x(t)$ is</div>
If $x(t)$ is dominated by $\frac{1}{t^N}$, what follows?	\item $\frac{d^n}{d\omega^n} X(\omega) = \int (-it)^n x(t) e_\omega(t)dt$
How do the rank and nullity of $A$ and $A^+$ relate?	\item If $A$ is $m \times n$ then<div><div>\item $\text{rank}(A) = \text{rank}(A^+) = r$</div><div>\item $\text{null}(A) = n - r$</div><div>\item $\text{null}(A^+) = m - r$</div></div>
Intuitively, what's the use of the right pseudoinverse?	\item It gives the solution of minimum norm of an underconstrained system
Intuitively, what's the use of the left pseudoinverse?	\item It gives the solution of minimum error of a system of overconstrained equations
What's the left pseudoinverse of a linear operator $A$?	<div>\item $A^\dagger_L = (A^+A)^{-1}A^+$&nbsp;</div><div>\item (such that $A^\dagger_L A = \mathbf{1}$)</div>
What's the use of a tight frame?	\item It mimics an orthogonal basis even though its vectors might be linearly dependent
In terms of it's bounds, when is a frame an orthogonal basis?	\item When it's exact
In terms of its bounds, when is a frame exact?	\item When the bounds are both 1&nbsp;
When does an operator $T^+_\phi T_\phi$ correspond to a frame?	\item When there are constants $A, B$ such that<div><div>\item $\|T^+_\phi T_\phi\| \leq B$</div></div><div>\item $\|(T^+_\phi T_\phi)^{-1}\| \leq A^{-1}$</div>
What's the reconstruction property of a frame and it's dual?	\item The $\{c_n\}$ of minimum norm that minimize the error in<div>\item $x(t) = \sum c_n \phi_n$&nbsp;</div><div>\item are</div><div>\item $c_n = \langle \xi_n, x \rangle$</div><div>\item and vice versa for the dual</div>
When can a function be uniquely reconstructed from the values $\langle \phi_n, x \rangle$ for a set of vectors $\{ \phi_n \}$?	\item Exactly when $\phi_n$ is a frame
Given an infinite frame, how can the inverse frame operator be approximated?	<div>\item Using the first $n$ terms of the Neumann expansion,</div><div>\item $S^{-1} = \frac{1}{C}\sum_{k=0}^\infty \left(1 - \frac{1}{C}S\right)^k$</div><div>\item where</div><div>\item&nbsp;$S$ is the frame operator</div><div>\item $C = \frac{1}{2}(A+B)$ is the average of the frame bounds</div>
What's the rate of convergence of the iterative algorithm for approximating the dual frame operator?	\item The error decays as $\left(\frac{B-A}{B+A}\right)^N$<div>\item where $A, B$ are the frame bounds</div>
How does the Laplace transform relate to the Fourier transform?	\item Evaluating the bilateral Laplace transform over the imaginary axis gives the Fourier transform&nbsp;
What's the Laplace transform?	\item $F(s) = \int_0^\infty e^{-st} f(t)$<div>\item where $s$ is the complex frequency</div>
What's the bilateral Laplace transform?	\item It's the Laplace transform with limits $(-\infty, \infty)$
What's the intuitive interpretation of the Laplace transform?	\item It decomposes a function into a superposition of moments
What's another name for up-sampling in signal processing?	\item Interpolation
What's another name for down-sampling in signal processing?	\item Decimation
What's the quadrature mirror filter property for discrete even-length filters in the time domain?	\item $h_1[n] = (-1)^n h_0[N-1-n]$
For discrete time, even length filters, what's the perfect reconstruction requirement in the frequency domain?	\item $X(z)$ component: $G_0(z)H_0(z) + G_1(z)H_1(z) = 2$<div>\item $X(-z)$ component: $G_0(-z)H_0(z) + G_1(-z)H_1(z) = 0$</div>
In the frequency domain, what's the result of downsampling then upsampling $X(z)$?	\item $Y(z) = \frac{1}{2}(X(z) + X(-z))$
What's the quadrature mirror filter property for infinite filters in the time domain?	\item $h_1[n] = (-1)^n h_0[1 - n]$
What's the quadrature mirror filter property for infinite filters in the frequency domain?	\item $H_1(z) = -\frac{1}{z} H_0\left(-\frac{1}{z}\right)$
What's the quadrature mirror filter property for discrete even-length filters in the frequency domain?	\item $H_1(z) = \left(-\frac{1}{z}\right)^{N-1} H_0\left(-\frac{1}{z}\right)$
How are infinite filters usually chosen to suppress the $X(-z)$ component in the reconstruction?	<div>\item By picking the analysis \&amp; synthesis filters to be time-reversed versions of eachother</div>\item $G_0(z) = H_0\left(\frac{1}{z}\right)$<div>\item $G_1(z) = H_1\left(\frac{1}{z}\right)$</div>
What's the practical version of the QMF property?	\item A QMF partner $h_1$ is obtained by reversing the coefficients of $h_0$ and then flipping the sign of every odd element&nbsp;
What's the intuitive use of the QMF property?	\item QMF pairs have opposite frequency responses<div>\item so together with smoothness and a vanishes-at-zero-freq constraint on one filter, leads to low and high pass filters</div>
Why are even-length filters usually the only ones considered?	\item Because under the PR and QMF properties, only even-length finite filters can suppress the $X(-z)$ component of the reconstruction
If the PR \&amp; QMF properties are enforced, what's the frequency-domain equation that a low-pass reconstruction filter must satisfy?	<div>\item&nbsp;$|H_0(\omega)|^2 +&nbsp;|H_0(\omega+ \pi)|^2 = 2$</div>
What are the relations enforced by the PR and QMF properties on the synthesis and reconstruction filters?	<div>\item QMF relates the high-pass filters and the low-pass filters</div><div>\item PR relates the synthesis and analysis filters</div>
What's the relation on the Dirac delta that suggests the Fourier inversion theorem?	\item $\int e_{\omega}^*(t) e_{\omega}(t^\prime) d \omega = \delta(t - t^\prime)$
What are the frequency spectra of the Haar high and low pass reconstruction filters?	\item Low pass is $\sim \cos(\omega/2)$<div>\item High pass is $\sim \sin(\omega/2)$</div>
What's the basis property for MRA subspaces?	\item A set of MRA subspaces $\mc{V}_n$ has the frame property if there is some $\phi(t) \in \mc{V}_0$ such that all shifted and suitably scaled versions of it form a basis for $\mc{V}_n$
What's the advantage of biorthogonal wavelets?	\item The only&nbsp;orthogonal&nbsp;FIR wavelet with linear phase response is the Haar wavelet<div>\item All others with those properties are biorthogonal&nbsp;</div>
What property should a wavelet scheme have when using it to construct a discrete approximation of a continuous signal?	\item First moment (the mean) of the scaling function should be zero
If the low-pass filter in a biorthogonal scheme has support $[N_1, N_2]$, what's the support of the associated high-pass function?	\item $[1-N_1, 1-N_2]$
If the low-pass filter in a biorthogonal scheme has support $[N_1, N_2]$, what's the support of the associated scaling function?	\item $[N_1, N_2]$
If the low-pass filters $h_0, h_0^\prime$ in a biorthogonal scheme have support $[N_1, N_2]$, $[N_1^\prime, N_2^\prime]$, what's the support of the associated $\psi$?	\item $\left[\frac{N_1 - (1- N_2^\prime)}{2}, \frac{N_2 - (1 - N_1^\prime)}{2} \right]$
What're the lazy filters in wavelet analysis?	\item The biorthogonal filters such that<div>\item the low-pass ones take every even sample<div>\item the high-pass ones take every odd sample</div><div>\item Don't actually lead to wavelets themselves; used for lifting schemes&nbsp;</div></div>
If $f$ is scalar-valued, when does $f(x) = c$ locally define a manifold?	\item When it's continuously differentiable<div>\item and $\nabla f(x_0) \neq 0$</div>
Assuming it exists, how does the level set $f(x_0) = c$ relate to the gradient?	\item The manifold $M$ of the level set at $x_0$ is orthogonal to $\nabla f(x_0)$
How is the gradient of a vector field defined in geometric calculus?	\item $\nabla f = e_i e_j \partial_i f_j$
Which elements of $\mbb{G}^n$ have inverses?	\item The ones such that $u^2 \neq 0$
How is the vector divergence defined in geometric calculus?	\item $\nabla \cdot f = \partial_i f_i$<div>\item (since $e_i \cdot e_j = \delta_{ij}$)</div>
How is the vector curl defined in geometric calculus?	\item $\nabla \wedge f = e_i \wedge e_j \partial_i f_j$
In geometric calculus, what's an irrotational vector field?	\item One such that $\nabla \wedge f = 0$
Given a curvilinear coordinate system $\{u_i\}$, what are the bases $\{\mb{x}^k\}, \{\mb{x}_j\}$?	\item $\mb{x}^k = \frac{\partial u_k}{\partial x} = \nabla u_k$<div>\item $\mb{x}_j = \frac{\partial x}{\partial u_j}$</div><div>\item Different from $x_j$, which are scalars!</div>
When discussing curvilinear coordinates, what do $x_j$ denote?	\item The coordinates in an orthonormal basis<div>\item A map from the curvilinear coordinates to the coordinates in the orthonormal basis</div>
What are reciprocal bases in geometric calculus?	\item A pair of bases $\{u^i\}, \{v_j\}$ such that<div>\item $u^i \cdot v_j = \delta_{ij}$</div>
Given a curvilinear coordinate system, what's $\nabla$ written in terms of the basis $\mb{x}^k$?	\item $\nabla = \mb{x}^k\frac{\partial}{\partial u_k}$<br />
When discussing curvilinear coordinates in geometric calculus, what does $\{ \mb{\hat x}_i\}$ denote?	\item The normalized version of $\{ \mb{x}_i \}$
Given a curvilinear coordinate system in $\mbb{G}^3$, what's the geometric interpretation of the basis vector $\mb{x^k}$?	\item If you fix $u_1$ in $\mb{x}(u_1, u_2, u_3)$, it defines a coordinate surface<br /><div>\item $\mb{x}^1$ is the vector orthogonal to this surface</div><div>\item Same for the other two</div>
Given a curvilinear coordinate system in $\mbb{G}^3$, what's the geometric interpretation of the basis vector $\mb{x_i}$?	\item If you alternately fix $u_2$ and $u_3$ in $\mb{x}(u_1, u_2, u_3)$, two coordinate surfaces are defined<br /><div>\item $\mb{x}_1$ is the vector tangent to the coordinate curve of intersection</div><div>\item Same for the other two</div>
If $\mb{x}(u, v)$ parameterizes a surface $S$, how is the vector derivative on $S$ defined?	\item $\mb{\partial} = \mb{x}^u \partial_u +&nbsp;\mb{x}^v \partial_v$<div>\item where&nbsp;</div><div>\item $\{\mb{x}^u, \mb{x}^v\}$ are the bases of the tangent space induced by the parameterization</div><div>\item $\partial_u = \frac{\partial}{\partial u}$</div><div>\item no summation is implied by $\mb{x}^u \partial_u$</div>
How can the vector derivative be defined in a coordinate-independent way?	<div>\item It's the projection of the gradient operator onto the tangent space of the surface</div>\item $\mb{\partial} = P_T(\nabla)$<div><br /></div>
What's an open set in a metric space?	\item It's a set such that if a point is in the set, so is the neighbourhood of that point
What's a closed set in a metric space?	\item A set which is closed under the limit operation
What's a necessary condition on the gradient for $f$ to have a local extremum at $x_0$?	\item $\nabla f(x_0) = 0$
In geometric calculus, how is the Hessian defined?	\item $H_f&nbsp;= \left[ \partial_{ij}(x) \right]$
In terms of the Hessian, what's a sufficient condition for $x_0$ to be a local minimum of $f$?	\item $\nabla f(x_0) = 0$<div>\item $H_f(x_0)$ is positive definite</div>
How should the eigendecomposition of the Hessian be interpreted geometrically?	\item $\lambda_i$ indicates the curvature of the surface along $u_i$
Given a constrained problem with objective $f$ and constraint $g$, how is the Lagrange multiplier $\lambda$ defined?	\item If $f(x_0)$ is an extremum of $f$ under the constraint $g(x) = c$, then<div>\item $\nabla f(x_0) = \lambda \nabla g(x_0)$</div><div>\item for some $\lambda$, the Lagrange multiplier</div>
Geometrically, how should the Lagrange multiplier $\lambda$ be interpreted?	\item Given objective $f(x)$ and constraint $g(x) = c_0$<div>\item if $M(c)$ is the value of the solution</div><div>\item then $M^\prime(c_0) = \lambda$</div>
What's the reality condition of the Fourier transform?	\item If $f(x)$ is real, then $F^*(\omega) =&nbsp;F(-\omega)$
When discussing the wavelet packet transform, what does $c^{(2j)}_{mn}$ denote?	\item The coefficients at level $m$ which are a low-pass filtering of $c^{(j)}_{m-1,n}$
When discussing the wavelet packet transform, what does $c^{(2j+1)}_{mn}$ denote?	\item The coefficients at level $m$ which are a low-pass filtering of $d^{(j)}_{m-1,n}$
When discussing the wavelet packet transform, what does $d^{(2j)}_{mn}$ denote?	\item The coefficients at level $m$ which are a high-pass filtering of $c^{(j)}_{m-1,n}$
When discussing the wavelet packet transform, what does $d^{(2j+1)}_{mn}$ denote?	\item The coefficients at level $m$ which are a high-pass filtering of $d^{(j)}_{m-1,n}$
When discussing the packet transform, what does $p^{(j)}_{mn}$ denote?	\item The basis function corresponding to the approximation coefficients<div>\item $c^{(j)}_{mn} = \langle&nbsp;p^{(j)}_{mn} | x \rangle$</div>
When discussing the packet transform, what does $q^{(j)}_{mn}$ denote?	\item The basis function corresponding to the detail coefficients<div>\item $d^{(j)}_{mn} = \langle q^{(j)}_{mn} | x \rangle$</div>
In the context of the wavelet transform, how is $p^{(k)}_{mn}$ defined in terms of $p^{(k)}$?	\item&nbsp;$p^{(k)}_{mn} = \mc{D}_{2^m} \mc{T}_{n} p^{(k)}$
In the context of the wavelet transform, how are the packet basis functions $P^{(k)}$ defined as a recursion?	\item $P^{(2j)}(2\omega) = \frac{1}{\sqrt{2}} H_0 (\omega) P^{(j)}(\omega)$<div>\item $P^{(2j+1)}(2\omega) = \frac{1}{\sqrt{2}} H_1(\omega)&nbsp;P^{(j)}(\omega)$</div>
In the context of the wavelet transform, how are the packet basis functions $Q^{(k)}$ defined as a recursion?	\item $Q^{(2j)}(2\omega) = \frac{1}{\sqrt{2}} H_0 (\omega) Q^{(j)}(\omega)$<div>\item $Q^{(2j+1)}(2\omega) = \frac{1}{\sqrt{2}} H_1(\omega) Q^{(j)}(\omega)$</div>
In the context of the wavelet transform, how are the packet basis functions $P^{(k)}$ defined in closed form?	\item By using the binary representation of $k$ and taking the product of the scaling function<br /><div>\item the low-pass filter for scale $j$ if the $j$th bit is 0</div><div>\item the high-pass filter for scale $j$ if the $j$th bit is 1</div>
What metric does the best basis algorithm use to judge the quality of a basis?	\item The entropy of its coefficients
How's the surface integral defined in geometric calculus?	<div>\item For a surface $S$ parameterized by $x$,</div>\item $\int_S F dS = \int_A (F \circ \mb{x}) |\mb{x}_u \wedge \mb{x}_v| dA$
How's the flux integral defined in geometric calculus?	\item For a surface $S$ parameterized by $x$,<div>\item $\int_S F d\mb{S} = \int_A (F \circ \mb{x}) (\mb{x}_u \wedge \mb{x}_v) dA$</div>
In the definition of the flux integral, how's the infinitesimal $d\mb{S}$ defined?	\item $d\mb{S} =&nbsp;(\mb{x}_u \wedge \mb{x}_v) dA$
What's the fundamental theorem of geometric calculus?	\item If $M$ is a oriented and bounded $m$-dim manifold with boundary $\partial M$<div>\item then&nbsp;</div><div>\item $\int_M d^m \mb{x} \partial F = \oint_{\partial M} d^{m-1} \mb{x} F$</div>
What does $d^m \mb{x}$ denote in the fundamental theorem of geometric calculus?	\item $d^m\mb{x} = \mb{I}_m(\mb{x}) d^mx$<div>\item where</div><div>\item $d^mx =&nbsp;dx_1\dotsb dx_m$</div><div>\item $\mb{I}_m(\mb{x})$ is the unit pseudoscalar of the tangent space to the manifold at $\mb{x}$</div>
In the fundamental theorem of geometric calculus, why does the infinitesimal appear on the left?	\item Because the multivector represented by the infinitesimal doesn't commute
In the fundamental theorem of geometric calculus, how must orientation be defined?	\item The pseudoscalar orienting $M$ and the pseudoscalar orienting $\partial M$ must be chosen such that<div>\item $\mb{I}_m = \mb{I}_{m-1} \mb{\bar n}$</div><div>\item where $\mb{\bar n}$ is the unit outward boundary normal to $M$</div>
What's an analytic field in geometric calculus?	\item $F$ is analytic on a manifold $M$ if<div>\item $\mb{\partial} F(\mb{x}) \equiv 0$</div>
What's intuitively special about analytic fields in geometric calculus?	\item Their value is wholly determined by their value on the manifold's boundary
What's an implicit definition of the Darboux bivector?	\item Given a curve with tangent $\mb{t}$, the Darboux bivector is the $\mb{\Omega}$ such that<div>\item $\mb{\dot t} = \mb{t} \cdot \mb{\Omega}$</div>
What does $\mb{\dot x}$ denote in the context of curves in differential geometry?	\item The derivative with respect to the arc length parameterization
What's the Frenet basis in differential geometry?	\item Given a curve $\mb{x}$ in $\mbb{R}^n$, it's the basis formed from<div>\item $\mb{t}$, the tangent</div><div>\item $\mb{n} \propto \mb{\dot t}$, the unit normal</div><div>\item $\mb{b} = \mb{t} \times \mb{n}$, the binormal</div>
How is the Darboux bivector defined in terms of the Frenet basis?	\item $\mb{\Omega} = \frac{1}{2}(\mb{t} \wedge \mb{\dot t} +&nbsp;\mb{n} \wedge \mb{\dot n} +&nbsp;\mb{b} \wedge \mb{\dot b})$
What's the curvature of a curve in 3D differential geometry?	\item It's the $\kappa$ such that<div>\item $\mb{\dot t} = \kappa \mb{n}$</div><div>\item in the Frenet basis</div>
What's the torsion of a curve in 3D differential geometry?	\item It's the $\tau$ such that<div>\item $\mb{\dot b} = -\tau \mb{n}$</div><div>\item in the Frenet basis</div>
What's the geometric interpretation of the Darboux bivector in $\mbb{R}^3$?	\item It characterizes the angular velocity of the Frenet basis<div>\item The plane associated with $\mb{\Omega}$ is the plane of rotation (the osculating plane)</div><div>\item and $\mb{\Omega}$ is the rotational speed</div>
How is the metric of a surface defined?	\item $G = [\mb{x}_i \cdot \mb{x}_j]$<div>\item where $\{\mb{x}_i\}$ is a basis for the tangent space of the surface</div>
How is the length of a curve in a surface defined in terms of the metric?	<div>\item If $u(t)$ parameterizes $C$ in the surface, then</div>\item $\ell(C) = \int \sqrt{g_{ij} u_i^\prime u_j^\prime} dt$<div>\item where</div><div>\item $g_{ij}$ are the elements of the metric</div><div>\item $u^\prime_i$ is the derivative of surface coordinate $i$ wrt $t$</div>
How can the inverse of the metric of a surface $G^{-1}$ be defined?	\item $G^{-1} = [\mb{x}^{i} \cdot \mb{x}^j]$<div>\item where $\{\mb{x}^i\}$ is the reciprocal basis to the one used to define $G$</div>
How are entries of the metric denoted in differential geometry?	\item $g_{ij}$ denotes the elements of $G$
How are elements of the inverse metric denoted in differential geometry?	<div>\item $g^{ij}$ denotes the elements of $G^{-1}$</div>
How is the differential on a surface defined?	<div>\item At a point $p$ on the surface, the differential of a field $f$ is</div>\item $f^\prime_p(h) = (h \cdot \partial)f(p)$<div>\item where $\partial$ is the vector derivative</div>
How can the differential of a surface be interpreted in terms of tangent spaces?	\item If the field $f$ maps $S$ to another surface $\bar S$<div>\item then $f^\prime_p$&nbsp;maps the basis $\{\mb{x}_i\}$ of $T_p$ to the basis $\{(f\circ \mb{x})_i\}$ of $T_{f(p)}$</div>
How is the directional derivative on a surface defined?	<div>\item The directional derivative of a field $f$ at a point $p$ in the direction $h$ is</div>\item $\partial_h f(p) = (h \cdot \partial)f(p)$<div>\item where $\partial$ is the vector derivative</div>
What's the Weingarten equation?	<div>\item Given a surface with tangent basis $\{\mb{x}_i\}$, shape operator $S$ and metric $G$</div>\item Define $[\sigma_{ij}] = \mb{x}_{ij} \cdot \mb{\hat n}$<div>\item Then $\Sigma = GS$</div>
How are curves in $\mbb{R}^3$ characterized in differential geometry?	\item Curves are defined up to congruence by their curvature and torsion<br />
How are surfaces in $\mbb{R}^3$ characterized in differential geometry?	\item Surfaces are defined up to congruence by their metric and shape operator
What's the Darboux basis of a curve in a surface?	\item $\{\mb{t}, \mb{\hat n} \times&nbsp;\mb{t}, \mb{\hat n} \}$&nbsp;<div>\item where</div><div>\item $\mb{t}$ is the tangent to the curve</div><div>\item $\mb{\hat n}$ is the unit normal to the surface</div>
How can the unit acceleration of a curve in a surface be decomposed in the Darboux basis?	\item $\mb{\dot t} = \kappa_n \mb{\hat n} + \kappa_g (\mb{\hat n} \times \mb{t})$<div>\item where</div><div>\item $\kappa_n$ is the normal curvature</div><div>\item $\kappa_g$ is the geodesic curvature</div>
How can the normal curvature of a curve in a surface be written in terms of the shape operator?	\item $\kappa_n = S(\mb{t}) \cdot \mb{t}$
What's the intuitive interpretation of the normal curvature?&nbsp;	\item It's the acceleration needed to `keep the curve in the surface'
What's the intuitive interpretation of the geodesic curvature?	\item It's the acceleration of the curve within the surface
Geometrically, what are the eigenvectors of the shape operator?	\item They're the directions of maximum and minimum normal curvature
What are the principle vectors of a surface?	\item They're the field of directions of maximal and minimal normal curvature&nbsp;
In terms of curvature, when is a curve in a surface a geodesic?	\item When $\kappa_g = 0$
How is the Gaussian curvature of a surface defined?	\item $K = \det S$<div>\item where $S$ is the shape operator</div>
Intuitively, what's the Gauss map $\eta$ of a surface?	\item It's the map that takes $\mb{p}$ to the point on the unit sphere corresponding to $\mb{\hat n}_\mb{p}$<br />
How can the Gaussian curvature be interpreted in terms of the Gauss map?	\item Let $A_\mb{x}$ be the area of a small disc on the surface<div>\item Let $A_\eta$ be the area of the image of that disc under the Gauss map</div><div>\item Then as the radius of the disc shrinks to 0, we get $A_\eta = |K| A_\mb{x}$</div>
How does the Gaussian curvature correspond to the metric?	\item In $\mbb{R}^3$, the metric defines the Gaussian curvature<div>\item In higher dimensions, things are more complicated</div>
What's the difference between extrinsic and intrinsic curvature?	\item Intrinsic curvature can be detected from within the surface (ex: sphere)<div>\item Extrinsic curvature cannot (ex: cylinder)</div>
What's another name for the metric in differential geometry?	\item The first fundamental form
What's the second fundamental form in geometry?	<div>\item&nbsp;$(u, v) \mapsto u \cdot S(v)$</div><div>\item where $S$ is the shape operator of the surface</div>
How is the shape operator defined in a coordinate-independent way?	\item $S(h) = -\partial_h I / I$<div>\item where $I$ is the unit pseudoscalar of the tangent space</div>
What's a linear program?	\item An optimization problem where the constraints and objective are all linear
What's the convention for denoting the objective and constraints in \emph{Convex Optimization}?	\item $f_0$ is the objective<div>\item $f_i \leq 0, \, i \in [1, m]$ are the inequality constraints</div><div>\item $h_j = 0,&nbsp;&nbsp;\, j \in [1, p]$ are the equality constraints</div>
What's a convex optimization problem?	\item A problem where the objective and constraints are all convex
What's the average time complexity of the simplex method?	\item $O(n^2m)$
What does $\text{aff}(X)$ denote?	\item The affine hull of the set $X$,<div>\item $\{\sum \theta_k x_k | \sum \theta_k = 1 \}$</div>
What's the affine dimension of a set?	\item The dimension of the affine hull of a set
What's $\text{relint}(C)$ denote in convex optimization?	\item It's the set of points in $C$ that lie in the interior of $\text{aff}(C)$
What's the relative boundary of a set in convex optimization?	\item $\text{cl} (C) \backslash \text{relint}(C)$
What's $\text{cl}(C)$ denote in convex optimization?	\item The closure of the set $C$
What's $\text{conv}(X)$ denote in convex optimization?	\item The convex hull of the set $X$,<div><div>\item $\{\sum \theta_k x_k | \sum \theta_k = 1, \theta_k \geq 0 \}$</div></div>
What's the smallest convex set containing a set $C$?&nbsp;	\item The convex hull of $C$
What's another name for a nonnegative homogeneous set?	\item A cone
When is a set $X$ a cone?	\item When for all $x \in X, \theta \geq 0$, $\theta x$ is also in $X$
What's the conic hull of a set?	\item $\{\sum \theta_k x_k| \theta_k \geq 0 \}$&nbsp;
What's the smallest convex cone containing a set?	\item The conic hull of the set
What are halfspaces?	\item The solution set to $a \cdot x \leq b$ for some $a \neq 0, b$
What transformation takes the unit sphere to a general ellipsoid?&nbsp;	\item The affine transforms
What's a norm cone?	<div>\item Given a norm $\| \cdot \|$, it's</div>\item $\{(x, t) \,|\, \|x\| \leq t\}$
Geometrically, what's a polyhedron?	\item It's an intersection of halfspaces and hyperplanes
What's a hyperplane?	\item The solution set of $a \cdot x = b$ for some $a \neq 0, b$
What's a polytope?	\item In some texts it's a bounded polyhedron<div>\item In others a polyhedron is a bounded polytope</div>
In \emph{Convex Optimization}, what does $x \succeq y$ denote for vectors $x, y$?	\item Componentwise $(\geq)$
What's a simplex?	\item It's the convex hull of an affinely-independent set $\{v_i\}$
When is a set of points affinely independent?	\item When $(x_i - x_0)$ are all linearly independent
What's the affine dimension of $k$ affinely-independent points?	\item $k-1$
What's the description of the $\ell_\infty$ unit ball in terms of inequalities?	\item It's the intersection of the $2n$ constraints $ \pm e_i \cdot x \leq 1$ for each unit vector $e_i$
What's the description of the $\ell_\infty$ unit ball as a convex hull?	\item It's the convex hull of the $2^n$ points with coordinates $\pm 1$<br />
What does $S^n_+$ denote in convex optimization?	\item The symmetric positive semidefinite matrices on $\mbb{R}^n$
What does $S^n_{++}$ denote in convex optimization?	\item The symmetric positive definite matrices on $\mbb{R}^n$
What does $R_{++}$ denote convex optimization?	\item The positive reals
What does $\mbb{R}_{+}$ denote convex optimization?	\item The nonnegative reals
What common operations preserve convexity on sets?	\item Intersection<br /><div>\item Partial sum</div><div>\item Projectivities</div>
What's the partial sum of $S_1, S_2 \in \mbb{R}^n \times \mbb{R}^m$?	\item $\{(x, y_1 + y_2)| (x, y_1) \in S_1, (x, y_2) \in S_2 \}$<div>\item where $x \in \mbb{R}^n$, $y_i \in \mbb{R}^m$</div>
What's another name for a linear fractional function?	\item A projectivity
What's the perspective function?	\item $P(z, t) = z/t$ where $z \in \mbb{R}^n$ and $t \in \mbb{R}_{++}$
What's the pinhole camera corresponding to the perspective function?	\item The sheet of paper is in the $x_1, x_2$ plane<div>\item The origin is the aperture<br /><div>\item The image plane is $x_3 = -1$</div></div>
How are projectivities related to the perspective function?	\item They follow from composing the perspective function with an affine function, $P \circ g$
What's a proper cone?	\item A cone $K$ which is<div>\item convex</div><div>\item closed</div><div>\item solid</div><div>\item pointed</div>
What does it mean for a set $X$ to be solid in convex optimization?	\item It has a nonempty interior
In convex optimization, what's it mean for a cone to be pointed?	\item It's a cone that contains no line in its entirety
How does a proper cone $K$ define a partial ordering?	\item $x \succeq_K y$ iff $x - y \in K$
How does a proper cone $K$ define a strict partial ordering?	\item $x \succ_K y$ iff $x - y \in \text{int}(K)$
Which cone produces the componentwise partial ordering on $\mbb{R}^n$?	\item $K = \mbb{R}_+^n$
What's an orthant?	\item The generalization of a quadrant to higher dimensions
What are the minimal elements of a partial ordering $(\preceq)$?	\item $x$ is minimal iff it's the only element such that $x \preceq x$<br />
Given a proper cone $K$, what does $x+K$ correspond to when interpreted in terms of $(\succeq_K)$?	\item It's the set of all $y$ such that $y \succeq_K x$
Given a proper cone $K$, arithmetically when is $x$ the minimum element of the ordering it induces?&nbsp;	\item When $X \subseteq x + K$, where $X$ is the set of all elements
In terms of sets, arithmetically when is $x$ a minimal element with respect to a proper cone $K$?&nbsp;	\item When $(x - K) \cap S = \{x\}$
What's the separating hyperplane theorem?	\item If $C, D$ are disjoint convex sets, then there's an affine function $f$ such that $f(C)$ is nonnegative and $f(D)$ is nonpositive
Does the existance of a separating hyperplane imply that two convex sets are disjoint?	\item No.<div>\item Stronger conditions need to be applied to the sets for this to hold</div>
What's an alternatives theorem in convex optimization?	\item A theorem which establishes that exactly one of a set of possible optimization problems is soluble
What's the theorem of alternatives for strict linear inequalities?	<div>\item Exactly one of&nbsp;</div>\item $Ax \prec b$<div>\item and<br /><div>\item $A^T \lambda = 0, &nbsp;\quad \lambda^T b \leq 0$</div><div>\item $\lambda \succeq 0, \quad \lambda \neq 0$</div></div><div>\item is soluble</div>
What's $\text{bd}(C)$ denote in convex optimization?	\item The boundary of $C$,&nbsp;<div>\item $\text{bd}(C) = \text{cl}(C) \backslash \text{int}(C)$</div>
What's a supporting hyperplane of a set $X$ at a point $x_0$?	\item It's a hyperplane $a \cdot (x - x_0) = 0$&nbsp;<div>\item such that $a \cdot (x - x_0) \leq 0$ for all $x \in X$&nbsp;</div>
What's the supporting hyperplane theorem?	\item For any convex $C$ and $x_0 \in \text{bd}(C)$<div>\item there exists a supporting hyperplane to $C$ at $x_0$</div>
What's the partial converse to the supporting hyperplane theorem?	\item If $C$ is closed, solid and has a supporting hyperplane at every point on its boundary<div>\item then it's convex</div>
What's the dual of a cone in convex optimization?	\item $K^* = \{y | &nbsp;y \cdot K &nbsp;\geq 0 \}$
Geometrically, how is the dual cone defined?	\item $K^*$ is the set of inward normals to halfspaces which contain $K$
How do dual cones relate to subspaces?	\item If $K$ is a subspace, then $K^*$ is its orthogonal complement
What's the dual cone to $S^N_+$?	\item It's self-dual
What's the dual cone to $\mbb{R}^n_+$?	\item It's self-dual
What's the dual of a norm cone on $\mbb{R}^n$?	\item It's the norm cone defined by the dual norm
What's the dual norm in the context of convex optimization?&nbsp;	\item $\|u\|_* = \sup\{u \cdot x\,|\, \|x\| \leq 1\}$
What are the two guaranteed properties of the dual cone?	\item It's closed<div>\item It's convex</div>
How does the subset relation interact with cone duality?	\item $K_1 \subseteq K_2 \implies K_2^* \subseteq K_1^*$
If the cone $K$ is solid, what can we say about $K^*$?	\item $K^*$ is pointed
When is $K^*$ guaranteed to be solid?	\item When $\text{cl}(K)$ is pointed&nbsp;
How can the cone $K^{**}$ be characterized?	\item It's the closure of the convex hull of $K$
When will $K^{**} = K$ for a cone $K$?	\item When $K$ is a proper cone
Given a proper cone $K$, what's the dual partial ordering it induces?	\item The partial ordering induced by $K^*$
In terms of the dual cone, when will&nbsp;$x \succeq_K y$?	\item Exactly when $K^* \cdot (x - y) \geq 0$
In terms of its dual, when will&nbsp;$x \succ_K y$ for some proper cone $K$?	\item Exactly when $\lambda \cdot (x - y) \geq 0$ for all $\lambda \in \text{cl}(K^*), \, \lambda \neq 0$
What's another name for generalized inequalities?	\item Partial orderings
What's the theorem of alternatives for linear strict generalized inequalities?	\item Exactly one of&nbsp;<div>\item $Ax \prec_K b$</div><div>\item and</div><div>\item $A^T \lambda = 0, \quad \lambda^T b \leq 0$</div><div>\item $\lambda \succeq_{K^*} 0, \quad \lambda \neq 0$</div><div>\item is soluble</div>
How can the minimum element of a cone-induced partial ordering be defined in terms of the dual cone?	\item $x$ is the minimum element of $S$ wrt $(\succeq_K)$ iff<div>\item $\lambda \cdot (z - x)$ is a strict supporting hyperplane of $S$&nbsp;for all $\lambda \succ_{K^*} 0$</div>
What's a strict supporting hyperplane of a set $S$ at a point $x_0$?	\item It's a supporting hyperplane of $S$ which intersects $S$ at only $x_0$, if at all
In terms of the dual cone, what's a \emph{sufficient} condition for $x$ to be minimal over $S$ wrt a cone-induced partial ordering?	\item If for some $\lambda \succ_{K^*} 0$ the hyperplane $\lambda \cdot (z - x)$ is a strict supporting hyperplane of $S$&nbsp;<div>\item then $x$ is minimal</div>
In terms of the dual cone, what's a \emph{neccessary} condition for $x$ to be minimal over a \emph{convex} set $S$ wrt a cone-induced partial ordering?	\item For any minimal element $x$&nbsp;<div>\item there exists a nonzero $\lambda \succeq_{K^*} 0$ such that $\lambda \cdot (z - x)$ is a strict supporting hyperplane of $S$</div><div>\item Note the `nonzero' and $(\succeq)$!</div>
Which functions are both concave and convex?	\item Exactly the affine ones
Geometrically, what's a convex function?	\item It's a function $f$ with a convex domain<div>\item and such that every chord lies on or above $f$</div>
What's a chord of a function?	\item A line segment between $(x, f(x))$ and $(y, f(y))$ for some $x, y$
What lemma is often used to test if an $n$-dimensional function is convex?	<div>\item $f$ is convex iff its restriction to any straight line is convex</div>
What's the extended-value extension of a convex function?	<div>\item $\tilde f(x) = f(x)$ if $x \in \text{dom}(f)$</div><div>\item $\tilde f(x) = \infty$ otherwise</div>
What's the usual use of the extended-value &nbsp;extension of a function?	\item It simplifies a lot of results by obviating the need to specify the domain
What's the convention regarding the notation for the extended value extension of $f$ in \emph{Convex Optimization}?	\item It's denoted by $\tilde f$ where necessary<div>\item but when there's no harm from the ambiguity, $f$ will be used</div>
How's the indicator function for a set $C$ defined in \emph{Convex Optimization}?	\item It's the $I_C$ which is zero on $C$ and $\infty$ elsewhere
What's the extended-value extension of a concave function?	<div>\item $\tilde f(x) = f(x)$ if $x \in \text{dom}(f)$</div><div>\item $\tilde f(x) = -\infty$ otherwise</div>
How can convex functions be characterized by their first derivative?	\item Convex functions are exactly those for which<div>\item the domain is convex</div><div>\item the first-order Taylor approximation globally lower-bounds it</div>
Intuitively, what's so special about the characterization of convex functions in terms of their first derivative?	\item It says that local information (the first derivative at a point) can be used to make a global assertion (that the first-order Taylor approximation there lower-bounds the function everywhere)
How can convex functions be characterized in terms of their second derivative?	\item Convex functions are exactly those for which<div>\item the domain is convex</div><div>\item the Hessian is positive-semidefinite everywhere</div>
What's the $\alpha$-sublevel set of a function $f$?	\item The $C_\alpha$ of points $x$ such that $f(x) \leq \alpha$
How do convex functions relate to their sublevel sets?	\item The sublevel sets of a convex function are all convex<div>\item The converse does \emph{not} hold</div>
What's the hypograph of a function?	\item The set of points below a function's surface
What does $\text{epi}(f)$ denote in convex optimization?	\item The epigraph of the function
What's Holder's inequality?	\item For all measurable $f, g$ on a space $S$,<div>\item $\|fg\|_1 \leq \|f\|_p \|g\|_q$</div><div>\item where $\frac{1}{p} + \frac{1}{q} = 1$ and $p, q \in [1, \infty)$</div><div>\item and $\|f\|_p = \left(\int |f|^p d\mu \right)^\frac{1}{p}$</div>
What's the arithmetic-geometric weighted mean inequality?	\item $a^\theta b^{1-\theta} \leq \theta a + (1-\theta)b$<div>\item where&nbsp;</div><div>\item $a, b \geq 0$</div><div>\item $\theta \in [0, 1]$</div>
What common operations preserve convexity on functions?	\item Conic combinations<br /><div>\item Pointwise maximum/supremum</div><div>\item Projectivities</div>
What are the conditions on $g, h$ for $f = h \circ g$ to be convex?	\item $f$ is convex if $h$ is convex and<div>\item $\tilde h$ is nondecreasing and $g$ is convex</div><div>\item $\tilde h$ is nonincreasing and $g$ is concave</div>
What are the conditions on $g, h$ for $f = h \circ g$ to be concave?	\item $f$ is convex if $h$ is concave and<div>\item $\tilde h$ is nondecreasing and $g$ is concave</div><div>\item $\tilde h$ is nonincreasing and $g$ is convex</div>
In the rules for the convexity of composite functions, why is the constraint on $\tilde h$ important?	\item It guarantees the domain of the composition will be convex
How do the rules for the convexity of composite functions extend to compositions $h \circ g$ where $g$ is vector-valued?	\item They're the same except the conditions on the inner functions $g$ are applied component-wise to $g_k$
When is $g(x) = \inf_{y \in C} f(x, y)$ a convex function?	\item When&nbsp;<div>\item $C$ is convex</div><div>\item $f$ is convex</div><div>\item $g(x) &gt; -\infty$ &nbsp;somewhere</div>
What's the conjugate function in convex analysis?	\item $f^*(y) = \sup_{x \in \text{dom}(f)} (y \cdot x - f(x))$<div>\item and its domain is wherever it is finite</div>
When is the convex conjugate itself convex?	\item Always.
What's Fenchel's inequality?	\item $f(x) + f^*(y) \geq x \cdot y$<div>\item where $f^*$ is the convex conjugate</div>
When is $f^{**} = f$ for the convex conjugate?	\item When $f$ is convex and closed
What's a closed function?	\item A function which takes closed sets to closed sets
In terms of its epigraph, when is a real-valued $f$ a closed function?	\item When its epigraph is closed
What's the Legendre transform?	\item It's the convex conjugate of a differentiable function
If $f$ is differentiable, how can the convex conjugate be found?	\item To find $f^*(y)$<div>\item first find the $x^\prime$ such that $y = \nabla f(x^\prime)$</div><div>\item Then $f^*(y) = x^\prime \cdot y - f(x^\prime)$&nbsp;</div>
What's the convex conjugate of $g(x) = af(x) + b$?	\item $g^*(y) = af^*(y/a) - b$
What's the convex conjugate of $g(x) = f(Ax + b)$ for a square, nonsingular $A$?	\item $g^*(y) = f^*(A^{-T} y) - A b \cdot y$
What's the convex conjugate of $g(u, v) = f_1(u) + f_2(v)$ if $f_1, f_2$ are convex?	\item $g^*(w, z) = f_1^*(w) + f_2^*(z)$
In terms of sets, when is a function quasiconvex?	\item When its domain and all sublevel sets are convex
What's a quasilinear function?	\item One which is both quasiconcave and quasiconvex
What's Jensen's inequality for a quasiconvex function $f$?	\item $f(\theta x + (1-\theta)y) \leq \max\{f(x), f(y)\}$<div>\item for any $\theta \in [0, 1]$</div>
When does Jensen's inequality for quasiconvex functions hold?	\item Exactly when the function in question is quasiconvex
What's Jensen's inequality for a quasiconcave function $f$?	\item $f(\theta x + (1-\theta)y) \geq \min\{f(x), f(y)\}$<div>\item for any $\theta \in [0, 1]$</div>
What lemma is often used to test if an $n$-dimensional function is quasiconvex?	\item $f$ is convex iff its restriction to any straight line is quasiconvex
How can continuous quasiconvex functions on $\mbb{R}$ be characterized?	<div>\item A continuous $f$ is quasiconvex if and only if</div><div>\item it is monotonic</div><div>\item or</div><div>\item there is a point such that it's nonincreasing to the left and nondecreasing to the right &nbsp;</div>
What's the first order condition for quasiconvex functions?	\item $f$ is quasiconvex iff it has a convex domain and<div>\item $f(y) \geq f(x) \implies \nabla f(x) (y-x) \geq 0$</div><div>\item for all $x, y \in \text{dom}(f)$</div>
What's the second order necessary condition for a function on $\mbb{R}$ to be quasiconvex?	\item $f^\prime = 0 \implies f^{\prime\prime}(x) \geq 0$
What's the geometric interpretation of the second-order necessary conditions for quasiconvex functions?	\item Wherever $\nabla f(x) = 0$, the Hessian should be positive-semidefinite<div>\item Wherever $\nabla f(x) \neq 0$, the Hessian should be positive-semidefinite on the subspace orthogonal to $\nabla f(x)$</div>
What's the geometric interpretation of the second-order sufficient conditions for quasiconvex functions?	\item Wherever $\nabla f(x) = 0$, the Hessian should be positive-definite<div>\item Wherever $\nabla f(x) \neq 0$, the Hessian should be positive-definite on the subspace orthogonal to $\nabla f(x)$</div>
What's a log-concave function?	\item It's a function $f &gt; 0$ such that $\log f$ is concave
How can log-concave functions be characterized without using logarithms?	\item A log-concave function is exactly one such that<div>\item $f(x)^\theta f(y)^{1-\theta} \leq&nbsp;f(\theta x + (1-\theta)y)$</div><div>\item for all $x, y \in \text{dom}(f)$ and $\theta \in [0, 1]$</div>
What are the second-order conditions that characterize a log-concave function?	\item $f$ is log-concave if and only if<div>\item $f \cdot \nabla^2 f \preceq \nabla f \otimes \nabla f$</div>
What does $(\otimes)$ denote in vector algebra?	\item The outer product<br />
How can the outer product $x \otimes y$ be interpreted?	\item $(x \otimes y)w = x \langle y, w \rangle$
How do log-concavity and log-convexity interact with addition?	\item Log-convexity is preserved under addition<div>\item Log-concavity is not though</div>
How do log-convexity and log-concavity interact with multiplication?	\item They're preserved under multiplication and positive scaling
When is log-concavity preserved by integration?	\item If $f \colon \mbb{R}^n \times \mbb{R}^m \rightarrow \mbb{R}$ is log-concave<div>\item then $g(x) = \int f(x, y) dy$ is log-concave</div>
What are some common operations that preserve log-concavity?	\item Positive scaling<div>\item Multiplication</div><div>\item Integration</div><div>\item Convolution/correlation</div>
When is a function nondecreasing with respect to a cone $K$?	\item Exactly when<div>\item $x \succeq_K y \implies f(x) \geq f(y)$</div>
When is a function increasing with respect to a cone $K$?	\item Exactly when<div>\item $x \succeq_K y,\, x \neq y \implies f(x) &gt; f(y)$</div>
What's a matrix monotone function?	\item A $f \colon S^n \rightarrow \mbb{R}$ which is monotone wrt $S^n_+$
What's the first-order condition in terms of the dual cone for a function to be $K$-nondecreasing?	<div>\item A convex-domain'd $f$ is $K$-nondecreasing iff</div>\item $\nabla f(x) \in \text{cl}(K^*)$<div>\item Note the $K^*$!</div>
What's the first-order condition in terms of the dual cone for a function to be $K$-increasing?	<div>\item A convex-domain'd $f$ is $K$-increasing iff</div>\item $\nabla f(x) &nbsp;\in K^*$<br />
What's a $K$-convex&nbsp;function?	\item A $f$ such that<div>\item $f(\theta + (1-\theta)y) \preceq_K \theta f(x) + (1-\theta)f(y)$</div>
In terms of the dual cone, what's a $K$-convex function?	\item A $f$ such that for every $w \in K^*$, the real-valued $w \cdot f(x)$ is convex
What's the first-order condition that characterizes a $K$-convex function?	\item $f$ is $K$-convex if and only if its domain is convex and<div>\item $f(y) - f(x) \succeq_K \nabla f(x) (y-x)$</div>
What's the definition of the optimal value of an optimization problem?	\item It's the infinium/supremum of the feasible values
What's the convention for denoting the optimal value in \emph{Convex Optimization}?	\item $p^*$, and it can take on $\pm \infty$
What's $X_\text{opt}$ denote in \emph{Convex Optimization}?	\item The set of all optimal points
What does it mean for the optimal value to be achieved?	\item There's a point in the feasible set at which the objective matches the optimal value
What's a locally optimal point of an optimization problem?	\item A point which is optimal when the problem restricted to a $R$-radius disk around it
What's an active constraint in an optimization problem?	\item The inequality $f_i(x) \leq 0$ is active at $x_0$ if $f_i(x_0) = 0$
What's a feasibility problem in optimization?	\item An optimization problem with $f_0(x) = x$
When are two optimization problems equivalent?	\item When a solution to one is easily transformed to a solution of the other, and vice versa
How can the $f_0$ of an optimization problem be transformed in such a way that the optimal points are preserved?&nbsp;	\item An increasing $\psi_0$ applied to $f_0$<br />
How can the $f_i$ of an optimization problem be transformed in such a way that the optimal points are preserved?&nbsp;	\item A $\psi_i$ such that $\psi_i(u) \geq 0 \iff u \geq 0$ applied to $f_i$
How can the $h_j$ of an optimization problem be transformed in such a way that the optimal points are preserved?&nbsp;	\item A $\psi_j$ such that $\psi_j(u) = 0 \iff u = 0$ applied to $h_j$
What's the idea with slack variables in optimization problems?&nbsp;	\item $f_i(x) \leq 0$ iff there's a $s_i \geq 0$ such that $f_i(x) + s_i = 0$
How are equality constraints usually eliminated from an optimization problem?	\item By parameterizing them and phrasing the optimization in terms of the parameters
What's an implicit constraint in an optimization problem?	\item A constraint encoded by the &nbsp;objective's domain
What are two other names for oracle optimization models?	\item Black-box model<div>\item Subroutine model</div>
What's an oracle optimization model?	\item An optimization problem where the objective or some of the constraints are provided by an oracle
In standard form, what's a convex optimization problem?	\item One with<div>\item a convex objective function</div><div>\item convex inequality constraint functions</div><div>\item affine equality constraint functions</div>
In standard form, what's a quasiconvex optimization problem?	\item One with<div>\item a quasiconvex objective function</div><div>\item convex inequality constraint functions</div><div>\item affine equality constraint functions</div>
What's a $\epsilon$-suboptimal set in optimization theory?	\item The set of points $x$ for whom $f_0(x)$ is $\epsilon$-close to $p^*$
What's an abstract convex optimization problem?	\item In the literature, it's a problem with a convex objective and a convex feasible set<div>\item possibly despite its constraints being non-convex or non-affine</div>
Are locally optimal points of quasiconvex problems also globally optimal?	\item Nope.
Are locally optimal points of convex problems also globally optimal?	\item Yup.
What's the first-order exact condition for an optimal point of a convex problem?	\item $x$ is optimal if and only if it's in the feasible set and&nbsp;<div>\item $&nbsp;(y - x) \cdot&nbsp;\nabla f_0(x)\geq 0$&nbsp;</div><div>\item for all $y$ in the feasible set</div>
What's the complimentarity condition?	\item Vectors $x, y$ satisfy the complimentarity condition if their sparsity pattern has a null intersection
What's the epigraph form of a convex optimization problem?	\item Minimize $t$ subject to $f_0(x) - t \leq 0$
When can a quasiconvex inequality constraint be replaced with a convex one?	\item Always, since there's always a convex function which has the sam $0$-sublevel set
What's a first-order sufficient condition for a point to be optimal in a quasiconvex optimization problem?	\item A $x$ in the feasible set is optimal if&nbsp;<div>\item $\nabla f_0(x) \cdot (y - x) &gt; 0$&nbsp;</div><div>\item for all $y$ in the feasible set</div>
What's the convex-feasibility approach to solving quasiconvex problems?	\item Find a convex $\phi_t$ such that $f_0(x) \leq t$ iff $\phi_t(x) \leq 0$<div>\item Then if the quasiconvex problem augmented with $\phi_t(x) = 0$ is feasible,&nbsp;</div><div>\item it must be that $p^* \leq t$</div><div>\item Now apply binary search.</div>
What's a standard form linear program?	\item One whose only inequality constraints are $x \succeq 0$
What's an inequality-form linear program?	\item One without any equality constraints
What's a general form linear program?	\item One with an affine objective, equality constraints and inequality constraints
What's the Chebyshev center of a polyhedron?	\item The center of the largest ball that can fit in the polyhedron
What's a linear-fractional program?	\item An optimization problem with<div>\item a projectivity objective</div><div>\item affine inequality constraint functions</div><div>\item affine equality constraint functions</div>
What's a generalized linear-fractional program?	\item An optimization problem with<div>\item a pointwise-maximum of projectivities objective</div><div>\item affine inequality constraint functions</div><div>\item affine equality constraint functions</div>
What's a quadratic program?	\item An optimization problem with<div>\item quadratic objective</div><div>\item affine inequality constraint functions</div><div>\item affine equality constraint functions</div>
What's a quadratically constrained quadratic program?	\item An optimization problem with<div>\item quadratic objective</div><div>\item quadratic inequality constraint functions</div><div>\item affine equality constraint functions</div>
What's a QCQP in optimization?	\item Quadratically constrained quadratic program
What's a second-order cone constraint in optimization?	\item A constraint of the form<div>\item $\|Ax+b\|_2 \leq c \cdot x + d$</div><div>\item so named because it's equivalent to requiring that $(Ax+b, c\cdot x + d)$ lie in the second-order cone of $\mbb{R}^{n+1}$</div>
What's the second-order cone?	\item It's the norm cone given by the $\ell_2$ norm
What are three other names for the second-order cone?	\item Quadratic cone<div>\item Lorentz cone</div><div>\item Ice-cream cone</div>
What's a second-order cone program in optimization?	\item An optimization problem with<div>\item an affine objective</div><div>\item second-order cone constraints for inequality constraints</div><div>\item affine equality constraint functions</div>
What's a SOCP in optimization?	\item Second-order cone problem
What's the idea in robust linear programming?	\item Allow the gradient of the linear inequality constraints to vary within an ellipsoid<br /><div>\item Require that the solution satisfies all possible settings of the gradients</div><div>\item Reduces to a SOCP</div>
What's a monomial?	\item $f(x) = c \prod x_i^{a_i}$
What's a posynomial?	\item $f(x) = \sum c_k \prod x_i^{a_ik}$<div>\item where $c_k &gt; 0$</div>
What's a geometric program?	\item An optimization program with<div>\item a posynomial objective</div><div>\item posynomial inequality constraints ($f_i(x) \leq 1$)</div><div>\item monomial equality constraints ($h_i(x) = 0$)</div>
What's a geometric program in convex form?	\item It's a geometric program with<div>\item the objective rewritten as a $\text{lse}$ function</div><div>\item the inequality constraint functions rewritten as $\text{lse}$ functions</div><div>\item the equality constraint functions rewritten as affine functions</div>
What's a conic form optimization problem?	\item An optimziation problem with<div>\item an affine objective</div><div>\item affine generalized $K$-inequality constraints</div><div>\item affine equality constraints</div>
What's another name for a conic form problem?	\item A cone program
What's a semidefinite program?	\item A cone program over cone $S^k_+$
What's a standard form semidefinite program?	\item An optimization problem over $S^n$ with<div>\item objective $\text{tr}(CX)$</div><div>\item inequality constraints $X \succeq 0$</div><div>\item equality constraints $\text{tr}(A_i X) = b_i$</div>
What's a LMI in optimization theory?	\item Linear matrix inequality
What's a vector optimization problem?	\item An optimization problem with a vector-valued objective,&nbsp;<div>\item minimized over some partial ordering&nbsp;</div>
What's a convex vector optimization problem?	\item It's an optimization problem with<div>\item a $K$-convex&nbsp;objective function&nbsp;</div><div>\item convex inequality constraints</div><div>\item affine equality constraints</div>
In terms of sets, when is a point $x^\star$ in a vector optimization problem optimal?	<div>\item When it's feasible and</div>\item $\mc{O} \subseteq f_0(x^\star) + K$
When is a point $x$ in a vector optimization problem Pareto optimal?	\item When it's feasible and<div>\item $(f_0(x) - K) \cap \mc{O} = \{ f_0(x) \}$</div>
What does $\mc{O}$ denote in optimization theory?	\item The set of objective values obtained by the feasible set
What does $\mc{P}$ usually denote in optimization theory?&nbsp;	\item The set of Pareto-optimal values
How does the set of Pareto optimal values relate to the set of obtained values in general?	\item $\mc{P} \subseteq \mc{O} \cap \text{bd}(\mc{O})$
What's the program used in scalarization in optimization theory?	\item For some $\lambda \in K^*$,&nbsp;solve the linear program with<div>\item objective $\lambda \cdot f_0(x)$&nbsp;</div><div>\item the same constraints</div>
What's the use of scalarization?	\item If $x$ is an optimal point of the scalarized program, then it is a Pareto-optimal point of the original program
What's the name of the $\lambda$ used in a scalarized program?	\item The weight vector
Can all Pareto optimal points be found via scalarization?	\item Nope
What's the geometric interpretation of scalarization?	<div>\item Solving the scalarized problem finds a feasible point on the boundary of $\mc{O}$ which has a supporting hyperplane of gradient $\lambda$</div>
If a vector optimization problem is convex, what can be said about the scalarized problem?	\item It's also convex
What's the converse theorem regarding Pareto optimal points and scalarization theorem?	\item If the program is convex then for every Pareto optimal point $x$, there's a weight vector $\lambda \in \text{cl}(K^*)$ for which $x$ is a solution to the scalarized problem corresponding to $\lambda$
What's the gap between the theorems regarding scalarization and Pareto optimal points?	<div>\item On a convex problem,</div>\item the scalarized program derived from $\lambda \succ_{K^*} 0$ will always find a Pareto optimal point<div>\item But for some Pareto optimal points the weight vector that recovers them may only satisfy $\lambda \succeq_{K^*} 0$</div>
Given a convex problem, in what two ways can \emph{all} the Pareto-optimal points be found?	<div>\item By solving the scalarization problem for $\lambda \succeq_{K^*} 0$ and testing which results are Pareto optimal</div>\item By finding the limits of the Pareto optimal points&nbsp;corresponding to $\lambda \succ_{K^*} 0$
What's a multicriterion optimization problem?	\item A vector optimization problem involving the cone $\mbb{R}^q_+$
When does one point $x$ dominate another $y$ in multicriterion optimization?	\item When $f_{0i}(x) \leq f_{0i}(y)$ for all $i$<div>\item and $f_{0j}(x) &lt; f_{0j}(y)$ for some $j$</div>
What's a strong tradeoff in multicriterion optimization?	\item There's a strong tradeoff at a Pareto optimal point if a large increase in one objective must be accepted to achieve a small decrease in another
What's a weak tradeoff in multicriterion optimization?	\item There's a weak tradeoff at a Pareto optimal point if a small increase in one objective will enable a large decrease in another
Intuitively, what's a Pareto optimal point?	\item One for which there is no strictly better alternative
What's an optimal tradeoff surface in multicriterion analysis?	\item It's the surface over created by the set of Pareto optimal points being fed into&nbsp;$f = (f_{01}, f_{02}, \dotsc, f_{0q})$
When scalarizing a multicriterion problem, how can the weight vector be interpreted?	\item $\lambda_i/\lambda_j$ is the relative weight of solution component $i$ and solution component $j$<div>\item ie decreasing $f_{0i}$ by $1$ requires increasing&nbsp;$f_{0j}$&nbsp;by $\lambda_i/\lambda_j$</div>
What's the definition of the Lagrangian?	\item For a standard-form optimization problem,<div>\item $L \colon \mc{D} \times \mbb{R}^m \times \mbb{R}^p \rightarrow \mbb{R}$<br /><div>\item $L(x, \lambda, \nu) = f_0(x) + \lambda \cdot f(x) + \nu \cdot h(x)$</div></div>
What's the dual function of an optimization problem?&nbsp;	<div>\item $g \colon \mbb{R}^m \times \mbb{R}^p \rightarrow \mbb{R}$</div><div>\item $g(\lambda, \nu) = \inf_x L(x, \lambda, \nu)$</div><div>\item where $L$ is the Lagrangian</div>
How does the dual function of an optimization problem bound the optimal value?	\item For any $\lambda \succeq 0$ and any $\nu$,<div>\item $g(\lambda, \nu) \leq p^\star$</div>
What's the dual feasible region of an optimization problem?	\item The $(\lambda, \nu)$ such that $\lambda \succeq 0$ and $g(\lambda, \nu) &gt; -\infty$
How can the Lagrangian be interpreted as a linear approximation?	\item An optimization problem can have its constraints folded into the objective by using indicator functions<div>\item ie $f_i(x) \leq 0$ becomes $I_{\leq 0}(f_i(x))$ which is zero on the nonpositives and infinite elsewhere</div><div>\item The Lagrangian term $\lambda_i f_i(x)$ is a linear approximation of this&nbsp;</div>
How can the dual function of a standard-form LP be written in terms of the conjugate?	\item $g(\lambda, \nu) = (-b \cdot \lambda - d \cdot \nu) - f_0^*(-A^T \lambda - C^T \nu)$
How can the domain of the dual function of a standard-form LP be written in terms of the conjugate?	\item $\text{dom}(g) = \{(\lambda, \nu) | -A^T \lambda - C^T \nu \in \text{dom}(f_0^*)\}$
What's the Lagrange dual problem associated with an optimization problem?	\item Maximize $g(\lambda, \nu)$<div>\item subject to $\lambda \succeq 0$</div><div>\item where $g$ is the dual function</div>
What are the optimal Lagrange multipliers for a problem?&nbsp;	\item The $(\lambda^\star, \nu^\star)$ which are optimal for the dual problem
Is the Lagrange dual function $g(\lambda, \nu)$ concave, convex or neither?	\item Concave<div>\item since it's the infinium of a family of affine functions on $(\lambda, \nu)$</div>
What's the dual problem to a standard form LP?	\item Maximize $-b \cdot \nu$<div>\item subject to $A^T \nu + c \succeq 0$</div>
What's the dual problem to a LP in inequality form?	\item Maximize $-b \cdot \lambda$<div>\item subject to</div><div>\item $A^T \lambda + c = 0$</div><div>\item $\lambda \succeq 0$</div>
What does $d^\star$ denote in optimization theory?	\item An optimal value of a dual problem
What's weak duality in optimization theory?	\item That $d^\star \leq p^\star$
What's the optimal duality gap in optimization theory?	\item $p^\star - d^\star$
What's strong duality in optimization theory?	\item $p^\star = d^\star$
What's a constraint qualification in optimization theory?	\item A condition on an optimization problem that ensures strong duality holds&nbsp;
What's Slater's theorem?	\item If the primal problem is convex and Slater's condition holds, then strong duality holds
What's Slater's condition?	\item There exists a strictly feasible point in $\text{relint}(\mc{D})$
What does $\mc{D}$ denote in optimization theory?	\item The domain of the objective of an optimization problem
How can Slater's condition be refined if some of the inequalities are linear?	\item For the linear constraints, it is only necessary that $f_i(x) \leq 0$<div>\item (rather than $f_i(x) &lt; 0$)</div>
What's a strictly feasible point?	\item One which satisfies the equality constraint and strictly satisfies the inequality constraints
When does strong duality fail for LPs?	\item Exactly when both the primal and dual are infeasible
What's the trust region problem?	\item An optimization problem where an approximation is optimized&nbsp;<div>\item over a restricted `trusted' region where the approximation is assumed to be valid</div>
What's the set $\mc{G}$ when discussing the geometric interpretation of weak duality?	\item The set of values taken on by the objective and constraint functions<div>\item $\mc{G} = \{(f(x), h(x),&nbsp;f_0(x)) | x \in \mc{G}\}$</div>
In terms of the set $\mc{G}$ of values obtained by the constraints and objective, how's the primal&nbsp;optimal&nbsp;value defined?&nbsp;	\item $p^\star = \inf \{ t | (u, v, t) \in \mc{G}, u \succeq 0, v = 0 \}$
In terms of the set $\mc{G}$ of values obtained by the constraints and objective, how's the dual function defined?&nbsp;	\item $g(\lambda, \nu) = \inf \{ (\lambda, \nu, 1) \cdot (u, v, t) | (u, v, t) \in \mc{G}\}$<div>\item ie $g$ is an infinium of supporting hyperplanes to $\mc{G}$</div>
What's the set $\mc{A}$ used when discussing the geometric interpretation of weak duality?	\item $\mc{A} = \mc{G} + \mbb{R}^m_+ \times \{0\}^p \times \mbb{R}_+$<div>\item ie the set of all values obtained by the constraints and objective, or strictly worse than them</div>
In terms of the set $\mc{A}$ of values obtained by the constraints and objective or worse than them, how's the primal&nbsp;optimal&nbsp;value defined?&nbsp;	\item $p^\star = \inf \{ t| (0, 0, t) \in \mc{A} \}$
In terms of the set $\mc{A}$ of values obtained by the constraints and objective or worse than them, how's the dual function defined?&nbsp;	\item $g(\lambda, \nu) = \inf \{ (\lambda, \nu ,1) \cdot (u, v, t) | (u, v, t) \in \mc{A}\}$
Geometrically, what's the purpose of Slater's condition?	\item It ensures that the supporting hyperplane of $\mc{A}$ corresponding to the optimal $\lambda^\star$ isn't parallel to the objective axis $t$
What's the max-min inequality?	\item For any $f$ and any $W, Z$,<div>\item $\sup_Z \inf_W f(w, z) \leq \inf_W \sup_Z f(w, z)$</div>
How can weak duality be described in terms of the max-min inequality?	\item $p^* = \inf_x \sup_{\lambda \succeq 0} L(x, \lambda, \nu)$<div>\item $d^* =&nbsp;\sup_{\lambda \succeq 0}&nbsp;\inf_x L(x, \lambda, \nu)$</div><div>\item By the max-min inequality, $d^* \leq p^*$</div>
What's the strong max-min property?	\item $f$ has the strong max-min property over $W, Z$ if<div>\item $\sup_Z \inf_W f(w, z) = \inf_W \sup_Z f(w, z)$</div>
What's another name for the strong max-min property?	\item The saddle-point property
What's a saddle-point in optimization theory?	\item $w_0, z_0$ is a saddle point of $f(w, z)$ over $W, Z$ if&nbsp;<div>\item $f(w_0, z_0)$ is a maximum of $f(w, z_0)$</div><div>\item $f(w_0, z_0)$ is a minimum of $f(w_0, z)$</div>
How do saddle points relate to the strong max-min property?	\item The strong max-min property holds if and only if a saddle-point exists
What's the effective domain of a function?	\item The part of the domain where it's finite
What's a proximal point to a function $f$ at a point $v$?	\item The value of $\text{prox}_f(v)$
In the scaled proximal operator, what's the effect of $\lambda$?	\item The larger the $\lambda$, the less weight is placed on finding a nearby point
What's a Euclidean projection onto a convex set $C$?	\item $\Pi_C(v) = \arg \min_{x \in C} \| x - v \|_2$<div>\item ie take each point to the nearest point in $C$</div>
What does the scaled proximal operator approximate when $f$ is smooth and $\lambda$ is small?	\item $\text{prox}_{\lambda f} (v) \approx v - \lambda \nabla f(v)$
What are the fixed points of the proximal operator?	\item Exactly the minimizers of $f$
What's the seperable sum property of the proximal operator?	<div>\item If $f(x, y) = \phi(x) + \psi(y)$</div>\item $\text{prox}_f(v,w) = (\text{prox}_\phi(v), \text{prox}_\psi(w))$
What's the proximal operator of $f(x) = \alpha \psi(x) + b$ for $\alpha &gt; 0$?	\item $\text{prox}_{f}(v) = \text{prox}_{\alpha \psi}(v)$
What's the proximal operator of $f(x) = \psi(Qx)$, where $Q$ is orthogonal?	\item $\text{prox}_f(v) = Q^{-1} \text{prox}_\psi(Qv)$
What's the proximal operator of $f(x) = \psi(\alpha x + b)$ where $\alpha \neq 0$?	<div>\item Let $L(x) = \alpha x + b$. Then</div>\item $\text{prox}_f(v) = (L^{-1} \circ \text{prox}_{\alpha^2 \psi} \circ L)(v)$
What's the proximal operator of $f(x) = \psi(x) + a\cdot x + b$?	\item $\text{prox}_f(v) = \text{prox}_\psi (v - a)$
What's the proximal operator of $f(x) = \psi(x) + \frac{\rho}{2}\|x - a\|^2_2$?	\item $\text{prox}_f(v) = \text{prox}_{&nbsp;\frac{1}{1+\rho}&nbsp;\psi} (&nbsp;\frac{1}{1+\rho}&nbsp;v +&nbsp;\frac{&nbsp;\rho&nbsp;}{1+\rho}&nbsp;a)$
What's a contraction map in a metric space?	\item A function on a metric space such that<div>\item $d(f(x), f(y)) \leq kd(x,y)$</div><div>\item for some constant $k$</div>
What's a non-expansive map?	\item A contraction map with a constant $k \leq 1$
In Hilbert space, what's a firmly nonexpansive map?	\item A function on a Hilbert space such that<div>\item $\|f(x+\delta) - f(x)\|^2 \leq \delta \cdot (f(x+\delta) - f(x))$</div>
What's the Krasnoselskii-Mann theorem?	\item $\alpha$-averaged operators are guaranteed to converge to a fixed point if one exists<br />
What's an $\alpha$-averaged operator?	\item An operator of the form<div>\item $(1-\alpha)I + \alpha N$&nbsp;</div><div>\item for some non-expansive operator $N$</div>
How do $\alpha$-averaged operators relate to firmly nonexpansive operators?	\item Firmly nonexpansive operators are exactly the $\frac{1}{2}$-averaged operators
What's nice about the class of $\alpha$-averaged operators?	\item It's closed under composition.
What class of operators does the proximal operator lie in?	\item The firmly nonexpansive ones
What's the proximal average of a set of closed, proper convex functions?	<div>\item Let</div>\item $\frac{1}{m} \sum \text{prox}_{f_i} = \text{prox}_g$<div>\item Then $g$ is the proximal average of $\{f_i\}$</div>
What's the Moreau decomposition?	\item $v = \text{prox}_f (v) + \text{prox}_{f^*}(v)$<div>\item where $f^*$ is the convex conjugate</div>
What's the Fenchel-Moreau theorem?	\item $f = f^{**}$ if and only if $f$ is convex and lower semi-continuous
Geometrically, what's the convex biconjugate $f^{**}$?	\item The closed convex hull of $f$
What's the convex hull of a function?	\item The function that describes the convex hull of its epigraph
What's a lower semi-continuous function?	\item One whose sublevel sets are all closed<br />
What're two other names for the sublevel sets of a function?	\item Lower levelsets<div>\item Trenches</div>
What's the use of the Moreau decomposition?	\item It lets you find the proximal operator of a function in terms of the proximal operator of its convex conjugate
What's the polar cone of a cone $K$?	\item $K^\circ = -K^*$<div>\item where $K^*$ is the dual cone</div>
What's the infimal convolution of two functions $f, g$?	\item $(f \square g)(v) = \inf_x (f(x) + g(v - x))$
What's the Moreau envelope of a function $f$?	\item $M_f(v) = f(x) \square&nbsp;&nbsp;\left(&nbsp;&nbsp;\frac{1}{2}\| x \|_2^2\right)$
What's another name for the Moreau envelope?	\item Moreau-Yosida regularization
What's the use of the Moreau envelope of a function $f$?	\item Irrespective of $f$, $M_f$ is<div>\item continuously differentiable</div><div>\item has a domain of $\mbb{R}^n$</div><div>\item has the same minimizers as $f$</div>
What's the duality property of infinial convolution?	\item $(f \square g)^* = f^* + g^*$<div>\item where $f^*$ is the convex conjugate</div>
What's the conjugate interpretation of the Moreau envelope?	\item $M_f(x) = (f^*(x) + \frac{1}{2}\| x \|^2_2)^*$<div>\item So it regularizes the conjugate then takes the conjugate again</div>
What's a strongly convex function?	\item A function $f$ such that for some $m &gt; 0$,<div>\item $m\| \delta \|^2 \leq \langle \nabla f(x) - \nabla f(x + \delta), \delta \rangle$</div>
In general, when does a closed, convex function $f$ have a smooth conjugate?	\item When $f$ is strongly convex
For convex functions, what's the analytic relationship between the proximal operator and the Moreau envelope?	\item $\text{prox}_f = \nabla M_{f^*}$
For convex functions, what's the intuitive relationship between the proximal operator and the Moreau envelope?	\item The proximal operator gives the point that minimizes the Moreau envelope
What's the resolvent of an operator?	<div>\item For operator $F$ and parameter $\lambda$,</div>\item $(I + \lambda F)^{-1}$
How does the proximal operator relate to the resolvent?	\item $\text{prox}_{\lambda f} = (I + \lambda \partial f)^{-1}$<div>\item where $\partial f$ is the subgradient</div>
Is the resolvent a map or a function?	\item A function - it's single-valued<div>\item (despite being composed of operators on relations)</div>
How can the convex conjugate be found for smooth, convex functions?	<div>\item If&nbsp;</div><div>\item $\nabla f = (\nabla g)^{-1}$&nbsp;</div><div>\item $f(x) + g(y) = x\cdot y$</div><div>\item then $f^* = g$</div>
How can the proximal operator be interpreted in terms of gradient descent algorithms?	\item The proximal operator of the Taylor approximation to $f$<div>\item at first order is a gradient descent step</div><div>\item at second order is a Levenberg-Marquardt step&nbsp;</div>
How can the proximal operator be interpreted in terms of trust region problems?	\item The proximal operator gives the solution to the trust region problem for $f$&nbsp;<div>\item for some trust radius $\rho$&nbsp;</div>
What's the proximal operator of a quadratic function?	\item If $f = \frac{1}{2}x^T A x + b^T x + c$ for a positive-definite $A$, then<div>\item $\text{prox}_f(v) = (I + A)^{-1}(v - b)$</div>
When can the Hessian be written as a sum of a rank-1 matrix and a diagonal?	\item When $f$ has the form&nbsp;<div>\item $f(x) = \gamma(\psi_i(x_i)) + \phi_i(x_i)$</div><div>\item where the $\psi, \phi, \gamma$ are all real-valued</div>
How fast can a system described by a diagonal matrix plus a rank $k$ matrix be solved?	\item $O(nk^2)$
What's the convex conjugate of the indicator function for a convex set?	\item The support function for the same set
What's the proximal operator of the $\ell_1$ norm?	\item The soft threshold function
What's the convex conjugate of a norm?	\item The indicator for the unit ball of that norm
What's the proximal operator for a norm?	\item $\text{prox}_\ell(v) = v - \Pi_\mc{B}(v)$<div>\item where $\mc{B}$ is the unit ball</div>
How can the dual norm be interpreted geometrically?	\item It's the support function for the unit norm ball
What's Moreau's identity?	\item $x = \text{prox}_f(x) + \text{prox}_{f^*}(x)$
How well do most Naive Bayes classifiers work? why?&nbsp;	in general, NB classifiers work surprisingly well; they work well when the errors due to incorrectly assuming indepedence among the features balance roughly evenly in the positive and negative directions&nbsp;<div>&gt;&nbsp;http://www.johndcook.com/blog/2015/03/26/clinical-trials-and-machine-learning/</div>
What's catastropic forgetting?	\item When a ML system is trained on one task then another, it tends to forget about the first task
What's the acronym SUCCES stand for in scientific writing?	\item Simple<div>\item Unexpected</div><div>\item Concrete</div><div>\item Credible</div><div>\item Emotional</div><div>\item Stories</div>
In terms of scientific writing, what's worth remembering about the ladder of abstraction?	\item The top (big ideas) and bottom (data) are easy to communicate<div>\item It's the ones in the middle that are difficult</div>
How is the credibility of a scientific work formed?	\item By establishing a chain of credibility linking data and previous work through to the conclusion
What should the emotional aspect of scientific writing be?	\item It should be an appeal to the reader's drive for \emph{understanding} rather than \emph{information}
How are stories modular?	\item A story is created by threading together multiple smaller stories
What's the acronym OCAR stand for in scientific writing?	<div>\item It gives a structure for stories</div>\item Opening<div>\item Challenge</div><div>\item Action</div><div>\item Resolution</div>
What's the acronym ABDCE stand for in scientific writing?	\item It gives a structure for stories<div>\item Action</div><div>\item Background</div><div>\item Development</div><div>\item Climax</div><div>\item Ending</div>
What's the LD acronym stand for in scientific writing?	<div>\item It's a structure for stories</div>\item Lead<div>\item Development</div>
What's the LDR acronym stand for in scientific writing?	<div>\item It's a structure for stories</div>\item Lead<div>\item Development</div><div>\item Resolution</div>
How do the OCAR/ABDCE/LDR/LD structures compare?	\item They're suited for different amounts of expected patience from the audience<div>\item OCAR is the slowest to start; LD the fastest</div>
What's the hourglass analogy of scientific writing?	\item The opening should be wide, dealing with high-level issues<div>\item The body should be exact, dealing with technical issues</div><div>\item The close should be as wide as the opening, dealing with the same level of issues</div>
What's an easy test for whether you're writing a literature review or an introduction?	\item Literature reviews have phrases of the form `[Smith 2003] found X`. It talks about what someone did.<div>\item Introductions have phrases of the form `X occurs [Smith 2003]`. It talks about how something works.</div>
What's the format of a good challenge in scientific writing?	\item `To learn X, we did Y'
What's the acronym IMRaD stand for in scientific writing?&nbsp;	\item Introduction<div>\item Methods</div><div>\item Results</div><div>\item and</div><div>\item Discussion</div>
What parts of a IMRaD is covered by the `action' component of OCAR?&nbsp;	\item Methods<div>\item Results</div><div>\item and</div><div>\item (most of) Discussion</div>
How should the methods section of a paper be structured?	\item Lead/development<div>\item since most readers won't care about the details</div>
What are the two principles to be kept in mind when structuring the results and discussion sections?	\item Structure them however best tells the story<div>\item Distinguish \emph{what you found} from \emph{what you think}</div>
What are the three kinds of information found in a paper?	\item Data<div>\item Inference, which are objective deductions</div><div>\item Interpretation, which are subjective deductions</div>
Why's it important to give results before discussing them?	\item Because then the story's being led by the characters<div>\item as opposed to the characters having plot enforced on them</div>
How should statistics play into scientific writing?	\item They should \emph{support} the story.<div>\item They definitely shouldn't \emph{be} the story</div>
How should the discussion section of a paper be structured?	\item As a mini-story,<div>\item following OCAR or LDR</div>
How is the resolution of a paper usually written?	\item As a single-paragraph walk back through OCAR<div>\item that places the AR of the paper in the original context given by the OC</div>
What should you be careful about when proposing new questions in the resolution?	\item That you frame them as a \emph{new} knowledge gap<div>\item rather than your failure to close an old one</div>
Should new ideas be presented in the resolution?	\item \emph{No}.<div>\item New ideas should appear earlier in the paper, and only be referenced in the resolution.</div>
What's the TS-D model of paragraphs in scientific writing?	\item Topic sentence<div>\item followed by development</div>
What are the two styles of paragraph?	\item Point first (LDR)<div>\item Point last (OCAR)</div>
What are the key steps in writing a good paragraph?	\item Identify who the story is about<div>\item Identify your point</div><div>\item Identify where you should make your point (first or last)</div>
From a structural perspective, what're the components of a simple sentance?	\item The topic, which comes first (O)<div>\item the middle bits (CA)</div><div>\item The stress, which comes last (R)</div>
What's the 2-3-1 rule in writing?	\item The last part of a sentance carries the greatest emphasis<div>\item The first part carries the second greatest emphasis</div><div>\item The middle bits carry the least emphasis</div>
What's the principle of subject-verb connection in scientific writing?	\item A sentance should open with an actor (the subject) and follow with an action (the verb)<div>\item then move on to details</div>
What structure should long sentences have?	\item LD
What's the critical aspect of developing flow in writing?	\item Every component should share a topic with what came prior, as well as a topic with what comes next.<br /><div>\item This is what separates stories from lists</div>
When are sentences-as-short-lists acceptable in scientific writing?	\item When they're on the same topic<div>\item It's only when you shift topics that you need to be concerned about flow</div>
Give an example of the active voice	\item Jane called John<div>\item Jane, the actor, is the subject</div>
Give an example of the passive voice	\item John was called by Jane<div>\item John, the acted-on, is the subject</div>
Should the active or passive voice be preferred?	\item Active
What're the usual reasons the passive voice might be used? &nbsp;	\item It can improve flow by&nbsp;shifting the perspective of a phrase.&nbsp;<div>\item It can hide actors which aren't important</div>
What are fuzzy verbs?	\item Verbs that describe abstract relationships<div>\item `occur', `affect', etc</div>
Give an example of a nominalized verb.	<div>\item `We conducted an investigation'</div><div>\item rather than</div><div>\item `We investigated'</div>
Give an example of a nominalized adjective.	\item `The characteristic of the condition is'<div>\item rather than</div><div>\item `The condition is characterized by'&nbsp;</div>
What is nominalization?	\item Converting an adjective or verb to a noun
Structurally, what's the best way to deal with terms that \emph{might} be considered jargon by the audience?	\item Use the term in position 3 of a 2-3-1 sentence<div>\item `Programmed cell death, or apoptosis, is...'</div>
Where should terms unfamiliar to the audience appear in a sentence?&nbsp;	\item At the end, in the 1 position of a 2-3-1 sentence
Give an example of a prepositional phrase and the corresponding compund noun.	\item `rate of reaction'<div>\item vs</div><div>\item `reaction rate'</div>
What's a preposition in writing?	\item of/in/on/etc
What's the preferred alternative to a prepositional phrase?	\item A compound noun
What are the two circumstances when a prepositional phrase is better than a compound noun?	\item When the compound noun is long and unweildy&nbsp;(aka a noun cluster)&nbsp;<div>\item When the phrase would put the noun you want in the stress position</div>
What are the five primary targets when condensing a piece of writing?	\item Redundant information<div>\item Obvious information</div><div>\item Modifiers</div><div>\item Metadiscourse</div><div>\item Verbosity</div>
What should be your high-level strategy for condensing writing?	\item Prune large limbs&nbsp;<div>\item Shake out dead leaves</div>
What's an example of metadiscourse?	\item `We found that'
When should a piece of writing be condensed?	\item At the last draft - it's easier to cut than it is to add
What's the usual argument for keeping filler words when writing?	\item They can improve flow
What's the acronym SCFL stand for in scientific writing?&nbsp;	<div>\item It's an approach to editing</div>\item Structure<div>\item Clarity</div><div>\item Flow</div><div>\item Language</div>
What's the intention of the clarity step in SCFL when editing?	\item Ensure the ideas in the writing are clear and complete
When writing science, where should you deal with weaknesses in your work?	\item In the opening (for scope limitations)<div>\item In the methods (for practical limitations)</div><div>\item In the discussion (for analytical limitations)<br /><div>\item \emph{Definitely} not in the resolution&nbsp;</div></div>
Where should weaknesses be included in the discussion section?	\item In the middle<div>\item Definitely not at the start or end</div>
What kind of tone should you use when discussing weaknesses in your research?&nbsp;	\item Concise and unapologetic
What's the message box approach to writing for the public?	\item Keeping the audience in mind,<br /><div>\item Explain the problem</div><div>\item Explain why the problem matters</div><div>\item Explain the solution</div><div>\item Explain the benefits</div>
What's the pumping lemma?	\item Any sufficiently long word $w$ in a regular language $L$<br /><div>\item can be broken into three parts $w = xyz$&nbsp;</div><div>\item such that for all $n$, $w_n = xy^nz$ is in $L$ too</div>
define Markov equivalence	two directly acyclic graphs that&nbsp;entail the same conditional independencies<div>&gt; i.e. have the same d-separations</div>
What are the main elements of the HDF5 data model?	\item Datasets<div>\item Groups</div><div>\item Attributes</div>
What're groups in HDF5?	\item Hierarchical containers
What are attributes in HDF5?	\item Metadata tags that can be attached to other objects
What's the biggest difference between NumPy and HDF5Py slices?	\item HDF5Py slices return a copy rather than a view
What's the command line tool to list the contents of a HDF5 file?	\item \ttt{h5ls}
What's the command line tool to dump out the contents of a HDF5 file to the prompt?	\item \ttt{h5dump}
How can you create a .hdf5 file in Python only if no other file of the same name exists?&nbsp;	"\item \ttt{h5py.File(name, ""w-"")}"
When opening a file in Python, what's the \ttt{a} mode?&nbsp;	\item Append mode
When opening a file in Python, what're the \ttt{r+, w+, a+} modes?&nbsp;	\item They open the file for updating (reading/writing)&nbsp;<div>\item but inherit the \ttt{r, w, a} rules on stream placement/file creation/file truncation</div>
What's the difference between the \ttt{r+, w+} file modes in Python?	\item \ttt{w+} will create a new file if it doesn't exist<div>\item \ttt{w+} will overwrite the current file if it already exists</div>
What's the difference between the \ttt{w, a} file modes in Python?	\item Writes in \ttt{a} mode will always appear at the end of the file
How should a h5py file be opened?	\item With a context manager
What's the HDF5 \ttt{core} driver?	\item It stores the file entirely in memory
What's the HDF5 \ttt{family} driver?	\item It stores the file as chunks, with each chunk being limited to a certain size
What're HDF5 drivers?	\item They're a low layer in the HDF5 library that provide a uniform interface to different kinds of storage
What's the \ttt{mpio} driver in HDF5?	\item It supports concurrent access to a HDF5 file
What's the user block in HDF5?	\item When opening a file, the library checks for the HDF5 header at 512b, 1024b, 2048b, etc into the file.&nbsp;<div>\item This means the first 512/1024/2048b can be used for arbitrary user data</div>
How can you modify the userblock of a HDF5 file from Python?	\item By specifying \verb|userblock_size| when creating the HDF5 file<div>\item then opening the file as a normal Python file</div>
How do you usually insert a NumPy array into a H5Py file?	\item \verb|h5py_file['key'] = numpy_array|
How can you read an entire H5Py dataset into an array?	\item \verb|arr = dset[...]|
How can you allocate a zero-initialized H5Py dataset?	\item \verb|dset = h5py_file.create_dataset('key', shape, dtype)|
How do you force H5Py to write its buffered data to disk?	\item \verb|h5py_file.flush()|
How can you fill an already-existing Numpy array with data from a H5Py file?	\item \verb|dset.read_direct(arr)|
When using \verb|create_dataset| in H5Py, how can you initialize the dataset to a specific value?	\item Specify \ttt{fillvalue}
How does H5Py enforce dataset shapes?	\item It only cares about the total size of the array;<div>\item it's happy to read a \ttt{(2, 3)} array into a \ttt{(3, 2)} dataset</div>
Is NumPy row- or column-major?	\item Row-major
What's row-major storage?	\item When the rightmost index varies the fastest as you scan the array
What happens internally in H5Py when a slice from a dataset is assigned from?&nbsp;	\item An empty NP array of the right shape is allocated, which HDF5 reads the appropriate parts of the dataset into<br />
What step sizes are allowed when slicing a H5Py array?	\item Positive ones only
What does \verb|arr[()]| return in NumPy?	\item For 1D and higher arrays, it returns the whole array<div>\item For 0D arrays, it returns the sole element as a scalar&nbsp;</div>
What does \verb|arr[...]| return in NumPy?	\item The whole array
How is boolean indexing implemented internally in HDF5?	\item By converting the array to list of coordinates corresponding to \ttt{True} values
Performance-wise, which of Boolean indexing and coordinate lists are faster in H5Py?	\item Coordinate lists, as H5Py will translate them into contiguous 'subselections' rather than just hunting for specific coordinates as it does with Boolean indexing
What are the limitations of slicing with a coordinate list in H5Py?	\item Only one axis at a time can use list slicing<br /><div>\item The list must be strictly increasing&nbsp;</div>
How does NumPy test whether one array can be broadcasted to another's shape?	\item By comparing the shapes of the two arrays right-to-left
What's the easiest way to create slice objects in NumPy?	\item \verb|sp.s_[idxs]|
How can you specify where data should be read from and into when using H5Py's \verb|read_direct|?	\item By specifying \verb|source_sel| and \verb|dest_sel| with NumPy slice objects
What's the advantage of the \verb|write_direct| method in H5Py?	\item There isn't any; it's no faster than regular slice assignment<div>\item It exists only for historical reasons</div>
How can you specify the endianness in a NumPy datatype?	"\item \verb|""&lt;f4""| is a little-endian 4-byte float<div>\item \verb|""&gt;f4""| is a big-endian 4-byte float</div>"
What's \verb|maxshape| in H5Py?&nbsp;	\item It's a keyword that can be specified to \verb|create_dataset|<div>\item that describes the maximum size the array can be reshaped to</div>
What happens if you don't specify \verb|maxshape| when creating an array in H5Py?&nbsp;	\item The array will not be resizable at all
How can you create a H5Py array that can be reshaped to an arbitrary size?	\item Specify one or more axis as \verb|None| to \verb|maxshape|
What's the rank of a NumPy array?	\item The number of axes
How can you add or remove axes from a H5Py dataset?	\item You can't; the rank is fixed
What happens to existing data when a&nbsp;H5Py&nbsp;dataset is resized?&nbsp;	\item If any axis shrinks, the data in the missing region is discarded<div>\item If any axis expands, the new locations are filled with the dataset's \verb|fillvalue|</div>
What's chunked storage in H5Py?	\item If a chunk shape is specified, when writing data to disk<div>\item H5Py will split the data into chunks of the given shape, flatten them, and write each flattened chunk as a contiguous block</div>
How do you specify a chunk shape in H5Py?	\item Using the \verb|chunks=(64, 64)| keyword of \verb|create_dataset| &nbsp;
What's auto-chunking in H5Py?	\item If you specify \verb|chunks=True| when creating a dataset<div>\item then H5Py will try to keep the chunks roughly cubic while obeying certain size limits</div>
Roughly what size should chunks be in H5Py?	\item More than 10KiB (to limit b-tree overhead)<div>\item less than 1MiB (so that the chunks can be cached)</div>
How does H5Py track chunked datasets?	\item Using a B-tree
What's a \verb|KiB|?	\item A kibibyte, $2^{10}$ bytes
What are filters in H5Py?	\item Modules that form a `pipeline' between memory and disk when working with chunked datasets<br />
What's the DEFLATE filter in H5Py?	\item Another name for the GZip compression filter
How can you specify GZIP compression when creating a H5Py dataset?	"\item By passing \verb|compression=""gzip""| to \verb|create_dataset|"
How does H5Py's LZF compression compare to GZIP?	\item LZF is Python-only<div>\item LZF is much faster</div><div>\item LZF has a lower compression ratio</div>
What's H5Py's SHUFFLE filter?	\item It rearranges data to exploit the inequal entropy distribution in most datatypes<div>\item Ex: with floats, most of the entropy is in the lower bytes</div><div>\item so SHUFFLE packs all the first bytes together (which can be efficiently compressed as they're almost all the same), then all the second bytes, and so on</div>
What's H5Py's FLETCHER32 filter?	\item It checksums the data
What's the root group in HDF5?	\item The group named \verb|/| which corresponds to the file object
How do you create a group in H5Py?	\item Use the \verb|create_group| method<div>\item Assign to a key containing \verb|/|s</div>
In general, how do H5Py groups behave?	\item Like dictionaries
How can you get the file associated with a H5Py &nbsp;group object?	\item \verb|group.file|
How can you navigate up the group hierarchy in H5Py?	\item \verb|group.parent|
What are links in H5Py?	\item Groups don't hold other objects directly; they hold links to those objects
How does garbage collection in H5Py work?	\item Reference counting hard links;&nbsp;<div>\item once no hard links to an object remain, it's destroyed</div>
How are hard links usually created in H5Py?	\item By assigning to a group's key; \verb|group['key'] = obj| or similar
How do you destroy links in H5Py?	\item \verb|del group['key']|
When a H5Py object has more than one hard link to it, what does \verb|obj.name| return?	\item One name; which one is indeterminate
What's the value in repacking in HDF5?	\item HDF5 doesn't track free space created by deletions across file open/close cycles<div>\item so you can end up with a `hole' of unusable space</div><div>\item which can be removed by using the \verb|h5repack| tool</div>
What's a soft link in H5Py?	\item It's a link that holds a name/path rather than a reference to an object&nbsp;
How do you create a soft link in H5Py?	\item \verb|group['key'] = h5py.SoftLink('path')|
What's the intuitive difference between hard and soft links?	\item Hard links refer to an object<div>\item Soft links refer to a place</div>
What happens if you try to access a H5Py group member which is a broken softlink?	\item You'll get a \ttt{KeyError}
What happens if you try to iterate over a H5Py group which contains a broken softlink?	\item The broken softlink will evaluate to \verb|None|
What's an external link in H5Py?	\item A softlink to an object in another HDF5 file
Are softlinks validated on creation in H5Py?	\item Nope
What are the two optional keywords to \verb|group.get| in H5Py?	\item \verb|getclass=True| returns metadata about the object rather than the object itself<div>\item \verb|getlink=True| returns the link to the object rather than the object itself&nbsp;</div>
What're the \verb|require_group, require_dataset| methods in H5Py?	\item They're like the \verb|create_group, create_dataset| methods<div>\item but if a group/dataset already exists with the same name and matches the requirements, it'll be returned instead</div>
How can you replace the hard-link at a key in a H5Py group?	\item By first deleting the existing hard link<div>\item (H5Py won't silently overwrite the hard-link, to prevent accidental data loss)</div>
What order will elements in a H5Py group be enumerated in?	\item `native' order, which is `whatever order is the fastest to get items out of the b-tree'&nbsp;<div>\item Can look like alphabetical ordering, but isn't</div>
How can you use POSIX-style paths (\verb|..|, etc) with H5Py?	\item By normalizing them first using \verb|posixpath.normpath|
How can you test whether the descendents of a H5Py group contain a certain path?	\item \verb|path in group|
What's the problem with \verb|x in d.keys()| in Python?	\item It unnecessarily constructs a list of keys in memory<div>\item Use \verb|x in d| instead</div>
How can you iterate over the names of descendents of a group in H5Py?	<div>\item Using the visitor pattern;</div>\item \verb|group.visit(f)| will call \verb|f| on every descendent
How does H5Py's \verb|visit| method respond to multiple links to the same object?	\item Each object will be visited only once
How can you iterate over the names and objects themselves descending from a H5Py group?	\item \verb|group.visititems(f)|<div>\item will pass each \verb|name, item| in turn to \verb|f|</div>
When using H5Py's \verb|visit| method, how can you interrupt the iteration early?	\item By returning something other than \verb|None|<div>\item which the \verb|visit| call will then return itself</div>
How do you deep-copy a H5Py group?	\item \verb|group.copy(origin_path, dest_path)|
How can you test whether a H5Py group is part of a currently open file?	\item \verb|bool(group)|
How do you attach attributes to a H5Py object?	\item \verb|obj.attrs['key'] = value|
What types can be used in a H5Py attribute?	\item Ones with corresponding HDF5 types - strings, numerics, etc
What's the maximum size of an HDF5 attribute?	\item 64KiB most of the time&nbsp;
How can you get a reference to a H5Py object?	\item \verb|obj.ref|
Given a H5Py reference, how do you get the associated object?	\item \verb|file[ref]|
What's the advantage of H5Py references over softlinks?	\item References are independent the object's name
What's the kind of a Numpy array?	\item \verb|arr.dtype.kind|, which is a character code indicating whether the data's boolean, integer, object, etc
What's a region reference in H5Py?	\item It's a reference to a specific slice of a dataset
How can you create a region reference in H5Py?	\item \verb|arr.regionref[slice]|
How can you get the dataset associated with a H5Py region reference?&nbsp;	\item \verb|file[region_ref]|<div>\item To get the slice that the reference was originally created for, \verb|file[region_ref][region_ref]|</div>
What's a named datatype in H5Py?	\item It's a NumPy dtype stored in a HDF5 file<div>\item references to which can be used to initialize other HDF5 objects, ensuring they all have the same type</div>
What are dimension scales in H5Py?&nbsp;	\item Datasets that describe how the indices into other datasets should be interpreted
How do you create a dimension scale in H5Py?	<div>\item To create a scale for an axis 0 on \verb|dset|,</div>\item Create a 1D dataset \verb|scale_x| the same length as the axes in question<div>\item Convert the scale dataset to a scale using \verb|dset.dims.create_scale|</div><div>\item Attach the scale to the axies using \verb|dset.dims[0].attach_scale|</div>
How many dimension scales can a H5Py dataset axis have?	\item As many as you want
What's the most important thing to remember when using H5Py with the multiprocessing module?	\item The state of the HDF5 library is inherited from the parent process
How should programs use H5Py when they're multiprocess?	\item Don't have any files open when you invoke \verb|multiprocessing| features<div>\item Have subprocesses open files as read-only after the process has been created</div><div>\item Have subprocesses write to different files, then merge the files when finished</div>
How do you launch a Python MPI program?	\item \verb|mpiexec -n 4 python main.py|
What's the main restriction on MPI parallelism for HDF5?	\item Modifications to file metadata must be done collectively<div>\item including opening/closing a file, creating new HDF5 objects, and moving/copying HDF5 objects</div>
What's it mean that an operation is collective in MPI?	\item That every process makes a call to the operation<div>\item and multiple collective operations must be called in the same order in each process</div>
What are the two flavours of IO in MPI programs?	\item Collective IO<div>\item Independent IO</div>
What happens in MPI when a call that should be collective isn't made by everyone, or is made out of order by someone?&nbsp;	\item It's undefined.
What's a common problem with MPI synchronization and HDF5?	\item If you write to a HDF5 file before a barrier,&nbsp;<div>\item and read from it afterwards</div><div>\item There's no guarantee that the write will actually have been committed before the read goes ahead</div>
What are the two usual ways to deal with the interactions between H5Py IO operations and MPI synchronization primatives?	\item Enable the \verb|atomic| flag, which reduces performance in return for greater consistency<div>\item Don't pass data between processes via the file - use MPI's message-passing capabilities</div>
When a H5Py object has more than one parent, what will \verb|obj.parent| return?	\item Whichever parent is consistent with the path in \verb|obj.name|
What's a communicator in MPI?	\item It's a group of processes that can communicate with eachother
What's a rank in MPI?	\item It's the unique identifier of a process in a communicator
What's a tag in MPI?	\item It's the unique identifier of a message
How are Python loggers' names structured?	\item Hierarchically;&nbsp;<div>\item The logger named \verb|foo.bar| is a child of the logger \verb|foo|</div>
Which Python logger name should you usually use?	\item \verb|logging.getLogger(__name__)|<div>\item since this will automatically organize the loggers into the same hierarchy as the modules</div>
What's the advantage of hierarchically-structured loggers in Python?	\item By default, events to child loggers will be propagated to the parent loggers
How do logging levels work in Python?	\item Messages with a level lower than a logger's level will be ignored&nbsp;<div>\item For a child logger, this means the message won't be passed to the parent</div><div>\item For a root logger, this means the message won't be processed</div>
What are the two keyword arguments to Python's \verb|Logging.debug| and similar methods?	\item \verb|exc_info| which if true will attach exception information to the message<div>\item \verb|extras| which can be used to add arbitrary objects to the \verb|LogRecord| created by the event</div>
How do filters work with Python's logging library?	\item Messages will be passed to each filter in turn;<div>\item if any one of them evaluates to false, it'll discard the message</div>
How do handlers work with Python's logging library?	\item Messages are passed to all handlers associated with a logger<div>\item and propagated to the logger's parent (if it has any and it's set to propagate)&nbsp;</div>
What are formatters in Python's logging library?	\item They eat \verb|LogRecord| objects and return strings that can be output
What does \verb|{}| do in a Python format string?	\item The first \verb|{}| binds to the first argument, the second \verb|{}| binds to the second, etc&nbsp;
How can you automatically convert an argument \verb|x| to a format string to \verb|str(x)|?&nbsp;	\item \verb|{x!s}|
How can you automatically convert an argument \verb|x| to a format string to \verb|repr(x)|?&nbsp;	\item \verb|{0!r}|
How can you get an attribute of an argument from a Python format string?	\item \verb|{0.weight}| will get the \verb|weight| attribute of the argument<br />
If a list is passed to a Python format string, how can you get the 5th element?	\item \verb|{key[5]}| will get the fifth element of the argument
What's the first half of the layout for a Python format string?	\item \verb|[[fill]align][sign][#]|
What's the second half of the layout for a Python format string?	\item \verb|[0][width][,][.precision][type]|
In the Python format string layout, what does \verb|fill| signify?	\item The character to use to fill the space around the value when it's aligned
In the Python format string layout, what can be used for \verb|align|?	\item \verb|&lt;|, to left-align<div>\item \verb|&gt;|, to right-align</div><div>\item \verb|=|, to pad a number with zeros between sign and digits</div><div>\item \verb|^|, to center-align</div>
In the Python format string layout, what can be used for \verb|sign|?	\item \verb|+|, to display a sign for both positive and negative numbers<div>\item \verb|-|, to display a sign only for negative numbers</div><div>\item a space, to use a space for positive numbers and a \verb|-| for negative&nbsp;</div>
In the Python format string layout, what does \verb|#| signify?	\item It's for integers; it'll prefix the number with \verb|0b, 0o, 0x| depending on whether it's binary/octal/hexadecimal&nbsp;
In the Python format string layout, what does \verb|,| signify?	\item Whether a thousands separator should be used with large numbers
In the Python format string layout, what does \verb|type| signify?	\item For numerics, it indicates how the output should be formatted - as hex, with an exponent, as a percentage, etc
When estimating $d$ parameters&nbsp;linearly dependent on&nbsp;$N$ measurements that are subject to Gaussian noise of standard deviation $\sigma$, what's the expected residual error?&nbsp;	\item $\epsilon_\text{res} = \sigma \sqrt{1 - d/N}$
When estimating $d$ parameters linearly dependent on $N$ measurements that are subject to Gaussian noise of standard deviation $\sigma$, what's the expected estimation error?&nbsp;	\item $\epsilon_\text{est} = \sigma \sqrt{d/N}$
What's the difference between the residual error and the estimation error?	\item Residual error is the distance of the estimated values from the measured (corrupted) values<div>\item Estimation error is the distance of the estimated values from true values</div>
What's an easy way to test whether an estimation algorithm is incorrect?	\item Take the some true measurements $\bar X$&nbsp;<div>\item and distort them with some small noise to $X$</div><div>\item then estimate them as $\hat X$</div><div>\item Assuming the model surface near $\bar X$ is planar, the Pythagorean formula</div><div>\item $\|X - \bar X\|^2 \approx \|X - \hat X\|^2 + \|\bar X - \hat X\|^2$</div><div>\item should hold</div>
If $X$ has covariance $\Sigma$, what's the first order approximation to the covariance of $f(X)$?	\item $J\Sigma J^T$<div>\item where $J$ is the Jacobian of $f$ at $\mbb{E}(X)$</div>
Given a parameter surface defined by an affine $f$ and a random measurement&nbsp;$X$ near that surface, what's the precision of the parameter estimate?&nbsp;	\item $J^T \Lambda_X J$<div>\item where $\Lambda_X$ is the precision of $X$</div>
What's the number of essential parameters of a parameterization?	<div>\item The parameterization $f$ defines a surface in measurement space</div>\item and the number of essential parameters is rank of $f$'s Jacobian&nbsp;
Given a parameter surface (possibly over-parameterized) defined by a general $f$ and a random measurement near that surface $X$, what's the covariance of the parameter estimate?&nbsp;	\item Let $J$ be the Jacobian of $f$<div>\item and let $S_P$ be a surface that's locally orthogonal to the nullspace of $J$</div><div>\item Then the covariance of the parameters is</div><div>\item $\Sigma_P = (J^T \Sigma^{-1}_X J)^+$</div><div>\item where&nbsp;</div><div>\item $\Sigma_X$ is the covariance of $X$</div><div>\item $(^+)$ is the pseudo-inverse</div>
What's the focal plane in a pinhole camera?	\item It's the plane $Z = f$ on which the image falls
What's another name for the image plane?	\item The focal plane
What's the camera center of a pinhole camera?	\item The point through which the projection is made
What's another name for the optical center of a pinhole camera?	\item The camera center
What's the principle axis of a pinhole camera?	\item The line perpendicular to the focal plane that passes through the camera center
What's the principle plane of a pinhole camera?	\item The plane parallel to the focal plane that passes through the camera center
What's the principle point of a pinhole camera?	\item The point where the principle axis meets the focal plane
What does $P$ denote when discussing pinhole cameras?	\item The camera projection matrix which takes world points to image points
What do $X, x$ denote when discussing pinhole cameras?	\item $X$ is a world point<div>\item $x$ is an image point</div>
How is the focal length represented in the camera projection matrix?&nbsp;	<div>\item $K = \begin{bmatrix}f &amp; &amp; \\ &amp; f &amp; \\ &amp; &amp; 1 \end{bmatrix}$</div>
How is an offset of the principle point from the image origin represented in the camera calibration matrix?&nbsp;	<div>\item If the principle point has coordinates $(p_x, p_y)$,&nbsp;</div>\item $K = \begin{bmatrix}f &amp; &amp; p_x \\ &amp; f &amp; p_y \\ &amp; &amp; 1 \end{bmatrix}$
What's the camera coordinate frame?	\item The coordinate system for world points created by&nbsp;<div>\item setting the origin to the camera center</div><div>\item setting the $Z$ axis to the principle axis</div><div>\item with the image plane sitting at $Z = f &gt; 0$ between the camera center and the world</div>
How is a specific camera coordinate frame related to the world coordinate frame?	\item A camera with center $\tilde C$ rotated by $R$ is represented by<div>\item $X_\text{cam} = [R | -R\tilde C] X$</div>
How is a world point in the camera coordinate frame related to the corresponding image point?	\item $x = K[I|0] X_\text{cam}$
What does $K$ denote when discussing pinhole cameras?	\item The camera calibration matrix
How are non-square pixels captured in the camera calibration matrix?	<div>\item If the pixels-per-unit distance are $(m_x, m_y)$,&nbsp;</div>\item $K = \begin{bmatrix}m_xf &amp; &amp; m_xp_x \\ &amp; m_yf &amp; m_yp_y \\ &amp; &amp; 1 \end{bmatrix}$
What's the skew parameter of the camera calibration matrix?	\item $s = K_{12}$, which is almost always zero
In terms of the projection matrix, what's a finite camera?	\item One with a non-singular $3 \times 3$ block on the left
How can you identify the camera center from a projection matrix?	\item It's the generator of the matrix's right nullspace&nbsp;
What's the geometric interpretation of the columns of a camera's projection matrix?	\item The first three columns are the vanishing points of the world coordinate axes<div>\item The last column is the image of the world origin</div>
What's the geometric interpretation of the rows of a camera's projection matrix?	\item The first two rows give the planes that map to the image axes<div>\item The last row gives the principle plane</div>
How can you deduce the principle axis from the camera projection matrix?	\item If $M$ is the left $3 \times 3$ submatrix of $P$<div>\item and $m^3$ is its third row</div><div>\item then $\det(M)m^3$ is the principle axis, pointing towards the front of the camera</div>
How can a camera projection matrix be decomposed into internal and external parameters?	\item By applying the QR decomposition to the left $3 \times 3$ submatrix $M$;&nbsp;<div>\item the orthogonal matrix is the rotation</div><div>\item and the upper-triangular matrix is the calibration matrix</div>
What should you be careful about when choosing an image coordinate system?	\item That you either have to preserve handedness<div>\item or deal with a flip of one of the axes</div>
Intuitively, how's an affine camera created?	\item By increasing the focal length and the distance from the subject at the same rate<div>\item until you reach infinity</div><div>\item This suppresses perspective effects</div>
Intuitively, what's the effect on points of approximating a projective camera with an affine camera?&nbsp;	\item Points are moved radially away from the principle point based on their depth
Given a camera projection matrix $P$ and a line in the image $l$, what's the set of world points that maps to that line?	\item $P^Tl$
Given a camera projection matrix $P$ and a conic in the image $C$, what's the set of world points that maps to that conic?	\item The cone $Q = P^T CP$
What's the contour generator of a surface $S$ with respect to a camera?	\item The set of points $\Gamma \subset S$ such that rays from the camera center are tangent to the surface
What's the apparent contour of a surface $S$ with respect to a camera?	\item The image $\gamma$ of the contour generator of the surface&nbsp;
Given a camera projection matrix $P$ and a quadric in the world $Q$, what's the image of the quadric's outline?	\item The conic $C$ given by<div>\item $C^* = PQ^* P^T$</div>
What's the effect on image points of rotating the camera without translating it?	<div>\item It applies a conjugate rotation</div>\item $x^\prime = KRK^{-1}x$
Geometrically, how do images captured by the same camera with the same camera center relate?	\item They're all related by a plane projectivity<div>\item (think about how only the focal plane can move if the center is fixed)</div>
How can the calibration matrix be interpreted as a transformation?&nbsp;	\item It's the transformation that takes a ray through the camera center $d$ to an image point $x = Kd$
How can you calculate the angle between two rays from a camera in terms of their image points?	\item $\cos \theta = \frac{\langle \pi_1, \pi_2 \rangle_{\omega}}{\|\pi_1\|_{\omega}\|\pi_2\|_{\omega}}$
What's the image of the absolute conic in terms of the calibration matrix?	\item $\omega = (KK^T)^{-1}$
If a line has direction $d$ in the camera's coordinate frame, what will its vanishing point in the image be?	\item $Kd$
When calibrating a camera from a single image, what parts of the scene are usually used as constraints?	\item Orthogonal lines<div>\item Orthogonal line and a plane</div><div>\item Planar objects of known size</div>
What's the geometric interpretation of a zero-skew constraint when calibrating a camera?	\item It's equivalent to saying that the image $x$ and $y$ axes should be orthogonal
Intuitively, what's the calibrating conic?	\item It's the image of a $45^\circ$ cone whose axis is the principle axis and whose apex is the camera center
What's the use of the calibrating conic?	\item It closely related to the IAC, but has real-valued points&nbsp;
Algebraically, what's the calibrating conic?	\item $C = K^{-T} \begin{bmatrix} 1 &amp; &amp; \\ &amp; 1 &amp; \\ &amp; &amp; -1 \end{bmatrix} K^{-1}$
How can the calibrating conic be interpreted?	\item It's an ellipse whose center is the principle point<div>\item while the axes' lengths give the aspect ratio times the focal length</div><div>\item and the axes' directions reflect the skewness</div>
What's the baseline of two cameras?	\item The line joining their camera centers
What're the epipolar planes of two cameras?	\item They're the pencil of planes whose axis is the baseline
What're the epipoles of two cameras?	\item They're the intersections of the baseline with the two image planes
What's an epipolar line?	\item The line at which an epipolar plane intersects an image plane
What constraint does epipolar geometry put on where a point in one image can appear in the other?	\item If $x$ lies on the epipolar plane $\pi$ in one image<div>\item then the corresponding point $x^\prime$ must lie on the same plane in the other image</div>
What's the permutation symbol?	\item $e_{i_1i_2\dotsb i_n}$ which is<div>\item $0$ if the indices don't cover $1, \dotsc, n$</div><div>\item $+1$ if the indices form an even permutation</div><div>\item $-1$ if the indices form an odd permutation</div>
What does $([a]_\times)_{ik}$ denote in multiview geometry?	<div>\item The skew-symmetric matrix formed from the elements of $a$,</div>\item $([a]_\times)_{ik} = e_{ijk}a^j$
How can the determinant of a matrix be written in terms of the permutation symbol?	\item $\det A = \frac{1}{n!} e^{i_1\dotsb i_n} e_{j_1\dotsb j_n} a_{i_1}^{j_1} \dotsb a^{j_n}_{i_n}$
How can a cross product be written using the permutation symbol?	\item $a \times b = [a]_\times b$
What's the mapping represented by the fundamental matrix of two cameras?	\item It's the mapping from points in one image to epipolar lines in the other
How can epipoles be interpreted as projections?	\item The epipole in one camera is the image of the other camera's center
How can the fundamental matrix of two cameras be written in terms of projection matrices?	\item $F = [e^\prime]_\times P^\prime P^+$<div>\item where $e^\prime$ is the epipole in the second camera's image</div><div>\item and $P^+$ is the pseudoinverse</div><div><br /></div>
How should relative changes betwen two variables be measured?	always use log(x/y)&nbsp;<div>&gt; satisfies statistical desiderata&nbsp;</div><div>&gt;&nbsp;jstor.org.ezproxy.rice.edu/stable/2683905</div>
For a camera at the world origin and another with rotation $R$ and translation $t$, what are the epipoles?	\item $e = KR^Tt$<div>\item $e^\prime = K^\prime t$</div>
Given the fundamental matrix $F$ of cameras $P, P^\prime$, what's the fundamental matrix of $P^\prime, P$?	\item $F^T$
How can you identify the epipoles from the fundamental matrix of two cameras?	\item They're the left and right null-vectors of the matrix
For a camera at the world origin and another with rotation $R$ and translation $t$, what's the fundamental matrix?	\item $F = K^{\prime -T} [t]_\times RK^{-1}$
Geometrically, what're the epipoles of two cameras related by a pure translation?	\item They're the images in each view of the vanishing point of the `rails' that the scene seems to move along
What's the horopter curve of two cameras?	\item The set of world-points that have the same coordinates in both images
What's the geometric interpretation of the symmetric part of the fundamental matrix?	\item It describes the Steiner conic
What's the geometric interpretation of the skew-symmetric part of the fundamental matrix?	\item It's the point whose polar intersects the Steiner conic at the two epipoles
What's the Steiner conic of two cameras?	\item It's the image of the horopter
If two pencils of lines on a 2D plane have a homography between them, what's the form of the set of intersections between corresponding lines?	\item A conic
How do you use the Steiner conic to find the epipolar line $l^\prime$ in one image of a point $x$ in the other?	\item The line through $e, x$ in the first image meets the Steiner conic at $e$ and a second point $x_c$<div>\item The line through $e^\prime, x_c$ in the second image is the epipolar line $l^\prime$</div>
Given a pair of canonical cameras, what's the fundamental matrix?	\item If $P = [I | 0]$ and $P = [M | m]$<div>\item then $F = [m]_\times M$</div>
What kind of bilinear form do skew-symmetric matrices correspond to?	\item An alternating form
What are the basic properties of an alternating form?	\item $x \cdot x = 0$<div>\item $x \cdot y = -y \cdot x$</div>
How can a pair of canonical projection matrices be recovered from a fundamental matrix?	\item $P = [I|0]$<div>\item and $P^\prime = [[e^\prime]_\times F | e^\prime]$</div><div>\item where the epipole solves $e^{\prime T}F = 0$</div>
What's a normalized camera matrix?	\item The projection matrix with the effect of the calibration matrix removed, $K^{-1}P$
Intuitively, what's the essential matrix of two cameras?	\item It's the fundamental matrix of two normalized cameras
Algebraically, what's the essential matrix of two canonical cameras, one at the origin and the other with translation $t$ and rotation $R$?	\item $E = [t]_\times R$
What're normalized coordinates in the context of two-view geometry?	\item The normalized coordinates of an image point $x$ are $\hat x = K^{-1}x$
How's the essential matrix characterized in terms of pairs of image points?	\item $\hat x^{\prime T} E \hat x = 0$<div>\item where $\hat x$ are normalized image coordinates</div>
How' are essential matrices characterized in terms of singular values?	\item A $3 \times 3$ matrix is an essential matrix iff&nbsp;<div>\item two of its singular values are equal</div><div>\item the third is zero</div>
How many degrees of freedom does the essential matrix have?	\item Five;&nbsp;<div>\item three from the translation</div><div>\item three from the rotation</div><div>\item minus one for the scale ambiguity</div>
Given an essential matrix and one camera at the origin, how many possible second cameras are there?&nbsp;	\item Four;<div>\item two twisted pairs, of which&nbsp;<br /><div>\item one pair with translation $+t$, one pair with translation $-t$</div></div>
Given an essential matrix and one camera at the origin, how can the correct second camera be identified from the four possible choices?&nbsp;	\item By finding the one in which the point is in front of both cameras
Which points can't be triangulated from two images?&nbsp;	\item The points on the baseline between the cameras
What's the 3D reconstruction ambiguity when using multiple calibrated cameras?	\item A similarity - a rotation, translation and scaling
What's the 3D reconstruction ambiguity when using multiple uncalibrated cameras?	\item A projectivity
What's the 3D reconstruction ambiguity when using multiple cameras that are calibrated except for their focal lengths?	\item A similarity
What's the 3D reconstruction ambiguity when using multiple cameras with an unknown but fixed calibration that are related by a translation?	\item An affinity
Intuitively, how do you refine a projective reconstruction of a scene into an affine reconstruction?	\item By finding the plane at infinity<div>\item (which means finding three points at infinity)</div>
Intuitively, what's the infinite homography?	\item It's the map $x^\prime = H_\infty x$<div>\item that takes a point $x$ in one image to the point $X$ at which its ray meets the plane at infinity</div><div>\item and then projects $X$ the point $x^\prime$ in the second image</div>
What kind of reconstruction does knowledge of the infinite homography between two cameras enable?	\item A affine reconstruction
What's a simple way to find a rank-deficient matrix that's close to a full-rank matrix?	\item Take the SVD and then zero the smallest eigenvalues
Which point correspondances are degenerate when trying to deduce the fundamental matrix of two cameras?	\item When the points and camera centers all lie on a (possibly degenerate) ruled quadric&nbsp;<div>\item When the camera centers are the same</div>
What's image rectification?	\item Finding a transformation of each image so that the epipolar lines run parallel to the $x$-axis<div>\item (which means that disparities between the image are in the $y$-axis only)</div><div>\item while minimizing the distortion applied to the image</div>
How is a homography between two cameras induced by a plane?	\item By projecting points from the first camera onto the plane $\pi$<div>\item Then projecting the points on the plane onto the second camera</div>
Algebraically, what's the homography induced by two cameras and a plane?	\item If the projection matrices are $P = [I|0], P^\prime = [A|a]$<div>\item and $\pi = (v | 1)$<br /><div>\item then $H = A - av^T$</div></div>
Algebraically, when does a homography $H$ represent a transform that corresponds to a fundamental matrix $F$?	\item When $H^TF$ is skew-symmetric
Given two cameras, how can the `depth' of a point be calculated relative to a plane in a scene?&nbsp;	\item Find the homography $H$ that corresponds to the plane<div>\item Then for any pair of points, $x^\prime = Hx + \rho e^\prime$</div><div>\item where $\rho$ gives the `depth' relative to the plane&nbsp;</div>
How is the infinite homography described as a plane-induced homography?&nbsp;	\item It's the homography $H_\infty$ induced by the plane at infinity
How can the infinite homography be thought as a mapping between image points?	\item It maps corresponding vanishing points between images
What are the two ambiguities that scene reconstruction from two affine cameras suffer that projective cameras don't?	\item Necker reversal ambiguity<div>\item Bas-relief ambiguity</div>
What's the Necker reversal ambiguity for affine camera reconstructions?	\item Rotating and object<div>\item and rotating its mirror in the opposite direction</div><div>\item are identical from an affine camera's perspective</div>
What's the bas relief ambiguity for affine camera reconstructions?	\item Rotating a distant object a small amount<div>\item and rotating a close object a large amount</div><div>\item are indistinguishable from an affine camera's perspective</div>
How are projection matrices usually denoted when discussing the trifocal tensor?	\item $P = [I|0]$<div>\item $P^\prime = [a_j^i]$</div><div>\item $P^{\prime\prime} = [b_j^i]$</div>
How many degrees of freedom does the trifocal tensor have?	\item 18<div>\item 11 degrees for each camera matrix</div><div>\item minus 15 for the projective world frame</div>
How is a 3-point represented in tensor notation?	<div>\item As a vector</div>\item $x = (x^1, x^2, x^3)$
How is a 3-line represented in tensor notation?	\item As a covector<div>\item $l = (l_1, l_2, l_3)$</div>
Given the projection matrices for three cameras where one is $P = [I|0]$, what's the trifocal tensor?	\item $\mathcal{T}^{jk}_i = a^j_i b^k_4 - a^j_4 b_i^k$
What's the valency of the trifocal tensor?	\item 3, with two contravariant indices and one covariant
How is a matrix written in tensor notation?	\item $A$ is $[a_j^i]$
How are corresponding lines in the second and third views of a scene transferred to the first?	\item $l_i = l_j^\prime l_k^{\prime\prime} \mathcal{T}^{jk}_i$
How is a point transferred from the first view to the third view of a scene via a plane defined by the second view?	\item $x^{\prime\prime k } = l_j^\prime \mathcal{T}^{jk}_i x^i$&nbsp;
What's the basic point-line-line correspondence encoded by the trifocal tensor?	\item $l^\prime_j l^{\prime\prime}_k \mathcal{T}_i^{jk} x^i = 0$<br />
What's the line-line-line correspondance of the trifocal tensor?	\item $l^\prime_j l^{\prime\prime}_k \mathcal{T}_i^{jk} (l_r e^{ris}) = 0^s$<br />
What's the point-point-point correspondance of the trifocal tensor?	\item $(x^{\prime j} e_{jpr}) (x^{\prime \prime k} e_{kqs})\mathcal{T}_i^{pq} x^i = 0_{rs}$<div>\item for the three views of a single world point</div>
What's the trifocal plane?	\item The plane containing the three camera centers
How are the epipoles of a three-camera configuration denoted?	\item $e_{ij}$ is the projection of camera $j$'s center onto camera $i$
For which lines and points do the trifocal correspondences hold?	\item Three views of the same point<div>\item Three views of any line that passes through that point</div>
What's the Gauss-Newton matrix?	\item $G = J^TJ$<div>\item where $J$ is the Jacobian</div>
What's the generalized Gauss-Newton matrix?	\item If the loss for a system is $h(\theta) = \sum_{x, y} L(y, f(x, \theta))$,<div><div>\item then $G = \frac{1}{|S|} \sum_{x,y} J_f^T H_L J_f$</div></div><div>\item where $J_f$ is the Jacobian of $f$ and $H$ is the Hessian of $L$</div>
What's the intuitive use of the generalized Gauss-Newton matrix?	\item It approximates the Hessian for the system<div>\item It's a robust approximation when based on subsets of the data</div>
What's the natural gradient of a system?	\item $\tilde \nabla h = F^{-1} \nabla h$<div>\item where $\nabla h$ is the gradient and $F$ is the Fisher information</div>
What's the intuitive interpretation of the natural gradient?	\item It's the direction of steepest descent with respect to metric defined by the KL divergence from the current location
How can adagrad optimization be interpreted as natural gradient methods?	\item It estimates the diagonal of the Fisher matrix<div>\item and uses that to estimate natural gradient steps</div>
What's the main theoretical advantage to natural gradient optimization?	\item The path it describes is invariant to reparameterization
What's spike timing dependent plasticity?	\item How neurons are suspected to learn;<div>\item the synaptic weight is reduced if there's a post-synaptic spike just before a pre-synaptic spike</div><div>\item and it's increased if there's a post-synaptic spike just after a pre-synaptic spike&nbsp;</div>
What's a submodular function?	\item One such that&nbsp;<div>\item $f(A) + f(B) \geq f(A \cup B) + f(A \cap B)$</div><div>\item for all $A, B$ formed from some ground set $V$</div>
What's a modular function (wrt submodularity)?	\item One such that&nbsp;<div>\item $f(A) + f(B) = f(A \cup B) + f(A \cap B)$</div><div>\item for all $A, B$ formed from some ground set $V$</div>
How can submodular functions capture fixed costs?	\item Ex: cost to drive to two stores and buy a thing at each<div>\item is greater than the cost of buying both at the same store</div>
What's the diminishing returns definition of submodularity?	\item If $A \subseteq B$ and $v \in B^\prime$ then for any submodular function<div>\item $f(A \cup v) - f(A) \geq f(B \cup v) - f(B)$</div><div>\item ie the value of adding $v$ to a set drops as the set gets bigger</div>
What's a pseudo-boolean function?	\item $f: \mbb{B}^n \rightarrow \mbb{R}$
How do supermodular functions relate to submodular functions?	\item $f$ is supermodular iff $-f$ is submodular
How's submodularity relate to monotonicity?	\item It doesn't;&nbsp;<div>\item submodularity doesn't imply monotone nondecreasingness</div><div>\item&nbsp;&nbsp;monotone nondecreasingness doesn't imply&nbsp;submodularity</div>
What's a polymatroid function?	\item A function which is&nbsp;<div>\item normalized</div><div>\item nondecreasing</div><div>\item submodular</div>
What's it mean for a function on sets to be normalized?	\item $f(\emptyset) = 0$
How can submodular functions be decomposed into a polymatroid function?	\item If $f$ is submodular<div>\item $f = f_p - m$</div><div>\item where$f_p$ is polymatroid and $m$ is modular</div>
What's a subadditive function?	\item $f(A) + f(B) \geq f(A \cup B)$
How does subadditivity relate to polymatroidality?	\item A polymatroidal function is subadditive
What's $f(j|A)$ in the context of submodularity?	\item The gain<div>\item $f(j|A) = f(A \cup \{j\}) - f(A)$</div>
How can submodularity be stated in terms of gain?	\item For all $j$, $f(j|A)$ is a nonincreasing function of $A$<br />
What's a common class of submodular functions defined in terms of concavity?	\item If $g_i$ are concave&nbsp;<div>\item and $m_i$ are modular and nonnegative</div><div>\item then $f = \sum g_i \circ m_i$ is submodular</div>
What's a set system?	\item $(V, \mc{I})$ where<div>\item $V$ is a finite ground set&nbsp;</div><div>\item $\mc{I}$ is a set of subsets</div>
What's an independence set system?	\item A set system $(V, \mc{I})$ which contains the empty set and is subclusive
What's a subclusive set system?	\item A set system $(V, \mc{I})$&nbsp;such that<div>\item &nbsp;if $I \in \mc{I}$ all subsets $J \subset I$ are $J \in \mc{I}$</div>
What's a matroid set system?	\item An independence system $(V, \mc{I})$ such that<div>\item if $I, J \in \mc{I}$ and $|I| = |J| + 1$</div><div>\item then there's an $x \in I \backslash J$ such that $J \cup x \in \mc{I}$</div>
What's the rank function of a matroid?	\item $r(A) = \max_{X \in \mc{I}} | A \cap X|$
Is the rank function of a matroid submodular?	\item Yup
Is entropy submodular?	\item Yup, over subsets of the variables involved&nbsp;
What's the principle submatrix of a matrix and a set of indices?	\item It's the matrix $M_A$ formed by removing the rows and columns of all indices not in $A$ from $M$
What's a chunk in Lua?	\item A sequence of statements
How can you enter multiple statements on one line in Lua?	\item \ttt{a = 1 b = a*2}<div>\item or alternatively</div><div>\item \ttt{a = 1; b = a*2}</div>
How large can Lua chunks be?	\item Arbitrarily large; several megabytes is just fine
How can you run the Lua interpreter in interactive mode?	\item \ttt{lua -i}
How can you run a file from a Lua script?	\item \ttt{dofile('filename')}
How are single-line comments denoted in Lua?	\item \verb|-- comments go here|
How are block comments denoted in Lua?	\item \verb|--[[ comments go here --]]|
What's a common trick to quickly comment/uncomment code in Lua?	\item Use block comments and uncomment by changing the opening symbols to<div>\item \verb|---[[|</div>
What's the null value in Lua?	\item \verb|nil|
What happens if you assign \verb|nil| to a global variable in Lua?	\item It effectively deletes the variable.<br />
How can you write a Lua file that can be executed as a script at the command line?	<div>\item Make the first line in the file</div>\item \verb|#!/usr/local/bin/lua|
How can you execute a string of Lua code from the commandline?&nbsp;	"\item \verb|lua -e ""print(""hello world"")""|"
How do you load a library into the Lua interpreter at the commandline?	\item \verb|lua -llibname|<div>\item will load \verb|libname|</div>
In Lua interactive mode, how can you print the value of an expression?	\item \verb| = expr|
Where does the Lua interpreter usually load its options from?	\item An environment variable, \verb|LUA_INIT|<div>\item which it'll interpret either as a chunk of code</div><div>\item or, if starts with a \verb|@|, a filename</div>
How do Lua scripts receive arguments from the commandline?	\item As the global variable \verb|arg|
How do you get a type of a value in Lua?	\item \verb|type(v)|
What are the eight basic types in Lua?	\item nil<div>\item boolean</div><div>\item number</div><div>\item string</div><div>\item userdata</div><div>\item function</div><div>\item thread</div><div>\item table</div>
What are the falsy values in Lua?	\item \verb|false|<div>\item \verb|nil|</div>
What're Lua's numeric types?	\item \verb|number|, a 64 bit float
How can you write hexadecimal constants in Lua?	\item \verb|0xa.bP2|<div>\item where</div><div>\item \verb|.b| is the fractional part<br /><div>\item \verb|P2| is a binary exponent</div></div>
What's an 8-bit clean system?	\item One that correctly handles 8-bit character encodings
What's the length operator in Lua?	\item \verb|#x|<div>\item Works on tables and strings</div>
How can you denote a one-line string literal in Lua?	"\item \verb|'s'|<div>\item \verb|""s""|</div><div><br /></div>"
How can you denote a multi-line string literal in Lua?	\item \verb|[[s]]|<div>\item \verb|[=[s]=]|</div><div><div>\item \verb|[==[s]==]|&nbsp;</div><div>\item etc</div></div>
What's Lua's \verb|\z| escape sequence?	"\item It's for use in string literals, and will skip all subsequent spaces when interpreting the literal<div>\item \verb|data = ""abc\z| \\</div><div>\verb| &nbsp; &nbsp; &nbsp; &nbsp;def""|</div>"
What's the string concatenation operator in Lua?	\item \verb|s .. t|
How does Lua coerce strings into numbers?	\item It tries to intelligently interpret the string as a number<div>\item Try not to use this though</div>
How can you interpret a string as a number in Lua?	\item \verb|tonumber(s)|
<div>How can you convert an object to a string in Lua?</div>	\item \verb|tostring(n)|
What's a table in Lua?	\item An associative array
How do you create an empty table in Lua?	\item \verb|{}|
What are the two ways to index into a table in Lua?	"<div>\item \verb|t[""attr""]|</div><div>\item \verb|t.attr|</div>"
Are tables in Lua zero or one indexed?	\item One-indexed by convention
What happens if you index in an uninitialized element of a Lua table?	\item It evaluates to \verb|nil|
What's a sequence in Lua?	\item A table indexed with values assigned to all keys in a range $1$ through $k$
If \verb|t| is a table, what's \verb|#t| in Lua?	\item Any integer \verb|n| such that&nbsp;<div>\item \verb|t[n]| is not \verb|nil|</div><div>\item \verb|t[n+1]| is \verb|nil|</div>
How's the modulo operator defined in Lua?	\item \verb|a == math.floor(a/b)*b + a % b|
What's the not-equal operator in Lua?	\item \verb|~=|
How does equality testing work in Lua?	\item If the two values have different types, they're not equal<div>\item if the two values have the same type, it's delegated to the type</div>
Is string concatenation in Lua left or right associative?	\item Right associative
What's the table constructor in Lua for lists?	\item \verb|nums = {'one', 'two', 'three'}|<div>\item will populate a table with keys 1, 2, 3</div>
What's the table constructor in Lua for keys which are positive numbers or proper identifiers?	"\item \verb|table = {one=1, two=2, three=3}|<div>\item \verb|table = {1=""one"", 2=""two"", 3=""three""}|</div>"
How do you delete an element from a table in Lua?	\item \verb|x[y] = nil|
What's the table constructor in Lua for keys which aren't proper identifiers?	"\item \verb|table = {[""-""]=""sub"", [""+""]=""add""}|"
Where can you use semicolons in Lua constructors?	\item Anywhere you'd use a comma<div>\item Convention is to use them to delimit different parts of the constructor</div>
How do you assign to multiple variables in a single statement in Lua?	\item \verb|a, b = 1, 2|
In what order does Lua carry out a multiple assignment?	\item It evaluates all the values first<div>\item then carries out the assignments</div><div>\item so \verb|x, y = y, x| swaps the values</div>
What happens with multiple assignment in Lua when there are a different number of variables to values?	\item The number of values is adjusted to the number of variables<div>\item with extra variables being assigned \verb|nil|</div><div>\item and extra values being discarded (going left-to-right)</div>
How do you create a local variable in Lua?	\item \verb|local x = 1|
What's the scope of a local variable in Lua?	\item The block where it's created
What're the three kinds of blocks in Lua?	\item The body of a control structure<div>\item The body of a function</div><div>\item A chunk</div>
In the Lua interactive compiler, how do you create chunks of more than one line?	\item Wrap the lines in \verb|do|, \verb|end|
How'd you write a do-while loop in Lua?	\item \verb|repeat|, \verb|until|
How'd you write a multiple conditional in Lua?	\item \verb|if cond then| \\<div>\verb| &nbsp;s|<br /><div>\verb|elseif| \\</div><div>\verb| &nbsp;t| \\</div><div>\verb|else| \\</div></div><div>\verb| &nbsp;u| \\</div><div>\verb|end|</div>
How'd you write a while loop in Lua?	\item \verb|while cond do| \\<div>\verb| &nbsp;s| \\</div><div>\verb|end|</div>
What's a useful difference in the scope of a loop in Lua from other languages?	\item The scope of a local variable declared inside a \verb|repeat| loop includes the condition
How'd you write a numeric for loop in Lua?	\item \verb|for i = start, stop, step do| \\<div>\verb| &nbsp;s| \\</div><div>\verb|end|</div><div>\item The step can be omitted; it'll be assumed to be 1</div>
How do you create an infinite for loop in Lua?	\item Use \verb|math.huge| as the upper bound
How can you escape a Lua loop early?	\item \verb|break|
What's the scope of the loop variable in a Lua numeric for loop?	\item Local (it's implicitly declared so)
What's the effect of changing the loop variable in a Lua numeric for loop?	\item Unpredictable. Don't do it.
How'd you write a generic for loop in Lua?	\item \verb|for x in iter do| \\<div>\verb| &nbsp;s| \\</div><div>\verb|end|</div>
How can you iterate over all key-value pairs in a Lua table?	\item \verb|pairs(t)|
How can you place a return in the middle of a block in Lua?	\item By surrounding the following code with \verb|do|, \verb|end|
Where can you place a \verb|return| in Lua?	\item At the end of a block
How do you define a label for use with \verb|goto| in Lua?	\item \verb|::labelname::|
Where does the scope of a local variable end in Lua?	\item On the last non-void statement of the block where the variable is defined
What's the usefulness of the non-void-statement rule with respect to \verb|goto| in Lua?	\item Labels are considered null statements<div>\item so you can jump to a label that appears at the end of a block, regardless of whether it defines a local variable</div>
What're the rules about which labels you can jump to using \verb|goto| in Lua?	\item The label must be visible<div>\item You can't jump out of a function</div><div>\item You can't jump into the scope of a local variable</div>
When can a function call be made without parentheses in Lua?	\item When the function takes a single argument that's either a literal string or a table constructor
What's the colon calling convention in Lua?	\item \verb|o:f(x)| is the same as \verb|o.f(o, x)|
How do you define a function in Lua?	\item \verb|function fname (args)| \\<div>\verb| &nbsp;s| \\</div><div>\verb|end|</div>
How do you define default arguments in Lua?	\item Have a parameter called \verb|x|<div>\item then in the function, define \verb|x = x or default_x|</div><div>\item If no value is passed to the parameter, it'll be \verb|nil| by default, which means it'll be assigned \verb|default_x| in the function&nbsp;</div>
When will a Lua function which returns more than one value actually return more than one value?	\item When the call is the last expression in a&nbsp;<div>\item multiple assignment</div><div>\item argument to another function</div><div>\item table constructor</div><div>\item return statement of another function</div>
What happens if a Lua function that returns more than one value is not the last expression in a list of expressions?&nbsp;	\item It'll only return the first value
How can you call a Lua function with a runtime-dependent number of arguments?	\item Use \verb|table.unpack|
What's the vararg expression in Lua?	\item \verb|...|, which can appear at the end of a parameter list and collects the extra arguments<div>\item \verb|...| can then be used inside the function as an expression</div>
How do you iterate over the varargs of a Lua function?	\item By converting them to a table using&nbsp;<div>\item \verb|{...}| if there are no \verb|nil| arguments</div><div>\item \verb|table.pack(...)| if there are</div>
How do you create a function which takes named arguments in Lua?	\item Have the function take a single argument, a table<div>\item and pass a table using the \verb|f{a=b, c=d}| syntax</div>
How do you create a function in an expression in Lua?	\item \verb|f = function (x) return 2*x end|
How can you create a function and assign it to a key of a Lua table, all in one line?	"\item \verb|function t.x (x) return 2*x end|<div>\item will create the function and store it in \verb|t[""x""]|</div>"
How do you write a recursive function in a restricted scope in Lua?	\item Define the variable before the function<div>\item \verb|local f| \\</div><div>\verb|f = function() return f() end|</div><div>\item In global scope, \verb|function f (args)| syntax does this implicitly</div>
Does Lua optimize tail calls?	\item Yup
What're two common situation in Lua where a tail call isn't a tail call?	<div>\item If a function \verb|f| ends with</div>\item \verb|return (g(x))|, because Lua will have to adjust the number of results<div>\item \verb|g(x)|, because Lua will have to discard the result</div>
How do you compile and run a string in Lua?	\item \verb|load(s)()|
What's compilation refer to in Lua?	\item Precompilation
What scope does Lua's \verb|load| compile chunks with respect to?	\item Global scope by default
How does Lua's \verb|load| interpret independent chunks?	\item As the body of an anonymous function with a variable number of arguments which are passed via \verb|...|
What's a binary chunk in Lua?	\item A compiled chunk of code
How can you directly load a function from an arbitrary C library in Lua?	\item \verb|f = package.loadlib(path, funcname)|
How do you make an assertion in Lua?	\item \verb|assert(cond, message)|<div>\item which triggers if \verb|cond| is false</div><div>\item and returns the result of \verb|cond|</div>
What are the two ways to guard against \verb|nil| returns in Lua?	\item Surround the call with \verb|assert|<div>\item Use \verb|f() or default_val|</div>
How do you catch errors in Lua?	\item Surround the call in a protected call<div>\item \verb|ok, msg = pcall(f())|</div>
How do you raise an error in Lua?	\item \verb|error(x, level)|<div>\item where \verb|x| is the error value</div><div>\item and \verb|level| indicates what depth in the call stack the fault is at &nbsp;<br /><br /></div>
What's \verb|xpcall| in Lua?	\item It's a variant of \verb|pcall| that takes a message handler<div>\item that is called before the stack unwinds (destroying information) when \verb|xpcall| returns</div>
What's the \verb|debug.debug| message handler in Lua?	\item It launches a prompt where the error was raised&nbsp;
How do you create a coroutine in Lua?	\item \verb|co = coroutine.create(f)|
What're the main differences between coroutines and threads?&nbsp;	\item Coroutines are collaberative;<div>\item only one coroutine runs at a time</div><div>\item execution is only surrendered when the running thread requests</div>
How do you get the status of a coroutine in Lua?	\item \verb|coroutine.status(co)|
How do you yield in a Lua coroutine?	\item \verb|coroutine.yield()|
How do you resume a Lua coroutine?	\item \verb|results = coroutine.resume(co, args)|
What's the \verb|normal| state of a Lua coroutine?	\item It's the state where it's not suspended or dead, but it's not running either<div>\item (typically because it's resumed another coroutine)</div>
What's the difference between symmetric and asymmetric coroutines?	\item Symmetric coroutines both resume and yield with the same call<div>\item Asymmetric coroutines use different calls to resume and to yield</div>
What're semi-coroutines?	\item Can refer to asymmetric coroutines<div>\item or more commonly, coroutines that can only yield from the bottom of their call stack (ie Python generators)</div>
What does \verb|coroutine.wrap(f)| do in Lua?	\item It creates a coroutine and returns a function that will resume it whenever it's called
What's a datafile in Lua?	"\item A plain Lua source file<div>\item though typically it consists of many calls to some small set of functions, like</div><div>\item \verb|Book{""authorname"", ""title"", ""publisher""}|</div>"
What's the derivative of $u(x)\cdot v(x)$ wrt a vector $x$?	\item $\frac{d u}{d x} v + \frac{d v}{d x} u$
If $u(x)$ and $x$ are both vectors, is $\frac{du}{dx}$ a vector or a covector?	\item Covector
What's the geometric interpretation of the Jacobian?	\item It gives the linear approximation to the function at a point
What's the pseudoinverse of a diagonal matrix?	\item $D^+_{ii} = 0$ if $D_{ii} = 0$<div>\item $D^+_{ii} = 1/D_{ii}$ otherwise</div>
How can the pseudoinverse be defined in terms of the SVD?	\item $A^+ = V D^+ U^T$
How do you define all (if any) solutions to a linear system using pseudoinverses?	\item $x = A^+ b + (I - A^+A)w$<br /><div>\item with the family of solutions parameterized by $w$</div>
What geometric property do the normal equations $(A^TA)x = A^Tb$ encode about a least-squares system?	\item That the residual in the least squares solution must be orthogonal to the columns of $A$&nbsp;
When is $A^TA$ invertible?	\item When $A$ has full column rank
What're the normal equations for a non-Euclidean norm given by $C$?	\item $(A^T C A) x = A^T Cb$<div>\item equiv $A^TC (Ax - b) = 0$</div>
Which $x$ minimizes $\|Ax\|$ subject to $\|x\| = 1$?	\item The right singular vector of $A$ corresponding to the smallest singular value
What's the geometric interpretation of the constraint $Cx = 0$?	\item That $x$ must lie in the orthogonal complement to the rowspace of $C$
What's $C^\perp$ denote in constrained minimization?	\item The orthogonal complement to the rowspace of $C$
How's the orthogonal complement of the rowspace of a matrix $C$ defined in terms of the SVD?	\item It's the set of right singular vectors corresponding to zero singular values
What approximation reduces Newton iteration to gradient descent?	\item Approximating the Hessian with $\lambda I$<div>\item where $\lambda$ is the inverse step size</div>
What're the augmented normal equations in Levenberg-Marquardt?	\item $(J^T J + \lambda I) x = &nbsp;-J^T\epsilon$<div>\item where $J$ is the Jacobian of the objective at the current point</div><div>\item $\lambda$ is the damping factor</div><div>\item $\epsilon$ is the residual</div>
Qualitively, how is the damping factor adjusted in Levenberg-Marquardt?	\item If a step increases the error, then the damping factor is increased<div>\item If a step decreases the error, then the damping factor is decreased</div>
What's kind of step will be taken when the damping factor is large in Levenberg-Marquardt?	\item A short, gradient-descent-like step
What's the second, less common set of augmented normal equations for Levenberg-Marquardt?&nbsp;	\item $(1 + \lambda)J^T J x = &nbsp;-J^T\epsilon$<div>\item where $J$ is the Jacobian of the objective at the current point</div><div>\item and $\lambda$ is the damping factor<br />\item $\epsilon$ is the residual</div>
What's the main conceptual difference between momentum optimization methods and second-order methods?	\item Momentum methods accelerate along low-curvature directions<div>\item Second order methods accelerate along low-curvature directions, but alsod \emph{decelerate} along high curvature directions</div>
What's the impossiblity result about vanishing gradients in RNNs?	\item Any RNN which can store one bit of information indefinitely<div>\item and is robust against noise</div><div>\item will suffer from vanishing gradients</div>
What's the theorem relating regularized objectives to constrained problems?	\item If $f$ and $R$ are smooth then for every local minimum $x^*$ of&nbsp;<div>\item $\min f(x)$ s.t $R(x) \leq \lambda$</div><div>\item there is a $\lambda^\prime$ such that $x^*$ is also a local minimum of</div><div>\item $f(x) + \lambda^\prime R(\theta)$</div>
What's real-time recurrent learning?	\item An alternative way to train RNNs<div>\item Online, but requires quadratic space + time</div>
What's the value in skip connections in RNNs?	\item It reduces the number of nonlinearities between a hidden unit and past information
What are the three gates that a LSTM adds to a RNNs?	\item Input gate<div>\item Output gate</div><div>\item Forget gate</div>
How is the cell state in an LSTM updated?	\item $m^\prime = m \odot f + i \odot i^g $<div>\item where</div><div>\item $i$ is the input gate</div><div>\item $f$ is the forget gate</div><div>\item $i^g$ is a nonlinear'd combination of the previous timestep's output and this timestep's input</div>
How is the output of a LSTM memory cell defined?	\item $o \odot m$<div>\item where&nbsp;</div><div>\item $o$ is the output gate</div><div>\item $m$ is the memory</div>
What do the gates in a LSTM cell get as input?	\item The previous layer's output<div>\item The input to the current layer</div><div>\item The previous cell state</div>
How should the forget gates in a LSTM be initialized?	\item With large, positive biases<div>\item (usually 5ish)</div>
What's the idea in truncated BPTT?	\item Run the network forward $k_1$ steps to step $t$<div>\item then run BPTT for $t$ down to $t-k_2$ steps</div><div>\item where $k_1 \gg k_2$</div>
What's the usual Levenberg-Marquardt heuristic?	\item Let $\rho = \frac{f(\theta + \delta) - f(\theta)}{q(\delta)}$, where $q$ is a local approximation to $f$ at $\theta$&nbsp;<div>\item If $\rho &gt; \frac{3}{4}$ then reduce damping, $\lambda \leftarrow \frac{2}{3} \lambda$</div><div>\item If $\rho &lt; \frac{1}{4}$ then increase damping, $\lambda \leftarrow \frac{3}{2} \lambda$</div>
In \emph{Numerical Optimization}, what do $\mc{E}$ and $\mc{I}$ denote?	\item The set of indices for the equality and inequality constraints respectively
What's the fundamental lemma of the calculus of variations?	\item If $\int_\Omega f(x) h(x) dx = 0$ for all compact, smooth $h$,<div>\item then $f$ is identically zero</div>
What's the intuitive use of the Euler-Lagrange equation?	\item A function satisfying the Euler-Lagrange equation is a stationary point of<div>\item $S(q) = \int_a^b L(t, q, q^\prime) dt$</div>
What's the definition of the covariant basis in tensor calculus?	\item $\mb{Z}_i = \frac{\partial \mb{R}(Z)}{\partial Z^i}$<div>\item where $Z^i$ are the coordinates</div><div>\item and $\mb{R}$ is a point in space parameterized by $Z$</div>
What are the contravariant components of a vector in tensor calculus?	<div>\item The $V^i$ in</div>\item $\mb{V} = V^i \mb{Z}_i$<div>\item where $Z_i$ the covariant basis</div>
How's the covariant metric tensor defined in terms of the covariant basis?	\item $Z_{ij} = \mb{Z}_i \cdot \mb{Z}_j$
How is the dot product defined in terms of the covariant metric tensor?	\item $\mb{U} \cdot \mb{V} = Z_{ij} U^i V^j$
How is the contravariant metric tensor defined in terms of the covariant metric tensor?	\item $Z^{ij}Z_{jk} = \delta^i_k$
How is the contravariant basis defined in terms of the covariant basis?	\item $\mb{Z}^i = Z^{ij} \mb{Z}_j$
How is the length of a vector defined in terms of the metric tensor?	\item $|\mb{V}| = \sqrt{Z_{ij}V^i V^j}$
How are the components of a vector calculated in tensor calculus?	\item $V^i = \mb{V} \cdot \mb{Z}^i$
What's the definition of the Christoffel symbol in terms of the covariant basis?	\item $\Gamma^k_{ij} = \mb{Z}^k \cdot \frac{\partial \mb{Z}_i}{\partial Z^j}$
What's the definition of the Christoffel symbol in terms of the contravariant basis?	\item $\Gamma^k_{ij} = -\mb{Z}_i \cdot \frac{\partial \mb{Z}^k}{\partial Z^j}$
How's the Christoffel symbol defined in terms of the metric tensor?	\item $\Gamma^k_{ij} = \frac{1}{2} Z^{km} \left( \frac{\partial Z_{mi}}{\partial Z^j} +&nbsp;\frac{\partial Z_{mj}}{\partial Z^i} - &nbsp;\frac{\partial Z_{ij}}{\partial Z^m} \right)$
Which indices is the Christoffel symbol symmetric in?	<div>\item The lower pair;</div>\item $\Gamma^k_{ij} = \Gamma^k_{ji}$
What's the intuitive interpretation of the Christoffel symbol?	\item It gives the coefficients of the decomposition of&nbsp;<div>\item $\frac{\partial \mb{Z}_i}{\partial Z^j}$</div><div>\item in terms of the covariant basis $\mb{Z}_k$</div>
Intuitively, what's a variant in tensor calculus?	\item An object which can be constructed using the same rules in any coordinate system
What's an example of a tensor calculus object that isn't a variant?	\item The Jacobian<div>\item since it relies on two coordinate systems</div>
When is a variant $T_i$ a covariant tensor?	\item When it changes as<div>\item $T_{i^\prime} = T_i J_{i^\prime}^i$</div><div>\item when you move from the unprimed to the primed coordinate system</div>
How is the Jacobian defined in tensor calculus?	\item For the Jacobian from coordinates $Z^i$ to $Z^{i^\prime}$,<div>\item $J^i_{i^\prime} = \frac{\partial Z^i}{\partial Z^{i^\prime}}$</div><div>\item where $Z^i$ denotes a map in the numerator and a coordinate in the denominator</div>
When is a variant a contravariant tensor?	\item When it changes as<div>\item $T^{i^\prime} = T^i J^{i^\prime}_i$</div><div>\item when you move from the unprimed to the primed coordinate system</div>
How are the Jacobians for inverse transforms related in tensor calculus?	\item $J^i_{i^\prime} J_j^{i^\prime} = \delta^i_j$<div>\item $J^{i^\prime}_i J^i_{j^\prime}&nbsp;=&nbsp;\delta^{i^\prime}_{j^\prime}$</div>
How does the covariant basis change under a change of coordinates?	\item $\mb{Z}_{i^\prime} = \mb{Z}_i J^i_{i^\prime}$
What's the flavour of a tensor?	\item The number of covariant and contravariant components
Intuitively, what's a quotient argument in tensor calculus?	\item `If $A = BC$ and $A, C$ are tensors, then $B$ must be too'
What's the order of a tensor?	\item The number of components
Is the Kronecker delta an invariant?	\item No!<div>\item It's geometrically equivalent to the metric tensor</div>
Is the derivative of a scalar field a tensor?	\item Yup
Is the derivative of a covariant tensor field also a tensor?	\item Nope
Which set of transformations are tensors defined with respect to?	\item It depends<div>\item Usually it's with respect to any change in coordinate system, but smaller classes of transformation (like affine transforms) are possible</div>
At an intuitive level, what's the contraction theorem?	\item The contraction of a tensor is a tensor.
What's another name for the flavour of a tensor?	\item Its index signature
Which tensors are invariants?	\item Tensors of order zero.
What's the gradient of a scalar field in tensor notation?	\item $\nabla F = \frac{\partial F}{\partial Z^i} \mb{Z}^i$<br />
Is $\frac{\partial F}{\partial Z^i}$ for a scalar field $F$ covariant or contravariant?	\item Covariant
What's the use of a dot $T^i_{\cdot j}$ in tensor calculus?	\item It spreads out the indices so that they remain in order when juggling indices
How do you raise an index in tensor calculus?	<div>\item By contracting with the contravariant metric tensor</div>\item $T^j = T_i Z^{ij}$
What do you get when you lower the contravariant index of $\delta^i_j$?	\item The covariant metric tensor, $Z_{ij}$
Why does the metric tensor appear so rarely in tensor calculus?	\item Because it's invisibly included via index juggling
How is the divergence of a tensor $T_i$ defined in terms of the covariant derivative?	\item $\nabla_i T^i$
How is the Laplacian of a scalar field $T$ defined in terms of the covariant derivative?	\item $\nabla^i \nabla_i T$
What's the effect of the covariant derivative on the flavour of a tensor?	\item It adds a covariant index
What does the covariant derivative reduce to in the Euclidean basis?	\item Old fashioned partial differentiation
What's the definition of the covariant derivative of a contravariant tensor $V^i$?	\item $\nabla_j V^i = \frac{\partial V^i}{\partial Z^j} + \Gamma^i_{jk}V^k$
Is the Christoffel symbol a tensor?	\item Nope.
What's the definition of the Christoffel symbol with respect to a contravariant basis?&nbsp;	\item $\Gamma^k_{ij} = -\frac{\partial \mb{Z}^k}{\partial Z^j} \cdot \mb{Z}_i$
What's the definition of the covariant derivative of a covariant tensor $V_i$?	\item $\nabla_j V_i = \frac{\partial V_i}{\partial Z^j} - \Gamma^m_{ij} V_m$
What's the covariant derivative of an invariant $F$?	\item $\nabla_i F = \frac{\partial F}{\partial Z^i}$
How does simple input/output work in Lua?	\item You set the currently open stream with \verb|io.input|/\verb|io.output|<div>\item You read/write strings with \verb|io.read|/\verb|io.write|</div>
What are the two normal ways to serialize numbers to disk in Lua?	<div>\item \verb|io.write(x)| to write a decimal number</div>\item \verb|io.write(string.format('%a', x))| to write an exact hexadecimal number<br />
How do you normally serialize a string in Lua?	\item \verb|io.write(string.format('%q', s))|<div>\item the format specifier \verb|%q| will escape the string</div>
What's a metatable in Lua?	\item A table associated with a value that defines various metamethods (behaviours) for that object
How are metatables mapped to values in Lua?	\item Tables and userdata instances can have a metatable per instance<div>\item Other types have one metatable per type</div>
How do you get or set the metatable of a table in Lua?	\item \verb|getmetatable|<div>\item \verb|setmetatable|</div>
How do you get or set the metatable of a value other than a table in Lua?	\item You can't from Lua; you have to go via C<div>\item but you probably shouldn't do it anyway</div>
How do you give a table a \verb|(+)| operator in Lua?	\item Create a \verb|__add| entry in the metatable
How does Lua deal with \verb|a + b| when \verb|a, b| have different metatables?	\item It looks for \verb|__add| on \verb|a|'s metatable first, and uses it if it finds it<div>\item It looks for \verb|__add| on \verb|b|'s metatable next, and uses it if it finds it</div><div>\item Else it throws an error</div>
How do comparison metamethods work in Lua?	\item Partial orderings can be defined via \verb|__lt|, \verb|__gt|, etc<div>\item but if only \verb|__lt| is available, Lua will infer the others</div>
What's the restriction on the equality metamethod in Lua?	\item If two values are different types, the equality metamethod won't even be called
How can you prevent third parties from changing the metatables of a value in Lua?	\item By setting \verb|__metatable| to a value other than the actual metatable<div>\item \verb|getmetatable| will then return that value, and \verb|setmetatable| will throw an error</div>
When's the \verb|__index| metamethod called in Lua?&nbsp;	\item When a table is indexed into with a missing value<div>\item If \verb|__index| is set, then \verb|__index(table, k)| will be returned</div>
What are valid values for the \verb|__index| metamethod in Lua?	\item A function which takes a table and a key<div>\item Another table, in which the missing key will be looked up (this is syntactic sugar)</div>
How do you usually implement inheritance in Lua?	\item By setting \verb|__index| to the parent table
How can you access a Lua table without invoking \verb|__index|?	\item \verb|rawget(table, key)|
What's the \verb|__newindex| metamethod in Lua?	\item It's like \verb|__index|, but used for assigning to empty positions in the table rather than getting from them<div>\item Can be set to a function or another table</div>
How can you assign to a table in Lua without invoking \verb|__newindex|?	\item \verb|rawset(table, key, value)|
Which variable in Lua can be used to access the global environment?	\item \verb|_G|
How does Lua handle global variables behind the scenes?	\item Chunks are compiled in the scope of an upvalue (local variable) \verb|_ENV|<div>\item Any free variable name \verb|x| is translated to \verb|_ENV.x|</div><div>\item By default, when the compiled chunk is loaded, \verb|_ENV| is set to the global environment</div>
How do you import a module in Lua?	"\item \verb|var = require ""module_name""|<div>\item \verb|require| takes a string and returns a table</div>"
What's a module in Lua?	\item Some code that can be loaded through \verb|require|<div>\item which creates and returns a table</div>
Where are loaded modules listed in Lua?	\item \verb|package.loaded|
How do you force \verb|require| to reload a module?	\item By setting \verb|package.loaded.modname = nil|
What does \verb|require| do behind the scenes in Lua?	\item It checks the \verb|packages.loaded| table to see if the module has already been loaded<div>\item Else it searches for a Lua file matching the module name, then loads \&amp; runs the file</div><div>\item Else it searches for a C file matching the module name and a \verb|luaopen_modname| function, and loads \&amp; runs it with \verb|loadlib|</div><div>\item Either way it stores the result in \verb|packages.loaded| and returns the value</div>
What function name does \verb|require| search for when looking through a matching C file?	"\item It strips the module name up to the first hyphen<div>\item and converts \verb|.|s to underscores<br /><div>\item \verb|require ""version-modname.submodname""| looks for \verb|luaopen_modname_submodname|</div></div>"
How does \verb|require| decide where to search for Lua modules?	\item It checks the \verb|package.path| string<div>\item and replaces every \verb|?| in the string with the module name</div><div>\item This is necessary because ANSI C doesn't have a concept of directories</div>
How is the \verb|package.path| variable initialized in Lua?	\item In order of preference, it initializes it from<div>\item the environment variable \verb|LUA_PATH_5_2|</div>\item the environment variable \verb|LUA_PATH|<div>\item a compiler-defined default</div>
What does \verb|;;| indicate in a Lua path variable?	\item \verb|;;| will be replaced by the compiler default
How does \verb|require| decide where to search for C &nbsp;modules?	\item It checks the \verb|package.cpath| variable<div><div>\item and replaces every \verb|?| in the string with the module name</div><div>\item This is necessary because ANSI C doesn't have a concept of directories</div></div>
What are searchers in Lua?	\item They're a way to hook into the machinery of \verb|requires|
How do you write a Lua module?	<div>\item Write a Lua script that</div>\item creates a table<div>\item puts things into the table</div><div>\item returns the table</div>
What's a package in Lua?	\item A tree of modules
What's \verb|require|'s default behaviour when dealing with names like \verb|parent.child| in Lua?	\item It converts the \verb|.| into a path separator and checks that path&nbsp;
What's the syntactic sugar for defining a method in Lua?	\item \verb|function Classname:methodname(args)| \\<div>\verb| &nbsp; &nbsp;self.test = args|<br /><div><div>\item It gets a hidden argument \verb|self| automatically</div></div></div>
How are class initializers usually defined in Lua?	\item \verb|function Classname:new()| \\<div>\verb| &nbsp;o = {}| \\</div><div>\verb| &nbsp;setmetatable(o, self)| \\</div><div>\verb| &nbsp;self.__index = self| \\</div><div>\verb| &nbsp;return o|&nbsp;</div>
What's a weak table in Lua?	\item It's a table which will be ignored by the garbage collector when deciding what objects are garbage
What's the \verb|__mode| of a weak table in Lua?	\item It sets which references from the weak table are weak references<div>\item \verb|'k'| means keys are weak</div><div>\item \verb|'v'| means values are weak</div><div>\item \verb|'kv'| means both keys and values are weak</div>
Which values can be weakly referenced in Lua?	\item Only objects<br /><div>\item strings, numbers and co are excluded</div>
What's an ephemeron table in Lua?	\item It's a table with weak keys and strong values<div>\item The reference to a value is only strong if there's a strong reference to the associated key</div><div>\item This means the value will be destroyed even if it references the key internally</div>
What's the metamethod for a finalizer in Lua?	\item \verb|__gc|
When are objects marked for finalization in Lua?	\item When the object is given a metatable with a non-nil \verb|__gc|<div>\item So don't make \verb|__gc| non-nil after the metatable has been assigned!</div>
In Lua, in what order will the finalizers of cyclically referenced objects be called?	\item Reverse of the order they were marked for finalization in
What's Lua's bit-manipulation library?	\item \verb|bit32|
What is the difference btwn&nbsp;multiple and multivariate regression?&nbsp;	'multiple' applies to the number of <i>predictors</i> that enter the model (or equivalently the design matrix) with a single outcome (Y response), while 'multivariate' refers to a matrix of <i>response</i> vectors<div>&gt; SE:&nbsp;For 'variate', I would say this is a common way to refer to any random variable that follows a known or hypothesized distribution, e.g. we speak of gaussian variates Xi as a series of observations drawn from a normal distribution (with parameters μ and σ2). In probabilistic terms, we said that these are some random realizations of X, with mathematical expectation μ, and about 95% of them are expected to lie on the range [μ−2σ;μ+2σ] .</div><div>&gt;&nbsp;http://stats.stackexchange.com/questions/2358/explain-the-difference-between-multiple-regression-and-multivariate-regression</div>
What's Lua's regex library?	\item It doesn't have one built in; it has it's own string matching standard instead
What's the main difference between Lua's \verb|print| and \verb|write|?	\item \verb|print| automatically applies \verb|tostring| to all its arguments
What're the possible arguments to \verb|io.read| in Lua?	\item \verb|'*a'| reads the whole file<div>\item \verb|'*l'| reads upto the next newline</div><div>\item \verb|'*L'| reads upto and including the next newline</div><div>\item \verb|'*n'| reads a number</div><div>\item \verb|5| reads a string of at most 5 chars</div>
How does Lua's \verb|io.read| indicate the end of the file?	\item It returns \verb|nil|
How does the complete IO model work in Lua?	\item You get a file handle with \verb|f = io.open(path, mode)|<div>\item You call \verb|f:read| and \verb|f:write|</div>
How do you get a handle to the currently open input file in Lua?	\item \verb|f = io.input()|
How do you create a temporary file in Lua?	\item \verb|f = tmpfile()|<div>\item It'll be destroyed when the program ends</div>
Which functions in Lua handle time?	\item \verb|os.time| converts a table to unix time<div>\item \verb|os.date| converts unix time to a table</div>
How do you run a system command from a Lua program?	\item \verb|os.execute(command_string)|
What's the problem with using Lua's \verb|debug| library?	\item It violates some otherwise useful truths about Lua programs<div>\item like not being able to see local variables from outside their scope</div>
What's the main introspective function in Lua?	\item \verb|debug.getinfo(x)|<div>\item where \verb|x| is an object or a stack level</div>
How does stack level indexing work in Lua?	\item \verb|0| is the function itself (usually \verb|debug.getinfo|)<div>\item \verb|1| is the function that called \verb|debug.getinfo|</div><div>\item etc</div>
How can you access the local variables of a function from a Lua debugger?	\item \verb|debug.getLocal|<br />
How can you set the local variables of a function from a debugger?	\item \verb|debug.setLocal|
How can you set the non-local variables of a function from the Lua debugger?	\item \verb|debug.setupvalue|
How do you inspect the work of a coroutine from the Lua debugger?	\item All the introspective functions in \verb|debug| take an optional coroutine argument
What are the four hooks supported by Lua's debugger?	\item \verb|'c'|, a function call<div>\item \verb|'r'|, a function return</div><div>\item \verb|'l'|, a line</div><div>\item \verb|'i'|, a number of instructions</div>
How do you set up a debugging hook in Lua?	\item \verb|debug.sethook(event, func)|
What's structural damping in RNNs?	\item Adding a term to the objective<div>\item $S(\theta) = D(h(\theta), h(\theta_0))$</div><div>\item that measures the distance between the hidden state sequence under the current parameters, $h(\theta_0)$, and the hidden state sequence under some proposed parameters $h(\theta)$</div>
What are Hessian-free optimization methods?	\item Optimization methods that try to exploit curvature information without explicitly computing the Hessian
What's an isolated minimizer?	\item A point of a function which is the \emph{only} local minimizer in some neighbourhood
What's a model function in numerical optimization?	\item It's a function $m$ that approximates the objective $f$ within some small trust region
When is the Newton step valid?	\item When the Hessian exists and is positive-definite
What's the secant equation?	\item $B^\prime(x^\prime - x) = \nabla f(x^\prime) - \nabla f(x)$
What's the use of the secant equation?	<div>\item It gives information about the Hessian without actually having to compute the Hessian</div>
How do nonlinear conjugate gradient methods compare to Newton methods?	\item Newton methods converge faster<div>\item CG methods don't need to store matrices</div>
What's the general form of the step in a conjugate gradient method?	\item $p^\prime = -\nabla f(x) + \beta^\prime p$<div>\item where $\beta$ is such that $p, p^\prime$ are conjugate</div>
What does it mean for an optimization problem to be poorly scaled?	\item Movement in one direction produces much larger changes in $f$ than in another direction&nbsp;
Which of steepest descent and Newton's is scale-invariant?	\item Newton's
When designing a quasi-Newton method, what's a sufficient condition on the Hessian approximation $B$ for the step to be guaranteed to be in a descent direction?	\item $B$ is positive definite<div>\item since then $p \cdot \nabla f(x) &lt;0$</div>
Algebraically, what's the Armijo condition?	\item That in line-search optimization, the step size should satisfy<div>\item $f(x + \alpha p) \leq f(x) + c_1 \alpha p \cdot \nabla f$</div><div>\item for some small $c_1 \approx 10^{-4}$</div>
Intuitively, what's the Armijo condition?	\item It ensures that the step taken in line-search optimization leads to a sufficiently large reduction in objective proportional to the step size
What's another name for the Armijo condition?	\item The sufficient decrease condition
Algebraically, what's the curvature condition in numerical optimization?	\item In line search, the step size should satisfy<div>\item $&nbsp;c_2 p \cdot \nabla f(x) \leq p \cdot \nabla f(x + \alpha p)$</div><div>\item where $c_2 \approx [0.1, 0.9]$</div>
Intuitively, what's the use of the curvature condition?	\item It ensures that the gradient at the destination of the step is sufficiently large compared to the gradient at the origin&nbsp;
What're the Wolfe conditions in numerical optimization?	\item The combination of the Armijo and curvature conditions
What's the difference between the Wolfe conditions and the strong Wolfe conditions?	\item The curvature condition is replaced by<div><div>\item $|p \cdot \nabla f(x + \alpha p)| \leq |c_2 p \cdot \nabla f(x)|$</div><div>\item which ensures the step ends near a stationary point</div></div>
What's the rate of return of a stock with price $S$?	\item $K_S = \frac{S(1) - S(0)}{S(0)}$
What does it mean for an asset to mature at time $T$ with face value $V$?&nbsp;	\item At time $T$, the asset is converted into value&nbsp;$V$
What's a portfolio in financial mathematics?	\item A linear combination over a set of assets
What's the assumption of divisibility in financial maths?	\item That you can own a fraction of an asset<div>\item This is almost achieved in the real world by dealing with very large volumes</div>
What's the assumption of liquidity in financial maths?	\item That you can buy or sell arbitrarily large quantities of an asset
How is short selling reflected in a portfolio?	\item By a negative coefficient
How is a short position in risk-free assets usually realised?	\item By borrowing cash<div>\item with the interest rate being determined by the asset price</div>
How is a short position in stocks usually realised?	\item By borrowing the stock from someone and selling it<div>\item At a later time, you buy the stock back and return it to the owner</div>
What's it mean to close a short position in stocks?	\item To repurchase the stock and return it to the owner
What's the solvency assumption in financial maths?	\item That the wealth of the investor must always be nonnegative<br />
What's an admissible portfolio?	\item One satisfying the solvency condition
Intuitively, what's the no-arbitrage principle?	\item That you cannot make risk-free profits with no initial investment
Formally, what's the no-arbitrage principle?	\item Every admissible portfolio with zero initial value is certain to have zero value in the future
What's the one-step binomial pricing model?	\item Both the risk-free asset $A$ and the risky asset $S$ start with value $S(0) = A(0) = 1$<div>\item At time $1$, the risk-free asset has value $A(1)$&nbsp;</div><div>\item and the risky asset has value $S^u$ with probability $p$,</div><div>\item and value $S^d$ with probability $1-p$&nbsp;</div>
In the one-step binomial pricing model, what constraint does no-arbitrage put on the risky asset prices at time $1$?	\item $S^d &lt; A(1) &lt; S^u$
What's the classic definition of the risk of a portfolio?	\item The standard deviation of the rate of return
What's a forward contract?	\item An agreement to buy or sell as risky asset at a future \emph{delivery date}&nbsp;<div>\item for a present, fixed \emph{forward price}</div><div>\item The money is exchanged at the delivery date</div>
What's a long forward position?	\item A forward contract to buy an asset
What's a short forward position?	\item A forward contract to sell an asset
In a portfolio, what's the value contributed by $z$ forward contracts?	\item $z(S(1) - F)$<div>\item where $S(1)$ is the future price</div><div>\item and $F$ is the forward price</div>
What are carrying costs in financial maths?	\item The costs of holding an asset<div>\item Storage costs for commodities,&nbsp;</div><div>\item Interest rates for currency (negative)</div><div>\item Dividends for stocks (negative)</div>
Intuitively, how does the no-arbitrage principle determine the forward price of forward contracts?	\item If the forward price is too high, you could borrow money to buy the asset now, then take a short forward position. When the contract closes, you can use the forward price to repay the loan.<div>\item If the forward price is too low, you could sell short the asset, invest the money, then take a long forward position. When the contract closes, you can use the asset from the forward contract to close the short.</div>
What's a call option?	\item A contract giving the holder the \emph{option} to buy an asset for a fixed \emph{strike price} at a future time&nbsp;
What's a put option?	\item A contract giving the holder the \emph{option} to sell an asset for a fixed \emph{strike price} at a future time&nbsp;
What're the two main differences between forward contracts and options?	\item Forward contracts commit you to buying/selling at a future date<div>\item Forward contracts require no payment when they're made</div>
What's it mean to replicate an option?	\item It means to construct a portfolio that will match the value of the option at the exercise time
What's it mean to price or value an option?	\item It means to calculate the cost of the replication portfolio at the current time
What's a perpetuity in financial maths?	\item A sequence of payments of a fixed amount to be made at equal time intervals and continuing indefinitely
What's an annuity in financial maths?	\item A finite sequence of payments of a fixed amount to be made at equal time intervals
Algebraically, what's the present value factor of an annuity?	\item At an interest rate of $r$,<div>\item $PA(r, n) = \sum^N_1 \frac{1}{(1+r)^n}$</div><div>\item which can be simplified using the geometric sum</div>
What's the sum of the first $N$ terms in a geometric series?	\item $\sum^N r^i = \frac{1- r^{N+1}}{1 - r}$
What's the formula for continuously-compounded interest?	\item $V(t) = e^{tr} P$<div>\item where $r$ is the interest rate and $t$ is the time</div>
What's the logarithmic return of an asset?	\item $k(s, t) = \ln \frac{V(t)}{V(s)}$
When are two compounding interest methods equivalent?	\item When the growth factors over one time unit are the same
What's a $\sigma$-algebra?	\item A $\mc{F} \subset \mc{P}(\Omega)$ which<div>\item contains the empty set</div><div>\item is closed under complement</div><div>\item is closed under union</div>
What's a probability measure?	\item A function $\mb{P} \colon \mc{F} \rightarrow [0, 1]$ on a $\sigma$-algebra $\mc{F}$<div>\item such that</div><div>\item $\mb{P}(\Omega) = 1$</div><div>\item $\mb{P}(\cup^N_1 A_n) = \sum^N_1 \mb{P}(A_n)$</div>
What's a probability space?	\item A triple $(\Omega, \mc{F}, \mbb{P})$<div>\item $\Omega$, the ground set</div><div>\item $\mc{F}$, the $\sigma$-algebra</div><div>\item $\mbb{P}$, the probability measure</div>
What's the Lebesgue measure $\mc{L}$?	\item It's the probability measure on $[0, 1]$ that sets the probability of $[a, b]$ to $b-a$
What's a Borel algebra?	\item A $\sigma$-algebra generated by open sets
What does $\mc{B}[0, 1]$ denote in measure theory?	\item The Borel sets on $[0, 1]$&nbsp;
What are the Borel sets of a Borel algebra?	\item The set of sets in the algebra
define&nbsp;generative model	a model for randomly generating observable-data values<div>&gt; W:&nbsp;typically given some hidden parameters. It specifies a joint probability distribution over observation and label sequences.</div>
What's $D$ usually represent when discussing distributed algorithms?	\item The diameter of the network
What's the basic, formal framework for modelling the evolution of a distributed algorithm in terms of configurations?	\item $\mc{C}$, a set of configurations<div>\item $(\rightarrow)$, a transition relationship on $\mc{C}$</div><div>\item $\mc{I}$, a set of initial configurations</div>
What's the difference between a state and a configuration when discussing distributed algorithms?	\item A state is local to one process<div>\item A configuration is global</div>
How are events related to configuration transitions in distributed algorithms?&nbsp;	\item Every transition is associated with a send, receive, or an internal event of some process
When is a process an initiator in terms of a distributed algorithm?	\item When the first event in that process is a send or an internal event
Formally, when is a distributed algorithm centralized?	\item When there is exactly one initiator
What's an assertion in terms of distributed algorithms?	\item A predicate on the configuration
When is an assertion a safety property in the context of distributed algorithms?	\item If it's true in every reachable configuration
What's an invariant in the context of distributed algorithms?	\item An assertion that's true in all initial configurations<div>\item and is preserved by transitions</div>
What's an execution in the context of distributed algorithms?	\item A sequence of configurations<div>\item that starts in a valid initial state</div><div>\item and such that each sequential pair of configurations is related by a transition</div>
What's a liveness property in the context of distributed algorithms?	\item An assertion which eventually holds for all executions
What's a fair execution in the context of distributed algorithms?	\item Either a finite execution<div>\item Or an infinite execution where every event that can occur in an infinite number of configurations, occurs an infinite number of times</div><div>\item (this excludes things like an infinite all-heads sequence of coin tosses)</div>
What's the causal order of a distributed algorithm?	\item $a \prec b$ if and only if $a$ must happen before $b$
How is the causal order of a distributed algorithm generated?	\item It's the smallest order such that<div>\item events within each process are totally ordered</div><div>\item send events precede corresponding receive events</div><div>\item transitivity holds</div>
What are concurrent events?	\item Events which are not causally ordered
What's a computation in the context of distributed algorithms?	\item It's the set of all causally-valid orderings of events in the algorithm
What's a logical clock?	\item A real-valued function $C$ such that for all causally ordered events $a \prec b$<div>\item $C(a) &lt; C(b)$</div>
What's Lamport's clock?	\item The logical clock that maps an event $a$ to the length of the longest causality chain terminating at $a$
How is Lamport's clock implemented?	\item Let $k$ be the clock value of the previous event in the process<div>\item If $a$ is an internal or send event, $LC(a) = k+1$</div><div>\item If $a$ is a receive event and $b$ is the corresponding send event, $LC(a) = \max\{k, LC(b)\} + 1$</div>
What's a common issue with Lamport clocks?	\item It can falsly order concurrent events;<div>\item ie there may be concurrent $a, b$ such that $LC(a) &lt; LC(b)$</div>
What's the fundamental property of the vector clock?	\item $VC(a) &lt; VC(b)$ exactly when&nbsp;$a \prec b$
How is the vector clock implemented?	\item For $N$ processes, $VC(a) = (k_0, \dotsc, k_{N-1})$<div>\item where $k_i$ is the largest Lamport clock value of an event $a^i$ in process $i$ such that $a^i \prec a$</div>
What are basic and control algorithms in distributed computing?	\item The control algorithm provides some specific service (like collecting garbage) for the basic algorithm
What's a consistent snapshot in distributed algorithms?	\item A representation of a configuration from the same computation<div>\item even though that specific configuration may never have occured</div>
In terms of events, when is a snapshot consistent?	\item When for each presnapshot event $b$, all $a \prec b$ are also presnapshot<div>\item and a basic message is included in the snapshot if and only if the send event is presnapshot and the receive event is postsnapshot</div>
In distributed snapshot algorithms, what's a presnapshot event?	\item An event that happens before the local snapshot of the process is taken
What's the use of the Chandy-Lamport algorithm?	\item To snapshot systems with FIFO channels
In the Chandy-Lamport algorithm, how is the state of channel $pq$ assessed?	\item It's all the messages received by $q$ after it gets the snapshot marker from someone,<div>\item but before it gets the snapshot marker from $p$</div>
At a high level, how's the Chandy-Lamport algorithm work?	\item A marker message is propagated through the network<br /><div>\item When a process gets its first marker message, it takes a local snapshot and propagates the marker message to all its neighbours</div><div>\item It terminates at a process when the marker has been received from all neighbours</div>
What are the two kinds of messages in the Lai-Yang algorithm?	\item A basic message with \verb|true| or \verb|false| appended<div>\item A control message sent after the local snapshot to every neighbour&nbsp;</div>
In the Lai-Yang algorithm, when does a process append \verb|false| to basic messages and when does it append \verb|true|?	\item \verb|false| until it's made it's local snapshot<div>\item \verb|true| afterwards</div>
How is the channel state computed in the Lai-Yang algorithm?	\item The state of $pq$ is all the messages received by $q$ that end \verb|false| after $q$ has taken its local snapshot
What's the contents of the control message in the Lai-Yang algorithm?	\item How many \verb|false| messages $p$ has sent into channel $pq$
When does a process take a snapshot in the Lai-Yang algorithm?	\item When it receives a control message from its neighbour
What's the purpose of the Lai-Yang algorithm?	\item To take snapshots of systems without needing FIFO channels
What are the three typical learning problems concerning mapping input to label sequences?	\item Sequence classification<div>\item Segment classification</div><div>\item Temporal classification</div>
What's the sequence classification problem?	\item Assign the whole sequence to a class
What's the segment classification problem?	\item Classify each predefined segment of a sequence
What's the temporal classification problem?	\item Segment a sequence and classify each segment
How is performance on temporal classification problems usually evaluated?	\item Using the edit distance between the estimated and the actual labellings
What's the high level idea in a bidirectional RNN?	\item Run a RNN through a sequence<div>\item then another through the reversed sequence</div><div>\item and then feed the activations on each element from both RNNs into a third, feedforward network, which produces the output</div>
What's the sequential Jacobian of a RNN?	\item $J^{tt^\prime}_{ki} = \frac{\partial y_k^t}{\partial x_i^{t^\prime}}$<div>\item where $y_k^t$ is the $k$th output at time $t$</div><div>\item and $x_i^{t^\prime}$ is the $i$th input at time $t^\prime$</div>
What's the mel scale?	\item A perceptual scale of acoustic frequency
When implementing neural networks, how can the backpropagation implementation be checked?	\item By perturbing each weight by $\pm 10^{-5}$ and using the central differences formula to numerically calculate the gradient
How is the complex cepstrum of a signal defined?	\item $\mc{F}^{-1} \circ \ln \circ \mc{F}$<br />
What's the useful analytic property of the complex cepstrum of a signal?	\item If a signal is generated as $C(\omega) = A(\omega)B(\omega)$,&nbsp;<div>\item the cepstrum of $C$ is the sum of the cepstrums of $A, B$</div>
In Grave's work on speech labelling, what were the nonlinearities of the LSTM?	\item $[0, 1]$ sigmoids on the gates<div>\item $[-2, 2]$ sigmoids on the input to and output from the cell&nbsp;</div>
How's a connectionist temporal classification layer implemented?	\item Augment the output language with a blank symbol<div>\item Have the network predict a `path' over the augmented language</div><div>\item Map paths onto labellings by removing repeated, sequential symbols, then blank symbols</div><div>\item Sum over probabilities of augmented sequences to get probabilities of original sequences</div>
What's the advantage of using blank symbols in connectionist temporal classification layers?	\item It stops the network from being burdened with having to predict a specific symbol during pauses in the data&nbsp;
What're the two gates in a gated recurrent unit?	\item $r$, the reset gate<div>\item $z$, the update gate</div>
What do the gates in a gated recurrent unit get as input?	\item Current input<div>\item Previous state</div>
What's the effect of the reset gate in a gated recurrent unit?	\item When it's $\approx 0$, the previous hidden state is ignored when computing the potential update to the hidden state
What's the effect of the update gate in a gated recurrent unit?	\item When it's $\approx 1$, the previous hidden state is preserved<div>\item When it's $\approx 0$, the hidden state is recalculated on the basis of the previous hidden state and the input</div>
What's a gated feedback RNN?	\item A RNN with stacked layers<div>\item where each layer connects to the one above it</div><div>\item and a sigmoid $g^{i \rightarrow j}$ gates the (additional) transfer of information from layer $i$ to layer $j$</div>
What's curriculum learning?	\item Giving a model simple examples first, then increasingly difficult ones
define online learning (ML)&nbsp;	exposing your learners to data one data point at a time<div>&gt;&nbsp;https://scottlocklin.wordpress.com/2014/07/22/neglected-machine-learning-ideas/</div>
What's the covariant derivative of $T_j^i$?	\item $\nabla_k T^i_j = \frac{\partial T^i_j}{\partial Z^k} + \Gamma^i_{km}T^m_j &nbsp;- \Gamma^m_{kj}T^i_m$<div>\item ie contravariant components have a positive term</div><div>\item and covariant components have a negative term</div>
When does the covariant derivative commute?	\item In Euclidean spaces
What's the product rule for the covariant derivative?	\item $\nabla_k (T^i U_j) = T^i (\nabla_k U_j) + (\nabla_k T^i) U_j$
What's the metrinilic property of the covariant derivative?	\item The co/contravariant metrics and basis vectors vanish under the covariant derivative&nbsp;
What's the algebraic consequence of the metrinilic property of the covariant derivative?	\item Metric tensors (and so free indices) can be pushed into or pulled out of a covariant derivative
How is the contravariant derivative defined?	\item $\nabla^i = Z^{ij}\nabla_j$
How is the Riemann curvature tensor defined in terms of the covariant derivative?	\item $R_{mij}^k T^m = (\nabla_i \nabla_j - \nabla_j \nabla_i) T^k$
How's the Riemann curvature tensor defined in terms of the Christoffel symbol?	\item $R_{mij}^k = \frac{\partial \Gamma^k_{jm}}{\partial Z^i} -&nbsp;\frac{\partial \Gamma^k_{im}}{\partial Z^j} + \Gamma^k_{in}\Gamma^n_{jm} - \Gamma^k_{jn}\Gamma^n_{im}$
When does the Riemann curvature tensor vanish?	\item In Euclidean space
What's another name for the Riemann curvature tensor?	\item The Riemann-Christoffel tensor
What's $e_{i_1 \dotsb i_n}e^{i_1 \dotsb i_n}$?	\item&nbsp;$e_{i_1 \dotsb i_n}e^{i_1 \dotsb i_n}= n!$<br />
How's the 3-dim delta system defined in terms of the permutation symbol?	\item $\delta^{ijk}_{rst} = e^{ijk} e_{rst}$
How can the determinant of a 3-dimensional matrix be written in terms of the delta system?	\item $A = \frac{1}{3!} \delta^{ijk}_{rst} a_r^i a_j^s a_k^t$
What's the intuitive definition of a delta system?	\item It's $+1$ when the upper and lower indices are an even permutation of eachother<div>\item $-1$ when they're an odd permutation</div><div>\item and zero otherwise</div>
How is the cofactor of a 3 dimensional matrix defined in tensor notation?	\item $A^i_r = \frac{1}{2!} \delta^{ijk}_{rst} a^s_j a^t_k$<div>\item ie the definition of the determinant with &nbsp;$a^i_r$ removed</div>
How is the determinant of a matrix $A^i_j$ commonly written in tensor calculus?	\item $A$
What's the matrix inverse property of the cofactor?	\item $A^i_r a^r_m = A \delta^i_m$
What's the volume element in tensor calculus?	\item $\sqrt{Z}$<div>\item where $Z$ is the determinant of the covariant metric tensor</div>
How does the determinant $Z$ of the covariant metric tensor transform under a coordinate change?	\item As a weight-2 relative invariant<br />
What's the Voss-Weyl formula?	\item $\nabla_i T^i = \frac{1}{\sqrt{Z}} \frac{\partial}{\partial Z^i} \left(\sqrt{Z} T^i\right)$<div>\item where $\sqrt{Z}$ is the volume element</div>
When is $T^i_j$ a relative tensor of weight $M$?	\item When it transforms as<div>\item $T^{i^\prime}_{j^\prime} = J^M T^i_j J^i_{i^\prime} J^j_{j^\prime}$</div><div>\item where $J$ is the determinant of the Jacobian</div>
What's an absolute tensor in tensor calculus?	\item A relative tensor of weight zero
If $A^i, B_j$ are relative tensors of weight $M, N$, what's the relative weight of $A^iB_i$?	\item $M+N$
What's the relative weight of the covariant Levi-Civita symbol $e_{ijk}$ when interpreted as a relative tensor?	\item $-1$
When interpreted as a relative tensor, what's the relative weight of the determinant of a relative covariant tensor $a_{ij}$ of weight $M$?	\item $2 + MN$, where $N$ is the dimension
What's the definition of the covariant Levi-Civita symbol?	\item $\varepsilon_{ijk} = \sqrt{Z} e_{ijk}$
In what way do the Levi-Civita symbols change under a transform?	\item Under an orientation preserving transform, they're absolute tensors
How can the covariant permutation symbol be related to the contravariant permutation symbol through index juggling?	\item It can't.
What's another name for a Hermitian matrix?	\item A self-adjoint matrix
What's the complex analogue of symmetric matrices?	\item Self-adjoint matrices
What's a normal matrix?	\item One such that<div>\item $A^* A = AA^*$</div>
Which class of matrices are diagonalizable?	\item The normal matrices
In terms of its eigenvalues, when is a normal matrix self-adjoint?	\item Exactly when the eigenvalues are all real
Do the normal matrices form a group?	\item Nope. Not over addition or multiplication at least
What's the complex equivalent of an orthogonal matrix?	\item A unitary matrix
What's a unitary matrix?	\item One such that $U^*U = I$<div>\item ie the adjoint is the inverse</div>
What's the complex number analogue of skew-Hermitian matricies?	\item Purely imaginary numbers
At a high level, how does the isomap algorithm work?	\item Find the neighbours of each point<div>\item Construct a neighbourhood graph</div><div>\item Compute the distances between all pairs of nodes</div><div>\item Use MDS to embed the distances</div>
What's the use of the isomap method?	\item It's a nonlinear dimensionality reduction method
What's the high-level idea in the t-SNE algorithm?	\item Construct a distribution over high-dim point pairs such that similar pairs have high probability<div>\item Construct a distribution over low-dim point pairs such that nearby pairs have high probability</div><div>\item Minimize the KL-divergence between the two</div>
What's the hashing trick in machine learning?	\item Map feature vectors $x$ to hash string $\phi$ using<div>\item $\phi_k(x) = \sum_{i:h(i)=k} x_i \xi(i)$</div><div>\item where $h \colon \mbb{N} \rightarrow [1, k]$&nbsp;and $\xi : \mbb{N} \rightarrow \{-1, +1\}$ are hash functions</div>
What's the useful property of the hash strings computed by the hashing trick?	<div>\item It approximately preserves inner products:</div>\item $\mbb{E}_\phi[\phi(x) \cdot \phi(y)] = x \cdot y$
What's teacher forcing in machine learning?	\item When a model is predicting a sequence<div>\item during training mistakes are corrected before the next character is predicted</div>
What's the hidden state allocation hypothesis?	\item When applying naive curriculum learning to neural networks<div>\item the optimal strategy on the early, easy examples is to use all the state available</div><div>\item which leaves no room for the extra state needed when computing later, harder examples</div>
What's beam search in the context of recurrent neural networks?	\item When making predictions with RNNs<div>\item beam search means keeping the $k$ highest-probability output sequences at each step</div>
What's an image saliency map for a neural network?	\item It's the map of how important each pixel is to the predicted class label
When adding auxiliary supervision to deep networks, where should the auxiliary supervisors be installed?	\item Where the gradients tend to vanish<div>\item ie every 3-4 layers in alexnet</div>
How should the auxiliary supervisor loss be weighted when training a deep network?	\item Starting at $0.3$ and decaying each epoch as $1 - e/E$<div>\item where $e$ is the current epoch and $E$ is the total number of epochs</div>
What's the hypercolumn of a pixel in a CNN?	\item The set of activations of all neurons which are `above' that pixel
What's the \verb|storage| of a Torch \verb|Tensor|?	\item It's a representation of the memory that backs the tensor
How do you make a copy of a Torch Tensor?	\item \verb|y = x:clone()|
How does Torch's \verb|Tensor| relate to \verb|FloatTensor, DoubleTensor|, etc?	\item \verb|Tensor| is an alias for whatever the default type of tensor is
How do you create a Torch tensor with more than four dimensions?	\item \verb|torch.Tensor(torch.LongStorage({1, 2, 3, 4, 5, 6}))|
How do you cast a Torch tensor to a float tensor?	\item \verb|x:float()|
How do you take a slice of a Torch tensor?	\item \verb|t[{1, {2, 4}}]|<div>\item is equivalent to the Python slice \verb|[1, 2:4]|</div>
What's the null slice in Torch?	\item \verb|x[{{}, 2}]|<div>\item is equivalent to Python's \verb|[:, 2]|</div>
What does \verb|x:gather(i, js)| do in Torch?	\item It returns a tensor whose leading shape matches \verb|js|<div>\item and whose elements are taken by indexing into dimension \verb|i| of \verb|x| using the elements of \verb|js|</div>
What does \verb|x:scatter(i, js, y)| do in Torch?	\item It sets the elements in \verb|x| corresponding to \verb|js| along dimension \verb|i| to the values of \verb|y|<br />
What are the three functions for applying an arbitrary function to one or more Torch \verb|Tensor|s?	\item \verb|apply, map, map2|
What are the two ways to break a Torch \verb|Tensor| up into a table of \verb|Tensors|?	\item \verb|split, chunk|
How can you share parameters between two \verb|Module|s in Torch?	\item \verb|module1:share(module2, param_name)|
What's a \verb|Module| in Torch?	\item The abstract class that all layers are derived from
What's the \verb|Parallel| container in Torch?	\item It applies it's \verb|i|th child module to the \verb|i|th slice of the input along some dimension<div>\item and concatenates the results alone some other dimension</div>
What's a \verb|Criterion| in Torch?	\item An abstract class which represents a loss function
What're the four main methods of a Torch \verb|Module|?	\item \verb|forward|<div>\item \verb|backward|</div><div>\item \verb|zeroGradParameters|</div><div>\item \verb|updateParameters|</div>
What's Zoutendijk's theorem in numerical optimization?	\item If $\nabla f$ is Lipschitz continuous and bounded below,&nbsp;<div>\item and the steps of a descent scheme satisfy the Wolfe conditions<br /><div>\item then the steps also satisfy the Zoutendijk condition</div></div>
What's the Zoutendijk condition in numerical optimization?	\item&nbsp;$\sum \|\nabla f_k\|^2 \cos^2 \theta_k &lt; \infty$<div>\item&nbsp;where $\theta_k$ is the angle between the step and the direction of greatest descent</div>
When the function is positive definite, what's the rate of convergence of Newton's method?	\item Quadratic
In terms of the secant matrix $B_k$, what's the theorem concerning the superlinear convergence of quasi-Newton methods?	\item If the function is smooth and convex, then a quasi-Newton method will converge \emph{exactly} when<div>\item $\frac{\|(B_k - \nabla^2 f(x^*))p_k\|}{\|p_k\|} \rightarrow 0$</div><div>\item ie when $B_k$ converges to $\nabla^2 f(x^*)$ along the step directions</div>
What's the difference between the Frobenius and nuclear norms?	\item Frobenius is $\sqrt{\sum \sigma_i^2}$<div>\item Nuclear is $\sum \sigma_i$</div>
What's the $\Delta$ with minimum Frobenius norm such that for a symmetric $A$, $A+\Delta$ is semipositive definite?	\item $\Delta = Q \text{diag}(\tau_i) Q^T$<div>\item where</div><div>\item $A = Q \Lambda Q^T$</div><div>\item $\tau_i = -\min(0, \lambda_i)$</div>
What's the $\Delta$ with minimum Euclidean norm such that for a symmetric $A$, $A+\Delta$ is semipositive definite?	\item $\Delta = \tau I$<div>\item where $\tau = -\min(0, \lambda_{\min})$</div>
How's the Cholesky decomposition compare to the LU decomposition?	\item Cholesky is faster<div>\item LU can always be used</div>
How does the LDL decomposition compare to the Cholesky decomposition?	\item LDL decomposition avoids taking square roots<div>\item LDL decomposition sometimes exists for indefinite matrices, where Cholesky doesn't</div>
What's the form of the indefinite factorization of a symmetric matrix $A$?&nbsp;	\item $PAP^T = LBL^T$<div>\item where&nbsp;</div><div>\item $P$ is a permutation matrix</div><div>\item $L$ is unit lower-triangular</div><div>\item $B$ is a block-diagonal matrix with blocks of $2 \times 2$ or $1 \times 1$</div>
What are the two phases of a typical step-length selection heuristic?	\item Bracketing, which finds an initial interval containing an acceptable step length<div>\item Selection, which refines the interval until the step length is found</div>
When applying line search methods to quasi-Newton algorithms, what should the initial trial step length be?	\item $1$<div>\item since if the termination conditions are satisfied there, various rate-of-convergence theorems will apply</div>
When picking a step size during line search, what's a typical maximum number of trial evaluations?	\item $10$
What's the ratio $\rho$ often used by trust-region methods?	\item $\rho = \frac{f(x) - f(x + p)}{m(0) - m(p)}$<div>\item where $p$ is the step</div><div>\item and $m$ is the model</div>
How do trust region methods usually respond to various values of $\rho$?	<div>\item $\rho \approx 1$ means the trust region should expand</div><div>\item $\rho \lesssim 1$ means the trust region should be preserved&nbsp;</div>\item $\rho \ll 1$ means the trust region should shrink&nbsp;
What's the Cauchy point $p^c$ in trust-region numerical optimization?	\item It's the minimum point of the model along the direction of steepest descent<div>\item inside the trust region boundary</div>
In a \verb|chmod| 3-digit code, how should you interpret the \emph{value} of each digit?	\item Each digit is the encoding of a three-digit binary string<div>\item representing read, write and execute priviledges&nbsp;</div><div>\item (\verb|r=4, w=2, x=1|)&nbsp;</div>
In a \verb|chmod| 3-digit code, how should you interpret the \emph{position} of each digit?	\item User, group, other
How do you add or remove a single privilege using \verb|chmod|?	\item \verb|chmod u+x| to add execute permissions to the user
What does having execute permission on a directory mean in Linux?	\item It means you have pass-through privilege; ie you can enter the directory
define cross tabulation&nbsp;	"aka a contingency table&nbsp;<div>&gt; eg used in R</div><div><img src=""paste-2985002270861.jpg"" /></div>"
define principle of common cause	if two variables are associated, then either one causes the other or they both share a third common cause&nbsp;<div>&gt; associated = e.g., correlated&nbsp;<br /><div>&gt; from Reichenbach 1956; has intuitive appeal but its formal standing is ambiguous&nbsp;</div></div><div>&gt; from&nbsp;http://fmwww.bc.edu/ec-p/wp689.pdf</div>
What is the theoretical difference between a linear regression with two variables and a Pearson correlation on the same variables?&nbsp;	"in a linear regression you have an independent and dependent variable, so all of the error is in one of the variables, whereas the other variable's values are fixed, while in the Pearson correlation there could be error in both of the variables<div>&gt;&nbsp;http://stats.stackexchange.com/questions/22718/what-is-the-difference-between-linear-regression-on-y-with-x-and-x-with-y<br /><div>&gt; ""Using our traditional loss function, we are saying that all of the error is in only one of the variables (viz., y). That is, we are saying that x is measured without error and constitutes the set of values we care about, but that y has sampling error. This is very different from saying the converse.""</div></div>"
What's a terminating semicolon mean in Matlab?	\item That the result won't be printed in the command window
What's the variable \ttt{ans} in Matlab?	\item It's the variable that unassigned expressions will be stored in in the command window
How do you create a matrix constant in Matlab?	\item \ttt{A = [1 2 3; 4 5 6]}<div>\item Comma or space for columns</div><div>\item Semicolon or linebreak for rows</div>
How do you continue a statement over two lines in Matlab?	\item \verb|s1 ... | \\<br /><div>\verb|s2|</div><div>\item Also automatically concatenates strings</div>
How do you receive multiple outputs in Matlab?	\item \verb|[x, y] = f()|
What's the easiest way to call a function with no parameters in Matlab?	\item Type just the function name
When a Matlab function returns multiple outputs, how can you ignore each one after the first?	\item \verb|x = f()|<div>\item will store only the first output in \verb|x|</div>
When a Matlab function returns two outputs, how can you ignore the first?	\item \verb|[~, y] = f()|
How can you test if a variable exists in Matlab?	\item \verb|exist('varname')|
What's command-function duality in Matlab?	\item If \verb|f| takes only strings and you don't need it's returns,&nbsp;<div>\item \verb|f('a', 'b')| is the same as \verb|f a b|</div>
What's a dot before an operator signify in Matlab?	\item An array operation instead of a matrix operation
How do you test if an array is empty in Matlab?	\item \verb|isempty(A)|
How do \verb|&amp;| and \verb|&amp;&amp;| differ in Matlab?	\item \verb|&amp;&amp;| is the short-circuit version
What do \verb|i, j| represent in Matlab?	\item The imaginary unit
What's the structure of an if statement in Matlab?	\item \verb|if expr1|<div>\\ &nbsp; &nbsp; &nbsp;\verb| &nbsp; &nbsp;s1|<div>\\ &nbsp; &nbsp; &nbsp;\verb|elseif expr2|</div></div><div>\\ &nbsp; &nbsp; &nbsp;\verb| &nbsp; &nbsp;s2|</div><div>\\ &nbsp; &nbsp; &nbsp;\verb|else|</div><div>\\ &nbsp; &nbsp; &nbsp;\verb| &nbsp; &nbsp;s3|</div><div>\\ &nbsp; &nbsp; &nbsp;\verb|end|</div>
What's the structure of a switch statement in Matlab?	\item \verb|switch|, \verb|case|, \verb|otherwise|
What's the structure of a for statement in Matlab?	\item \verb|for varname = array|<div>\\ \verb| &nbsp;...|</div><div>\\ \verb|end|</div>
How'd you match against a regular expression in Matlab?	\item \verb|regexp(string,&nbsp;pattern, 'match')|
What's a dynamic regular expression in Matlab?	\item A regular expression which contains a chunk of Matlab code&nbsp;
What's a cell array in Matlab?	\item An array for non-numeric data
What's the use of a comma-separated list in Matlab?	\item It can be used to pass multiple variables at once
Is Matlab row or column major?	\item Column major
How do you mass-assign to a comma separated list in Matlab?	\item \verb|[csl1] = deal(csl2)|
How can you get a comma-seperated list from a Matlab cell array?	\item Index using \verb|{}|<div>\item \verb|C{5}| to get the fifth column as a CSL</div>
How do you create an empty cell array of a specific size in Matlab?	\item \verb|cell(1, 4)| will create a 1-by-4 cell array
For a Matlab array \verb|A|, what does \verb|A(:)| get?	\item A column array view onto \verb|A|
How do you generate a stepped sequence in Matlab?	\item \verb|1:10:2|
How can you enter multiple statements on a single line in Matlab?	\item Separate them with a comma
How'd you make a cell array literal in Matlab?	\item \verb|C = {1 2 3}|
How do you write a single-line comment in Matlab?	\item \verb|% comment|
How do you write a block comment in Matlab?	\item \verb|%{|<div>\\ \verb|comment|</div><div>\\ \verb|%}|</div>
What's the difference between indexing an array with \verb|()| and \verb|[]| in Matlab?	\item \verb|()| can take a vector of indices to access
What's the not operator in Matlab?	\item \verb|~x|
How do structs relate to arrays in Matlab?	\item Structs are a kind of array
What's the difference between matrices and arrays in Matlab?	\item A matrix is a 2D array
How do you test for a \verb|nan| in Matlab?&nbsp;	\item \verb|isnan(x)|
How can you get the datatype of an object in Matlab?	\item \verb|class(x)|
What's a logical array in Matlab?	\item A boolean array
How do you map a function over the contents of an array in Matlab?	\item \verb|arrayfun(@f, A)|
How can you get a summary of an arbitrary object in Matlab?	\item \verb|whos(A)|
How do you test whether every item of a Matlab logical array is true?	\item \verb|all(A(:))|
How do you escape quotation marks in strings in Matlab?	\item Use a double quotation mark
How do you concatenate strings in Matlab?	\item Use the concatenation operator, \verb|[s t]|
In Matlab, what's the difference between using \verb|strcat| and \verb|[s t]| to concatenate strings?	\item \verb|strcat| will strip trailing spaces
What's a character array in Matlab?	\item An array of characters, with the dimension being the number of chars
How do you format a string in Matlab?	\item \verb|sprintf|
How do you compare strings in Matlab?	\item \verb|strcmp|
What's a categorical array in Matlab?	\item An array of values drawn from a finite base set<div>\item possibly with an ordering</div>
How can you mimic enums in Matlab?	\item Use a categorical array with the protected flag set
What's an ordinal categorical array in Matlab?	\item A categorical array with a sense of order on its elements
What's a table in Matlab?	\item A way to represent columnar data
How do you delete a row from an array in Matlab?	\item \verb|T[5] = []|
How do you access a column of a Matlab table?	\item \verb|T.colname|
What's the difference between indexing a Matlab table with \verb|(), {}|?	\item \verb|()| returns a table<div>\item \verb|{}| returns the extracted data</div>
With respect to a Matlab table, what are properties?	\item Contents of \verb|T.Properties|<div>\item including variable names, descriptions, units, etc</div>
In a Matlab struct, how do you set a field with a runtime-defined name?	\item \verb|s.(fieldexpr) = val|
When can two Matlab structs be put in the same struct array?	\item When all their fields have the same names
How'd you create an anonymous function in Matlab?	\item \verb|f = @(args) expr|
What's a map in Matlab?	\item A dictionary
How do you write a map literal in Matlab?	\item \verb|containers.Map({k1, k2}, {v1, v2})|
How are class constructors defined in Matlab?	\item By defining a method with the same name as the class
How are packages defined in Matlab?	\item They're folders that begin with \verb|+|
How can you list all the properties of a Matlab class?	\item \verb|properties('classname')|
How do you test objects for equality in Matlab?	\item \verb|isequal(x, y)|
How can you get documentation for a Matlab class?	\item \verb|doc('classname')|
How do you declare a class in Matlab?	\item \verb|classdef| to open the class<div>\item \verb|properties|, \verb|methods|, \verb|events| sections within</div>
How do you declare a function in Matlab?	\item \verb|function result = f(args)|<div>\item then assign to \verb|result| whatever you want returned</div>
How do you delete an object manually in Matlab?&nbsp;	\item \verb|delete(x)|
What's a code section in Matlab?	\item A chunk of code delimited by \verb|%% titlename|<div>\item which can easily be run as a whole</div>
What's a persistent variable in Matlab?	\item A variable in a function marked \verb|persistent| that maintains its value between calls
How do you access another workspace in Matlab?	\item Using the \verb|evalin, assignin| functions
How's a private function defined in Matlab?	\item By placing its file in a folder called \verb|private|
What should you be careful about when defining arrays of anonymous functions in Matlab?	\item Spaces will be interpreted as column separators<div>\item so enclose expressions in parentheses</div>
How can you count the number of input or output arguments received in Matlab?	\item They're assigned to \verb|nargin, nargout|
How can you receive a variable number of arguments in Matlab?	\item Use an argument called \verb|varargin|<div>\item which will be a cell array with one arg per cell</div>
How do you support a variable number of outputs in Matlab?	\item By naming the output variable \verb|varargout|<div>\item which should be a cell array with one output arg per cell</div>
In Matlab, how can you assert that the number of input arguments is within a certain range?	\item Use \verb|narginchk|
How can you implement type checking in Matlab?	\item By using the \verb|validateattributes| function
How can you pass a null value to some parameter of a Matlab function?	\item \verb|f(~)|
How can you implement optional arguments in Matlab?	\item Use an \verb|inputParser|
What's P-code in Matlab?	\item An obfuscated Matlab format
How do you catch errors in Matlab?	\item \verb|try, catch ME, end|
How is the variety of an error defined in Matlab?	\item By the \verb|MException|'s \verb|identifier| field
What's the usual format of a Matlab error identifier?&nbsp;	\item \verb|component:mnemonic|<div>\item where \verb|component| is \verb|Matlab| or \verb|Simulink| or another product</div><div>\item \verb|component| is what variety of error it is</div>
How do you usually create an error object in Matlab?	\item \verb|MException(identifier, message)|
How do you raise an exception in Matlab?	\item \verb|throw MException(identifier, message)|
How do you usually do cleanup work in Matlab?	\item \verb|x = onCleanup(@f)|<div>\item When \verb|x| is destroyed, \verb|f| will run</div>
How do you issue a warning in Matlab?	\item \verb|warning(identifier, message)|
How are named arguments usually passed in Matlab?&nbsp;	\item As a pair of successive arguments<div>\item \verb|f('argname', arg)|</div>
How can you get an array of handles to all the local functions in Matlab?	\item \verb|localfunctions()|
What's the difference between active risk and total risk?&nbsp;	\item Active risk is the risk due to the decisions made by the portfolio manager
What's residual risk in portfolio management?	\item The component of the return that's uncorrelated with the benchmark return
What's an indifference curve in portfolio management?	\item The tradeoff curve between risk and return with constant loss
Intuitively, what's the information coefficient&nbsp;in portfolio management?	\item The correlation between forecasts and (residual) returns<div>\item ie a measure of the skill of the forecaster</div>
Intuitively, what's breadth in active portfolio management?&nbsp;	\item The number of independent times per unit time that information from forecasts can be applied
What's the fundamental law of active management?	\item $\text{IR} = \text{IC} \cdot \sqrt{\text{BR}}$<div>\item where $\text{IC}$ is the information coefficient</div><div>\item and $\text{BR}$ is the breadth</div>
How's the information ratio of a portfolio defined in terms of the residual return in active portfolio management?	\item $\text{IR}_P = \alpha_P / \omega_P$<div>\item where $\alpha, \omega$ are the mean and volatility of the residual return</div>
What are preferences in active portfolio management?	\item What kind of investment the client would like<div>\item usually couched in terms of high risk/low risk</div>
What's an equity in finance?	\item A security representing an ownership interest
Intuitively, what's alpha in finance?	\item Ex ante: a forecast of the residual return<div>\item Ex post: average of the realized residual return</div>
How does alpha relate to score?	\item $\alpha = \text{volatility} \cdot \text{IC} \cdot \text{score}$
What's a score&nbsp;in active portfolio management?	\item A zero-mean, unit-standard-deviation representation of a forecast of a residual return
What's the use of defining the alpha in terms of IC and score&nbsp;in active portfolio management?	\item If the scores contain no information, then $\text{IC} = 0$, so the alpha will be zero
What's CAPM stand for&nbsp;in active portfolio management?	\item Capital asset pricing model
How is the market portfolio of the CAPM usually implemented?	\item Via a value-weighted index of domestic equities (NYSE Composite, etc)
What's the beta of a portfolio $P$ in the CAPM?	\item $\beta_P = \text{cov}(r_P, r_M)/\text{var}(r_M)$<div>\item where $r_P$ is the excess returns on the portfolio and $r_M$ is the excess returns on the market portfolio</div>
What are excess returns in the context of the CAPM?	\item Total returns minus the returns on a risk-free asset over the same period
What's the beta of the market portfolio in the CAPM?	\item 1
What's the beta of a risk-free asset in the CAPM?	\item 0
What's the realized beta in the CAPM?	\item It's the $\beta_P$ that arises as the slope when you construct a linear regression of the portfolio excess returns vs the market excess returns
How's the residual return $\theta_P$ defined in the CAPM?&nbsp;	\item $r_P = \beta_P r_M + \theta_P$<div>\item ie it's the part of the return not correlated with the market</div>
How's the residual variance $\omega_P^2$ defined in the CAPM?&nbsp;	\item $\sigma^2_P = \beta_P^2 \sigma^2_M + \omega_P^2$<br />
What's the foundational statement of the CAPM?	\item $\mbb{E}[\theta_P] = 0$<div>\item where $\theta_P$ is the residual return</div>
What're the weak, semistrong and strong forms of the efficient market hypothesis?	\item Weak: can't outperform the market using historical data<div>\item Semistrong: can't outperform the market using public data</div><div>\item Strong: can't outperform the market</div>
What's the security market line in the CAPM?	\item The line relating beta of a portfolio to CAPM-derived expected return of the portfolio
What's the intercept of the market security line?	\item The return on risk-free assets
What's the Sharpe ratio in active portfolio management?	\item $S_P = \mbb{E}[r_P]/\text{std}[r_P]$
What's ex-ante mean?	\item Before the event
What are the two important characteristic portfolios in the CAPM?	\item $C$, the minimum-variance portfolio<div>\item $Q$, the portfolio with the greatest Sharpe ratio</div>
In terms of characteristic portfolios, how can the CAPM be stated?	\item That the portfolio with the highest Sharpe ratio is the market portfolio
In active portfolio management, how's the exposure of a portfolio to an attribute defined?	\item $a_P = \mb{a} \cdot \mb{h}$<div>\item where $\mb{a}$ is the vector of asset attributes</div><div>\item and $\mb{h}$ is the vector of portfolio holdings</div>
Given an attribute vector $\mb{a}$ in active portfolio management, how do you calculate the characteristic portfolio?	\item $\mb{h}_a = \Lambda \mb{a} / \|\mb{a}\|^2_\Lambda$<div>\item where $\Lambda$ is the precision matrix of the excess returns</div>
What's the intuitive definition of the characteristic portfolio associated with an attribute vector?	\item It's the portfolio with minimum risk and unit exposure to the attribute
How are the portfolios on the efficient frontier in CAPM formed?	\item As linear combinations of the minimum-risk and market portfolios
What does $\Sigma_X c$ represent for a covariance matrix $\Sigma_X$?	\item The covariance of the linear combination $c \cdot X$ with respect to $X$
What does $\Lambda_X d$ represent for a precision matrix $\Lambda_X$?	\item It gives the linear combination over $X$ which has covariance $d_i$ with $X_i$
What's the variance of the characteristic portfolio for attribute vector $\mb{a}$?	\item $\sigma^2_\mb{a} = \frac{1}{\|\mb{a}\|^2_\Lambda}$
How is the portfolio with the maximum Sharpe ratio calculated in the CAPM?	\item It's the characteristic portfolio of the expected excess returns
What's semivariance?	\item The variance of the returns below the mean
What does $\sigma_P$ represent in active portfolio management?	\item The standard deviation of the return on portfolio $P$
What's the rule of thumb for the risk in a large portfolio whose stocks have risk $\sigma$ and pairwise correlation $\rho$?	\item $\sigma_P \approx \sigma \cdot \sqrt{\rho}$
Is return variance additive over time?	\item For most asset classes, yes<div>\item since returns accross periods are uncorrelated</div>
What's the tracking error of a portfolio?	\item aka the active risk<div>\item the standard deviation of the active return</div>
What's a typical range of residual risk for large US equities?	\item 20\% to 35\%
What's a typical range of beta for large US equities?	\item 0.8 to 1.35
What's the problem with estimating a full covariance matrix for $N$ stocks from $T$ historical time periods?	\item The rank of the covariance matrix is $\min(N, T-1)$<div>\item and commonly $T \ll N$</div><div>\item meaning the covariance matrix is singular</div>
How's the excess return decomposed in a linear structural risk model?&nbsp;	\item $\mb{r}(t) = X(t)\mb{b}(t) + \mb{u}(t)$<div>\item where</div><div>\item $\mb{r}$ is the vector of excess returns</div><div>\item $X(t)$ is the factor loading, giving the exposure of each stock to each factor</div><div>\item $\mb{b}$ is the factor return</div><div>\item $\mb{u}$ is the specific return</div>
How's the covariance of the excess returns decomposed in a linear structural risk model?&nbsp;	\item $\Sigma = X F X^T + \Delta$<div>\item where</div><div>\item $X$ are the factor loadings</div><div>\item $F$ is the factor covariance matrix</div><div>\item $\Delta$ is a (usually diagonal) specific covariance matrix</div>
What are the three categories of factor that usually turn up in structural risk models?	\item Responses to external influences<div>\item Cross-sectional comparisons of asset attributes</div><div>\item Internal/statistical factors</div>
What's a macrofactor in active portfolio management?	\item An economic force expressed as a risk factor&nbsp;
What are descriptors in active portfolio management?	\item They're the specific measurements that contribute to risk indices
What are risk indices&nbsp;in active portfolio management?	\item Measures of stock exposure to various investment themes<div>\item volatility, liquidity, size, etc</div>
What's the difference between excess, residual and active risk?	\item Excess is with respect to a risk-free asset<div>\item Residual is with respect to the market/benchmark</div><div>\item Active is due to the manager's decisions</div>
What are the three categories of active risk?	\item Inherent risk is part of the benchmark<div>\item Intentional risk is taken on knowingly</div><div>\item Incidental risk is a side-effect of the active position</div>
What's a factor portfolio with respect to a structural risk model?	\item It's a portfolio that has&nbsp;<div>\item unit exposure wrt one factor</div><div>\item zero exposure wrt all others</div><div>\item minimal risk&nbsp;</div>
How is the marginal contribution to total risk defined in a structural risk model?	\item $\text{MCTR} = \frac{\partial \sigma_P}{\partial \mb{h}_P}$
How are cash holdings usually represented in holding vectors?	\item Implicitly as&nbsp;<div>\item $\mb{h}_0 = 1 - \sum_{i \geq 1} \mb{h}_i$</div>
How can the expected return be decomposed into four components?	\item $\mbb{E}[r] = 1 + i_F + \beta \mu_B + \beta \Delta f_B + \alpha$<div>\item $i_F$ is the time premium</div><div>\item $\beta \mu_B$ is the risk premium</div><div>\item $\beta \Delta f_B$ is the exceptional benchmark return</div><div>\item $\alpha$ is the expected residual return</div>
What's the time premium in active portfolio management?	\item It's the return the investor gets with parting with the stake for a unit period<div>\item (so it's the return on a risk-free asset)</div>
What's the exceptional benchmark return in active portfolio management?	\item It's the expected difference between the future excess benchmark return and the long-term historical return
What's a typical range of values for the risk premium for equity markets?	\item 3\% to 7\%
What's a basis point in finance?	\item One hundredth of one percent
What's a benchmark timing strategy in active portfolio management?	\item A strategy of buying or selling depending on price movement predictions
What are the three reasons for using mean and variance to select portfolios?	\item Returns are normally distributed<div>\item The investor has a quadratic utility function</div><div>\item Quadratic utility functions can mimic any utility function over a short period of time</div>
How's expected utility usually defined in active portfolio management?	\item $U[P] = f - \lambda \cdot \sigma^2$<div>\item $f$ is the expected excess return</div><div>\item $\lambda$ is the aversion to risk</div><div>\item $\sigma^2$ is the variance of the portfolio</div>
What's a normal value for the total risk aversion parameter $\lambda_T$ in portfolio management?	\item $\lambda_T \approx 0.75$
What's the active beta in portfolio management?	\item $\beta_\text{PA} = \beta_P - 1$
What's the timing component of the value-add in portfolio management?	\item $\beta_\text{PA} \Delta f_B - \lambda_\text{BT} \beta_\text{PA}^2 \sigma_B^2$<div>\item $\Delta f_B$ is the exceptional benchmark return</div><div>\item $\beta_\text{PA}$ is the active beta</div><div>\item $\lambda_\text{BT}$ is the benchmark timing risk aversion</div>
What's the residual component of the value add in portfolio management?	\item $\alpha_P - \lambda_\text{R} \omega_P^2$<div>\item $\lambda_\text{R}$ is the residual risk aversion&nbsp;</div>
What are the two reasons that active beta $\beta_\text{PA}$ is typically close to zero?	\item Because timing risk aversion $\lambda_\text{BT}$ is typically very high<div>\item Because the exceptional benchmark forecast $\Delta f_B$ is typically close to zero</div>
When are active and residual returns identical?	\item When benchmark timing is avoided and $\beta_P = 1$
How does the residual return of a portfolio relate to alpha?	\item $\theta_P(t) = \alpha_P + \epsilon_P(t)$<div>\item $\alpha_P$ is the average residual return<br /><div>\item $\epsilon_P$ is the mean-zero random component</div></div>
What's the alpha of the benchmark portfolio?	\item $0$, since it's the expectation of the residual returns
What are typical values for ex-post information ratios?	\item $-0.5$ to $+0.5$
What's a typical ex-ante residual risk in active portfolio management?	\item $\approx 5\%$
How's the ex-ante information ratio of an active portfolio manager defined?	\item As the maximum $\text{IR}_P$ over all possible portfolios
Why is it important to only compare information ratios across the same time horizon?	\item Because expected returns and variances tend to grow linearly with the time horizon<div>\item so the IR grows as $\propto \sqrt{T}$&nbsp;</div>
What's the certainty equivalent return in portfolio management?	\item Another name for the value add
How does the value-add relate to the information ratio and risk aversion of an active manager?	\item $\text{VA}^* = \frac{\text{IR}^2}{4\lambda_R}$<div>\item where</div><div>\item $\text{IR}$ is the information ratio</div><div>\item $\lambda_R$ is the residual risk aversion</div>
What's special about the information ratio of the characteristic portfolio of the alphas, $A$?&nbsp;	\item It's the maximal information ratio over all portfolios
How is the portfolio $Q$ with maximal Sharpe ratio related to the characteristic portfolio $A$ of the alphas?	\item It's a linear combination of $\mb{h}_A$ and $\mb{h}_B$, the benchmark portfolio
How's the information ratio of a portfolio related to the Sharpe ratio?	\item $\text{SR}^2 = \text{SR}_B^2 + \text{IR}^2$<div>\item where $\text{SR}_B^2$ is the Sharpe ratio of the benchmark</div>
What's the portfolio $A$ usually stand for in active portfolio management?	\item The characteristic portfolio of the alphas
How can the alphas of a set of stocks be written in terms of the marginal contribution to residual risk?	\item $\mb{\alpha} = \text{IR} \cdot \mb{MCRR}_Q$<div>\item where $Q$ is the portfolio with maximal Sharpe ratio</div>
How can the information ratio of a portfolio be defined in terms of the information ratio of portfolio $A$?	\item $\text{IR}_P = \text{IR}_A \cdot \text{corr}[\theta_P, \theta_A]$<div>\item where $A$ is the characteristic portfolio of the alphas</div>
What's $e_P$ typically denote for a portfolio $P$?	\item The fraction invested in risky assets
How is the portfolio $Q$ with maximal Sharpe ratio most easily constructed?	\item It's the characteristic portfolio of the expected excess returns $\mb{f}$<br /><div>\item but scaled to be fully invested in risky assets</div>
How's the information ratio relate to the residual risk of the characteristic portfolio of alphas?	\item $\omega_A = \frac{1}{\text{IR}}$
What's the characteristic attribute of the portfolio $C$ in active portfolio management?	\item $\mb{e}$, the all-ones vector
What's the intuitive interpretation of the portfolio $C$ in active portfolio management?	\item It's the fully invested portfolio with minimum risk
How's the information ratio defined in terms of the alphas?	\item $\text{IR} = \|\mb{\alpha}\|_\Lambda$<div>\item where $\Lambda$ is the precision of the residual returns</div>
What're the three major assumptions underlying the fundamental law of active management?	\item The manager must be hypercompetent<div>\item The bets must be independent</div><div>\item Each bet is made with the same skill (IC)</div>
What's hypercompetence in active management?	\item It means the manager exploits information optimally<div>\item and can accurately assess how well she can exploit information (her IC)</div>
In the information model of active portfolio management, what does $\mb{x}$ typically represent?	\item The whitened residual returns, with<div>\item $\mb{\theta} = \mb{A}\mb{x}$</div>
In the information model of active portfolio management, what does $\mb{y}$ typically represent?	\item The whitened signals, with<div>\item $\mb{z} = \mb{E}\mb{y}$</div>
In the information model of active portfolio management, what does $\mb{z}$ typically represent?	\item The standardized signals
What's the general method for finding a position given some signals $\mb{z}$?	\item Maximize the value-add \emph{conditional on} the signals<br />
What's Hutchinson's trick?	\item $\text{tr}(A) = \mbb{E}[z^T A z]$<div>\item and the RHS can be estimated by sampling from a Rademacher distribution</div>
What's a Rademacher distribution?	\item Uniform on $\{+1, -1\}$
How are value multiples related to risk-adjusted expectations?	\item $\mbb{E}^*_s[\text{cf}(s)] = \mbb{E}_s[\nu(s) \cdot \text{cf}(s)]$<div>\item where $\mbb{E}^*$ is the risk-adjusted expectation&nbsp;</div><div>\item $\text{cf(s)}$ is the cashflow of outcome $s$</div><div>\item $\nu$ is the value multiple</div>
What are the constraints on value multiples $\nu(s)$ in valuation theory?	\item $\nu(s) &gt; 0$<div><div>\item $\mbb{E}[\nu(s)] = 1$</div></div><div>\item $\nu(s) \propto r_S(s)$</div><div>\item where $S$ is the portfolio with minimum second moment of total return</div>
How does the risk-adjusted expectation relate to the covariance of the cashflow and value multiples?	\item $\mbb{E}^*[\text{cf}(s)] = \text{cov}[\text{cf}(s), \nu(s)] + \mbb{E}[\text{cf}(s)]$
Under the assumption that there are no arbitrage opportunities, what's the formula that defines the value multiples $\nu(s)$?	\item For any asset $n$ and future time $t$<div>\item $p_n = \mbb{E}_s\left[\nu(s) \cdot \frac{p_n(s)}{p_0(s)}\right]$</div><div>\item where $p_0(s)$ is the future price of the risk-free asset in state $s$</div><div>\item and $p_n$ is the initial price of asset $n$</div>
How's portfolio $S$ typically defined in valuation theory?	\item Its the portfolio over risky and risk-free assets that minimizes $\mbb{E}[R^2]$, the second moment of total return
How are value multiples defined in terms of the minimum-second-moment portfolio $S$?	\item $\nu(s) = \frac{R_S(s)}{\mbb{E}_s[R_S(s)]}$
How can the expected excess return of a portfolio be related to the covariance with portfolio $S$?	\item $\mbb{E}[r_P] = \frac{\text{cov}[r_P, r_S]}{\mbb{E}[R_s]}$<div>\item where $S$ is the portfolio that minimizes the second moment of total return</div>
What's the operational/financial division of a firm?	\item The operational part creates the value<div>\item The financial part deals with dividends and investment</div><div>\item Cash flows between the two parts</div>
What's the Modigliani/Miller conjecture about corporate finance?	\item Dividend and finance policy don't affect the share price<div>\item All the value comes from the operational side of the firm</div>
What's the idea in the dividend discount model?	\item The value of a stock is the risk-adjusted expectation of its dividends
What are the two main ways to calculate the present value of a future cash flow?	\item Either apply a discount rate different from the risk-free interest rate<div>\item Or use the risk-free discount rate, but use risk-adjusted expectations rather than regular expectations</div>
What's the price of a stock delivering a constant dividend $d(1)$ when discounted at constant rate $y$?	\item $p(0) = \frac{d(1)}{y}$
Under the simple model of capital appreciation, how is the dividend growth rate expressed?	\item $g = (1- \kappa) \rho$<div>\item where $\kappa$ is the payout ratio</div><div>\item and $\rho$ is the return on reinvested earnings</div>
What's a company's payout ratio?	\item The fraction of earnings paid out as dividends
What's the golden rule of the dividend discount model?	<div>\item $g$ in, $g$ out</div><div>\item If the growth prediction is garbage then the stock price prediction is garbage</div>
What's an implied growth rate in valuation theory?	\item It's the growth rate calculated by assuming the stock is fairly-priced, and working back from there
How do implied growth rates tend to compare to forecast growth rates?	\item Forecast growth rates tend to be higher than implied growth rates
What's the basic idea in the three-stage dividend discount model?	\item Growth forecasts are usually more accurate at 1-4 years than the long term<div>\item so you should interpolate between the forecast and the implied growth rate as you move further into the future</div>
How is the dividend discount model used in internal rate of return mode to caclulate exceptional returns?	\item Use the dividends and current market prices to solve for the internal rates of return $y_n$ for each stock<div>\item Use the internal rates of return to estimate the benchmark excess return $f_B$§</div><div>\item Use $y_n$ and $f_B$ to calculate $\alpha_n$</div>
How is the dividend discount model used in net-present-value mode to caclulate exceptional returns?	\item Use the dividend stream, betas and expected benchmark return to calculate a discount rate $y_n$<div>\item and solve for a fair market price $p^\text{model}_n$</div><div>\item which can be compared against the current market price $p^\text{market}_n$</div>
What's comparative valuation?	\item Valuing stocks by comparing the company to its peers over some set of attributes
What's the idea in returns-based analysis?	\item Try to predict the returns on some stocks from some set of company attributes<div>\item and consider the errors to be pricing errors rather than model errors</div>
What's the naive forecast in active management?	\item The informationless one that leads to the benchmark portfolio
How's the formula for calculating a refined forecast from a raw forecast arise?	\item Form a joint Gaussian of the excess returns $\mb{r}$ and the raw forecast $\mb{g}$<div>\item where $\mu_\mb{r}$ is the naive forecast</div><div>\item Then the refined forecast is $\mu_{\mb{r}|\mb{g}} - \mu_\mb{r}$</div>
What's a typical range of `good' information coefficients in active management?	\item 5\% to 10\%
Fundamentally, why is forecasting risk harder than forecasting returns?	\item Because with typical information ratios of 5\%-10\%<div>\item $\Sigma_{\mb{r}|\mb{g}} \approx \Sigma_\mb{r}$</div><div>\item for jointly-distributed Gaussian returns $\mb{r}$ and forecasts $\mb{g}$</div>
What are the two standard tests for any new stock forecasting technique?	\item Feed it random data<div>\item Feed it simulated data with a hidden relationship</div>
What's the use of ARCH and GARCH models in finance?	\item To forecast volatility and correlations
Should raw forecast scores \emph{usually} be standardized across stocks or across time?	\item Across stocks<div>\item There's usually a strong correlation between score volatility and stock volatility, so there's usually not much reason to standardize across time</div>
What are the two steps in information analysis in active management?	\item Turn the predictions into portfolios<div>\item Evaluate the performance of the portfolios</div>
What's an event study in active management?	\item Investigating how rare events (like changes in CEOs) affects share price
What's the half-life of information in portfolio management?	\item The time it takes for the information ratio derived from that information to drop to one-half its value
What are the two ways in which two correlated signals can be combined in portfolio management?	\item Diversification: if they're strong signals but weakly correlated, average them to reduce noise<div>\item Hedging: if they're weak signals but strongly correlated, take the difference to reduce noise</div>
How does the correlation between lagged strategies relate to their information coefficient?	\item $\text{corr}[\theta_k, \theta_0] = \frac{\text{IR}_k}{\text{IR}_0}$<div>\item where $\theta_k$ are the returns of the $k$-period lagged strategy</div><div>\item and $\text{IR}_k$ is the information ratio of the $k$-period lagged strategy</div>
What's a lagged strategy in portfolio management?	\item It's a strategy that uses $k$-period-old data
How does combining old and current information increase the information ratio in active management?	\item By reducing the volatility<div>\item It doesn't increase the alpha of the strategy</div>
What's the fundamental interaction between real and finanical assets in corporate finance?	\item Financial assets are sold to pay for real assets<div>\item Real assets produce cash flows that support the financial assets</div>
What's a security in finance?	\item A tradeable financial asset
Naively, what's an investment decision in corporate finance?	\item A decision about the purchase of real assets&nbsp;
Naively, what's a finance decision in corporate finance?	\item A decision about the sale of financial assets
What's capital expenditure in corporate finance?	\item It's investment in an asset that will be useful beyond the current financial year
What's a capital structure decision in corporate finance?	\item The choice between debt and equity finance<div>\item and specific kinds of debt and equity</div>
What's a closely held company?	\item A company where the shares aren't traded publicly, but instead held privately by a few people
What are typically the three most senior financial roles in a company?	\item CFO<div>\item Under the CFO, a treasurer and a controller</div>
What's the fundamental role of a financial manager?	\item To act as an intermediary between the financial markets (investors holding financial assets)&nbsp;<div>\item and the firm's operations (real assets)</div>
When should a financial manager reinvest rather than paying dividends?	\item When the reinvestment will achieve a greater rate of return than can be achieved by the shareholders investing in the market at the same risk
What's the cost of capital in financial management?	\item The rate of return investors would get from investing in the market at the same risk<div>\item which needs to be beat by any of the corporation's investment projects</div>
Why is the objective of a financial manager to maximize the firm's shareholder value?	\item Because the shareholders can themselves manage the risk of their investments and the timing of payouts through the financial markets<div>\item Only thing they can't manage is the value of their shares!</div>
What are agency costs in finance?	\item Costs arising from managers working towards their own ends rather than the shareholder's
How's the present value of an investment in a project calculated in corporate finance?	\item It's the return of the investment discounted by the return on an equally-risky investment in the market
What's the rule of 69 in finance?	\item A continuously-compounded investment takes $69.3/r$ periods to double
What's the rule of 72 in finance?	\item A discretely-compounded investment takes $72/r$ periods to double
What's a bond's coupon?	\item The interest on the bond
What's the face value of a bond?	\item The amount at which the issuer pays interest<div>\item (and which is - for most bonds - repaid when it matures)</div>
What's the difference between US Treasury bills, notes and bonds?	\item Bills mature in a year or less<div>\item Notes mature in ten years or less</div><div>\item Bonds mature in more than ten years</div>
How do interest rates change with bond prices?	\item Oppositely<div>\item Rising interest rates mean falling bond prices</div>
How's the duration of a bond calculated?	\item $\text{duration} = \frac{1}{\text{PV}} \sum t \cdot \text{PV}(C_t)$<div>\item where $C_t$ is the cashflow at time $t$</div><div>\item and $\text{PV}$ is the present value of the bond</div>
How's the yield of a bond defined?	\item It's the interest rate that explains the bond's price in terms of its cashflow<div>\item ie the $y$ such that $\text{PV} = \sum \frac{C_t}{(1+y)^t}$</div>
How's the volatility of a bond defined in terms of the duration?	\item $\text{volatility} = \frac{\text{duration}}{1+y}$
How's the volatility of a bond defined as a derivative?&nbsp;	\item $\frac{d\text{PV}}{dy} = -\text{volatility}$<div>\item So a 1\% change in the yield means -volatility\% change in present value</div>
What're spot rates in the context of bonds?	\item They're the rate $r_t$ at which cash flows $t$ years should be discounted<div>\item so if $r_4 = 4\%$, then a cashflow in four years has present value $C_4/1.04^4$</div>
What's the term structure of interest rates in the context of bonds?	\item How spot rates change as you move further into the future
What's a stripped bond?	\item One that makes a single payment
What's the yield curve in the context of bonds?	\item The relationship between yield and maturation date
How does the term structure reflect beliefs about interest rates?	\item An upward-sloping term structure indicates interest rates are expected to rise<div>\item A downward-sloping term structure indicates interest rates are expected to fall</div>
How does uncertainty about interest rates affect the term structure?	\item High uncertainty leads to an upward-sloping term structure<div>\item (since long-term bonds are more heavily impacted by changes in interest rates)</div>
What's an indexed bond?	\item A bond whose payments are dependent on inflation
How do expectations about inflation generally affect real compared to nominal interest rates?	\item Real interest rates remain relatively constant<div>\item Nominal interest rates adjust to match</div>
What are investment-grade bonds?	\item Bonds with a rating of BBB or above
What are junk bonds?	\item Bonds with a rating BB or below
What's the `primary market' for shares?	\item Direct sales of shares from a company to investors
What's the difference between a dealer market and an auction market?	\item In an auction market, transactions are between investors&nbsp;<div>\item In a dealer market, a dealer/market-maker intermediates trades</div>
What're limit orders in auction markets?	\item An order to buy/sell at a certain price, when possible
What're market orders in auction markets?	\item An order to buy/sell at the best price available
What's `ttm' stand for in stock reports?	\item Trailing twelve months
What's P/E stand for in stock reports?	\item Price to earnings (per share)
How does `stock' differ from `share'?	\item Stock is usually used to describe ownership of any company<div>\item Share is usually used to describe ownership of a specific company</div><div>\item It's a linguistic difference at most</div>
What's EPS stand for in stock reports?	\item Earnings per share
What's the dividend yield of a stock?	\item The ratio of the dividend to the price
What's the net book value of a company?	\item The total value of all its assets, minus the total value of all its liabilities
What's GAAP stand for in finance?	\item Generally accepted accounting principles
What's going-concern value?	\item The value added when a group of assets are organized into a business
What's P/B stand for in stock reports?	\item Price-to-book value (per share)
What are growth stocks and cash stocks?	\item Growth stocks are bought in the hopes of capital gains<div>\item Cash stocks are bought for the dividends</div>
What about a company makes it a growth stock rather than a cash stock?	\item That a substantial part of its share price is derived from future investments
What's the free cash flow of a business?	\item The amount of cash the business can pay out to investors after paying for all growth investments
What's a valuation horizon?	\item When valuing a firm, its present value can be calculated as free cash flows out to a valuation horizon<div>\item plus the value of the firm at the horizon</div>
Why's it important to calculate the value of a business in multiple ways?	\item Because any single way can be very sensitive to errors
What's a good way to set the valuation horizon?	\item Pick the period that the market is likely to fall into competitive equilibrium<div>\item since beyond that growth opportunities become much rarer</div>
What's the book rate of return of a project?	\item $\text{book rate of return} = \frac{\text{book income}}{\text{book assets}}$
What's the payback rule in finance?	\item Projects should be judged on how long they'll take to cover their initial investment
What's the internal rate of return of a project?	\item The discount rate which leads to a net present value of zero.
What're the problems with using the IRR to judge a project?	\item When finding the IRR, the equation sometimes has zero or many roots<div>\item IRR can give flawed results when comparing mutually exclusive projects</div><div>\item IRR can't account for time-varying costs of capital</div>
What's capital rationing in corporate finance?	\item When there's only a fixed amount of investment available, and it needs to be distributed between projects
What're the betas of each asset with respect to the characteristic portfolio of attribute $\mb{a}$?	\item $\mb{a}$
What's the definition of the partial correlation $\rho_{XY\cdot Z}$?	\item If $r_{X}$ is the residual of a linear model of $X$ using variables $Z$<div>\item then $\rho_{XY \cdot Z} = \text{corr}(r_X, r_Y)$</div>
How can the precision matrix be interpreted in terms of partial correlations?	\item $\rho_{X_i X_j \cdot X_{-ij}} = -\Lambda_{ij}/\sqrt{\Lambda_{ii} \Lambda_{jj}}$
How can partial correlations be interpreted in terms of a Gaussian distribution?	\item If $X, Y, Z$ are normal<div>\item then $\rho_{XY \cdot Z} = 0$ iff $X$ is independent of $Y$ given $Z$</div>
How can the maximum Sharpe ratio be defined in terms of the expected excess returns $\mb{f}$?&nbsp;	\item $\text{SR}_q = \|\mb{f}\|_\Lambda$
What's the goal when rescaling alphas in active portfolio management?	\item To give them a standard deviation of $\text{volatility} \cdot \text{IC}$,&nbsp;<div>\item as they should have if the scores have standard deviation $1$</div>
What's a rule of thumb for choosing which alphas to trim in active portfolio management?	\item Anything above $3\sigma$ should be investigated
What's factor neutralization in active portfolio management?	\item Recentering some alphas so the factor has alpha $0$&nbsp;
What's the rule of thumb for estimating annualized transaction costs?	\item $\text{annualized transaction costs} \approx \frac{\text{round-trip cost}}{\text{holding period}}$
How do transactions costs constrain the alpha in an optimal portfolio?	\item $-\text{SC} \leq \text{MCVA}(\alpha) \leq \text{PC}$<div>\item where SC is the sales cost and PC is the purchase cost</div><div>\item so it only makes sense to buy or sell when the alpha changes to push the MCVA outside this band</div>
What are screens in portfolio construction?	<div>\item It's a method for portofolio construction:</div>\item Rank the stocks by alpha<div>\item then buy the first $n$ in the list</div><div>\item and sell the last $m$</div><div>\item to equal weight</div>
What's stratification in portfolio construction?	\item Applying a screen in each of several categories
When is the long-only constraint most damaging?	\item When the universe has many assets<div>\item When the volatility of each asset is low</div><div>\item When the strategy has high risk</div>
What's the usual model of the distribution of weight in a portfolio benchmark?	\item Log-normal
What's market impact?	\item The additional cost of trading more than one unit of a stock<div>\item since the lowest offer might only be for a handful of units</div>
What's the implementation shortfall approach to measuring the cost of trading?	\item The cost of trading is the difference between a paper portfolio and the actual portfolio
What does VWAP stand for in finance?	\item Volume-weighted average price
What's the idea in the inventory risk model of transaction costs?	\item Transaction costs are proportional to the risk that the liquidity supplier takes on by facilitating the trade<div>\item taking into account trade volume and stock volatility</div>
What's the rule of thumb for estimating trading costs?	\item It costs one day's volatility to trade one day's volume
How's purchase turnover defined between a current and a desired portfolio?	\item $\text{TO}_P = \sum_n \max(0, h^\prime_n - h_n)$
How's turnover defined between a current and a desired portfolio?	\item $\text{TO} = \min (\text{TO}_P, \text{TO}_S)$
What's the rule of thumb about value-add when turnover is restricted?&nbsp;	\item You can achieve 75\% of the value-add with 50\% of the turnover
How can transaction costs be interpreted in terms of the value-add/turnover curve?	\item If transaction costs are constant across assets<div>\item then the point on the value-add/turnover curve where the derivative equals the transaction costs is the optimal point to move to</div>
How can trading towards a portfolio be phrased as an optimization problem?	\item $\text{utility} = \alpha_\text{short} - \lambda \psi_\text{short}^2 - \text{MI}$<div>\item where $\alpha_\text{short}, \psi_\text{short}$ are alpha and risk accumulated by the trades</div><div>\item and $\text{MI}$ is the market impact.</div><div>\item These terms can all be written as integrals, and the holding function over $h(t)$ optimized against them</div>
How's the geometric average return defined in portfolio management?	\item It's the $g$ such that<div>\item $(1 + g)^T = \prod_t R(t)$</div><div>\item where $R(t)$ is the return for period $t$</div>
How's the average log return defined in portfolio management?	\item It's the $z$ such that<div>\item $e^{z\cdot T} = \prod R(t)$</div><div>\item where $R(t)$ is the return for period $t$</div>
How's the arithmetic average return defined in portfolio management?	<div>\item It's the $a$ such that</div>\item $1 + a = \frac{1}{T} \sum R(t)$
How do the arithmetic, geometric and exponential rates of return compare?	\item $\text{exp} \leq \text{geo} \leq \text{ari}$<div>\item $z \leq g \leq a$</div>
What's the idea in performance attribution in portfolio management?	\item Use the factor model developed for predicting returns&nbsp;<div>\item to evaluate the performance of different factors</div><div>\item which can then be t-tested</div>
What's the difference between strategic and tactical asset allocation in portfolio management?	\item Strategic allocation establishes a target allocation<div>\item Tactical allocation deals with the variation around that target</div>
What's the difference between domestic and global asset allocation?	\item Domestic allocation chooses between stocks/bonds/cash/etc<div>\item Global allocation chooses between geographic equity/bond markets&nbsp;</div>
Why should the approach to asset allocation be different to the approach to asset selection?	\item Allocation has only 3-20 assets to choose between<div>\item Selection has hundreds or thousands</div>
Why does asset allocation usually involve time-series asset models rather than selection's cross-sectional models?	\item Because correlation between assets is much lower
How do you convert portfolio returns between currencies?&nbsp;	\item $R(\text{U.S.}|0, T) = \frac{(\text{USD}/\text{GBP})(T)}{(\text{USD}/\text{GBP})(0)} \cdot R(\text{U.K.}|0, T)$
When dealing with international investments, how should the excess returns be calculated when moving between countries?	\item $r_P(\text{U.S}) = r_P(\text{U.K}) - r_\text{USD}(\text{U.K}) + \sigma_\text{P, GBP}(\text{USD})$<div>\item so the excess returns on $P$ for a US investor</div><div>\item are the excess returns on $P$ for a UK investor</div><div>\item minus the excess returns on USD for a UK investor</div><div>\item plus the covariance between $P$ and GBP for a US investor</div>
What are BSK and COM in asset allocation?	\item COM is a composite currency<div>\item BSK is the portfolio of currencies that determines the makeup of COM</div>
What's the usual way to take a benchmark timing position in a portfolio?	<div>\item By taking a position in futures contracts for the benchmark</div><div>\item This avoids any risk and transaction costs involved in using stocks to take an active beta</div>
What's a typical range of IC for benchmark timing?	\item $0.05$ to $0.1$
How does gradient descent work?	Gradient descent optimizes the parameters of linear regression equation (y = theta_0 + theta_1*x_1 &nbsp;+ theta_2*x_2 + ... + theta_n *x_n). It finds the minimum of the cost function (like least squares cost) by descending in the direction of the minimum (gradient =0) by finding partial derivatives with respect to each theta and taking steps proportional to the negative of the gradient.
What is a Newton's method of optimization (nonlinear conjugate gradient descent)?	It locally approximates a nonlinear function by quadratic functions, finds it's minimum and moves in that direction to find the minimum of the original function
What is Adagrad?	It is a weight optimization algorithm for neural networks. The intuition behind it is that if the data point is more rare, it's more predictive (like tf/idf). So, if some particular thing produces huge changes in weights, we want to make it more important
What is cross-entropy?	Cross-entropy is a measure of correctness of prediction, e.g. of a neural network. It is computed like this: -( (ln(probability of a class)*0) + (ln(0.3)*1) ) So, it returns how sure was the network about the correct label.
What is bias and variance? What is a tradeoff between them?&nbsp;	"Bias is an error that an algorithm makes from the expected value. High bias results in underfitting (the model is too simple). Variance is error from the sensitivity to small fluctuations (the model is too complex). High variance causes overfitting.<div><img src=""bias-variance_trade-off_1.jpg"" /></div>"
What is a kernel trick and how does it work?&nbsp;	Kernels are similarity functions that are applied to feature vectors. An output of applying a kernel function is an m-dimensional vector, where m is amount of data points in the data set. It returns a desired output for the ground truth data point (0 or 1). Then, parameters theta are learned for each of the outputs (1..m) of the kernel function. Therefore, we can learn non-linear hypothesis.&nbsp;
What are the main steps of Machine Learning	1- Question<div>2- Input Data</div><div>3- Looking for features</div><div>4- Implementing Algorithm</div><div>5- Solving for Alg. parameters</div><div>6- Evaluation</div>
<div>“The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.”</div><div>―John Tukey</div>	
What are the attributes of GOOD features?	1- They could lead to data compression<div>2- Retain relevant information</div><div>3- Created basing on expert info. systems.</div>
Common mistakes that we commit	1- Trying to automate<div>2- Not paying attention to data specific quirks</div><div>3- Throwing info. away.</div>
The best machine Alg. should be?	"<img src=""paste-25778393710593.jpg"" />"
Prediction is about tradeoffs	1- Interpretability vs. Accuarcy<div>2- Speed vs. Accuracy</div><div>3- Simplicity vs. Accuarcy</div><div>4- Scalability vs. Accuarcy</div>
"What is the <font color=""#0000ff"">In-Sample error</font>?"	The error you get on the same dataset that you use to build your model
What is the out of sample error?	"The error you get when you try your algorithm on new data set and it's called <font color=""#0000ff"">Generlization error</font>"
What we are trying to fit, in every dataset? Fitting the {{c1::signal and leaving the noise}} to avoid the overfitting	
What is bad about building high accuracy predictors?	We might end up capturing the noise as well
What are [in general] the steps of prediction study design	1- Define your error rate<div>2- split your data into training and testing</div><div>3- on the training set pick a feature.</div><div>4- Pick a prediction function</div><div>5- Apply one time to the testing set (if there is no validation required)</div><div>6- If it's required apply to test set and refine</div>
Sample preferrable split.	60% training and 40% testing or (20+20) testing and validation
What are the types of errors related to prediction	"1- Positive: Algorithim decided that you are <font color=""#ff0000"">IN</font> the class<div>2- Negative:&nbsp;Algorithim decided that you are <font color=""#ff0000"">NOT</font> IN the class</div><div>3- True: You are actaully <font color=""#ff0000"">IN</font> the class</div><div>4- False You are<font color=""#ff0000""> NOT</font> in the class</div><div><br /></div><div>----------------------------------------------------------------------------------</div><div><img src=""nrneph.2013.281-f1.jpg"" /></div>"
What is the sensitivity?	"The probability of getting positive test&nbsp;person giving actual deseased<div><br /></div><div><i>Pr (Positive Test | Deseased)&nbsp;</i></div><div><i><font color=""#ff0000"">The goodness of our test procedure</font></i></div>"
Specificity?	Pr (Negative test| No desease)
Positive Predictive Value?	Pr (Desease | Positive test)<br />
Negative Predictive Value	Pr (No Desease| Negative test)
"Reciever Operating Charachteristic <font color=""#00007f""><b>ROC Curve</b></font>"	"<div>1- In the prediction you usually give a probability other that 01 answers. (i.e. P( of being alive)). <font color=""#00007f"">Depending on the cutoffs you will get different results.</font></div><div>2- <font color=""#ff0000"">Fall-Out </font>is (1-Specificity) [How many of the cases you are missing]</div><div>3- <font color=""#00007f"">These curves can tell you how good a test can distiguish between a patient and &nbsp;a healthy person for example</font></div><div><br /></div><img src=""paste-20551418511361.jpg"" />"
The area under the ROC curve tells you how good a test in distinguishing between good and bad results.	"<img src=""paste-21406117003265.jpg"" />"
Cross Validation	
What cross validation is used for?	<div>Probably the simplest and most widely used method for estimating prediction</div><div>error is cross-validation.</div>
K-Fold Cross-Validation Process	"<img src=""paste-3474628542465.jpg"" />"
What is the CV approach	"<img src=""paste-1760936591361.jpg"" />"
What are the styles of CV	"1- Random Sampling<div><img src=""paste-2052994367489.jpg"" /></div><div><br /></div><div>2- K-fold sampling</div><div><img src=""paste-2100239007745.jpg"" /></div><div>3- Leave-one-out</div><div><img src=""paste-2168958484481.jpg"" /></div><div><br /></div>"
Some considerations of CV	"<div><img src=""paste-2529735737345.jpg"" /></div>"
"Caret Package <font color=""#ff0000""><b>[How to fit a model?]</b></font>"	"<div><font color=""#0000ff"">set.seed(32343)</font></div><div><font color=""#0000ff"">modelFit &lt;- train(type ~.,data=training, method=""glm"")</font></div>"
SPAM Example: Prediction	<div>predictions &lt;- predict(modelFit,newdata=testing)</div>
Testing the accuracy by using the {{c1::Confusion Matrix}}	<div>confusionMatrix(predictions,testing$type)</div>
Data Slicing and Splitting	"<div>inTrain &lt;- createDataPartition(y=spam$type,p=<font color=""#ff0000"">0.75</font>, list=FALSE) <font color=""#ff0000"">[Example on the splitting ratio you need to implement for the data]</font></div>"
How to create folds using caret package	"<div>folds &lt;- createFolds(y=spam$type,<font color=""#ff0000"">k=10</font>,&nbsp;list=TRUE,returnTrain=FALSE) <font color=""#ff0000"">[Number of folds in the dataset]</font></div>"
How to perfrom resampling in dataset using caret package?	"<img src=""paste-18094697218049.jpg"" />"
What are the metrics to measure the error of the prediction	"<img src=""paste-20435454394369.jpg"" />"
"<img src=""paste-7378753814529.jpg"" />"	This is a detailed review for the caret package
"<div>The {{c1::train}} function can be used to</div><div><br /></div><div>** evaluate, using resampling, the effect of model tuning parameters on performance</div><div>** choose the ""optimal"" model across these parameters</div><div>** estimate model performance from a training set</div>"	
<div>What is the first step in tuning the model?</div><div><br /></div>	- (line 1 in the algorithm above is to choose a set of parameters to evaluate. For example, if fitting a Partial Least Squares (PLS) model, the number of PLS components to evaluate must be specified.<div><br /></div><div><br /></div><div><br /></div>
What is&nbsp;The first step in tuning the model?	"&nbsp;(line 1 in the algorithm above is to choose a set of parameters to evaluate. For example, if fitting a Partial Least Squares (PLS) model, the number of PLS components to evaluate must be specified.<div><br /></div><div><img src=""TrainAlgo.png"" /></div><div><br /></div><div><br /></div>"
Once the model and tuning parameter values have been defined, {{c1::the type of resampling}} should be also be specified.&nbsp;	
"What are the sampling techniques available with <font color=""#ff0000""><u>train</u></font> command in <font color=""#ff0000""><u>caret</u></font> package&nbsp;"	k-fold cross-validation (once or repeated), leave-one-out cross-validation and bootstrap
By default, {{c1::simple bootstrap}} resampling is used the sampling	
What are the pre-process commands can be passed to the train command	1- Centering<div>2- Scaling</div><div>3- NA impute</div><div>4- Spatial sign application</div><div>5- Feature extraction</div>
<div>Two levels of covariate creation</div>	"<img src=""paste-9680856285185.jpg"" />"
Prediction with trees	"<img src=""paste-9865539878913.jpg"" />"
<div>What is the Basic algorithm for prediction with trees?</div>	"<img src=""paste-9968619094017.jpg"" />"
What is&nbsp;monotonic transformation?	"<img src=""paste-10106058047489.jpg"" />"
What are the main steps of Bagging? [Bootstrap Aggregation]	"<img src=""paste-13383118094337.jpg"" />"
Bagging example	"<img src=""paste-13494787244033.jpg"" /><div><img src=""paste-13580686589953.jpg"" /></div>"
Random Forest Steps	"<img src=""paste-13773960118273.jpg"" />"
Naive Bayes<br>	p(y|x1..xN) = p(x1..xN|y)*p(y)/p(x1..xN). The idea is to find the most probable class given all the features. Assumes that each feature is independent which is insane, but works pretty well in some cases. Especially in NLP. Fast. Doesn't need much training data. Don't trust predicted probabilities. Different flavors - Gaussian assumes that the liklihood of features has a gaussian distribution. Multinomial assumes liklihood of features has a multinomial distribution (BOW). Bernoulli is for bivariate features. <br>
Linear Regression<br>	goal is min of squared error E(yi-xi*B). This can be solved by (xTx)^-1(XTy). Assumes independent features. High bias, low variance. If features standardized, beta weights reflect feature importance. <br><br><br>Assumes errors are independent. Constant Variance. Assumes normality of errors, non-stochastic.<br>If assumptions hold. linreg is BLUE - best, linear, unbiased, estimator. (gauss markov theorem)<br>
Ridge Regression<br>	L2. Form of regularization used by GLM models. Penalty for larger beta weight&nbsp; - the l2 norm which is the matrix multiplication of weights. alpha parameter determines strength of regularization. solved by (xTx+alpha*I)xTy. - same complexity of linear regression. Can set alpha with cross validation. Shrinks weights to a hypersphere around 0. Can be thought of as a gaussian prior of 0 for each weight with width of gaussian determined by alpha (narrower as alpha grows).&nbsp; <br>
Lasso Regression<br>	L1. Better for finding sparser beta weight vectors (although does not explicitly gain sparse ones. that would be L0). Adds L1 penalty to least square problem. L1 is sum of absolute values. alpha controls the amount of regularization. Usually uses coordinate descent to fit.&nbsp; <br>
Multi-Task Lasso<br>	Fits a lasso regression model to multiple problems simultaneously. Using multiple y (problems) can move the model closer to ground truth. Uses both L1 and L2. <br>
Elastic Net<br>	Model with L1 and L2. Sparse and reduced weight sizes. Especially useful for correlated features. <br>
Least Angle Regression (LARs)<br>	Good for high dimensional data (especially when more columns than rows). Just as fast as forward selection and has same complexity as linear regression. <br>Based on iterative refitting of residuals, which makes it sensitive to noise. <br>Iteratively fits data at each iteration the beta weights are pushed in the direction of the features correlation with the residuals. <br>
Orthogonal Matching Pursuit<br>	Forward selection algorithm, but approximates the L0 norm, so its trying to find a sparse solution. At each step, includes the feature that is most correlated with the residuals. <br>
Linear Discriminant Analysis<br>	p(y=k|X) = p(X|y=k)*p(y=k)/p(X). Assumes p(X|y) is gaussian. Most bias of classifier algorithms. How does it compare to naive bayes? Assumes all classes share a common covariance matrix (I believe this is how it differs from logistic regression. Check with Hastie though). Can use shrinkage when have a bad feature to sample ratio. <br>
Kernel Ridge Regression<br>	Ridge regression with the kernel trick. Similar to support vector regression but with squared error instead of SVM error. Faster than support vector regression when the dataset is relatively small since this can be solved in closed form. <br>
Support Vector Machines<br>	Effective in high dimensional spaces. <br>Effective when number of features exceeds the number of samples (but not too much)<br>Only uses a subset of training examples to fit the data - memory efficient. <br>Flexible. <br>Does not provide probability estimates. <br>In multi-class classification, uses one against one approach so has to train many models. <br>Quadratic programming problem scales between O(#features*#samples^2) and O(#features*#samples^3).<br>Can use kernel functions to explore non-linear spaces. <br>Use C parameter to regularize. It controls the number of support vectors I think. Check this out in Hastie.<br>
Nearest Neighbor Methods<br>	Find closest K items to a given point. Distance measure should be defined. <br>Highly non-parametric and space required scales linearly with dataset size. <br>In classification, each of K items vote as to which class the given item should be. <br>Can use RadiusNeighorsClassifier too, which counts the number of items in a radius from the given item.Generally chosen when data are relatively uniformly distributed.&nbsp; <br>As K goes up, the model loses flexibility. <br>Other tweaks include weighting items by their distance from the given item.<br>In Regression, the item is assigned to the mean of K. <br>K-D Tree and Ball Tree are methods that try to approximate K-Neighbors but without brute force checking each item in dataset. <br>
Decision Trees<br>	"non-parametric models that predicts target variable from simple decision  rules. Deeper trees = more flexibility. Easy to interpret-boolean  logic. Don't need to normalize data/can handle categorical data (doesn't  care about number magnitude). training is ~O(log(training_points)). Use  ""pruning"" to prevent over-fitting. Not good for unbalanced classes. Hard to find the global minimum of the model. <br>Likely to overfit when many features. <br># of samples needed to populate the tree doubles for each extra depth<br>Increasing leaf size increases bias"
Ensemble Models<br>	Combine predictions of multiple models. Generally improves generalizability of models.<br>Averaging methods average predictions of multiple models (bagging). These methods improve generalizability, so used to reduce overfitting. This works best with models that tend to overfit (full decision trees). <br>Boosting Methods - models are built sequentially and the goal is to reduce the bias of previous models. Works best with models that tend to underfit (shallow decision trees). <br>
Bagging Methods<br>	Used to improve generalizability, so best with models that often overfit data (deep decision trees). <br>The idea is to average the prediction of multiple models. <br>Draw random samples from the data and feat a model to each random sample of the data. Typically sampling is done with replacement. <br>
Random Forests<br>	Bagging method special for trees. <br>Each tree is built by sampling data with replacement. Also, when splitting nodes, the split chosen is not the best split among all features, is the best split given a random subset of features. This increases model bias,&nbsp; but averaging of the models makes up for the flexibility. <br>Paramters = number of trees (more trees = better but expensive) and max_features (number of features to use when splitting nodes, less features is more bias). <br>Cross-validate with out of bag score. <br>
Feature Importance in Random Forests<br>	The rank (i.e., depth) of a feature in decision nodes roughly reflects its importance. Features at the top of the tree are more important. <br>Thus, the fraction of samples they control is their relative importance. <br>Averaging this fraction of samples across trees reduces variance in predictions. <br>
AdaBoost	Based on the idea of fitting a sequence of weak learners (models that are only slightly better than random) on modified versions of data. Predictions are then combined as weighted majority vote. <br>So what do I mean by modified versions of data!? At first, the weight of each training sample is 1/N, but the weighting changes such samples that previous models missed are more important when creating the future models (and vice versa). The idea is future models concentrate on examples that were missed by previous ones. <br>Paramters = number of estimators (number of models) and learning rate (how final models weighted in final combination). <br>Weak Learners are usually decision stumps, but can make more complex. <br>
Gradient [Tree] Boosting<br>	Boosting for arbitrary loss functions. <br>Can handle mixed data types, great off the shelf, robust to outliers, but suffers with scalability (have to train models sequentially). <br>Parameters = n_estimators (number of trees), max_depth (depth of trees), and max_leaf_nodes (how many leaf nodes), and learning rate. <br>Can handle interactions up to the level of the tree depth. <br>Shrinkage (learning rate) used to reduce overfitting.Smaller learning rate means each new model contributes less to the decisions, and these more specialized (more flexible) models contribute less to flexibility. <br>Can choose n_estimators with early stopping, but this interacts with learning rate - lower learning rate requires more estimators. <br>
Feature Selection<br>	"*Variance threshold - remove feature with variance &lt; x. <br>*Univariate selection - select the K ""best"" features where best could be association with target (assumes no interactions). <br>*Recursive Feature Elimination - remove features whose weights are less than some threshold. <br>*Forward selection algorithms (Least Angle Regression), <br>"
Label Propagation<br>	Semi-supervised method for generalizing labels of known data to unknown data. <br>Clamping parameter basically controls how much we trust the labeled data (can we consider that some are labeled incorrectly?)<br>Assumes that we have a good spatial sense of the data (similar labeled items appear near each other in our new space).<br>
Gaussian Mixture Modeling<br>	Fit through Expectation Maximization - basically assign labels then find mean of different labels. <br>Assumes data generated from a mixture of gaussians. Similar to K-means, but with information about covariance structure of data. <br>Can use BIC to estimate the optimal number of clusters. <br>Covariance can be: spherical - same amount of variance in each direction (K-means), diagonal - different features have different amounts of variance across clusters (only constraint is all variance assumed independent), full - no constraints (so can have correlated variance), tied - all clusters have same variance. <br>
Variational Bayesian Gaussian Mixture<br>	Maximizes lower bound on model evidence rather than data likelihood. <br>Uses EM algorithm, but adds regularization by using priors. <br>Concentration parameter controls how likely the model is to find more or less components (low value=few components). <br>Components modeled as from a dirichlet process. <br>Slower than GMM, but lets the model have more input in how many components to select.<br>
Isomap<br>	(Isometric Mapping). Form of manifold learning. Extension of Multi-Dimensional Scaling or Kernel PCA. Seeks a lower dimensional embedding that maintains geodesic distances between points. <br>Complexity is &gt;O(N**2)<br>
Locally Linear Embedding<br>	Basically a series of local PCAs which are combined for a global non-linear embedding. <br>Complexity &gt;O(N**2)<br>Regularization is a problem when the number of neighbors is greater than input dimensions - rank deficiency. Modified LLE designed to combat this. <br>
Multi-Dimensional Scaling<br>	Used for similarity/dissimilarity data (in general) and models this as distances. <br>Comes in two flavors. Metric - tries to maintain actual distances and nonmetric which tries to maintain the rank of data rather than distances - x is closer to y than z. <br>
t-SNE	t-distributed Stochastic Neighbor Embedding. <br>Probably the most popular. <br>Treats affinities of data points as probabilities. <br>Focuses on local clusters which is nice when the data is comprised of multiple manifolds.<br>KL divergence of joint probabilities in original and embedded space minimized by gradient descent - not convex so different starts/restarts get different answers. <br>Parameters = perplexity - number of local neighbors to consider in algorithm (more neighbors = more linear bias), learning rate, iterations, angle (again whether to emphasize local or global structure). <br>
K-Means	Separates data into K groups with equal variance. <br>Minimizes the within cluster sum of squares (distance from mean of cluster). <br>Assumes spherical clusters. <br>Relies on distance measures, so curse of dimensionality can be a problem. <br>Uses a simplified EM algorithm. <br>Nonconvex, so multiple starts needed. <br><br>
Affinity Propagation<br>	Send messages between pairs of items asking how similar pairs of items are. Ends when a key number of exemplar items are chosen. These are the cluster centers. <br>Chooses number of clusters itself. <br>Preference parameter controls how many clusters are created. <br>O(N**2*T) where T is number of iterations. Memory complexity is O(N**2). <br><br>
Hierarchical Clustering<br>	Family of clustering methods that build nested clusters. Either merges or splits clusters depending on method. <br>Heirarchy of clusters are a tree (root has all data). <br>Leaves only have one item. <br>Agglomerative Clustering means start from bottom up. <br>Ward minimizes sum of squared differences within all clusters. <br>Linkage methods minimize the distance between pairs of clusters. <br>Uses distance metrics. <br>
DBSCAN<br>	Models data as areas of high density (core samples) separated by areas of low density (non-core samples). <br>This is a highly flexible model. <br>min_samples governs number of points needed to find a set of core samples (a cluster). eps is the maximum distance between these core samples. <br><br><br>
Silhouette Score<br>	Used for testing unsupervised models. Compares mean distance between a sample and all samples in same cluster to the mean distance between a sample and all samples in the next nearest cluster. <br>Bound between -1 and 1. 1 is the goal. <br>Works better for spherical clustering methods. <br>
Calinski-Harabaz Index<br>	ratio of between cluster and within cluster dispersion. <br>Basically distance of items from the center of their cluster compared to the distance of cluster centers from center of data. BD/WD so higher score is better. <br>Again, better for methods assuming spherical clusters. <br>
PCA	Decompose dataset into orthogonal components.<br>Whiten z-scores data. <br>SKlearn includes a method for estimating the number of meaningful components. <br>Finds eigenvectors with largest magnitude eigenvalues. <br>
Kernel PCA<br>	Similar to PCA but attempts to find non-linear explanations of data. <br>Throws data through Kernel then performs PCA. How the Kernel is chosen....?<br>
Singular Value Decomposition<br>	Similar to PCA (square roots of eigenvalues are singular values). For finding orthonormal basis (independent factors). Easier to compute than PCA. <br>
ICA	Separates multivariate signal into (maximally) independent additive subcomponents.<br>Idea is to separate superimposed signals. <br>Whiten before using!<br>Can also be used for dimensionality reduction... not too complex so I should add to this. <br>
Matrix Factorization<br>	For matrix with non-negative values, can be used to find lower dimensionality representation. <br>minimizes 1/2E(X-WH)**2. Expand this!<br>
Latent Dirichlet Allocation<br>	Generative probabilistic model for collections of discrete data. <br>Topic Modeling...<br>Draw the topic from Dirichlet(n) for each topic. <br>For each document draw from a dirichlet(alpha). For each word in a document, draw a topic from a multinomial and draw a word from a multinomal governed by the output of the topic dirichlet.<br><br>p(topic, document,and words in a topic | word, topic distribution, and document distribution).&nbsp; <br>
Novelty Detection<br>	Comparing new datum to existing data (assuming that existing data does not have outliers) and compute probability of this new datum arising from same generator as previous data. <br><br>One class SVM often used. RBF is common kernel (gaussian data). <br>
Outlier Detection<br>	Similar to Novelty Detection, but does not presuppose clean start data. <br><br>Goal is to separate data produced by desired generator from data generated by...something else. <br><br>One way to do this is to fit a gaussian to central mode and assume other data generated by a noise process. Then estimate mahalanobis distance (how many standard deviations from data). <br><br>Isolation Forest can estimate outliers. This counts the number of splits between max and min in order to isolate feature. Basically, does an item tend to be eccentric. Especially useful when data generated by multiple processes (bimodal).&nbsp; <br>
Kernel Density Estimation<br>	Histogram is simplest form. <br><br>Can think of it as Kernel Smoothing. Applying a gaussian kernel to histogram of data. <br><br>Bandwith of kernel determines bias flexibility trade-off. With wider kernel smoothing the data more and giving more bias. <br><br>Many different kernels available. <br>
Overfitting	Model fits both generating process and additional noise...the model will not generalize well to future data because this data shares generating process but not noise. <br>
Underfitting	"Each model assumes a generative process underlies the data, and this assumption is virtually always wrong. The question is how wrong is this assumption. In the case of linear regression, if the data are not a linear projection of the inputs than this assumption can be very wrong, but the model can't ""learn"" this. The model's ""bias"" insists on its generative process. <br>"
Cross Validation<br>	Splitting the data K times and training K models. We can then look at variability in test set predictions and average model ability. <br><br>Can use to fit hyper parameters, but always use hold out data!! Remember pre-processing is basically a hyper parameter. <br>
Grid Search<br>	"Algorithm for identifying optimal hyper parameters (remember test set data!!). Exhaustive is trying every possible value in some range of step size x. This is fine, but random hyper parameter values tends to work better. It isn't hurt by adding parameters, can help with finding the distrubition of loss amounts given hyper parameters. <br><br>Obviously picking the ""accuracy"" or desired outcome is important and accuracy isn't always best. <br>"
Precision and Recall<br>	Precision is false positive rate. Recall is false negative rate. <br>
Hinge Loss<br>	Loss function used by SVM, only considers items where the model guess incorrectly. <br>
Log Loss<br>	Used by logistic regression and neural nets. sum(y*log(p)). We use logs because we like addition and we don't want numerical underflow. <br><br>
Matthews Correlation Coefficient<br>	Correlation for binary classes<br>
ROC	graphical plot depicting performance as decision threshold varies. Plots fraction of true positives vs fraction of false positives. <br>
F1 Score<br>	Measure of both precision and recall 2*(precision*recall)/(precision + recall)<br>
Explained Variance<br>	1-(variance y-y_hat)/variance(y)<br>
Mean Square and Mean absolute error<br>	sum(y_i-y_hat_i)**2 (or just absolute value)<br>
R**2	(y_i-y_hat_i)**2/(y_i-y_bar_i)**2
One-hot encoding<br>	Binary transformation of categorical variables. One column for each unique value in the category. <br>
BOW	Each distinct word in corpus has column. Number of times that word appears in sample is the value of that words column. If bi-grams then each distinct pair of words has a column...ect. <br>
Tf-idf<br>	term frequency, inverse document frequency. <br><br>algorithm for down weighting frequent words in a corpus. the value is term_frequency (# times in document)&nbsp; * 1+ log(1+total_document_#)/(1+#_docs_with_term). this multiplier term is then normalized by the euclidean norm. <br>
Min-Max Scaling<br>	Scales all data between 0 and 1 by subtracting minimum and dividing by the max. <br>
Normalization	subtract mean and divide by standard deviation. Goal is to end with mean of 0 and standard deviation of 1. <br>
Feature Binarization<br>	Thresholding feature and putting everything above as 1 and below as 0 (or vice versa)<br>
Polynomial Features<br>	Linear models can fit non-linear data if the data are projected into a non-linear space. An example of this is squaring input features or any other non-linear transformation<br>
Missing Values<br>	We often want to replace missing values rather than throwing away the same point. <br><br>How do we replace the missing value without making too strong of an assumption about what the value would be in this place? Often replace with mean, median, or mode. <br>
Random Projections<br>	Using random matrices you can dramatically reduce the dimensionality of data while largely maintaining the distance between points. I don't understand how this works...<br>
Cosine Similarity<br>	L2 normalized dot product of vectors. Called cosine because L2 normalization projects vectors onto a unit sphere. This then becomes the cosine of the angle between points denoted by the vectors. <br><br><br>
Radial Basis Function<br>	exp(sigma**-||x-y||**2). x and y are input vectors and sigma is a gaussian kernel with variance sigma. <br>
Bayes Theorem<br>	p(A|B) = (p(B|A)*p(A))/p(B).<br><br>Often hardest part is finding p(B). The goal is to add different conditions of P(B|A) together. <br>
Maximum Likelihood Estimtion<br>	Maximize (or minimize) log-likelihood sum(log(p(x_i | theta).&nbsp; <br>
Central Limit Theorem<br>	(1/sqrt(N))*sum(x_i-mu) ----&gt; as n goes to infinity ---&gt; N(0,sigma**2)<br>
p-value<br>	Probability that we could observe this effect under the null-hypothesis. <br>
How to test difference in proportion<br>	z-statistic - normalize and see how many standard deviations away from expected effect. <br>
Testing regression coefficients<br>	t-statistic
Goodness of fit<br>	Chi**2 statistic<br>
ANOVA	F-statistic. <br>Used for testing differences in categorically defined data. FactorsxLevels. Equivalent to regression wtih dummy variables. between group SSE / within group SSE is the key here. <br>
Contingency Table<br>	Chi**2 statistic<br>
Model Comparison<br>	F-statistic
QQ plot<br>	quantile, quantile plot. Can use to visualize similarity of distributions. Very useful when visualizing normality of errors<br>
Wilcoxon Rank-Sum Test<br>	Between group, pairwise, nonparametric test. <br>
Sign Rank Test<br>	within group, pairwise, non-parametric comparison<br>
Kruskal-Wallis<br>	Non-parametric between group anova (similar to wilcoxon) <br>
NLP Pipeline<br>	tokenization, stemming, lemmatization, remove stop words, remove punctiuation, BOW/tf-idf, n-gram, word embeddings<br>
word2vec	neural network trained embedding that seeks to guess word by its context (or vice versa) which basically means learning the conditional word probabilities, but in a smaller space. Produces embedding that seems to carry information about word meaning - the difference between king and queen is similar to man and woman. <br>
Bootstrap	Basically non-parametric confidence interval estimation. The idea is repeatedly sample subsets of the data and perform the analysis (find mean/run classifier/whatever). By looking at the distribution of scores from this analysis on sampled data, we can get an idea of the variability. I typically then try to come up with a null distribution to compare my bootstrapped distribution to. <br>
Jack-Knife	Similar to boot-strap, but the subsets are of size n-1 and there are n subsets (so run the analysis once for every sample and leaving that sample out). Works well when not much data, but I wouldn't use it except for extreme circumstances. <br>
Kolmogrov Smirnov Test<br>	Test for evaluating whether a sample is not normal. Critical for looking at regression residuals, data before t-tests, ect. Basically use it all the time. <br>
Power Analysis<br>	If we assume we have effect size x with a chosen alpha and beta (power) value, we can then estimate how many samples we will need. The key here is we want to maximize the probability of finding an effect (power) and really the only way we can change this is sample size. We can also kinda change effect size, but less so. Also practicality of small effect sizes should be taken into account. Does the business model care about the size of the effect? People like to use g power. <br>
Neural Networks<br>	"Family of models. Segmented function approximators. Basically operate by doing a series of logistic regressions on the data. The hardest part of them is how to train the models. They have a ton of parameters (need tons of data) and have a segmented series of layers, which the error signal has to be pass-backed through. People ""back propograte the errors."" <br><br>All training is done in stochastic gradient descent because the optimization problem is non-convex. <br>It's actually a super weird problem. Turns out local minima are not really the problem. Saddle points are harder to traverse. For this reason, people have assigned a number of backprop techniques that try to give the loss function ""momentum."" Really interesting stuff. <br><br>Largely thought of as local pattern matching. <br><br>Great for image recognition - convolutional neural nets. <br>Getting better at language. <br>Turing complete, so can solve any problem. The question is more how to direct the learning of the model - convolutional layers constrain learning towards a solution we know is better for visual problems. Recurrent nets contrain learning towards solutions we believe better for sequential inputs. All these models could be implemented as fully connected, but we direct the model towards better solutions.<br><br>Can also regularize the models. Dropout is super useful. Helps the model learn sparser solutions, which also tend to be more generalizable. L2 regularization of weights is also relatively common, but dropout is so successful and dead simple that people use it. <br>"
Binomial	Distribution of bernoulli (yes/no) trials. <br>Parameters are n (trials) and p (probability of success). <br>Mean is n*p. <br>Variance is np(1-p)<br>
Poisson	Exponential but variance equals the mean. <br>Discrete probability distribution. <br>Probability of a given number of events over a fixed interval of time. <br><br>
Gaussian<br>	Normal distribution. Mean is mu. Variance is sigma squared. <br>The pdf is (1/sqrt(2*pi*sigma**2))*e**(-(x-mu)**2/2*sigma**2)<br>The mode, median, and mean are all the same. <br>
Bernoulli	Special case of binomial, but with a single trial. <br><br>
Beta Distribution<br>	Conjugate of prior distribution of binomial distribution. <br>Continuous in the interval between 0 and 1. So great for representing probabilities.<br>Controlled by parameters alpha and beta. <br>mean = alpha/(alpha+beta)<br>variance = (alpha*beta)/((alpha+beta+1)*(alpha+beta)**2)<br>
Collaborative Filtering<br>	Basic idea is if two people agree on one issue, they are more likely than chance to agree on another issue. <br><br>The idea is that I have a matrix of users by products and I want to find a user embedding and a product embedding which when matrix multiplied can replicate the original matrix. The great part about this isn't the parts of the matrix that are replicated, but its the previously empty cells that now have a user x product prediction in them. <br><br>The hard part about this is coming up with the embedding matrices, but this can be trained through gradient descent. It's basically a simple autoencoder. You would train the net by creating two embedding matrices. Dot multiplying them and comparing to original matrix. Can validate by leaving some data out and then checking whether the model was correct regarding this data.<br><br>
Sufficient statistic condition	Neccessary and sufficient condition for [$$]t(x)[/$$] to be sufficient for [$$]p(x|\theta)[/$$] is that [$$]p(x|\theta) = f(t(x),\theta)g(x)[/$$]. This extends to any number of parameters and statistics.
Posterior given x and given sufficient statistic t(x)	Posteriors are the same for any prior distribution!
Exponential family definition	A density [$$]p(x|\theta)[/$$] which can be written in the form&nbsp;<div>[$$]p(x|\theta) = exp\{t(x)\phi(\theta)\}G(\theta)H(x)[/$$], where&nbsp;</div><div>[$$]\{G(\theta)\}^{-1} = \int_X \exp\{t(x)\phi(\theta)\}H(x)dx[/$$],</div><div>is called exponential family. The function [$$]\phi(\theta)[/$$] is called natural parameter.</div>
Given random sample from fixed density [$$]p(x|\theta)[/$$], a family [$$]\mathcal{F}[/$$] of distributions over [$$]\theta[/$$] is closed under sampling wrt&nbsp;[$$]p(x|\theta)[/$$] iff for ANY sample...	[$$]p(\theta) \in \mathcal{F} \Rightarrow p(\theta|x) \in \mathcal{F}[/$$]<div>This is equal to saying [$$]\mathcal{F}[/$$] is a conjugate prior for [$$]p(x|\theta)[/$$]&nbsp;</div>
Conjugate prior of exponential family and corresponding posterior	If&nbsp;[$$]p(x|\theta)[/$$] is exponential family, then<div>[$$]p(\theta) \propto \exp\{a\psi(\theta)\}G(\theta)^b[/$$]</div><div>is conjugate prior with posterior</div><div>[$$]p(\theta|x) \propto \exp\{\psi(\theta)(\sum t(x_i) + a)\}G(\theta)^{n+b}[/$$]</div>
Posterior given likelihood [$$]x \sim No(\theta, \epsilon)[/$$] with known precision [$$]\epsilon[/$$] and prior [$$]\theta \sim No(\mu_0, \epsilon_0)[/$$] for n samples [$$]x_i[/$$]	[$$]p(\theta|\underline{x}) \sim No(\frac{n \epsilon \hat{x} + \epsilon_0 \mu_0}{n \epsilon + \epsilon_0}, n \epsilon + \epsilon_0)[/$$]<div>Posterior precision = n * Data + prior precision</div><div>Posterior mean: Weighted average of prior mean [$$]\mu_0[/$$] and data mean [$$]\hat{x}[/$$] with weights equal to the weighted precisions</div>
Posterior of normal with known mean 0 (subtract mean from data if its non-zero).<div>If [$$]x_i \sim No(0, \epsilon)[/$$] and [$$]\epsilon \sim Ga(\alpha / 2, \beta / 2)[/$$] then</div>	[$$]p(\epsilon|x) = Ga((\alpha + n)/2, (\beta + \sum x^2_i)/2)[/$$]
Posterior given normal likelihood with unknown mean [$$]\mu[/$$], precision [$$]\epsilon[/$$]	TODO
Mixtures of/compound priors of exponential families with density [$$]p(x|\theta)[/$$]	Prior [$$]p(\theta) = \alpha p_1(\theta) + \beta p_2(\theta)[/$$] with [$$]p_1(\theta)[/$$] and&nbsp;[$$]p_2(\theta)[/$$] conjugate priors and [$$]\alpha + \beta = 1[/$$]. Then posterior is&nbsp;<div>[$$]p(\theta|\underline{x}) = \alpha'p_1(\theta|\underline{x}) + \beta'p_2(\theta|\underline{x})[/$$]</div><div>with [$$]\alpha' + \beta' = 1, \alpha' = \frac{\alpha p_1(\underline{x})}{\alpha p_1(\underline{x}) + \beta p_2(\underline{x})}, p_i(\theta|\underline{x}) = \frac{p(\underline{x}|\theta)p_i(\theta)}{p_i(\underline{x})}[/$$]</div>
Jeffreys Prior.&nbsp;With random sample X from density&nbsp;[$$]p(x|\phi)[/$$], we choose the prior as	[$$]\pi(\phi) \propto h(\phi)^\frac{1}{2}[/$$] where<div>[$$] h(\phi) = - \int_X p(x|\phi) \frac{\Delta^2}{\Delta \phi^2} \log p(x|\phi) dx[latex][/latex][/$$]</div>
Predictive distribution	With [$$]x_1, \ldots, x_n[/$$] and [$$]y[/$$] as random samples from distribution [$$]p(x|\theta)[/$$] and prior [$$]p(\theta)[/$$], predictive distribution is<div>[$$]p(y|x) = \int p(y|\theta, x)p(\theta|x) d\theta[/$$]</div><div>[$$]= \int p(y|\theta)p(\theta|x)d\theta[/$$]</div>
Prior predictive/marginal likelihood	A predictive distribution based on a prior rather than a posterior: Parameters [$$]\theta[/$$] of likelihood have been integrated out (marginalised) so that resulting distribution depends only on prior parameters:<div>[$$]p(\underline{x}) = \int p(\underline{x}|\theta)p(\theta) d\theta[/$$]</div>
Implementing parameter constraints	Two equivalent ways<div>1. Integrate into posterior: With [$$]\Omega[/$$] as unconstrained parameter space of [$$]\theta[/$$] and constraint [$$]C: \theta \in \Omega_C[/$$] it follows that&nbsp;<div>[$$]p(\theta|C,x) = p(\theta|x) \frac{Pr[C|\theta, x]}{Pr[C|x]}[/$$]</div><div>2. Build into prior [$$]p(\theta)[/$$]</div></div>
Bayes estimate	<div>Point estimation of posterior according to loss function:</div>[$$]argmin_t \int l(t,\theta)p(\theta|\underline{x})d\theta[/$$]<div>t is Bayes estimate</div>
Bayes estimates for squared and absolute error loss	For [$$]l(t,\theta)=(t-\theta)^2[/$$], Bayes estimate is [$$]t = E[\theta|x][/$$]<div>For [$$]l(t,\theta)=|t-\theta|[/$$], Bayes estimate is the posterior median</div>
Credible interval (a,b) for [$$]\theta[/$$] given posterior [$$]p(\theta|x)[/$$]	(a,b) is a [$$]100 \cdot (1-\alpha)\%[/$$] credible interval for [$$]\theta[/$$] if<div>[$$]\int_a^b p(\theta|\underline{x})d\theta = 1-\alpha[/$$]</div><div>Also called Bayesian confidence interval</div>
Highest posterior density interval (HPD)	(a,b) is a [$$]100 \cdot (1-\alpha)\%[/$$] HPD interval if (a,b) is a&nbsp;[$$]100 \cdot (1-\alpha)\%[/$$]&nbsp;credible interval and [$$]p(a|\underline{x}) = p(b|\underline{x})[/$$]<div>Multimodal posterior: HPD can be union of multiple intervals!</div>
Bayes factor for hypotheses [$$]H_0, H_1[/$$]	<div>Ratio of marginal likelihoods. If [$$]H_0[/$$] and [$$]H_1[/$$] have support over the parameter intervals [$$]\theta_0, \theta_1[/$$], then the factor is</div><div>[$$]\frac{\int_{\theta \in \theta_0} p(\underline{x}|\theta) p_0(\theta) d\theta}{\int_{\theta \in \theta_1} p(\underline{x}|\theta) p_1(\theta) d\theta}[/$$]</div>
Interpretation of Bayes factor values	B &gt; 1: supports H0<div>B &gt; [$$]10^{-\frac{1}{2}}[/$$]: slight evidence against H0</div><div>B &gt; [$$]10^{-1}[/$$]: moderate evidence against H0</div><div>B &gt; [$$]10^{-2}[/$$]: strong evidence against H0</div><div>B &lt; [$$]10^{-2}[/$$]: decisive evidence against H0</div>
Handling nuisance parameters	If [$$]\theta_1[/$$] are parameters of interest,&nbsp;[$$]\theta_2[/$$] nuisance parameters, just integrate out&nbsp;[$$]\theta_2[/$$]:<div>[$$]p(\theta_1|\underline{x}) = \int p(\theta_1|\theta_2, \underline{x})p(\theta_2|\underline{x})d\theta_2[/$$]</div>
Linear model definition	With [$$]\underline{y}[/$$] vector of n observations, [$$]E[\underline{y}|\underline{\theta}]&nbsp;[/$$] &nbsp;vector of p parameters, A as known n x p design matrix, and n x n dispersion Matrix C ([$$]C^{-1}[/$$] is precision matrix):<div>[$$]E[\underline{y}|\underline{\theta}] = A\underline{\theta}[/$$]<div>[$$]E[\underline{y}|\underline{\theta}] = \int \underline{y} p(\underline{y}|\underline{\theta}) d\underline{\theta}[/$$]</div></div>
Multivariate normal density function	n-dimensional observations y with mean [$$]E[\underline{y}] = \underline{\mu}[/$$] and variance-covariance/dispersion matrix [$$]V = (\underline{y} -&nbsp;\underline{\mu})(\underline{y} -&nbsp;\underline{\mu})^T[/$$] if density is<div>[$$]p(\underline{y}|\underline{\mu},\underline{V})=\frac{1}{\sqrt{(2\pi)^n |V|}} \exp\{(-\frac{1}{2}(\underline{y}-\underline{\mu})^T V^{-1} (\underline{y} -&nbsp;\underline{\mu})\}[/$$]</div><div>[$$]|V|[/$$] is determinant of [$$]V[/$$]</div>
Linear model with uniform prior	With [$$]\underline{\mu} = A\underline{\theta}, V=C[/$$] (A, C known):<div>[$$]p(\underline{y}|\underline{\theta}) \propto \exp \{(-\frac{1}{2}(\underline{y} - A\underline{\theta})^T C^{-1} (\underline{y} - A\underline{\theta}) \}[/$$]</div><div>With least squares estimator [$$]\hat{\underline{\theta}} =&nbsp;(A^T C^{-1} A)^{-1} A^T C^{-1} \underline{y}[/$$] this becomes</div><div>[$$]p(\underline{y}|\underline{\theta}) \propto \exp \{ (-\frac{1}{2}((\underline{\theta} - \hat{\underline{\theta}}) A^T C^{-1} A (\underline{\theta} - \hat{\underline{\theta}}) \}[/$$]</div><div>With uniform prior, [$$]p(\underline{\theta}|\underline{y}) \propto p(\underline{y}|\underline{\theta})[/$$], so posterior of [$$]\underline{\theta}[/$$] is a normal density with mean [$$]\hat{\underline{\theta}}[/$$] and dispersion matrix [$$](A^T C^{-1} A)^{-1}[/$$]</div>
Two stage linear model definition	[$$]\underline{y}|\underline{\theta_1} \sim N(A_1&nbsp;\underline{\theta_1}, C_1)[/$$]<div>where [$$]A_1, C_1[/$$] are known, and a normal prior</div><div>[$$]\underline{\theta_1} \sim N(\underline{\mu}, C_2)[/$$]</div><div>where [$$]\underline{\mu}, C_2[/$$] are known.</div>
Lindley-Smith theorem	Given a two stage linear model, the posterior of [$$]\underline{\theta_1}[/$$] is [$$]N(B\underline{b}, B)[/$$] where<div>[$$]B^{-1} = A_1^T C_1^{-1} A_1 + C_2^{-1}[/$$]</div><div>[$$]\underline{b} = A_1^T C_1^{-1} \underline{y} + C_2^{-1}&nbsp;\underline{\mu}[/$$]</div><div>Marginal distribution of [$$]\underline{y}[/$$] is [$$]N(A_1&nbsp;\underline{\mu}, C_1 + A_1 C_2 A_1^T)[/$$]</div><div>Least-squares estimate of [$$]\underline{\theta_1}[/$$] is [$$](A_1^TC_1^{-1}A_1)^{-1} A_1^TC_1^{-1}\underline{y}[/$$]</div>
Matrix lemma	For any matrices [$$]A_1, C_1, C_2[/$$] of appropriate dimensions for which the inverses as stated in the result exist we have<div>[$$]C_1^{-1} - C_1^{-1}A_1(A_1^TC_1^{-1} A_1 + C_2^{-1})^{-1}A_1^T C_1^{-1} = (C_1 + A_1 C_2 A_1^T)^{-1}[/$$]</div>
Three stage linear model	With [$$]A_1, A_2, C_1, C_2, C_3,&nbsp;\underline{\mu}[/$$] known:<div>[$$]&nbsp;\underline{y} |&nbsp;\underline{\theta_1} \sim N(A_1&nbsp;\underline{\theta_1}, C_1)[/$$]</div><div>[$$]&nbsp;\underline{\theta_1} |&nbsp;\underline{\theta_2} \sim N(A_2 \underline{\theta_2}, C_2)[/$$]</div><div>[$$]&nbsp;\underline{\theta_2} \sim N(\underline{\mu}, C_3)[/$$]</div>
Posterior of [$$]\underline{\theta_1}|\underline{y}[/$$] for three stage linear model	[$$]N(D\underline{d}, D)[/$$] with<div>[$$]D^{-1} = A_1^T C_1^{-1} A_1 + (C_2 + A_2 C_3 A_2^T)^{-1}[/$$]</div><div>[$$]\underline{d} = A_1^T C_1^{-1}&nbsp;\underline{y} + (C_2 + A_2 C_3 A_2^T)^{-1} A_2&nbsp;\underline{\mu}[/$$]</div>
Lemma on the inverse of a certain sort of patterned matrix	[$$] (a I_n + b J_n)^{-1} = \frac{1}{a} I_n - \frac{b}{(a+nb)a} J_n[/$$]<div>for [$$]a &gt; 0, b \neq -(a/n)[/$$], where [$$]I_n[/$$] is [$$]n \times n[/$$] identity matrix and [$$]J_n[/$$] a [$$]n \times n[/$$] matrix of ones</div>
Exchangeability assumption	Given data points [$$]y_i \sim N(\theta_i, \sigma^2)[/$$], exchangeability assumes that our beliefs about the different [$$]\theta_i[/$$] are the same, thus from a common distribution.<div>If we think this common distribution is normal ([$$]\theta_i \sim N(\mu, C_2)[/$$]), we end up with two stage linear model.</div>
Taylor approximation of function [$$]f(x)[/$$] at point a	[$$]Tf(x; a) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!} (x - a)^n[/$$]
Posterior approximation with Taylor approximation	Assuming posterior [$$]p(\theta|y)[/$$] is unimodal and roughly symmetric, we can approximate it with a normal centred at its mode [$$]\hat{\theta}[/$$] with Taylor expansion of [$$]\log p(\theta|y)[/$$] at point [$$]\hat{\theta}[/$$]:<div>[$$] \log p(\theta|y) = \log p(\hat{\theta}|y) + (\theta - \hat{\theta}) [ \frac{d}{d\theta} \log p(\theta|y) ]_{\theta=\hat{\theta}} + \frac{1}{2}(\theta - \hat{\theta})^2&nbsp;[ \frac{d^2}{d\theta^2} \log p(\theta|y) ]_{\theta=\hat{\theta}} + \ldots [/$$]</div><div>Ignoring higher-order terms and noting that first derivative is 0, we have</div><div>[$$]p(\theta|y) \approx c \cdot \exp \{-\frac{1}{2}I(\hat{\theta}) (\theta-\hat{\theta})^2 \}[/$$] with</div><div>[$$]I(\theta) =&nbsp;[- \frac{d^2}{d\theta^2} \log p(\theta|y) ] [/$$]</div><div>Thus posterior is approximated with normal with mean [$$]\hat{\theta}[/$$] and variance [$$]I(\hat{\theta})^{-1}[/$$]</div>
Gibbs sampling with model with likelihood [$$]p(\underline{x}|\theta,\delta,\phi)[/$$] and prior [$$]p(\theta,\delta,\phi)[/$$]	Based on MCMC,which builds a Markov Chain so that the distribution of sampled values in the chain tends towards the actual one.<div>Gibbs sampling: We only need to find a way to split the variables of interest into groups so that we can sample from the conditional distribution of each given all others: [$$]p(\theta|\delta,\phi,\underline{x}), p(\delta|\phi,\theta,\underline{x}), p(\phi|\theta,\delta,\underline{x})[/$$]</div><div>Algorithm:</div><div>1. Choose initial estimates [$$]\theta_0, \delta_0, \phi_0[/$$]</div><div>2. Given current estimates, simulate new values</div><div>3. Return to step 2</div><div>Often burn-in of length L to remove dependency on initial values, and take every K samples after that to reduce serial correlation effects.</div><div>Posterior mean/median/HPD can be determined based on sample.</div><div>Kernel density estimation can give us smooth approximation to this sample.</div><div>Predictive density of new observation y can be estimated by averaging [$$]P(y|\theta_i,\delta_i,\phi_i)[/$$] over samples i</div>
Constraints on parameters in Gibbs sampling	Can always use rejection sampling technique: Pick initial values so that constraints are fulfilled, then when sampling from the conditionals, resample repeatedly until the sample fulfils the constraints. This may need many simulations. More efficient to sample directly from an appropriately constrained distribution if available
Handling missing data in Gibbs sampling	Treat missing data as extra set of parameters: If we knew missing data, we can simulate from conditional distribution of parameters and vice versa. Therefore introduce conditional distribution for missing data given parameters and perform normal Gibbs sampling.
Standard normal and conversion to standard normal	Standard normal CDF:<div>[$$]\Phi(z) =&nbsp;\int_{-\infty}^z&nbsp;\frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}t^2}dt[/$$]</div><div><div>Conversion: Let X be a normal with mean [$$]\mu[/$$], standard deviation [$$]\sigma[/$$]. Then:</div></div><div>[$$]F_x(x) = Pr(X \leq x) = Pr(Z \leq \frac{x-\mu}{\sigma})[/$$]</div>
Gamma function definition	[$$]\Gamma(n) = (n-1)![/$$]
Expectation and properties	[$$]E[g(X)] = \int_{-\infty}^{\infty} g(x)p(x)dx[/$$]<div>Montonicity: If X and Y are RVs so that [$$]X \leq Y[/$$] then [$$]E[X] \leq E[Y][/$$]</div><div>Linearity: [$$]E[X+Y] = E[X] + E[Y], E[aX] = aE[X][/$$]</div>
Covariance	[$$]\sigma_{XY} := E[(X-E(X))(Y-E(Y))] = E[XY] - E[X]E[Y][/$$]
Variance and properties	[$$]Var(X) = \sigma_x^2 = E[(X-E[X])^2][/$$]<div>[$$]Var(X) = E[X^2] - E[X]^2[/$$]</div><div>[$$]Var(X+a) = Var(X)[/$$]</div><div>[$$]Var(aX) = a^2 Var(X)[/$$]</div><div>[$$]Var(aX+bY) = a^2Var(X) + b^2Var(Y) + 2abCov(X,Y)[/$$]</div>
Integration by parts	[$$]\int uv' = uv - \int u'v[/$$]
Quotient rule	[$$](\frac{u}{v})' = \frac{u'v - uv'}{v^2}[/$$]
Chain rule	[$$](f(g(x)))' = f'(g(x)) \cdot g'(x)[/$$]
Recursive integration by parts (tabular method)	Wanted: [$$]\int u(x)v(x) dx[/$$]. Assume u has zero as n-th derivative.<div>Write down u and v next to each other, then below the derivatives of u and the integrals of v.</div><div>Solution is then uV - u'V^{2} + u''V^{3} (start with first row of u, second of v, then alternate signs)</div>
Log-trick	[$$]\frac{df}{d\theta} = f(\theta) \frac{d}{d\theta} \log(f(\theta))[/$$]
Univariate normal density function	[$$]p(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi}\sigma} \exp \{- \frac{1}{2}\frac{(x-\mu)^2}{\sigma^2} \}[/$$]
Beta function	[$$]B(a,b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}[/$$]
Find a% HPD interval for a normal with mean [$$]\mu[/$$], variance [$$]\sigma^2[/$$]	Look at which z has the A(z) (area under the standard normal) that is closest to [$$]1-\frac{1-a}{2}[/$$], then the interval is<div>[$$]\mu +- z \sigma[/$$]</div>
What is a sigmoid function and what is it used for?&nbsp;	"<div>Sigmoid is a special case of logistic function, with midpoint set to 0 and width of 1. It is often used as an activation function for a neuron.</div><img src=""sigmoid.png"" />"
What is stochastic gradient descent?	In ordinary gradient descent, we use all data to update our weights, in stochastic descent, we compute gradients on small batches and descent gradually.&nbsp;
What is the difference between L1 and L2 regularization?&nbsp;	"L1 (lasso) norm adds as a penalty term to objective function to minimize sum of absolute values of the parameters:&nbsp;<div>regularization_parameter*∑(w)</div><div><br /></div><div>L2 (ridge) minimizes sum of squared values of parameters:</div><div>&nbsp;regularization_parameter*∑(w^2)</div><div><br /></div><div>L1 norm function is linear and reduces the size of parameters much quicker and therefore results in many parameters equal 0. Therefore, it also has inbuilt feature selection&nbsp;</div><div>L2 norm is more useful in most cases and there's an analytical solution, therefore it's faster to compute.&nbsp;</div><div><br /></div><div><img src=""lasso ridge.png"" /></div>"
What is chain rule and how is it applied in machine learning?	Chain rule is a rule that helps to compute a derivative of a function of a function. For instance, we derivate a function sin(2x+5). First we compute sin'(2x+5) = cos(2x+5), then we compute (2x+5)'=2. Therefore sin(2x+5)' = 2cos(2x+5). In machine learning, we use it to back propagate in a neural network.&nbsp;
How does backpropagation and weight optimization work?	Backpropagation computes the derivative of the cost function (for example, quadratic loss) with respect to every weight in the network. Then optimization step updates the weights in the direction opposite the gradient proportional to second derivative (slope steepness)&nbsp;
How can I compute the size of the output feature map for a convolutional layer if I have filters of size FxF, stride S, and padding P?	We can compute the spatial size of the output volume as a function of the input volume size (W), the receptive field size of the Conv Layer neurons (F), the stride with which they are applied (S), and the amount of zero padding used (P) on the border. You can convince yourself that the correct formula for calculating how many neurons “fit” is given by (W−F+2P)/S+1. For example for a 7x7 input and a 3x3 filter with stride 1 and pad 0 we would get a 5x5 output. With stride 2 we would get a 3x3 output.
What is hinge loss and when is it particularly useful?	"Hinge loss is less aggressive than RMSE loss, formulated as Loss = max(0, 1-t*y) where t is the true label (+-1) and y is a prediction. Hinge loss is useful when there are outliers because then the outliers do not get penalized that harshly and don't skew the prediction.&nbsp;<img src=""Fig-4-The-hinge-loss-function.png"" />"
What is Laplace's Rule of Succession?	The probability of A = (A + 1) / (A + !A + 2), basically, assume you've observed one of each possible state already
Logistic function	"\[\sigma(t) = \frac{1}{1+e^{-t}}\]<div><br></div><div><img src=""218px-Logistic-curve.svg.png""><br></div><div><br></div>"		By Qef, Public Domain, https://commons.wikimedia.org/w/index.php?curid=4310325<br>
Central Limit Theorem	For any random variable with finite mean \(\mu\) and stddev \(\sigma\):&nbsp;<div><br></div><div>Random samples of the mean converge to a normal distribution with mean \(\mu\) and stddev \(\frac{\sigma} {\sqrt N}\).</div><div><ul> </ul></div>		
What are the assumptions behind linear regression?	1. Relationship is actually linear (dependent variable is a linear combination of independent variables)<div>2. Errors are independent,</div><div>3. Normally distributed,</div><div>4. Constant variance</div><div><br></div><div>(5. Non-collinear samples is not a requirement of linear regression as a technique, but of OLS, one method of solution)</div>		
What does the p-value of a coefficient in linear regression tell you?	The chance the variable doesn't matter.<div><br></div><div>(Technically: given that the coefficent&nbsp;<i>is</i>&nbsp;zero, the probablity you erroneously find it non-zero)</div>		
What is the interpretation of a coefficient in a linear regression model?	The mean change in the dependent variable for a unit change in that independent variable (i.e., the slope)		
How is R<sup>2</sup>&nbsp;interpreted in linear regression?	Explained variance.<div><br></div><div>The proportion of variance in the dependent variable explained by the independent variables.<div><br></div><div>\[R^{2} = 1 - \frac{\sum{\text{residuals}^2}}{\sum{\text{variance} * n}} <br>= 1 - \frac{\sum{(y_i - \hat{y}_i)^2}}{\sum{(y_{i} - \bar{y})^2}}\]</div></div><div><br></div><div>(Also called coefficient of determination)</div>		
What are some methods of dealing with class imbalance?	<b>Weight</b>: minority instances higher<div><br><div><b>Metrics</b>: precision, recall, F1, normalized accuracy (kappa), AUC...</div><div><br></div><div><b>Resample</b>: Upsample small classes or downsample large ones</div><div><br></div><div><b>Interpolate</b>: Generate synthetic samples by interpolation or SMOTE (randomly-weighted combinations of neighbors)</div></div><div><br></div><div><b>Bag</b>: Divide majority class into N subsets of same size as minority, train N classifiers, combine</div>	http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/<br>	
Explain the bias-variance tradeoff	<b>Bias</b>: Getting wrong answers, usually from underfitting<div><b><br></b></div><div><b>Variance</b>: Highly variable answers (from small input changes), usually from overfitting</div><div><br></div><div>For a given model it's usually impossible to reduce both. &nbsp;Ensembles and mixtures can.</div><div><br></div><div>Low bias \(\Leftrightarrow\) high accuracy \(\Leftrightarrow\)&nbsp;high variance \(\Leftrightarrow\)&nbsp;overfitting \(\Leftrightarrow\)&nbsp;poor generalization</div><div><br></div><div>Low variance \(\Leftrightarrow\)&nbsp;low accuracy \(\Leftrightarrow\)&nbsp;high bias \(\Leftrightarrow\)&nbsp;underfitting \(\Leftrightarrow\)&nbsp;good generalization</div>		
Explain bagging	"Combining several models to reduce variance. &nbsp;(<b>B</b>ootstrap <b>ag</b>gregating)<div><br></div><div><div>Train multiple models on subsets of the data and combine outputs, by e.g., averaging or majority vote.<br></div></div><div><br></div><div>Usually uses ""strong,"" low-bias models.<br></div>"		
Explain boosting	"Combining many models to reduce bias.<div><br></div><div>Sequentially train models, weighting <i>mispredicted</i>&nbsp;samples&nbsp;<i>higher</i> in the next model. &nbsp;Combine models weighting by accuracy.</div><div><br></div><div>Gradient boosting trains each model to predict the <i>error</i>&nbsp;of the previous model (the gradient of the loss function).</div><div><br></div><div>Usually uses ""weak,"" high-bias models.</div>"		
How do decision trees work?	"Recursively split the data into groups based on most discriminating feature; each leaf gives a prediction.<div><br></div><div>To build:</div><div><br></div><div>Compute ""purity"" metric on labels for all splits of all features (e.g. Gini impurity, information gain)</div><div>Take best-scoring split, create child nodes for each subgroup</div><div>Recurse on each child node, stop at some desired level of purity</div>"		
Bayes Theorem	\[P(A|B) = \frac{P(B|A)P(A)}{P(B)}\]		
What is logistic regression?	Linear regression squashed to the range [0, 1] with a logistic function to do binary classification.<div><br></div><div>\[L(x) = \frac{1}{1 + e^{-xw + b}}\]</div><div><br></div><div>\(x\) = vector of independent variables</div><div>\(w\) = learned weight vector</div><div>\(b\) = learned bias</div>		
Logit (Log-Odds) Function	"\[logit(p) = \ln\frac{p}{1 - p}\]<br><div><img src=""220px-Logit.svg.png""><br></div><div>Inverse of the logistic function.</div>"		By Krishnavedala - Own work, CC0, https://commons.wikimedia.org/w/index.php?curid=21731574<br>
When can logistic regression fail?	Too many variables<div><br></div><div>Colinear samples</div><div><br></div><div>Empty classes</div><div><br></div><div>Samples are perfectly separated</div>		
How can you evaluate the results of logistic regression?	\(\chi^2\) between labels and predictions.<div><br></div><div>Wald statistic: ratio of each coeff to its std err, squared; \(\chi^2\)&nbsp;with 1 dof.<div><br></div><div>Likelihood ratio: \(-2\ln \left( \frac{\text{prob weight is 0}}{\text{prob weight is result}} \right) \) for each weight compared to \(\chi^2\) with 1 dof</div></div><div><br></div><div>Usual suspects: cross-validation of accuracy, precision, recall, F1, AUC...</div>		
How does k-means clustering work?	"Start with k random samples as centroids<div>Assign all points to nearest centroid</div><div>Recompute centroids (vector averages)</div><div>Repeat until stationary</div><div><br></div><div><br></div><div><img src=""KMeans-Gaussian-data.svg.png""><br></div>"		By Chire - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=17085714<br>
How do you choose k in k-means clustering?	"<div>The ""elbow method:""</div><div><br></div><div>Plot ratio of between-group variance to total variance (or silhouette coefficient) vs. # clusters, pick the elbow in the graph.</div><div><br></div><div><br></div><div><br></div><div><img src=""clustering-elbow-method.jpg""><br></div>"	https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set<br>	CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=641651<br>
How does DBSCAN clustering work?	"Finds areas of high density (many neighbors)<div>Grows clusters of points with at least <i>m</i> neighbors within distance <i>eps</i></div><div>Also attach edge points, excludes outliers</div><div><br></div><div><img src=""dbscan.png""><br></div>"	http://scikit-learn.org/stable/modules/clustering.html<br>	
How does spectral clustering work?	"Embed pairwise distance matrix in a low-dimensional space (PCA)<div>Then use k-means</div><div><br></div><div><img src=""spectral-clustering.png""><br></div>"		Copyright 2017, Dario Colombo, Erik Rosolowsky, Adam Ginsburg, Ana Duarte-Cabral, and Annie Hughes<div>http://scimes.readthedocs.io/en/latest/algorithm.html<br></div>
How does hierarchical clustering work?	"Bottom up (agglomerative)<div>Start with all points as clusters</div><div>Merge close clusters (distance: sum-squared, mean, max)</div><div>Repeat until target # clusters remain.</div><div><br></div><div><img src=""hierarchical-clustering.png""><br></div>"		ALGLIB is a registered trademark of the ALGLIB Project.<div>http://www.alglib.net/dataanalysis/clustering.php<br></div>
How do you evaluate clusterings without ground-truth labels?	"Compare within-cluster distances to between-cluster distances.<div><br></div><div>Example: Silhouette Coefficient<br><div><br></div><div><div><img src=""cluster-evaluation.jpg""><br></div></div></div>"		Copyright 2017 Umer Mansoor<div>https://codeahoy.com/2017/02/19/cluster-analysis-using-k-means-explained/<br></div>
What is A/B testing, statistically speaking?<div>How do you do it, at a very high level?</div>	Significance testing (hypothesis testing). &nbsp;<div><br><div>Try two versions of something, compare their metrics with a significance test.</div><div><br></div></div>		
Significance test for binary (binomial) outcomes&nbsp;<div>(e.g., conversions out of visitors)</div>	<div>\(\chi^2\) with 1 d.o.f.</div><div><br></div><div>or, for small samples or unbalanced classes, Fischer's Exact Test based on the hypergeometric distribution.</div>		<div><br></div>
Significance test for a continuous (normal-ish) variable<div>(e.g., spend per user)</div>	"Welch's t-test<div><br></div><div><img src=""210px-Gaussian_distribution.svg.png""><br></div>"	https://en.wikipedia.org/wiki/A/B_testing#Common_test_statistics<br>	By Fleshgrinder - Own work, Public Domain, https://commons.wikimedia.org/w/index.php?curid=7062715<br>
Significance test for multiple count (multinomial) data<div>(e.g., number of each product purchased)</div>	<div>\(\chi^2\)</div><div>with \(k - 1\) d.o.f. for \(k\) counts/classes.</div><div><br></div>	https://en.wikipedia.org/wiki/A/B_testing#Common_test_statistics<br>	
What are the assumptions for (unpaired) generic t-tests?	Independent samples<div><br></div><div>Normal distribution<div><br></div><div>(Non-normal works fine for large N)</div></div>	https://en.wikipedia.org/wiki/Student's_t-test<br>	
One-sample t-test statistic formula	\[t = \frac{\text{difference of means}}{\text{std err of mean}} = \frac{\bar{x} - \mu}{\sigma / \sqrt{N}}\]		
Welch's t-test statistic formula<div>(two-sample (independent), unpaired, unequal sizes, unequal variance)<br></div>	\[t = \frac{\text{difference of means}}{\text{std err of mean}} = \frac{\overline{x_1} - \overline{x_2}}{\sqrt{\frac{\sigma_1^2}{N_1} + \frac{\sigma_2^2}{N_2}}}\]		
What is a p-value (in significance testing)?	The probability that, given no significance, you mistakenly find significance.		
What is the danger of repeated significance testing (the multiple comparisons problem)?<div>How do you handle it?</div>	Some of the tests will erroneously exceed the threshold for significance by random chance.<div><br></div><div>The Bonferroni correction: just divide your significance level by the number of tests</div><div>\[ \alpha^* = \frac{\alpha}{m} \]</div>	https://en.wikipedia.org/wiki/Multiple_comparisons_problem	
What is the problem with stopping an A/B test as soon as you see a significant result?<div>How do you avoid it?</div>	You may get falsely significant results, as you are effectively running many significance tests (the multiple comparisons problem).<div><br></div><div>Set the test sample size(s) in advance to get the power you need and don't stop early.</div>	http://www.evanmiller.org/how-not-to-run-an-ab-test.html<br>	
What is regularization, and what problem does it address?	Adding information to a model, often constraints, to make a problem well-defined and/or avoid overfitting.	https://en.wikipedia.org/wiki/Regularization_(mathematics)<br>	
What is L2 regularization and how does it work?	Adding a term for the L2 norm of the weights to the loss function of a model.<div><br><div>Penalizes large weights to reduce variance and overfitting.</div><div><br></div><div>Also known as ridge regression; a special form of Tikhonov regularization.</div></div>		
What is L1 regularization and how does it work?	Adding a term for the L1 norm of the weights to the loss function of a model.<div><br><div>Penalizes a large <i>number</i> of (non-zero) weights, for feature selection and simpler models.</div><div><br></div><div>(The L1 norm is a convex approximation to the L0 norm (the number of nonzeros), which is what you actually want.)<br></div><div><br></div><div>Also known as lasso regression.</div></div>		
How does gradient descent work?	"Minimize the loss function with respect to the weights by taking small steps in the opposite direction of the gradient.<div><br></div><div>\[w \leftarrow w - \eta \nabla J(w) \\ \texttt{weights -= learning rate * gradient} \]</div><div><br></div><div><img src=""gradient-descent.png""><br></div>"		© 2013-2017 Sebastian Raschka<div>https://sebastianraschka.com/faq/docs/closed-form-vs-gd.html<br></div>
How does stochastic gradient descent work?	"Like gradient descent, but at at each step, compute the gradient and update the weights using only one or a few (mini-batch) training samples. &nbsp;<div>The samples are randomly shuffled or sampled.<div><br></div><div>More time and space efficient.<div><br></div><div><img src=""sgd.png""><br></div></div></div>"		https://wikidocs.net/3413<br>
How does k-nearest neighbors work?	"Training stores samples in a kd-tree or similar. &nbsp;Prediction then finds the k nearest neighbors and takes the majority of their labels for classification, or averages them for regression.<div><br></div><div><img src=""KnnClassification.svg""><br></div><div><br></div><div><br></div>"		By Antti Ajanki AnAj - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=2170282<br>
What is the curse of dimensionality?	"<div>As the number of dimensions increases...</div><div><br></div>Volume scales exponentially, requring exponentially more sample data to learn functions in the space.<div><br></div><div>Distance metrics lose usefulness; relative distances between near and far points approach zero.</div><div><br></div><div>Distance to the center or mean increases; ""every point is an outlier""</div><div><br></div><div>Any partition of samples becomes linearly separable (Cover's Theorem), leading to overfitting.</div>"		
What is the definition of log loss (a.k.a. cross-entropy), and why is it used?	\[ -\frac{1}{N}\sum_{i=1}^n {y_i\log(p_i) + (1 - y_i)\log(1 - p_i)} \]<div><br></div><div>Binary classification metric, measures similarity of two probability distributions, punishes extreme confidence. &nbsp;<br></div><div>Natural error function for logistic regression.</div>		
Define precision	<div>\[ \frac{\text{true predicted positives}}{\text{all predicted positives}} \]</div>\[ \frac{TP}{TP + FP} \]		
Define recall (sensitivity)	<div><div>True Positive Rate</div><div>\[ \frac{\text{correctly predicted positives}}{\text{actual positives}} \]</div><div>\[ \frac{TP}{TP + FN} \]</div></div>		
Define specificity	True Negative Rate<div>\[ \frac{TN}{TN + FP} \]</div>		
Define F1 measure	F1 = \( 2 \frac{precision * recall}{precision + recall} \)<div><br></div><div>The harmonic mean of precision and recall</div>		
Define the ROC curve	"Plot of true positive rate against false positive rate.<div><br></div><div><img src=""roc.svg""><br></div><div><br></div><div>(TP = recall = sensitivity, FP = 1 - specificity)</div>"		By EpochFail - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=36605046<br>
Define AUC	Area under the ROC curve.<div><br><div>The probability that a random positive sample scores higher than a random negative sample.</div></div>		
How does a random forest work?	"Bagging multiple decision trees.<div><br></div><div>Plus ""feature bagging,"" selecting the split feature from a random subset of all features, to reduce correlation between trees</div>"		
What is statistical power?<div>What factors influence power?</div>	Probability that a test finds significance given it is actually there.<div><br></div><div>The significance level (\(\alpha\)), desired effect size, and number of samples affect the power.</div>	https://en.wikipedia.org/wiki/Statistical_power<br>	
How does Hadoop work?	Hadoop is an open-source implementation of google's distributed file system and MapReduce. The data is stored in HDFS and processed there using MapReduce
What is SVD?	Singular Value Decomposition is a dimensionality reduction technique.<div>Factors a matrix \( X = U\Sigma V^T \) where<br></div><div>\[\begin{align} <br>X &amp;= m \times n \\ <br>U &amp;= m \times m &amp;&amp; \text{orthogonal} \\ <br>\Sigma &amp;= m \times n &amp;&amp; \text{diagonal, the singular values of } X \\<br>V^T &amp;= n \times n &amp;&amp; \text{orthogonal} <br>\end{align}\]</div><div><br></div><div>By taking only the largest singular values (and corresponding vecotrs of \(U\) and \(V\)), you obtain a low-rank approximation to \(X\) (minimizes the Frobenius norm between \(X\) and \( U\Sigma V^T \) ).</div><div><br></div><div>The number of non-zero singular values is the rank of \(X\) (# linearly independent columns, dimension of space spanned by rows or cols).</div><div><br></div><div><br></div>		
What is the ROC curve?	Receiver Operating Charactaristic, it plots the sensitivity (true positives) as a function of the fall-out (false positives), for a binary classifier
Law of Total Probability	\[\begin{align} <br>\text{P}(A) &amp;= \text{P}(A \cap B) + \text{P}(A \cap \overline{B}) \\ <br>&amp;= \text{P}(A \mid B) \text{P}(B) + \text{P}(A \mid \overline{B}) \text{P}(\overline{B}) <br>\end{align}\]<div><br></div><div>In general, for a partition of the sample space \( B \):</div><div><br><div>\[<br>\text{P}(A) = \sum_i \text{P}(A \cap B_i) <br>=&nbsp;\sum_i \text{P}(A \mid B_i) \text{P}(B_i) <br>\]</div></div>		
Probability Multiplication Rule (Joint Probability)	\[ \begin{align} <br>\text{P}(A \cap B) = \text{P}(A \mid B) \cdot \text{P}(B) \\<br>= \text{P}(B \mid A) \cdot \text{P}(A) <br>\end{align} \]		
Binomial Distribution	The probability of exactly \(k\)&nbsp;successes in \(n\)&nbsp;independent trials, each with probability&nbsp;\(p\)<div><br><div><div>\[ {n \choose k} p^k(1-p)^{n-k} \\ \]</div><div>\[ \mu = np \\ \]</div><div>\[ \sigma^2 = np(1 - p) \]</div></div></div>	https://en.wikipedia.org/wiki/Binomial_distribution<br>	
Poisson Distribution	The probability of exactly \(k\) independent events in an interval, given an average of \( \lambda \) events per interval<div><br></div><div><div>\[ \frac{\lambda^k e^{-\lambda}}{k!} \\ \]</div><div>\[ \mu = \lambda \\ \]</div><div>\[ \sigma^2 = \lambda \]</div></div>	https://en.wikipedia.org/wiki/Poisson_distribution<br>	
Geometric Distribution	Probability of \(k\) independent trials to reach one success, each with probability \(p\)<div><br></div><div>\[ (1 - p)^{k - 1}p \\ \]</div><div>\[ \mu = \frac{1}{p} \\ \]</div><div>\[ \sigma^2 = \frac{1 - p}{p^2} \]</div><div><br></div>	https://en.wikipedia.org/wiki/Geometric_distribution<br>	
Negative Binomial Distribution	Probability of \(k\) successes before \(r\) failures, each independent with probability \(p\)<div><br></div><div>\[ {k + r - 1 \choose k} p^k(1 - p)^r \\ \]</div><div>\[ \mu = \frac{pr}{1-p} \\ \]</div><div>\[ \sigma^2 = \frac{pr}{(1-p)^2} \]</div>	https://en.wikipedia.org/wiki/Negative_binomial_distribution<br>	
Hypergeometric Distribution	Probability of \(k\) successes in&nbsp;\(n\) draws without replacement from&nbsp;\(N\) items containing&nbsp;\(K\) successes<div><br></div><div>\[ \frac{\binom{K}{k} \binom{N - K}{n - k}}{\binom{N}{n}} \]<br></div><div>\[ \mu = n\frac{K}{N} \\ \]</div><div>\[ \sigma^2 = n{K\over N}{(N-K)\over N}{N-n\over N-1} \]</div>	https://en.wikipedia.org/wiki/Hypergeometric_distribution<br>	
Normal Distribution	\[ \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\left ( \frac{x - \mu}{\sigma} \right )^2} \]	https://en.wikipedia.org/wiki/Normal_distribution<br>	
Define linear independence for vectors	"A set of vectors \(v_i\) is linearly independent iff the equation<div>\[ \sum_i {a_i v_i} = 0 \]</div><div>has only the trivial (all-zero \(a_i\)) solution.</div><div><br></div><div><img src=""linear-independence.png""><br></div><div><br></div><div>Can be determined by gaussian elimination on the above equation.</div>"	https://en.wikipedia.org/wiki/Linear_independence<br>	By Schnelliboy - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=38609973<br>
Define orthogonality for vectors	The dot product is zero.	https://en.wikipedia.org/wiki/Orthogonality<br>	
Define the span of a set of vectors	The set of all linear combinations of the vectors.		
Define the rank of a matrix	The dimension of the space spanned by the columns; the number of linearly independent vectors among the columns.		
Define the eigenvectors and eigenvalues of a matrix	The eigenvectors of a matrix \(A\) are the vectors \(x\) such that<div>\[ A x = \lambda x \]</div><div>i.e., multiplication by \(A\) acts like scalar multiplication by \(\lambda\), the eigenvalue corresponding to \(x\).</div>		
Define a basis of a vector space	A set of linearly independent vectors that span the space, i.e., the number of vectors equals the dimension of the space.		
State as many equivalencies of the Invertible Matrix Theorem as you can.<div>An \(n \times n\) matrix \(A\) is invertible if and only if...<br></div>	<div>The equation \(Ax = 0\) has only the trivial solution \(x = 0\).<br></div><div><div>The determinant of \(A\) is nonzero.</div><div>The rows and columns of \(A\) are linearly independent.</div><div>The rows and columns of \(A\) span and form a basis for \(\mathbb{R}^n\).<br></div></div><div>\(x \to Ax\) is one-to-one and onto.</div><div>The transpose is invertible.</div><div>The inverse of \(A\) exists and is unique.</div><div>\(A\) has rank \(n\).</div><div>The null space of \(A\) is \(0\).</div><div>\(A\) has \(n\) nonzero eigenvalues and singular values.</div>		
How do support vector machines work?	"SVMs find the hyperplane of maximum distance (margin) from the nearest samples of each class (the ""support vectors"").<div><br></div><div>For non-separable data, we minimize a combination of the distance from the margin (for misclassified samples) and the inverse of the margin size.</div><div><br></div><div>SVMs can find non-linear hyperplanes in higher dimensions via the kernel trick, since it only makes use of distances (dot products) between samples.</div><div><br></div><div><img src=""svm.png""><br></div>"	https://en.wikipedia.org/wiki/Support_vector_machine<br>	By Alisneaky - Own work, CC0, https://commons.wikimedia.org/w/index.php?curid=14941564<br>
How is the (soft-margin) loss function derived for support vector machines?	"The hyperplanes bounding the (hard) margin are \( w \cdot x - b = \pm 1 \) for weight and bias vectors \(w\) and \(b\). &nbsp;The distance between them is \(2 \over ||w||\), so minimizing \(||w||\) maximizes separation, subject to the constraints that the samples lie on the correct side of the margin:<div><div><div>\[<br>y_i(w \cdot x_i - b) \ge 1 \iff <br>\begin{cases} <br>w \cdot x_i - b \ge +1 &amp; \qquad y_i = +1 \\<br>w \cdot x_i - b \le -1 &amp; \qquad y_i = -1<br>\end{cases}<br>\]</div></div></div><div>For the soft-margin (not linearly separable) case, we introduce the hinge loss \( \max(0, 1 -&nbsp;y_i(w \cdot x_i - b)) \), and minimize the average hinge loss over all samples plus the inverse margin size:<br></div><div>\[ \left [ \frac{1}{n} \sum_i \max(0, 1 -&nbsp;y_i(w \cdot x_i - b)) \right ] + \lambda ||w||^2 \]<br></div><div>This can be solved as a constrained quadratic programming problem with standard techniques like conjugate gradient, or minimized with (sub-)gradient descent or coordinate descent.<br></div><div><br></div><div><img src=""svm-math.png""><br></div>"	https://en.wikipedia.org/wiki/Support_vector_machine<br>	By Cyc - Own work, Public Domain, https://commons.wikimedia.org/w/index.php?curid=3566688<br>
What is principal component analysis?	"<div>PCA ""rotates"" data such that features become linearly independent and ordered by variance, useful for decorrelating features or dimensionality reduction.</div>"	https://en.wikipedia.org/wiki/Principal_component_analysis<br>	
How is PCA related to SVD?	<div>The right-singular vectors of \(X\) are the principal components - the eigenvectors of the covariance matrix \(X^TX\)</div><div>The component weights (eigenvalues) are the squares of the singular values.<br></div><div><br></div><div>Given the SVD of \(X = U\Sigma V^T\), the principal components are the columns of \(V\) and their weights (eigenvalues) are the squares of the singular values \(\Sigma\).</div><div><br></div><div>PCA can be computed by SVD. &nbsp;After mean-centering each column, PCA finds the matrix of eigenvectors \(W\) and diagonal matrix of eigenvalues \(D\) of the covariance matrix \(X^TX\), such that \(X^TX = WDW^{-1}\).</div><div><br></div><div>\[ \begin{align} <br>X &amp;= U\Sigma V^T \\ <br>X^{T}X &nbsp;&amp;= V\Sigma U^T U\Sigma V^T \\ <br>&amp;= V\Sigma^2V^T &nbsp;&amp;&amp; \text{since } U \text{ is orthogonal} \\ &nbsp;<br>&amp;= V\Sigma^2V^{-1} &amp;&amp; &nbsp;\text{since } V \text{ is orthogonal}&nbsp;\\ &nbsp;<br>&amp;= &nbsp;WDW^{-1}<br>\end{align} \]</div><div><br></div>	https://en.wikipedia.org/wiki/Principal_component_analysis#Singular_value_decomposition<br>	
How do you decide the number of components to keep in PCA?	Plot explained variance vs. number of components and pick a point of diminishing returns.<div><br></div><div>The explained variance is the sum of the retained eigenvalues divided by the sum of all eigenvalues.</div>		
Define covariance	\[ \begin{align} <br>\operatorname{cov}(X,Y) &amp;= \operatorname{E}{\big[(X - \operatorname{E}[X])(Y - \operatorname{E}[Y])\big]} \\ <br>&amp;= \operatorname{E}\left[X Y\right] - \operatorname{E}\left[X\right] \operatorname{E}\left[Y\right] <br>\end{align} \]<br><div><br></div><div>For discrete data \(x_i\) and \(y_i\):</div><div>\[ \frac{1}{N} \sum_i{(x_i - \bar{x})(y_i - \bar{y})} \]<br></div><div><br></div><div>The entries of the covariance matrix of \(N\) observations of \(K\) discrete variables \(X\):</div><div>\[ c_{jk}=\frac{1}{N}\sum_{i=1}^{N}\left(  X_{ij}-\bar{X}_j \right)  \left( X_{ik}-\bar{X}_k \right) \]</div>	https://en.wikipedia.org/wiki/Covariance<br>	
What are some techniques for feature selection?	"<div><b>Univariate Ranking:&nbsp;</b>Choose the best features as ranked by variance, correlation with labels, mutual information, etc.<br></div><div><br></div><div><b>Forward selection</b>: find the best single feature via cross-validation. &nbsp;Then add each remaining feature, one at a time, to find the best pair of features. &nbsp;Repeat, adding one feature each iteration until ""good enough.""</div><div><br></div><div><b>Recursive feature elimination</b>: Use a model that gives weights to features, train with all features. &nbsp;Remove the lowest-weight features, repeat until satisfied.</div><div><br></div><div><div><b>Dimensionality reduction</b>: PCA, SVD</div></div><div><br></div><b>Built-in</b>: Some algorithms have feature selection built in: LASSO, decision trees"		
What is bootstrapping?	Computing a quantity of interest many times on random subsamples of the data to estimate uncertainty or reduce variance.	https://en.wikipedia.org/wiki/Bootstrapping_(statistics)<br>	
What are the limitations of PCA?	Sensitive to the scale of features<div>Assumes features with less variance are less important</div><div>Assumes (Gaussian) variance accurately characterizes features</div><div>Assumes features are orthogonal</div><div>Only performs linear transformations (but see kernel PCA)</div><div>Only removes linear correlation</div>	https://arxiv.org/pdf/1404.1100.pdf<br>	
Define cosine similarity	<div>The cosine of the angle between two vectors.</div>\[ \cos(\theta) = \frac{a \cdot b}{||a|| ||b||} \]<div>1 for parallel vectors, 0 for orthogonal vectors, -1 for opposite direction.<br></div>	https://en.wikipedia.org/wiki/Cosine_similarity<br>	
How does Naive Bayes classification work?	<div>Computes the probability of each class given a sample using Bayes' Rule, and returns the most likely class.</div><div><br></div><div>For class \(C_k\) and sample \(x = (x_1, ..., x_n)\),&nbsp;<br></div><div><br></div><div>\[ \begin{align} <br>P(C_k \mid x) &amp;= \frac{P(x \mid C_k)P(C_k)}{P(x)} &amp;&amp; \text{Bayes Theorem} \\ <br>&amp;= \frac{P(C_k) P(x_1 \mid C_k) \cdots P(x_n \mid C_k)}{P(x_1) \cdots P(x_n)} &amp;&amp; \text{Assuming independent } x_i <br>\end{align} \]</div><div><br></div><div>For categorical features, you can tabulate the probabilities directly. &nbsp;For continuous features, a normal distribution is usually assumed; for count features, a multinomial distribution is appropriate.<br></div>	https://en.wikipedia.org/wiki/Naive_Bayes_classifier<br>	
Give some examples of power-law distributions	Word frequency in natural language (Zipf's law)<div>Income</div><div>Population of cities</div><div>Connections in social networks</div>		
Describe power-law distributions. &nbsp;<div>Why are they difficult to work with?</div>	"\[ f(x) = cx^{-\alpha} \]<div><br></div><div><img src=""power-law.png""><br></div><div><br></div><div>The mean and variance are infinite for values of \(\alpha \le 2\) or \(3\) (resp.), which are common, invalidating typical assumptions of normality.</div>"	https://en.wikipedia.org/wiki/Power_law<br>	By User:Husky - Own work, Public Domain, https://commons.wikimedia.org/w/index.php?curid=1449504<br>
How do you determine the sample size needed to measure a given difference with a certain confidence?	<div>View it as a \(t\)-test of significance of the difference \(\delta\):</div><div>\[ \frac{\delta}{\sigma \over \sqrt{n}} \gt t \]<br></div><div><div>Then&nbsp;</div><div>\[ n \gt \frac{t^2 \sigma^2}{\delta^2} \]</div></div><div>where \(t\) is the critical value for the desired level of confidence (with high d.o.f.), or equivalently, the corresponding standard normal deviate, e.g. \(95\% \to t = 1.96\). &nbsp;</div><div><br></div>	http://www.itl.nist.gov/div898/handbook/ppc/section3/ppc333.htm<br>	
What is a quick formula for confidence intervals of normal-ish data?	\[ \mu \pm z\sigma \]<div>or in general<br></div><div>\[ \text{ statistic } \pm \text{ critical value } \times \text{ std dev of the statistic } \]<br></div><div><div><br></div><div>\(z\) is the critical value of the test statistic corresponding to the desired confidence (e.g., \(z = 1.96\) for \(95\%\) confidence with normal data), and \(\sigma\) is the stddev of the statistic (e.g., the SEM = \(\sigma \over \sqrt{n}\) for a mean), <i>not the population</i>.</div></div>	http://stattrek.com/estimation/confidence-interval.aspx<br>	
Define conditional probability	\[ P(A \mid B) = \frac{P(A \cap B)}{P(B)} \]	https://en.wikipedia.org/wiki/Conditional_probability<br>	
Instances	Input. Vectors of values of attributes.
Concept	Classification. Function we care about. Essentially the entire set of examples of the label, membership test.
Target Concept	Classification Learning. The correct set of examples which are the target answer.
Hypothesis Class	Classification Learning. The set of all possible functions being considered.
Sample	Classification Learning. Training Set. Set of input examples with labels.
Candidate	Classification Learning. Concept which may be target concept.
Testing Set	Classification Learning. Set of instances with labels. Used to measure performance of candidate concept.
Define the silhouette score	<div>\[ \frac{\text{nearest cluster dist - within cluster dist}}{\max(\text{nearest cluster dist, within cluster dist})} \]<br></div>Averaged over all samples	https://en.wikipedia.org/wiki/Silhouette_(clustering)<br>	
Why is the Central Limit Theorem important?	It lets you approximate most any random variable with a normal variable, and quantifies the error of the approximation.		
Decision Trees	Split the dataset on an attribute at each node until all examples remaining have the same label
Demorgan's Law	A and B = !(!A or !B)
What is the computational complexity of parity function?	O(2^n) - it is a hard (superexponential) function
How many possible decision trees are there for n binary attributes and binary labels?	The total number of decision trees possible are 2^2^n, which is basically infinite. This means decision trees are incredibly expressive, and finding the right one can be hard without a heuristic.
What is the ID3 Decision Tree algorithm?	Greedy approach to creating a decision tree. Pick best attribute, split examples, if not perfectly sorted recurse.
"What is a common ""best attribute"" in decision trees?"	Information gain. Reduction of randomness based on splitting on an attribute. The difference of the entropy in the original set and the sum of weighted entropy of the resulting sets.
What is the formula for entropy?	"-&nbsp;<span style=""color: rgb(51, 51, 51); font-family: &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; font-size: 14px; background-color: rgb(249, 249, 249);"">Σ_</span>v (p(v) * logp(v))"
How does entropy change when an evenly labeled set is split into two evenly labeled sets?	It doesn't change at all, even if the two sets are different sizes.
What are the two main biases of algorithms searching in a space?	Restriction Bias, Preference Bias
What is restriction bias?	The bias we get when we pick a solution method which reduces our hypothesis space.
What is preference bias?	Preference Bias tells us which hypotheses in the total space our algorithm prefers. All heuristics impart a preference bias.
What are the main two inductive bias in the ID3 algorithm?	Prefers trees with good splits at the top<div>Prefers correct trees over incorrect trees</div><div>Prefers shorter trees over longer trees (consequence of first)</div>
What is a good way to prevent overfitting with decision trees?	Prune the tree, collapse nodes up the tree as long as the resulting error in the cross validation set is low.
How do you handle the output of a decision tree for regression?	The leaves must vote somehow. An average or linear fit should work.
What is regression to the mean in the height of children?	The slope of the line mapping parents heights to childrens heights against the average is 2/3. Because it is less than 1 it is an example of regression to the mean.
How do you represent distinct choices in regression?	Bit vectors work well, not implying and ordering
What is the activation of a perceptron?	The sum of the inputs multiplied by their weights
What is the perceptron rule?	How to set the weights of a single unit (and threshold value, by adding a bias term of 1).<div>deltaW_i = learning rate * (y_desired - y_estimated) * X_i</div><div>The perceptron rule will linearly separate linearly separable data.</div>
Gradient Descent	delta w_i = learning rate * (label - activation) * x_i<div>Gradient Descent can converge even if the data is not linearly separable</div><div>Gradient Descent will converge to local optima</div>
Sigmoid Function	1 / (1 + e^-a)
What are the hidden layers in a neural net?	All of the layers not including the input layer or the output.
Back Propagation	Computationally beneficial organization of the chain rule / gradient desent
Optimizing Weights	Momentum<div>Higher order derivatives</div><div>Randomized Optimization</div><div>Penalty for complexity</div><div>Penalty for large weights</div>
What is the restriction bias of neural networks?	With sufficiently complex network structure you can represent:<div>Boolean functions</div><div>Continuous functions</div><div>Arbitrary functions (with at least 2 hidden layers)</div>
What is the preference bias of neural nets?	By starting with low random initial weights<div>Prefers low complexity explanations</div><div>Prefers correct expanations</div>
For logistic regression, what function is used to transform label probabilities to recast the problem as linear regression?<div>When can't this method be used, and what to use instead?</div>	<div>The logit function</div><div>\[ logit(p) = \ln\frac{p}{1 - p} \]<br></div><div>This is undefined for \(p = 0\) or \(1\), so have to use iterative methods like gradient descent.<br></div>		
In what sense is dimensionality reduction by PCA optimal?	The basis formed by the \(k\) largest principal components (eigenvectors) minimizes the least-squares projection error in \(k\) dimensions.<br>		
What does PCA compute (in matrix-theoretic terms)?	The eigenvectors of the covariance matrix (the principal components).&nbsp;		
What is the \(\chi^2\) test, and how is it computed?	"<div>Compares an actual discrete distribution \(a_i\) to an expected distribution \(x_i\).</div><div>\[ \chi^2 = \sum^k_{i=1}{\frac{(x_i-a_i)^2}{x_i}} \]<br></div><div>Compare to critical value from table with \(k-1\) d.o.f.<br></div><div><br></div><div>The errors (differences) must be independent and normally distributed.</div><div><br></div><div><img src=""chi-square.png""><br></div>"	https://en.wikipedia.org/wiki/Chi-squared_test<br>	By Mikael Häggström - File:Chi-square distributionCDF.png, Public Domain, https://commons.wikimedia.org/w/index.php?curid=10633630<br>
Define correlation	Covariance normalized by the standard deviations<div>\[<br>Corr(X,Y) = \frac{Cov(X, Y)}{\sigma_X \sigma_Y} = <br>\frac{\operatorname{E}{\big[(X - \operatorname{E}[X])(Y - \operatorname{E}[Y])\big]}}{\sigma_X \sigma_Y}<br>\]<br></div><div><br></div><div>For discrete data \(x_i\) and \(y_i\):</div><div>\[ \frac{\sum (x_i-\bar{x})(y_i-\bar{y})} {\sqrt{\sum (x_i-\bar{x})^2 \sum (y_i-\bar{y})^2 }} \]</div>	https://en.wikipedia.org/wiki/Correlation_and_dependence<br>	
What are the advantages of decision trees?	Interpretable<div>No feature engineering necessary</div><div>Nonlinear model</div><div>Provide feature importance weights</div><div>Prediction is efficient</div>		
What are the disadvantages of decision trees?	Prone to overfitting<div>High variance</div><div>Hard to learn some simple functions (parity, xor)</div><div>Axis-parallel decision boundaries (not great for smooth boudaries)</div>	https://stats.stackexchange.com/questions/24437/advantages-and-disadvantages-of-svm<br>	
What are the advantages of SVMs?	"<div>Can model known non-linear relationships with kernels</div><div>Can find ""best"" model&nbsp;for given hyperparams, since error function has global minimum</div>"		
What are the disadvantages of k-nearest neighbors?	<div>Sensitive to feature scaling</div><div>Suffers from class imbalance; weighting can help</div><div>Suffers from curse of dimensionality (all points basically same distance in high dimensions). &nbsp;<br></div><div>Model size grows with data; must store all samples</div>		
What are the advantages of Naive Bayes classification?	Interpretable<div>Efficient</div><div>Compact models</div><div>Works with small data<br></div>		
What are the disadvantages of Naive Bayes classification?	Assumes features are independent (given the class)<div><div>Assumes a distribution for continuous features (usually normal)</div><div>Does not handle sparse data well<br><div>Fixed-sized model; diminishing returns with more data</div></div></div>	https://www.quora.com/What-are-the-disadvantages-of-using-a-naive-bayes-for-classification<br>	
What are the disadvantages of SVMs?	Slow and large in both training and prediction; don't scale well<div><div>Not great with multiclass problems</div><div><br></div></div>	https://stats.stackexchange.com/questions/24437/advantages-and-disadvantages-of-svm<br>	
Describe a project or research you've done	&lt;your response here&gt;		
Describe a challenge you faced and how you overcame it	&lt;your response here&gt;		
Describe a mistake or failure in your previous experience, and how you overcame it	&lt;your response here&gt;		
Describe something you've enjoyed in your previous experience	&lt;your response here&gt;		
Describe a conflict in your previous experience, and how you handled it	&lt;your response here&gt;		
Describe something from your previous experience that you would do differently	&lt;your response here&gt;		
Describe a time when you took initiative	&lt;your response here&gt;		
Describe a time when you worked with others to solve a problem	&lt;your response here&gt;		
Describe a change in project scope or schedule in your previous experience, and how you handled it	&lt;your response here&gt;		
How does an artificial neuron (perceptron) work?	"Applies an activation function to the weighted combination of its inputs.<div><br></div><div>\[ y = f \left( \textstyle \sum w_i x_i \right) \]</div><div><br></div><div>Common activation functions are linear, step, sigmoid, tangent, rectified linear, etc.</div><div><br></div><div><img src=""neuron.jpg""><br></div>"	https://en.wikipedia.org/wiki/Perceptron	http://www.theprojectspot.com/tutorial-post/introduction-to-artificial-neural-networks-part-1/7
How does a (fully-connected, feedforward) neural network work?	"A neural network is composed of layers of neurons that recieve the same inputs, apply an activation function, and produce an output. &nbsp;The outputs of one layer become the inputs of the next.<div><br></div><div>Neural networks are trained via backpropagation, which iteratively updates the weights in the direction that minimizes error at the outputs (often via gradient descent).<br><div><br></div><div><img src=""neural-network.gif""><br></div><div><br></div><div><br></div></div>"	https://en.wikipedia.org/wiki/Artificial_neural_network	http://wordassociation1.net/lookup.html
How does backpropagation work?	Backpropagation iteratively updates the weights of a neural network to minimize the error between the actual and desired outputs.<div><br></div><div>Each weight gets updated in the opposite direction of the derivative of the loss function with respect to that weight (the gradient). &nbsp;The derivatives at each layer depend on the derivatives of all successive layers (between it and the output), so the weight updates are calculated from the output back: backpropagation.</div><div><br></div><div><br></div>	https://en.wikipedia.org/wiki/Backpropagation	
What is the kernel trick?<div>Why is it useful?</div>	"<div>The kernel trick can compute the results of vector dot products after non-linear mappings into high-dimesional space using only dot products in the original low-dimensonal input space.</div><div><br></div><div>It finds high-dimensional non-linear descriptions of data at low computational cost.</div><div><br></div><div><img src=""kernel-trick.png""><br></div><div>If \(\phi: \mathbb{R}^n \to \mathbb{R}^m\) maps vectors to a higher-dimensional space (\(m \gt n)\), then the corresponding kernel function \(K: \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}\)<br></div><div>\[ K(x,y) = \langle \phi(x), \phi(y) \rangle \]</div><div><i>acts</i>&nbsp;as a dot product in higher-dimensional mapped space, but can be <i>computed</i>&nbsp;using only low-dimensional dot products \(\langle x,y \rangle\).</div>"	http://www.eric-kim.net/eric-kim-net/posts/1/kernel_trick.html	https://datascience.stackexchange.com/a/17537
Between-factor one way ANOVA: <i>Purpose, SS partition, F</i>	"<img src=""paste-3508988280833.jpg"" /><div><br /></div><div>F=1 does not prove means are equal but fails to find evidence that the group means are the same</div>"
Values of an ANOVA table:	SS, df, MS, F, p-value
What to do if the omnibus F test rejects H<sub>0</sub>?	- at least one group differs from the other groups, based on one or more effects (main/interaction)<div><br /></div><div><u>further inspection:</u></div><div>- visual inspection (no statistical proof)</div><div>- multiple comparison (test or CI´s)</div><div>1. planned -&gt; contrasts</div><div>2. post hoc comparisons</div><div><br /></div><div>Finding the groups which differ increase F rejects H<sub>0</sub></div>
ANOVA: Assumptions	1. <b>Independent</b> observations<div>2. In each group the scores are <b>normally</b> distributed (QQ-plots; skewness and kurosis)</div><div>3. In all groups <b>equal variances</b>&nbsp;</div><div>- (check sample variances (or SD´s): max/min &lt;2 is ok&nbsp;</div><div>- Levene´s test: be catious, use of a significance test to confirm H<sub>0</sub></div>
Experiments have 3 characteristics:	"<ol type=""1"" start=""1""><li><b>Manipulation</b> of treatment levels (researcher controls nature and timing of each level)</li><li><b>Random assignment </b>of cases to levels; groups (remove bias, average out differences among cases)</li><li><b>Control</b> of extraenous variables (only treatment level changes during experiment)</li></ol><div>- when all three hold, differences in scores are attributed to differences in treatment</div>"
How to control extraneous variables:	"<ul style=""margin-left: 20px; ""><li>hold them constant</li><li>counterbalance their effects</li><li>turn them into extra factors</li></ul><div><br /></div>"
Between-subjects designs: <i>Information</i>	"Differences due to treatments are tested between groups of subjects<div><ul style=""margin-left: 20px; ""><li>cases are randomly assigned to treatment levels</li><li>different cases in every level</li><li>between-subject (each subject appears in one treatment only)</li></ul><div><img src=""paste-3878355468289.jpg"" /></div><div><br /></div></div>"
Factorial designs (between subject designs)	"<ul style=""margin-left: 20px; ""><li>treatment levels are determined by more than one factor</li><li>main effects of each factor, and interaction(s)</li><li>interaction effect between a and b (differences in factor a depend on which group b you are in)</li><li>differences may differ between a<sub>1-3</sub>&nbsp;on b</li></ul><div><img src=""paste-4660039516161.jpg"" /></div>"
Factorial ANOVA	"<ul style=""margin-left: 20px; ""><li><u>Usually more than one factor</u> (defining different groups): a*b groups, and <i>main</i> effect and <i>interaction</i> effect can be tested</li><li>Why several factors?: (design or substantive reason, statistical resion i.e. reduction of error variance, interplay between variables)</li></ul>"
Sources of Variance: Identify them	"<ol type=""1"" start=""1""><li>List each factor as source</li><li>Examine each combination of factors (completely crossed - include interaction as source)</li><li>When effect is repeated, with different instances, at every level of another factor - include factor as source</li></ol><div>Example:</div><div><ul style=""margin-left: 20px; ""><li>Factor A, B, subjects S</li><li>A, B, AxB, and S</li><li>Different S, at each level of A and B: A, B, AxB, and S(AB)</li></ul><div>- include subjects (measure multiple times) as factor explaining variance</div></div>"
What is bagging?	Fit a model to a subset of the data, do this n times, and average the n models to model the entire dataset
What is a weak learner?	A hypothesis which does better than chance on any distribution of the data
What is VC Dimension?	Vaprix-Chervonenkis Dimension. The largest number of points that a hypothesis space can shatter
What does shatter mean?	A hypothesis space shatters a dataset if it is capable of labeling all of the data correctly for all possible labels
What is a hypothesis space?	A set of many hypotheses.
Computational Complexity	How much computational effort is needed for a learner to converge?
Sample Complexity	Batch - How many training examples are needed for a learner to create a successful hypothesis?
Mistake Bounds	Online learning - How many misclassifications can a learner make over an infinite run?
Consistent Learner	A learner such that the estimated label is consistent for all examples in the training data
Version Space	The Version Space of S is the set of all hypothesis in the hypothesis space which are consistent with the sample data S.
What is PAC Learning?	Probably Approximately Correct Learning
What are the parameters in PAC Learning?	C: Concept Class<div>L: Learner</div><div>H: Hypothesis Space</div><div>n: |H| size of hypothesis space</div><div>D: distribution over inputs</div><div>0&lt;=Epsilon&lt;=1/2 Error Goal</div><div>0&lt;=Delta&lt;=1/2 certainty goal</div><div><br></div><div>Probably (1-Delta) Approximately (Epsilon) Correct (error_D(h)=0)</div>
When is a concept class PAC learnable?	C is PAC-learnable by L using H iff learner L will, with probability 1-delta output a hypothesis h \exists H such that error_D(h) &lt;= \epsilon in time and samples polynomial in 1/epsilon, 1/delta &amp; n.
Epsilon-exhausted version space	VS(S) is Epsilon exhausted iff for all hypothesis in the version space VT(S) error_D(h) &lt;= Epsilon (all hypotheses remaining have error below epsilon)
Haussler's Theorem	Bounds True Error as a function of the number of samples drawn from a distribution.<div>Let error_D(h_1, ..., h_k in H) &gt; epsilon</div><div>Probability of this error remaining after m samples is Pr(h_i consistent with c on m examples) &lt;= (1-epsilon) ^ m</div><div>Probability of at least one hypothesis with greater error consistent with c no m examples is then...</div><div>&lt;= k*(1-epsilon)^m &lt;= |H|(1-epsilon)^m &lt;= |H| * e ^ (-epsilon * m)</div><div>Doing some math shows</div><div>m &gt;= (1/epsilon) * (ln(|H|) + ln(1/delta))</div>
What is the kernel trick?	Because not everything is linearly separable, we can use the kernel trick to project the data into a higher dimensional space by replacing the dot product similarity term in the SVM weight calculation with a better similarity function using domain knowledge.
What is the radial basis kernel?	e ^ -(||x - y||^2 / (2 sigma^2))
What is the Mercer Condition?	Basically that the measure behaves similar to a distance. This definition needs improvement.
What is a SVM?	"Support Vector Machine, which is a ""Machine"" for finding ""Support Vectors"". Support vectors are the examples required to define the boundary."
What is the margin of an SVM?	The distance between the hyperplane and the closest data points on either side. This commits the least to the data, while still correctly classifying it. It helps increase generalization and reduce overfitting.
Why is boosting resistant to overfitting?	Because boosting essentially increases the margins. Boosting is very unlikely to overfit.
When does boosting overfit?	When the data is disturbed by pink noise (uniform noise). Also when the underlying weak learner overfits.
What is the optimization model for finding maximum margins?	Quadratic programming
What is the uninformed prior?	Treating all hypotheses as equally likely
What are Bayesian Networks?	Bayesian Networks help represent and manipulate probabilistic quantities over complex spaces.
What is Joint Distrobution?	Where two probability distributions are related.
Conditional Independence	X is conditionally independent of Y given Z if the probability distribution governing X is independent of the value of Y given the value of Z, that is is for all X,Y,Z, P(X = x | Y = y, Z = z) = P(X=x | Z=z) or more compactly P(X|Y,Z) = P(X|Z)
What is the formula for independent variables?	Pr(x, y) = Pr(x) * Pr(y)
What is the probability chain rule?	Pr(x, y) = Pr(x | y) * Pr(y)<div>which also implies Pr(x | y) = Pr(x) for independent distributions</div>
What is a Belief Network / Bayes Nets / Bayesian Networks?	Directed graph showing dependence of probability distributions
What order do you sample probabilities in, in a Joint Distrobution Bayes Net?	Topological Order, which is an ordering such that for every directed edge u,v in the graph, the node u comes before v in the ordering.
What is probability marginalization?	P(x) = sigma_y P(x,y)
How do you perform classification using a naiive Bayes Net?	argmax P(V) PI_i P(a_i | V)
What does naiive Bayes mean?	Naiive Bayes assumes strong independence between variables. Given a label you can infer the attributes, and then you can work backwards from attributes to infer the label using Bayes Rule.
What are some of the downsides of Naiive Bayes?	One unseen attribute (probability of it is 0) in the product of all of the probabilities, reduces the whole product to 0. Also it doesn't actually estimate the probabilities well, due to not taking into joint probabilities. Though it doesn't need to correctly estimate the probabilities, if the only goal is classification.
What are some of reasons Naiive Bayes is cool?	Tractible, the gold standard (best we can possibly do) if the attributes are iid, and can perform inference in any direction. Also readily handles missing attributes.
Hill Climbing	Sample points in the neighborhood, move to larger value, repeat until no larger values exist
What are the tricks to improve performance of Randomized Hillclimbing?	Keep track of positions you've already been at, and don't reevaluate them.
What is the simulated annealng algorithm?	For a finite set of iterations:<div>sample a new point in neighborhood</div><div>Jump to new sample with probability given by P(X, X_t, T)</div><div>Decrease temperature T</div><div><br /></div><div>P(X, X_t, T) = 1 if f(X_t) &gt;= f(X),</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; e^((f(X_t)-f(X))/T), otherwise</div>
What is the probability of simulated annealing ending at a particular X?	Pr(ending at x) = e^(f(x)/T)/Z_t (where Z is a normalizing term)
What is the basin of attraction?	The state space where gradient decent results in a particular local maxima
What are the important parts of genetic algorithms?	Population of individuals<div>Mutation (local search)</div><div>cross over (information sharing)</div><div>generations (iterations of improvement)</div>
What is one point crossover?	For genetic algorithms, choose a random bit and create children with half of their information from opposite parents, split on that bit
What are the assumptions in using crossover in genetic algorithms?	Locality of bits is important<div>There are subspaces to optimize independently</div>
What is uniform crossover in genetic algorithms?	each bit is randomly selected from one parent (and the other child gets the other parents bit)
What is the point of randomized optimization?	It overcomes local minima, because it has the option of taking steps which are not in the best direction
What is the basic idea of MIMIC	Directly model underlying probability distrobution, and successively refine this model through iterations
What is the MIMIC algorithm?	Generate samples from P_thetat(x) // starts at uniform<div>Set theta_t+1 to nth percentile // fittest</div><div>Retain only those samples s.t. f(x) &gt;= theta_t+1</div><div>Estimate P_thetat_1(x)</div><div>Repeat</div>
How does MIMIC use dependency trees to estimate distrobutions?	It uses dependency trees as a minimal representation of relationships between variables, which are then able to generate new samples probabilistically in time linear in the number of features using topological sort on the dependency tree.
What is the right way to compare similarity of probability distrobutions?	D_kl(P || P_pi) = \sigma p[lg(p) - lp(p_pi)]<div>This implies that you should pick parents which maximize the sum of the mutual information between every feature and its parents&nbsp;</div>
How can you create a dependency tree from samples for MIMIC?	Create a fully connected graph of all features in the data<div>Label the edges of the graph with the mutual information between the features</div><div>Find the maximum spanning tree</div><div><br /></div>
What are the practicle issues with MIMIC?	MIMIC does well with structure, because it models it.<div>MIMIC doesn't get stuck in local optima often</div><div>MIMIC gets you probability theory built in</div><div>MIMIC is very time complex, though it finishes in very few iterations</div><div>This is very good for fitness functions which are very expensive to evaluate</div>
Missing Data	Lack of response due to several reasons such as: e.g. subject refuse to participate or the answer is unreadable&nbsp;
When is a missing score a missing datum?	Only if an underlying true value exists! Important!
How does SPSS deal with missing data?	SPSS would just remove the case with missing values total exclusion from the analysis
Why shall we not ignore missing data?	I. Inefficiency - loss of information and size -&gt; loss of power<div><br /></div><div>II. Biased results, depending on:</div><div>a) systematic differences between respondents and non-respondents (depending on nature of missingness)</div><div><br /></div><div>b) Proportion of missing data (when comparing two treatments and the bias is the same in both treatments, there is no bias in the comparison!)</div><div><br /></div><div>III. Incorrect inferential information (e.g. standard errors, statistical tests) -&gt; serious problem!</div>
What is unit non-response?&nbsp;	A sample unit is not observed, the entire data collection fails -&gt; Data are <u>completely </u>missing<div><br /></div><div>(e.g. subject did just not come)</div>
Missing by design	Data are <u>partially</u> missing<div><br /></div><div>not-applicable items, incomplete designs</div><div><br /></div><div>(e.g. if you answer question 2 with no, please got to question 6)</div><div><br /></div><div><b>Predictable!</b></div>
Partial non-response (time dependency)	Data are <u>partially</u> missing<div><br /></div><div>attrition, missing baseline, break-off during interview, drop-out</div><div><br /></div><div>Important: ask yourself what really happened</div>
Item non-response	Data are <u>partially</u> missing<div><br /></div><div>skipped items, inadequate responses, information lost</div><div><br /></div><div>E.g. scores forgotten to put on the sheet.</div><div><br /></div><div>Note: if the pattern looks random, this is the easiest one to deal with<br /><div><br /></div><div><br /></div></div>
Q: first item to administer is selected on the basis of age of child. What is the typology of missing data?	Missing by design
Q: last item administered depends on the performance of the child. (Stop after 3 false items) What is the missing data typology?	Missing by design
An item was skipped and no score was given. What is the missing data typology?	item non-response
A child refused to further participate. What missing data typology is this?	Partial non-response (if it was more than one item missing).<br /><br />If this resulted in just one item that could not be scored, it would be item non-response
What are potential sources of non-response?	1) <b>Mode</b> of data collection (experimenter, telephone...)<div><br /></div><div>2) <b>Questionnaire</b> (layout, wording, hard questions...)</div><div><br /></div><div>3) <b>Respondent</b> (accidental skipping, refusal, do not know answer...)</div><div><br /></div><div>4) <b>Interviewer</b> (guidance, probin, recording...)</div><div><br /></div><div>5) Data <b>processing</b> (coding, editing...)</div>
How does Matrix R look like?	Indicator variables (matrix) R indicate whether an element of the data matrix is observed ( R = 1) or missing (R = 0)<div><br /></div><div><br /></div>
How is the distribution of R called?	The missing data mechanism
What is a missing data mechanism an what is it used for?	It's a mathematical device used for:<div><br /></div><div>1) describing rats and patterns of missing values</div><div><br /></div><div>2) capture roughly possible relations between missingness and the (unobserved) values of the missing items</div><div><br /></div><div>3) BUT it does <b>not</b> capture causal relationships</div><div><br /></div><div><i>A missing data mechanism is always an assumption!</i></div>
What are the three typologies of missingness mechanisms?	Missing completely at random (<b>MCAR</b>)<div>Missing at random (<b>MAR</b>)</div><div>Missing not at random (<b>MNAR</b>)</div>
What does MCAR imply?	<b>Missingness is not related</b> to the observed (Yobs) and missing data (Ymis): P(R) does not depend on Yobs and Ymis.<div><br /></div><div><b>No bias</b> due to (systematic) differences.</div><div><br /></div><div>Respondents are a <b>representative</b> (sub)sample of the population: only loss of power (because of data loss)</div><div><br /></div><div>So: if MCAR - the sample is still a good representative of the population</div><div><br /></div><div><br /></div>
What das MAR imply?	Missingness may be related ot the observed (Yobs) but<b> not to the missing data</b> (Ymis): P(R) may depend on Yobs but not on Ymis.<div><br /></div><div><b>No bias</b> due to (systematic) differences given observed data.</div><div><br /></div><div>Subgroups of repondents are <b>representative</b> subsample of the population.</div><div><br /></div><div>-&gt; Non-reponse can be predicted by observed data!</div><div><br /></div><div><br /></div><div><br /></div><div><br /></div>
Q: When is data MAR in a longitudinal study?	When the missingness depends on previous measurements but not on actual (and future) measurements.<div><br /></div><div>Be careful! If further speculation is needed - MNAR</div>
What does MNAR imply?	<div>Missingness is related to the missing data (Ymis) (and maybe the observed data Yobs): P(R) depends on Ymis.</div><div><br /></div><div>Systematic bias due to (systematic) differences</div><div><br /></div><div>-&gt; it is unknown what we do not measure</div>
What is a different name for MNAR?	informative non-response
Q:When is data MNAR in a longitudinal study?	missingness is related to the actual measurement and maybe future measurements<div><br /></div><div>e.g. drop out because of future anticipation (it was hurting and therefore there will be pain involved again in the future)</div>
How can we try to check our assumptions (regarding missing data mechanisms)	compare respondents with non-respondents on the observed scores
In which settings in MAR plausible?	Missing by design (planned missingness)<div><br /></div><div>Latent variables: missing with probability 1</div>
How can we find causes and correlates that confirm our assumptions (regarding missing data mechanisms)?	1) Descriptive techniques to investigate patterns of missingness<div><br /></div><div>2) Testing MCAR vs. MAR (testing MAR vs. MNAR is <b>not</b> possible)</div><div><br /></div><div>3) Follow-up of nonrespondents (rather unrealistic)</div>
How should we handle Missing Data?	1) Avoid/ prevent it<div><br /></div><div>2) Collect data on reasons for missing (obtain information about the missing data mechanism)</div><div><br /></div><div>3) Use descriptive techniques and test MCAR vs. MAR</div><div><br /></div><div>4) Where possible, do a MAR approach</div><div>&nbsp;- direct modeling of observed and missing data (multilevel)</div><div>- multiple imputation of missing data: predicting missing scores</div><div>-(possible other missing data treatments)</div>
How should we handel MNAR?	<div>this mechanism is non-ignorable and</div>requires advanced modeling&nbsp;<div><br /></div><div>(but Jorge does not specify how)</div>
What are the two deletion methods and when are they applicable?	Listwise deletion<div><br /></div><div>Pairwise deletion</div><div><br /></div><div>Applicable only when data is MCAR or MAR</div>
What is listwise deletion?	complete case analysis = casewise deletion: delete subjects for which at least 1 score is missing<div><br /></div><div>-&gt; this is the method SPSS uses</div>
What is pairwise deletion?	available case analysis = delete subjects that miss at least 1 score necessary for the analysis at hand
When do the deletion methods give unbiased estimates?	Only if missing data is MCAR<div><br /></div><div>although they are applicable for MCAR and MAR (as Jorge says during the lecture)</div>
How are the procedures based on imputation called?	Single imputation<div><br /></div><div>Multiple imputation</div>
How do imputation methods work?	They substitute plausible values for the missing scores
What are the advantages of imputation methods?	More <b>efficient</b> than analyzing complete cases (more powerful)<div><br /></div><div>Opportunity to use <b>information about missing scores</b></div><div><br /></div><div>Completed data can be analyzed with <b>standard procedures and software</b></div><div><b><br /></b></div><div>Results in completed data set that is the same for all following analyses</div>
What are the disadvantages of imputation methods?	Sometimes <b>hard to implement</b> (especially multivariate cases) (he says during the lecture that single imputation is easy)<div><br /></div><div>Some (ad hoc) imputations severely bias distributions and relations&nbsp;<br /><div><br /><div><br /></div></div></div>
What are the three single imputation methods and how do they work?	1. <b>Unconditional</b> means: filling in means<div><br /></div><div>2. <b>Conditional</b> means: filling in model predictions (e.g. regression imputation)</div><div><br /></div><div>3. <b>Conditional</b> distributions: filling in draws from the distribution of Ymis given Yobs</div><div>(e.g. filling in predictions plus random error)</div>
Which are the most and least preferred single imputation methods?	Least:Unconditional means<div><br /></div><div>Middle: Conditional means</div><div><br /></div><div>Most: Conditional distributions (adds noise and is therefore more realistic)</div>
What's problematic with single imputation of unconditional means?	<b>Biased variances and covariances</b><div><br /></div><div>(slide 34 and the previous and following give examples)</div>
What is problematic with single imputation of conditional means?	<b>biased covariances</b><div><b><br /></b></div><div>(slide 34 and the previous and following give examples)</div>
What is problematic with the single imputation of conditional distributions?	nothing much.<div><br /></div><div>They are unbiased under MAR</div>
Shortcomings of single imputation	<b>Biased estimations</b>: means and/or variances and/or covariances<div>The <b>joint distribution</b> of the variables is disrupted</div><div><br /></div><div>SEs, p values and other <b>uncertainty measures </b>are misleading because they do not take into account the extra uncertainty caused by missing values</div><div><br /></div><div>imputations are treated as observations</div><div>sample size is not equal to n</div>
What does Multiple Imputation correct for and how?	Repeat the imputation process:<div><br /></div><div>parameter estimates vary due to the <b>random character</b> of the imputation procedure and this variation can be used to <b>correct the variances</b> and SEs</div>
What is the <i>procedure</i> of Multiple Imputation?	1. repeat imputation process <i>m</i> times:<i> m</i> imputed data sets<div><br /></div><div>2. Analyze the <i>m</i> data sets seperately using standard techniques</div><div><br /></div><div>3. Summarize the results, taking into account differences within datasets (uncertainty in data) and between datasets (uncertainty due to missing data and imputation)</div>
What are Maximum Likelihood-based procedures and how do they work?	maximum likelihood estimate of a parameter is the value of the parameter that is most likely to have resulted in the observed data<div><br /></div><div>How?</div><div>Analyze the full, incomplete data set using maximum likelihood estimation</div><div>With missing data: Likelihoods computed for cases with:</div><div>- complete data on some variables</div><div>- compplete data on all variables</div><div>- two likelihoods are maximized together</div>
Pros and Cons of Maximum Likelihood-based procedures	Pro: ML based procedures give unbiased parameter estimates and standard errors<div><br /></div><div>Con: Only available for linear models (e.g. regression)</div><div><br /></div><div><br /></div><div>Advantage over multiple imputation: it does not require the careful selection of variables used to impute values</div><div><br /></div><div><br /></div>
3 Steps of Missing Data treatment in practice	1. Avoid MD<div>2. If MD occurs, administer reasons for MD for each case</div><div>3. Data analysis:</div><div><br /></div><div>- Very few MD? Single imputation using plausible model</div><div><br /></div><div>- More than very few? Consider mechanism(s) underlying MD</div><div><br /></div><div>- M(C)AR: Likelihood-based procedure or Multiple imputation</div><div><br /></div><div>-MNAR: specific likelihood-based methods (pattern mixture, use of auxiliary variables)</div>
Effects:&nbsp;Two-way ANOVA<div><br /></div>	"<div>- A main effect is the average of the simple effects for a certain factor (for all levels of the remaining factors)</div><div>- <i>Main effects</i>: Most appropriately interpreted with no interaction</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>-&nbsp;Not representative of simple effects if interaction is present</div><div><br /></div><div><i>Factorial design produces two types of information:</i></div><div><b>interaction</b> <b>effects</b> (comparison of the simple effects)</div><div><b>main</b> <b>effects</b> (two single-factor experiments)</div><div><br /></div><div><br /></div><div><div>First look at simple effects A on only B1 (if same for B2… exclude interaction effect)</div></div><div><br /></div>"
Effect sizes:&nbsp;p-value	<div>Measures the significance of a factor:</div><div>E.g. viewcat: p &lt; .001: strongly significant</div>
Effect sizes: e.g.&nbsp;η2	<div>Measures the size of the difference:&nbsp;</div><div><br /></div><div><div>E.g. η2 = 7811/39438 = 0.198</div><div>Some other effect sizes measures exist, each with their own advantages</div><div>Viewcat explains roughly 1/5th of the variance</div></div><div><br /></div><div>-&nbsp;Look at combination of p-value and effect size to judge relevance of a variable</div><div><i>With huge n, even the tiniest difference is significant</i></div><div><br /></div>
Unequal / equal n per cell	<div><b>Preferred</b>: Equal number of subjects per cell</div><div>Sum of squares of effects and interactions are orthogonal</div><div>Effects are completely separated, and tests are independent</div><div><br /></div><div><b>Unequal number of subjects per cell</b>: Different ways to decompose effects</div><div>1. <i>Regression approach</i> (adjust each effect for all other effects to obtain its unique contribution) (‘Type III SS’; SPSS default)</div><div>2. <i>Experimental method</i>: Estimate the main effects ignoring the interaction, estimate the interaction adjusting for the main effects (‘Type II SS’)</div><div>3. <i>Hierarchical approach</i>: Use a (theoretically based) order in decomposing the effects (‘Type I SS’)</div><div><br /></div>
<div>Factorial-blocks design</div><div><br /></div>	<div><b>- Factorial block design&nbsp;</b></div><div>with minimally two factors&nbsp;</div><div>one factor serves as a so-called blocking factor</div><div><br /></div><div><b>- Blocking factor</b></div><div>Intrinsic to the subjects (e.g., sex)</div><div>Related to the dependent variable (e.g., therapy-effect)</div><div><br /></div><div><b>- Purposes:&nbsp;</b></div><div>Draw separate conclusions about each block (e.g., differential therapy-effects in men and woman)</div><div>Error reduction (more power to reveal, e.g., overall therapy effects)</div><div><br /></div>
<div>Factors in factorial ANOVA</div><div><br /></div>	-&nbsp;Two types of Factors&nbsp;<div>Experimental (i.e., conditions in experiment)</div><div>Blocking (i.e., fixed characteristics of subjects)</div><div><br /></div><div><br /></div><div>- Factorial-blocks design</div><div>1. Randomized-blocks design</div><div>2. Post-hoc block design</div><div><br /></div>
<div>Randomized-blocks design</div><div><br /></div>	"<div><b>Randomized blocks design:&nbsp;</b></div><div>Simplest case of two-way design</div><div>- Factor A: Experimental factor</div><div>- Factor B: Blocking factor&nbsp;</div><div><b><br /></b></div><div><b>Blocking factor</b></div><div>- Homogeneous blocks of subjects are formed beforehand to reduce within-group variability</div><div>- Blocking factor defines blocks: error control</div><div><img src=""Bildschirmfoto 2017-10-10 um 12.47.26.png"" /></div><div><br /></div><div><div>There may be only&nbsp;<u>1 observation in each cell</u></div><div>of the design&nbsp;</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>-&nbsp;no interaction between the factors measurable</div></div><div><img src=""Bildschirmfoto 2017-10-10 um 12.48.25.png"" /></div><div><br /></div>"
<div>Randomized-blocks design and its Advantages:</div><div><br /></div>	<div><b>Advantages</b></div><div>- Reduction of error variance&nbsp;</div><div>- Increases comparability of groups by assuring the block sizes are equal (making the groups more homogeneous)</div><div>- Interaction between factors can be detected</div><div><br /></div><div>Always include blocking variable in ANOVA,&nbsp;regardless of significance</div><div><br /></div>
<div>Post-hoc blocking</div><div><br /></div>	<div>Blocking after collection of the data</div><div><br /></div><div>Blocking not initially planned in design</div><div>- Form blocks post hoc, segregating subjects into homogeneous blocks</div><div>- <i>Problem</i>: often unequal sample sizes</div><div>- <i>Problem</i>: data fishing</div><div><br /></div><div>If blocking variable is continuous, blocking causes a loss of information (median splits are evil); Consider alternatives</div><div>- ANCOVA</div><div>- Regression analysis</div><div><br /></div>
<div>Types of Experimental designs</div><div><br /></div>	"<div><b>Between-subjects designs</b></div><div>- Differences due to treatments are tested between groups of subjects</div><div>- One of more factors in the experimental design</div><div>- Different cases in each cell of the experimental design</div><div><br /></div><div><b>Repeated-measures designs&nbsp;</b></div><div>- Each case participates in two or more treatment levels and is measured once at each level</div><div>- Within-subjects designs: differences due to treatments are tested within the same set of subjects &nbsp;<span class=""Apple-tab-span"" style=""white-space:pre""> </span></div><div><br /></div>"
Fixed <i>vs.</i> random effects (example)	"<div><u>Study</u>: Treatment effectiveness</div><div><u>Factor</u>: Hospital, 3 levels (Groningen, Leeuwarden, Assen).</div><div><br /></div><div><i>Goal of study</i>: Are the main hospitals in this region equally effective?<span class=""Apple-tab-span"" style=""white-space:pre""> </span><b>fixed factor&nbsp;</b></div><div><br /></div><div><i>Goal of study</i>: Are Dutch hospitals similar; these 3 are a random sample of all Dutch hospitals? <b>random factor</b></div><div><br /></div><div>_________________________________________________</div><div><div>Fixed: only the 3, no extrapolation to other hospitals</div><div>Random: extrapolation to the population of dutch hospitals</div></div><div><br /></div>"
<div><div>Matrix algebra -&nbsp;<b>terminology</b>:&nbsp;<i>Matrix</i></div></div>	"<div>Example of a Matrix:&nbsp;</div><div>(capital letter, bold)</div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-10 um 12.53.36.png"" /></div>"
Matrix algebra -&nbsp;<b>terminology</b>:&nbsp;<i>Vector</i>	"<div>Example of a Vector:</div><div>(small letter, bold)&nbsp;</div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-10 um 12.54.07.png"" /></div>"
Matrix algebra -&nbsp;<b>terminology</b>:&nbsp;<i>Scalar</i>	"<div><div>Example of a Scalar:&nbsp;</div><div>(small letter, italics)&nbsp;</div></div><div><br /></div><img src=""Bildschirmfoto 2017-10-10 um 12.54.10.png"" />"
Matrix algebra -&nbsp;<b>terminology</b>:&nbsp;<i>Size of a Matrix</i>	"<div>Number of rows and number of columns</div><div>Also called: Order or dimension</div><div>Example of notation:&nbsp;</div><div>matrix <b>A</b> is of order (3x2)</div><div><img src=""Bildschirmfoto 2017-10-10 um 12.55.07.png"" /></div><div><br /></div>"
Matrix algebra -&nbsp;<b>terminology</b>:&nbsp;<i>Length of a Vector</i>	"<div>Length of a Vector:</div><div>Number of elements</div><div>Example: length of vector <b>a </b>is<b> 3</b></div><div><b><br /></b></div><div><img src=""Bildschirmfoto 2017-10-10 um 12.55.11.png"" /></div>"
Matrix algebra -&nbsp;<b>terminology</b>:&nbsp;<i>Transpose</i>	"<div><b>Transpose</b> of a matrix (vector):</div><div>interchanging rows and columns</div><div><img src=""Bildschirmfoto 2017-10-10 um 12.56.02.png"" /></div>"
Matrix algebra -&nbsp;<b>terminology</b>:&nbsp;<i>Column Vector</i>	"<div><b>Column</b> vector</div><div><img src=""Bildschirmfoto 2017-10-10 um 12.56.07.png"" /></div>"
Matrix algebra -&nbsp;<b>terminology</b>: Row<i>&nbsp;Vector</i>	"<div><b>Row</b> Vector:</div><img src=""Bildschirmfoto 2017-10-10 um 12.56.10.png"" />"
Matrix algebra -&nbsp;<b>terminology</b>: <i>Multiplication</i>	"<div>Multiplying a scalar by a matrix:</div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-10 um 13.01.34.png"" /></div>"
Matrix algebra -&nbsp;<b>terminology</b>:&nbsp;<i>Multiplication of two matrices</i>	"<div>Multiplying two matrices:</div><div><img src=""Bildschirmfoto 2017-10-10 um 13.02.06.png"" /></div><div><br /></div>"
<div>Square matrix:&nbsp;</div><div><br /></div>	-&nbsp;equal numbers of rows and columns, i.e., order (dd)<div><br /></div>
<div>Diagonal matrix</div><div><br /></div>	"-&nbsp;square matrix, with off-diagonal elements&nbsp;equal to zero<div><img src=""Bildschirmfoto 2017-10-10 um 13.03.22.png"" /></div>"
<div>Symmetric matrix:&nbsp;</div><div><br /></div>	"<div>- Square matrix where each element (i, j) is identical to element (j, i)</div><div><img src=""Bildschirmfoto 2017-10-10 um 13.03.25.png"" /></div>"
<div>Inverse of a scalar and matrix</div><div><br /></div>	"<div>The <b>inverse</b> of a <b>scalar</b> a is equal to &nbsp;1/a:</div><div>&nbsp;<img src=""Bildschirmfoto 2017-10-10 um 13.04.15.png"" /></div><div><br /></div><div><b>Inverse</b> of a <b>matrix</b> A is equal to A<sup>-1</sup>&nbsp;</div><div><img src=""Bildschirmfoto 2017-10-10 um 13.04.18.png"" /></div><div><br /></div><div><br /></div><div><br /></div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span></div><div><br /></div>"
Inverse: <i>Detailed</i>	"<div>Inverse of a matrix <b>A</b></div><div>- Only defined if A is a square matrix.</div><div>- Only defined if A is of full rank (not explained here).</div><div><u>Example</u>:</div><div><img src=""Bildschirmfoto 2017-10-10 um 13.05.34.png"" /></div><div><br /></div><div><br /></div><div><b>- Note</b>: You must be able to check whether the given matrices are the inverse of each other.</div><div>- You don’t have to be able to compute the inverse of a matrix.</div><div><br /></div>"
<div>Multivariate data, and associated parameters: Matrix</div><div><br /></div>	"<img src=""Bildschirmfoto 2017-10-10 um 13.06.14.png"" />"
<div>Sum-of-squares: Matrix</div>	"<img src=""Bildschirmfoto 2017-10-10 um 13.06.38.png"" />"
<div>Parameters of multivariate distributions: Matrix</div>	"<img src=""Bildschirmfoto 2017-10-10 um 13.07.01.png"" /><div><br /></div><div><div><br /></div><div>- <b>Covariances</b> (how much the variances influence each other)</div><div>- <b>Symmetric</b> matrix fields are equal in size (covariance between A&amp;B = B&amp;A)</div><div><br /></div><div><br /></div><div><br /></div></div>"
<div>Determinant (Matrix)</div>	"<div><b>(co)variance matrix:</b></div><div>- Σ and S: Population and sample covariance matrix, respectively</div><div>- <i>Generalized variance:&nbsp;</i></div><div>the determinant of the sample covariance matrix</div><div><img src=""Bildschirmfoto 2017-10-10 um 13.07.56.png"" /></div><div><br /></div><div>- Association between the variables (covariance)&nbsp;</div><div>reduces the generalized variance</div><div>&nbsp; - Variation (variance) in one variable is attributed to variation in another variable</div><div><br /></div><div><br /></div><div><u>Examples - determinant:</u></div><div><div>Extreme case 1 (r = 1):</div><div><img src=""Bildschirmfoto 2017-10-10 um 13.08.53.png"" /></div><div><br /></div><div>Extreme case 2 (r = 0):&nbsp;</div><div style=""text-decoration: underline; ""><img src=""Bildschirmfoto 2017-10-10 um 13.08.55.png"" /></div></div><div style=""text-decoration: underline; ""><br /></div><div><div><i>S1 factor 1.5 (r=1) between values therefore =0</i></div><div><i>S2 (r=0) result will be equal to the product 4*9</i></div><div><u><br /></u></div><div><u><br /></u></div><div><u><br /></u></div><div style=""text-decoration: underline; ""><br /></div></div>"
Experimental control	<div><u>Control in experimentation</u></div><div>Eliminate confounding and minimize variability</div><div><br /></div><div><b>Control by randomization</b>: random assignment</div><div><b>Control by design</b>: Control nuisance variables</div><div>- Hold constant throughout experiment</div><div>- Counterbalance effects&nbsp;</div><div>- Model as extra factor (categorical IV): blocking</div><div>- Model as covariate (continuous IV): ANCOVA</div><div><br /></div>
<div>Why ANCOVA?</div>	<div>1. <b>Eliminate systematic differences</b> (bias) between the experimental groups</div><div>- Especially in non-experimental (observational) or quasi-experimental studies</div><div><br /></div><div>2.<b> Reduction of within group variance</b> (error variance)</div><div>- By making the groups more homogeneous (cf. blocking in factorial designs, repeated measures)</div><div>- More power</div><div><br /></div>
<div>ANCOVA in experiments</div>	"<div><u>Experiments</u>:</div><div>- Dealing with<b> systematic differences </b>(bias) by random assignment of subjects to groups</div><div>- Therefore, bias due to variables outside the experiment is the same for all groups</div><div>- And thus any <b>systematic differences</b> between groups is due to manipulation of the factors (under control)</div><div><br /></div><div><u>Then why use covariates?</u></div><div><b>Reduction of error variance</b></div><div>If group sizes are small, systematic differences (chance differences) are more possible</div><div>Use covariates to adjust means for differences</div><div><br /></div><div><br /></div><div><u>ANCOVA in other studies:</u></div><div>- Non experimental:</div><div><div>No random assignment to groups:</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>-&nbsp;Natural groups are used</div><div>This means that any systematic differences are due to initial differences (some variables) or due to manipulation of treatment levels (factors) ⇒ <b>confounded</b></div></div><div><b><br /></b></div><div>- again reduction of systematic bias by using covariates to adjust (posttest) means for initial differences:&nbsp;</div><div>i.e. groups start equally on the covatiates (equate the groups)</div><div>- also errors will be reduced</div><div><br /></div>"
<div><i>Analysis of Covariance</i>:&nbsp;<b>Covariate</b></div><div><br /></div>	<div><b>Covariate</b></div><div>- Usually continuous variable (interval level); categorical covariates are also used (rarely)</div><div>- To have an effect, the covariate should be &nbsp;correlated with the dependent variable</div><div>- Linear relationship (regression)</div><div>(when relation clearly non-linear, a transformation could help)</div><div>- Use this dependency to make better predictions (less bias, less uncertainty) of the means in the groups: Adjust the group means</div><div><br /></div>
<div><i>Analysis of Covariance</i>:&nbsp;<b>Combine regression and ANOVA</b></div><div><b><br /></b></div>	<div>1. Perform a regression analysis to predict the dependent variable using the covariates</div><div>The <b>residuals</b> of this analysis are ‘corrected’ values of &nbsp;the dependent variable</div><div><br /></div><div>2. Perform an ANOVA on the corrected dependent variable (residuals) to examine groups (treatments)</div><div><i>Combine both steps in one model</i></div><div><br /></div><div><br /></div>
<div>Equal regression slopes: <i>Univariate ANCOVA procedure</i></div>	"<div>1) Compute regression line to model association between X and Y.</div><div><i>This line has the same slope for all a groups.</i></div><div><br /></div><div>2) Determine the <b>within-groups variance</b> with respect to the regression lines (within the a groups).</div><div><br /></div><div>3) To calculate between-groups variance use differences between corrected (adjusted) means.</div><div>Calculate corrected means using the regression lines by filling in the <b>total mean of the covariate</b> (grand mean).</div><div><br /></div><div>4)&nbsp;Calculate <b>adjusted means </b>using the regression lines by filling in the mean of the covariate (grand mean)</div><div><br /></div><div>5) Testing treatment effects</div><div>- test <i>adjusted means µ<sub>i</sub>*: H<sub>0</sub>: µ<sub>1</sub>* = µ<sub>2</sub>* </i>using F test</div><div><img src=""Bildschirmfoto 2017-10-10 um 13.40.01.png"" /></div><div>- SS calculated via model-based approach</div><div><img src=""Bildschirmfoto 2017-10-10 um 13.40.32.png"" /></div>"
ANCOVA definition:	<div>- The analysis of covariance tests for differences between groups by comparing a description of the data based on a single regression line to one based on lines with the same slope and different intercepts for each group</div><div><br /></div><div>- Do not add covariates without considerable thought</div><div>Correlations between covariates cause problems</div><div><br /></div><div><i>Advice</i>: Never use more than two, and only use two if they are logically unrelated quantities and correlation is small</div><div><br /></div>
<div>Assumptions in ANCOVA:</div>	"<div><b>1. Independent</b> <b>observations</b></div><div>- Design, intraclass correlation</div><div><br /></div><div><b>2. Normally distributed error</b></div><div>- Scores (DV) in each group: Yi ~ N(μ<sub>i</sub>,σ)</div><div>- Skewness, kurtosis, PP-plot, histogram, Boxplot</div><div><br /></div><div><b>3. Homogeneity of variances</b></div><div>- Sample SDs, Levene test, BF-test</div><div><br /></div><div>- (1 to 3 are just the usual ANOVA assumptions) -&nbsp;</div><div><br /></div><div><div><b>4. Linearity</b></div><div>-<span class=""Apple-tab-span"" style=""white-space:pre""> </span>The relation between y and the covariate is linear.</div><div><br /></div><div><b>5. Homogeneity of regression slopes</b></div><div>-<span class=""Apple-tab-span"" style=""white-space:pre""> </span>The regression lines are parallel, i.e., groups have equal slopes</div><div>&nbsp;</div><div><b>6. The covariate is measured without error</b></div><div>-<span class=""Apple-tab-span"" style=""white-space:pre""> </span>Important with natural groups</div><div><br /></div><div><u>Correction of violations:</u></div><div><i>Transformations</i></div><div><i>Nonlinear ANCOVA</i></div></div><div><br /></div>"
<b>Violated</b>&nbsp;Assumptions in ANCOVA:	<div><b>Heterogeneous (unequal) regression slopes</b> indicate interactions between factors and covariates</div><div>- Test the significance of the interaction to investigate the assumption of homogeneous regression slopes</div><div>- Thus, a significant interaction effect indicates unequal slopes</div><div><br /></div><div><b>Unequal slopes</b> can be modeled by including the interaction in the model ≠ (traditional) ANCOVA</div><div>- However, only equal slopes ensure that differences in means are matched by differences in height of the regression lines, and H0 has the same meaning as in an ordinary ANOVA</div><div><br /></div>
<div>ANCOVA in randomized designs</div>	<div><b>Random assignment of subjects to groups</b></div><div>Systematic differences between subjects are more or less equally divided over groups</div><div>- No systematic differences in covariate means</div><div>- Primary effect is error reduction.</div><div><br /></div><div>When <u>pre-existing classification</u> is used (groups are defined by classification factor) systematic differences between the groups may arise:</div><div>- These are partially reflected in the covariate</div><div>- Pre-existing classification known as natural / intact groups</div><div><br /></div>
<div>ANCOVA with natural groups</div><div>(i.e. non randomized)</div>	"<div><b>Non-randomized designs:</b></div><div>- Systematic bias may exist between groups that is not due to manipulation of experimental factors</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span></div><div>__________________________________________________</div><div><b>Example</b>: Neuropsychological study</div><div>- Two groups of patients (natural groups) with brain damage</div><div>- Compare performance on cognitive task</div><div>- Performance (partially) related to age (covariate)</div><div>- Difference in performance between groups can be due to difference in brain damage but also to differences in age</div><div>- What happens when ANCOVA is used?</div><div><br /></div><div><i>ANOVA can give different results than ANCOVA</i></div><div><img src=""Bildschirmfoto 2017-10-10 um 13.46.26.png"" /></div><div><div>ANCOVA compares groups on equivalent basis (with respect to age)</div><div>- Correction of means: Describes how the data might have been if ages were comparable &nbsp;(Not realistic)</div><div><br /></div><div>ANCOVA tests different hypothesis in this situation:&nbsp;</div><div>- Test the ANOVA hypothesis as it would be when there were no systematic differences (on age)</div><div><br /></div><div>- Causes</div><div>Validity of linear regression model?</div><div>Is grand mean of covariate representative for all groups?</div><div>No measurement error in covariate? (Lord´s Paradox)</div></div><div><br /></div><div><br /></div>"
<div>Lord’s paradox</div><div><br /></div>	"<div><i>Investigating the effect on students of the diet provided in the university dining halls and any sex difference in these effects</i></div><div><i><br /></i></div><div><b>Dependent variable</b>: <u>Weight</u> of the students</div><div>- Pre measurement and post measurement of weight</div><div>- Two groups: Men and women</div><div><br /></div><div><br /></div><div>In Example:&nbsp;</div><div>- mean weight for both groups does not change:&nbsp;</div><div>- mean difference score is 0</div><div><br /></div><div>“Crucial question:&nbsp;</div><div>is group membership unrelated to pre-test score?”&nbsp;</div><div><img src=""Bildschirmfoto 2017-10-10 um 13.48.48.png"" /></div><div><b><br /></b></div><div><b>Explanation</b></div><div><div>ANCOVA asks conditional question: How much are the groups expected to change if they had both come from a population with the same baseline mean?</div><div><u>That is:&nbsp;</u></div><div>- The groups are compared with the average of the observed baseline means.</div><div>- For weight of men and women this is unrealistic:&nbsp;</div><div>Men and women do not have equal weights</div><div><br /></div><div>(Example of invalid ANCOVA with Natural groups)</div><div style=""font-weight: bold; ""><br /></div></div><div><br /></div><div><br /></div>"
<div>Structure Analyses&nbsp;</div><div><br /></div>	"<img src=""Bildschirmfoto 2017-10-10 um 13.50.37.png"" /><div><br /><div><img src=""Bildschirmfoto 2017-10-10 um 13.51.31.png"" /></div></div>"
<div>k-group case:<i>&nbsp;Univariate ANOVA</i></div><div><br /></div>	<div><b>Univariate ANOVA</b></div><div><br /></div><div><u>Assumptions</u>:</div><div>- populations: y1 ~ N(1,), … , yk ~ N(k,)</div><div>- k samples with size n1, … , nk &nbsp;(N = n1+ … + nk )</div><div>- is constant in all populations</div><div><br /></div><div><u>Test</u> &nbsp;H0: µ1 = µ2 = … = µk</div><div>- ANOVA F test: F= MS<sub>b</sub>/MS<sub>w</sub></div><div>- F distribution with (k – 1) and (N - k) <i>df’s</i></div><div><br /></div>
<div>k-group case:<i>&nbsp;Multivariate test</i></div><div><i><br /></i></div>	"<div><b>Multivariate test</b></div><div><br /></div><div><u>Assumptions</u>:</div><div>- vectors &nbsp;y1, … , yk have a <i>multivariate <b>normal</b> <b>distribution</b></i> with<u> means</u> µ1, … , µk and<u> covariance matrix</u> Σ</div><div>- k samples with sizes n1, … , nk</div><div>- Σ is <b>constant</b> across k groups</div><div>- <b>Linear</b> <b>relation</b> between all DV’s</div><div><img src=""Bildschirmfoto 2017-10-10 um 14.00.27.png"" /></div>"
<div>k-group MANOVA: <i>partitioning of (co)Variance </i>(uni/multivariate)</div><div><br /></div>	"<div><b>Univariate ANOVA:</b></div><div>Partitioning of total variance</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>SS<sub>total</sub> = SS<sub>bg</sub> + SS<sub>wg</sub></div><div><br /></div><div><b>Multivariate ANOVA for k-groups:</b></div><div>Partitioning of total covariance (matrix)</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>Total SSCP = Between SSCP + Within SSCP</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span><i>T = B + W</i></div><div><br /></div>"
<div>k-group MANOVA:&nbsp;<i>Test statistic</i></div><div><br /></div>	"<div>Test statistic<b> Wilks’ Λ</b>:</div><div><img src=""Bildschirmfoto 2017-10-10 um 14.06.08.png"" /></div><div><br /></div><div><i>Determinants</i> of SSCP matrices are <b>generalized variances</b></div><div>&nbsp;- Wilks’ Λ give <u>percentages</u> <b><font color=""#0000ff"">unexplained variance</font></b></div><div>&nbsp;-<i> measure of badness of fit&nbsp;</i></div><div>(cf. in regression R2 is the goodness of fit)</div><div>If <b>&nbsp;B = 0</b>, there is no treatment effect, and Λ = 1</div><div>If &nbsp;<b>W = 0</b>, there is no within group dispersion, and Λ = 0</div><div><br /></div><div><br /></div>"
<div>k-group MANOVA:&nbsp;<i>Distribution of Λ complicated&nbsp;</i></div><div><i><br /></i></div>	<div><u>approximate</u>:</div><div>- with χ2 distribution, with p(k – 1) <i>df’s</i></div><div>- with F distribution, with df’s that may be non-integer</div><div>- SPSS uses F, which is better for small n</div><div>- F is exact for some values of p and k (e.g., when k = 2)</div><div><br /></div><div><div><u>There are other statistics:</u></div><div>Roy’s largest root (based on BW<sup>-1</sup>)</div><div>Hotelling-Lawley trace (based on BW<sup>-1</sup>)</div><div>Pillai-Bartlet trace (based on BT<sup>-1</sup>)</div></div><div><br /></div>
<div>k-group MANOVA:&nbsp;<i>Which statistic to use?</i></div><div><i><br /></i></div>	<div>– Usually, statistics point in the same direction</div><div><br /></div><div>– <u>In case differences are observed:</u></div><div>- Wilks, Pillai-Bartlett, Hotelling-Lawley equally quite robust with respect to violation of the assumption of homogeneity of covariance matrices, provided that group sizes are approximately equal</div><div>- In some situations Roy's largest root has more power, but differences with respect to power between the four statistics are small</div><div>- Understanding of differences requires knowledge of discriminant analysis (treated in course Multivariate Models)</div><div><br /></div>
<div>k-group MANOVA:&nbsp;<i>Effect size</i></div><div><i><br /></i></div>	"<div>– p-value reports <i>significance</i>;&nbsp;effect size reports <i>relevance</i></div><div><br /></div><div>– <b>Effect size:</b> <font color=""#0000ff"">η2 = 1 – Λ</font></div><div>- Interpretation similar to R<sup>2</sup> in regression:&nbsp;</div><div>&nbsp; percentage of <i>explained (generalized) variance</i>.&nbsp;</div><div><br /></div><div>– <i>Problem</i>: Sum of all effects η2 might <i>exceed one</i>.</div><div><br /></div><div>– <i>Solution</i>: <font color=""#0000ff"">Partial η2</font> =<i> 1 – Λ<sup>1/s</sup> </i><u>where</u></div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>s = min(<i>nr. of DV’s, ‘Hypothesis df’ effect</i>)</div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-10 um 14.12.35.png"" /></div>"
Roy-Bargmann Stepdown Analysis	<div>- Method for selection of important DV’s</div><div><br /></div><div>- Conceptually similar to backward elimination in multiple regression</div><div><br /></div>
Roy-Bargmann Stepdown Analysis: <i>Procedure</i>	<div><b>Procedure</b>:</div><div>1. Rank order the DV’s, based on theoretical considerations, or effect sizes in separate ANOVAs&nbsp;</div><div><br /></div><div>2. Do a univariate ANOVA on the most important &nbsp;DV</div><div>- Significant: ‘select’ DV and go to step 3.&nbsp;</div><div>- Else: stop.</div><div><br /></div><div>3. Do ANCOVA with next-most significant DV as DV, and the selected DV as covariate.</div><div>- Significant: include DV in ‘selection list’, repeat 3.&nbsp;</div><div>- Not significant: stop. The selected DV’s are “most important”</div><div><br /></div>
MANOVA:&nbsp;<i>Type I and II errors:&nbsp;</i><div>Nominal and actual levels&nbsp;</div><div><br /></div>	<div>– <b>Terminology</b></div><div>- nominal α: α that you specify (e.g., 0.05)</div><div>- actual α: real α of the test (i.e., proportion of tests that are incorrectly declared significant if you test with your specified α)</div><div><br /></div><div>– <b>Violation</b> of model assumptions may affect&nbsp;</div><div>- <i>Type I errors</i>: nominal α and actual α differ</div><div>- Thus also nominal and actual Type II levels differ</div><div><br /></div>
MANOVA:<i>&nbsp;Two kind of Type I errors</i><div><br /></div>	"<div>1. <b>Actual α larger than nominal α:</b></div><div>- Test or test statistic is called <font color=""#0000ff"">liberal</font></div><div>- Consequence: Too often falsely rejecting H0</div><div><br /></div><div>2. <b>Actual α is smaller than nominal α:&nbsp;</b></div><div>- Test or test statistic is called <font color=""#0000ff"">conservative</font></div><div>- Consequence: Less often falsely rejecting H0</div><div><br /></div>"
<div>Model assumptions in (M)ANOVA</div><div><br /></div>	"<div>1. <b>Independent</b> observations</div><div><br /></div><div>2. Distributional assumptions within each group</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>ANOVA: Observations (of dependent variable) follow a &nbsp;normal distribution</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>MANOVA: <b>Multivariate normal distribution of dependent variables</b></div><div><br /></div><div>3. (Co)variances assumptions within each group</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>ANOVA: Population variances are equal&nbsp;</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>MANOVA: <b>within-group covariance matrices are equal</b></div><div><br /></div><div>4. <b>Linear relation between all DV’s</b></div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>ANOVA: not applicable (only 1 DV)</div><div><br /></div>"
<div>Model assumptions in (M)ANOVA:&nbsp;</div><div><br /></div><div><div>1. Independent observations</div></div>	"<div><b>No relationship between cases</b></div><div>– <u>Effect of violation:</u></div><div>- Estimators of standard errors are generally too small:&nbsp;</div><div>thus test liberal</div><div><br /></div><div>– <u>Detection of violation:</u></div><div>- Design: experiment, sample, data collection</div><div>- Intraclass correlation</div><div><br /></div><div>– <u>Correction of violation:</u></div><div>- Test at <i>more stringent level of significance</i>: Smaller nominal α level, such that the actual α will have a ‘normal’ value<span class=""Apple-tab-span"" style=""white-space:pre""> </span><i>Consequence</i>: Decreased power</div><div>- Much better: Model relationships between cases:&nbsp;</div><div>Hierarchical linear modeling (Rep.Measures: lectures 5a,5b,6)</div><div><br /></div>"
<div>Model assumptions in (M)ANOVA:&nbsp;</div><div><br /></div><div><div><div>2. Multivariate normality of dependent variables</div></div></div>	"<div>MANOVA: <u>Observations on dependent variables follow a multivariate normal distribution</u></div><div><br /></div><div>– <b>Stringent assumption, <i>meaning</i></b>:</div><div>- All individual variables univariate normally distributed</div><div>- Any linear combination normally distributed</div><div>- All subsets of variables are multivariate normally distributed</div><div><br /></div><div>– <b>Detection of violatio</b>n (necessary but not sufficient checks):</div><div>- Check the marginal distributions of the individual variables: univariate normal distributions</div><div>- Check bivariate distributions of all pairs of variables:</div><div>bivariate normal distributions</div><div><img src=""Bildschirmfoto 2017-10-10 um 14.19.56.png"" /></div><div><img src=""paste-9083855831374.jpg"" /></div>"
<div>Model assumptions in (M)ANOVA:&nbsp;</div><div><br /></div><div><div><div>(2.)&nbsp;Checking multivariate normality</div></div></div>	"<div><b>Checking univariate normality:</b></div><div><i>Graphs</i>: &nbsp;Probability plot (<font color=""#0000ff"">PP, QQ</font>), <font color=""#0000ff"">histogram</font>,<font color=""#0000ff""> box plot</font></div><div><i>Statistics</i>: <font color=""#0000ff"">Skewness, kurtosis</font></div><div><i>Tests</i>: <font color=""#0000ff"">Shapiro-Wilk test</font> – interpretation of non-significance</div><div>(Use combinations)</div><div><b><br /></b></div><div><b>Checking multivariate normality:</b></div><div>1. Check marginal distributions: Univariate normal</div><div>2. Check bivariate distributions − pairwise scatterplots:</div><div><i><font color=""#0000ff"">circle</font></i>: no association</div><div><i><font color=""#0000ff"">ellipse</font></i>: association (the thinner, the higher the correlation)</div><div><br /></div><div><b>Check whether scatterplot for each pair is <font color=""#0000ff"">elliptical</font></b></div><div><br /></div>"
<div>Model assumptions in (M)ANOVA:&nbsp;</div><div><br /></div><div><div><div>(2.)&nbsp;What if multivariate normality is violated?&nbsp;</div></div></div><div><br /></div>	"<div><b>Correction of violation:</b></div><div>- Transformation of the dependent variables (separately; Stevens gives examples for standardized variables)</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span><i>Consequence</i>: <i>More difficult to interpret</i></div><div>- Collect <i>more data</i> (central limit theorem)</div><div>- Data <i>trimming</i> (remove largest variables; outliers)</div><div>- Check if data contain <i>outliers</i> (and remove..??)</div><div>&nbsp; &nbsp;Inspect standardized or ‘studentized’ residuals&nbsp;</div><div>&nbsp; &nbsp;Between –3 and 3</div><div><br /></div><div><b>Alternative to correction:</b> Use appropriate model</div><div>- e.g., for binary dependent variable: logistic multilevel model</div><div><br /></div>"
<div>Model assumptions in (M)ANOVA:&nbsp;</div><div><div><br /></div><div><div><div><div>3. Equality of within-group covariance matrices&nbsp;</div></div></div></div><div><div><b>Effect of violation:</b></div></div></div><div><b><br /></b></div>	"<div>Within each group: <u>variances and covariances are equal</u></div><div>= Homogeneity of Σ<sub>g</sub>, g = 1,…, G groups</div><div><br /></div><div><b>Effect of violation:</b></div><div>- For equal group sizes actual α levels are very close to the nominal α levels</div><div>- For unequal group sizes:&nbsp;</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>&nbsp;sometimes F <i>liberal</i> (large variances, small groups)</div><div>&nbsp; sometimes <i>conservative</i> (large variances, large groups)</div><div>-<i> Balanced designs</i> (all n<sub>ij</sub> equal) are very important</div><div><br /></div>"
<div>Model assumptions in (M)ANOVA:&nbsp;</div><div><br /></div><div><div><div><div>3. Equality of within-group covariance matrices&nbsp;</div></div></div></div><div><div><b><div>Checking Equality and Correction</div><div><br /></div></b></div></div>	<div><div><b>Checking Equality</b></div></div><div><i>- Visual</i>: compare observed within-covariance matrices&nbsp;</div><div><i>- Test</i> with Box’s M test&nbsp;</div><div>&nbsp;Be cautious, use of a significance test to confirm H<sub>0</sub>&nbsp;</div><div>&nbsp;Box’s M test very sensitive for non-normality</div><div><br /></div><div><div><b>Correction of violation:</b></div></div><div><div>- Transformation of the individual variables, to stabilize the variances (EXAMINE in SPSS)</div><div>&nbsp; &nbsp;relationship means and SD’s &nbsp;square root</div><div>&nbsp; &nbsp;proportions &nbsp;(arcsine transformation)</div><div>- Use different model (i.e., multilevel model)</div></div><div><br /></div>
"<div><i>Model assumptions in (M)ANOVA:&nbsp;</i></div><div style=""font-weight: bold; ""><br /></div><div><div><div><div>4. Linear relation between DV’s (checking and correction)</div></div></div></div><div><div><span style=""font-weight: bold""><div><br /></div></span></div></div>"	"<div><b>Checking</b>:</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>Scatterplots of Yi vs Yj</div><div><br /></div><div><b>Correction</b>:</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>- Transformations</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>- Nonparametric MANOVA (not part of this course)</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>- If only one out of many DV’s misbehaves: Remove it</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span></div><div><br /></div>"
"<div><i>Model assumptions in (M)ANOVA:&nbsp;</i></div><div style=""font-weight: bold; ""><br /></div><div><div><div><div><b>Guidelines</b></div></div></div></div><div><div><span style=""font-weight: bold""></span></div></div>"	<div><u>Guidelines</u></div><div>1. Check <b>independence</b> assumption</div><div>2. Check multivariate <b>normality</b></div><div>3. Check <b>equality of (co)variances</b> with Box M</div><div>4. Check <b>linear relations</b></div><div><br /></div><div><i>If ‘not 4’ then check sample sizes n and variances (using determinants):</i></div><div>- Roughly equal sample size: actual and nominal &nbsp;α's about the same</div><div>- Determinant(s) largest for smaller sample size groups: test liberal</div><div>- Determinant(s) largest for larger sample size groups: test conservative</div><div><br /></div>
<div>Multiple comparisons</div><div><br /></div>	"<div><u>More than one comparison among the treatment means:</u></div><div>- “statistical minefield”&nbsp;</div><div>- multiple testing affects error rates</div><div><br /></div><div><br /></div><div><b>Example:&nbsp;</b></div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>I = 4 treatments &nbsp;test six null hypotheses:&nbsp;</div><div>H0: µ1 = µ2, H0: µ1 = µ3,<span class=""Apple-tab-span"" style=""white-space:pre""> </span>H0: µ1 = µ4, H0: µ2 = µ3, H0: µ2 = µ4, H0: µ3 = µ4</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span></div><div>- Take <i>alpha</i> = 0.05 for each test, than the overall error rate for six independent comparison equals 1 – (1 – 0.05)6 = 0.26</div><div>- Capitalization on chance: <i>Falsely reject H0 too often&nbsp;</i></div><div><br /></div>"
<div>Post-hoc tests</div><div><br /></div>	<div><b>General idea</b>: When testing several (related) hypotheses,&nbsp;</div><div>adjust critical values of test</div><div>(or corresponding p values and confidence intervals)</div><div><br /></div><div>- <i>Bonferroni</i> procedure for dependent t tests</div><div>in multivariate approach</div><div><br /></div>
<div>Bonferroni procedure</div><div><br /></div>	<div><b>General multiple testing procedure</b></div><div>– When performing a number of tests, say m, at level α, the probability of making a Type I error increases (chance capitalization)</div><div>– This probability is maximally m x α&nbsp;</div><div>Instead of performing each test at level α, use significance level equal to α/m to guarantee overall level of α</div><div><br /></div>
Contrasts in MANOVA:&nbsp;	"<div>– Specify comparison under contrasts or via L-matrix in GLM module, or make your own transformed variables</div><div><br /></div><div>– Key idea: Test combination of effects</div><div><br /></div><div>– Example: 4 treatment groups, i.e., we have µ1, µ2, µ3, µ4</div><div>- Research question: Is treatment 1 better than treatments 2 through 4?</div><div>- Effect to test:&nbsp;</div><div><img src=""Bildschirmfoto 2017-10-10 um 14.36.29.png"" /></div>"
Contrasts in MANOVA:&nbsp;Coefficients for Contrasts	"<img src=""Bildschirmfoto 2017-10-10 um 14.36.56.png"" /><div><img src=""Bildschirmfoto 2017-10-10 um 14.37.07.png"" /></div>"
Advantages of&nbsp;Contrasts:	<div>– Working with independent contrasts has many advantages (Stevens, 5.10)</div><div><br /></div><div>– Various contrasts coefficients specify same contrast</div><div>(1, -1/2, -1/2)</div><div>(-1, 1/2, 1/2)</div><div>(2, -1, -1)</div><div><br /></div><div>– To fix a choice, often (non-necessary) guidelines:&nbsp;</div><div>- largest coefficient – smallest coefficient = 1</div><div>- First non-zero coefficient is positive</div><div><br /></div>
<div>Preferred testing approach</div><div><br /></div>	<div>– The fewer tests, the better</div><div>- Prefer contrasts over multiple comparisons&nbsp;</div><div><br /></div><div>– Post-hoc tests</div><div>- Bonferroni</div><div>- In specific cases (e.g. with a reference group),&nbsp;</div><div>specific alternatives better</div><div><br /></div><div>– Conceptual post hoc testing is similar to situation univariate ANOVA</div><div><br /></div>
Type I error (α)	<b>Chance to reject the null hypothesis, while the null hypothesis is true</b><div><b><br /></b></div><div>- reducing alpha increases chance of Type II error</div><div>- only way to reduce both is to increase sample size</div>
“<b>nominal</b> α” and “<b>actual</b> α”	- <b>nominal alpha</b> is the one you chose (.05)<div><br /></div><div>- <b>actual</b> <b>alpha</b> is the real alpha of a certain test given a certain sample</div><div><br /></div><div>(if all assumptions are met, and you only perform one test; actual = nominal)</div>
Type II error (ß)	"<b>Chance to not reject the null hypothesis, while the null hypothesis is not true.&nbsp;</b><div><br /></div><div>- This means that based on the sample, you would assume no relation exists between the dependent and independent variable, when there really is one.</div><div>- Unlike the α, it’s not possible to directly set the level of type II error, but it is linked to the α, along with the sample size and effect size.&nbsp;</div><div>- When α increases, ß will decrease.</div><div><img src=""Bildschirmfoto 2017-10-15 um 13.16.02.png"" /></div><div><br /></div>"
Power (1 – ß)	<b>Chance to reject the null hypothesis, while the null hypothesis is not true</b><div><b><br /></b></div><div>- increasing Type II will decrease power</div><div>- increasing power by increasing alpha, adding variables (reducing unexplained variance)</div>
Effect size:	<b>the size of the effect, which aims to provide information free from sample size, to get an idea how strong an effect is in practice.&nbsp;</b><div><br /></div><div>- Examples are <b>η²</b> for (M)AN(C)OVA or <b>R² </b>for regression.</div><div>- the effect size is low, it takes a large sample size before this small effect is significant.&nbsp;</div><div>- If the effect size is large, the sample size required to prove the existence of this effect in the population will obviously be a lot lower.</div>
Chance capitalization:	<b>problem with performing many consecutive analyses, and the reason why it’s not recommended</b><div>- i.e. k*(k-1)/2</div><div>- for alpha .05 with 6 tests equals .95<sup>6</sup>= .735 meaning at least one error with 26.5% chance</div><div>- no way to find out which test or how many</div><div><br /></div>
Statistical significance vs. Practical significance:	-&nbsp;<b>Statistical</b> significance is to look at the<b> p-value</b> alone from a significance test, and decide whether to reject the null hypothesis based on this value<div>-&nbsp;<b>Practical</b> significance is about whether the effect that was found in a sample actually matters in practice, something only the researcher can decide</div><div><br /></div><div>– <i>average</i> sample sizes, statistical significance usually overlaps with practical significance</div><div>–&nbsp;<i>huge</i> sample size even the smallest difference is statistically significant, while perhaps not being practically relevant</div><div>- conversely, with a <i>tiny</i> sample size a medium effect size isn’t enough to find a statistically significant result, while possibly still useful in practice (uncertainty when generalizing a tiny sample size of, say, 10 people to the population, but it might well provide an interesting starting point for future research and possible covariates)</div><div><br /></div><div>(both types of significance should be considered, using different alpha values to bring them in sync - larger sample and smaller alpha)</div>
Outliers:	-&nbsp;can majorly influence results when they’re particularly far away from the mean or when the sample size is small<div>-&nbsp;rule of thumb is to look for values that are more than 3 standard deviations away from the mean (most appropriate for average sample sizes; for large <i>n </i>use 5SD)</div><div>-&nbsp;measures to find outliers are <i>Cook’s Distance</i> and <i>Mahalanobis Distance</i></div>
Cook’s distance	-&nbsp;measures the influence of points, and should be smaller than 1
Mahalanobis Distance	also sometimes transformed to Leverage, is based on how far away an observed value is from the mean, and should be smaller than 15
Proper design for proper analysis:	- proper measurement<div>- what measured is assumed real</div><div>- get the most accurate scores</div><div>- limit non response</div><div>- no third variables</div><div>- generalize to the right population</div><div>- external motives of researcher´s papers</div>
Experimental research: There are three ways in which they differ from observational research:	1. <b>Random</b> assignment to groups (removes any third variable statistically; with natural groups it´s useful to include covariates)<div><br /></div><div>2. Treatments may be <b>manipulated</b></div><div><br /></div><div>3. Allow <b>causality</b> to be proven beyond reasonable doubt</div>
Null hypothesis:	“There is no relation between the independent and dependent variable(s)”<div><br /></div><div>- <b>ANOVA</b>: SSG=0,&nbsp;so there is no difference between the group means and by extension the total mean. This means that <i>“H<sub>0</sub>: µ1 = µ2 = … = µk”</i></div><div>-&nbsp;<b>matched pairs t-test</b> shows that the difference between the mean of the pre- and post- measurement being divided by the SE. When the means of both measurements are equal, 0 is divided by the SE, which would lead to a t-value of 0, so <i>“H<sub>0</sub>: difference score = 0”</i></div>
There are three major types of hypothesis:	<div>H<sub>0</sub> : All group means are equal</div><div>H<sub>0</sub>&nbsp;: Difference score is equal to 0</div><div>H<sub>0</sub>&nbsp;: There is no relation between variables</div><div><br /></div><div>H<sub>a</sub> : At least one group mean is different</div><div>H<sub>a</sub> : Difference score is different from 0</div><div>H<sub>a :</sub> There is a relation between variables</div>
Continuous variable	A variable containing scores, such as IQ or extraversion
Categorical variable	A variable containing group identification, like gender or education level
Ordinal variable	A categorical variable with an order, like education level
Nominal variable	A <b>categorical</b> variable <u>without</u> order, like gender or favourite colour
Binary/Dichotomous variable	A categorical variable with two groups, like gender
Population&nbsp;	– A particular group of people in the world a theory is developed for
Sample&nbsp;	– A particular group of people that theory is tested on, to generalise to the population
Descriptive Statistics&nbsp;	– Statistics that aren’t meant to be generalized, but are used to summarize&nbsp;observed values (<i>Mean, Histogram, Standard Deviation, Median</i>)
Inferential Statistics	– Statistics that tries to generalise values from a sample to a population (Significance testing, Confidence Interval)
Orthogonal	– <b>Independence between variables</b> (<i>r = 0</i>).&nbsp;<div>- Orthogonal actually means “90-degree angle”, which corresponds to two variables being completely independent from each other in matrix algebra, because a change on a horizontal axis doesn’t affect the value on the vertical axis</div>
Sequential / Hierarchical analysis	– Analysis for which variables are entered in steps instead of all at once, so that different sets can be tested instead of just the entire model or individual variables
Linear combination	"– A sum of two or more numbers. Even 2 + 2 = 4 is a linear combination.&nbsp;<div>It’s an all-encompassing <b>term for two or more variables being summarized </b>as an<b> <font color=""#0000ff"">expected</font> <font color=""#0000ff"">value</font></b> (<i>linear regression</i>), <b><font color=""#0000ff"">function</font></b> (<i>MANOVA &amp; Discriminant Analysis</i>), or <b><font color=""#0000ff"">factor</font></b> (<i>Factor Analysis</i>)</div>"
Effect Size	– Reflects the size of an observed effect for a certain test. This effect could for instance be a relation between variables, difference between groups, or proportion explained variance
Between Group Effect	– The <i>part of the Sum of Squares Total</i> that is <u>explained</u> by the <b>difference between groups</b>
Within Group Effect (Residuals)	"– The <i>part of the Sum of Squares Total</i> that is&nbsp;<u><i><font color=""#ff0000"">not</font></i></u> explained by the <b>difference between groups</b>, thus <b>remaining unexplained</b>"
Between-Subjects Effect	– Reflects the <b>difference between groups</b> of <i>unrelated subjects</i>
Within-Subjects Effect	– Reflects the <b>difference between multiple measurements</b> of <i>one subject</i>
Fixed Factor	– A <b>categorical variable</b> that limits itself to the listed groups in the population
Random Factor	– A <b>categorical variable</b> where the listed groups are a random representation of a bigger pool of groups in the population.&nbsp;<div><br /></div><div>For instance: Selecting 10 random hospitals out of all hospitals in the Netherlands. Multilevel analysis is especially suited to test these factors.</div>
Bivariate r	Reflects the <u>strength</u> of the <i>linear relationship</i> between two <b>continuous</b> or <b>binary</b> <b>variables</b>. Is part of the statistical base for many other tests, such as MANOVA, regression, multilevel modelling and factor analysis. (Statistics 1A)
Chi-Square (test)	– Reflects <i>degree of association</i> between <b>two categorical variables</b> (Statistics 1B)
Multiple R	– <i>Degree of linear association</i> between a <u>set</u> of <b>continuous or binary variables</b> (IV), and a <b>single continuous variable</b> (DV).&nbsp;<div><br /></div><div>Mostly used as part of multiple linear regression. The <i>set of variables is being combined into one variable</i>, like the predicted values based on the linear combination of the model for regression, followed by a calculation of the correlation between this variable and the DV. (Statistics 2)</div>
Sequential R	"– <i>Degree of linear association</i> between a <b>set of continuous or binary variables</b> (<font color=""#0000ff"">IV</font>), after <b>correcting</b> for variables that were <i>previously entered in the model</i>, and a <b>single continuous variable</b> (<font color=""#0000ff"">DV</font>).&nbsp;<div><br /></div><div>- Mostly used as part of <i>hierarchical linear regression</i>.&nbsp;</div><div>- The set of variables is being combined into one variable, like the predicted values based on the linear combination of the model for regression, followed by a calculation of the correlation between this variable and the DV. (Statistics 3)</div>"
Canonical Correlation	"– <i>Degree of linear association </i>between a <b>set</b> of <b>continuous or binary variables</b>, and <font color=""#0000ff"">another</font> <b>set of continuous or binary variables</b>.&nbsp;<div><br /></div><div>Both<i> sets are combined</i> into one variable through a linear combination of either set, followed by a <i>correlation</i> between <b>both</b> linear combinations. (Multivariate Models)</div>"
Multiway Frequency Analysis	"– <i>Degree of association</i> between <b>multiple categorical variables</b>, when<font color=""#0000ff""> no</font> <u>variable is clearly defined as IV or DV</u>, like with correlation. (Multivariate Models)"
Multilevel Modelling	"– Overarching term for <i>multiple types of models</i> which all have the same goal of <b>trying to predict the degree of association between variables</b>, while taking into account that some groups are <font color=""#0000ff"">nested</font> into other groups.&nbsp;<div><br /></div><div>For instance, Psychology students may be compared to Sociology students, with study year (1, 2, 3, Master) as a nested group of study. (Repeated Measures)</div>"
T-test	To test the <i>difference between two groups</i> of a <b>single independent variable</b>, on a <b>single dependent variable</b>. (Statistics 1B)
Oneway-ANOVA	– To test the <i>difference between two or more groups</i> of a <b>single independent variable</b>, on a <b>single dependent variable</b>. (Statistics 2)
Oneway-ANCOVA	"– To test the <i>difference between two or more groups</i> of a <b>single independent variable</b>, on a <b>single dependent variable</b>, where a (set of) <u>continuous variable(s)</u> is <font color=""#0000ff"">added</font> to the model to <b>reduce error and/or bias</b>. (Multivariate &amp; Repeated)"
Twoway-ANOVA	– (Factorial ANOVA) To test the<i> difference between two or more groups</i> of <b>two or more independent variables</b>, on a <b>single dependent variable</b>. (Statistics 2)
Twoway-ANCOVA	"– (Factorial ANCOVA) To test the <i>difference between two or more group</i>s of <b>two or more independent variables</b>, on a <b>single dependent variable</b>, where a (set of) <u>continuous variable(s)</u> is <font color=""#0000ff"">added</font> to the model to <b>reduce error and/or bias</b>. (Multivariate &amp; Repeated)"
Hotelling’s T²	"– (Not identical to Hotelling’s Trace for MANOVA) To test the <i>difference between </i><font color=""#0000ff"">two</font><i> groups</i> of a <b>single independent variable</b>, on<b> two or more dependent variables</b>.&nbsp;<div><br /></div><div>(Multivariate &amp; Repeated)</div>"
Oneway-MANOVA	– To test the<i> difference between two or more groups</i> of a <b>single independent variable</b>, on<b> two or more dependent variables</b>.<div><br /></div><div><br /></div><div>&nbsp;(Multivariate &amp; Repeated)</div>
Oneway-MANCOVA	"– To test the <i>difference between two or more groups</i> of a <b>single independent variable</b>, on <b>two or more dependent variables</b>, where a (set of) continuous variable(s) is <font color=""#0000ff"">added</font> to the model to <b>reduce error and/or bias</b>.&nbsp;<div><br /></div><div>(Multivariate &amp; Repeated)</div>"
Twoway-MANOVA	– (Factorial MANOVA) To test the <i>difference between two or more groups</i> of <b>two or more independent variables</b>, on <b>two or more dependent variables</b>. (Multivariate &amp; Repeated)
Twoway-MANCOVA	"– (Factorial MANCOVA) To test the <i>difference between two or more groups</i> of <b>two or more independent variables</b>, on <b>two or more dependent variables</b>, where a (set of) continuous variable(s) is <font color=""#0000ff"">added</font> to the model to <b>reduce error and/or bias</b>. (Multivariate &amp; Repeated)"
Repeated Measures ANOVA	"– To test the<i> difference between two or more groups</i> of <b>one or more independent variables</b>, on <b>one dependent variable</b> that has been<font color=""#0000ff""> measured multiple times</font>. Especially useful with small samples and no missing data (Statistics 3 &amp; Repeated)<div><br /></div>"
Repeated Measures MANOVA / Profile Analysis	"– To test the <i>difference between two or more groups</i> of <b>one or more independent variables</b>, on <b>one dependent variable</b> that has been <font color=""#0000ff"">measured multiple times</font>.&nbsp;<div>Especially useful with <u>lack of sphericity and no missing data</u>&nbsp;</div><div><br /></div><div>(Repeated Measures)</div>"
Discriminant Analysis	"– The mathematical <font color=""#0000ff"">opposite</font> of a MANOVA.&nbsp;<div>- Using <b>one more continuous independent variables</b>, one or more functions are created that optimally <i>combine all independent variables</i> in such a way that <u>explained variance is maximised</u> while <u>minimising the number of functions</u>.&nbsp;</div><div><br /></div><div>These functions are used to <b>predict group membership</b>, <i>defined by the dependent variable</i>, of each participant.&nbsp;</div><div>- Similar to MANOVA, it is possible to <i>expand</i> discriminant analysis to <u>multiple categorical variables </u>(<b>Factorial Discriminant analysis</b>), and like linear regression it is possible to perform a <u>hierarchical analysis</u> (<b>Sequential Discriminant Analysis</b>).&nbsp;</div><div><br /></div><div>(Multivariate Models)</div>"
Multiway Frequency Analysis (Logit)	"- Degree of <i>association between multiple categorical variables</i>, with <font color=""#0000ff"">clearly</font> <b>defined dependent variables and independent variables</b>. (Multivariate Models)"
Logistic Regression	"– On the basis of <b>one or more categorical or continuous independent variables</b>, the <font color=""#0000ff"">probability</font> to be <b>part of each group</b> of the dependent variable is calculated separately.&nbsp;<div>The predicted group membership is the group with the highest calculated probability.&nbsp;</div><div><br /></div><div>(Statistics 2)</div>"
Principal Component Analysis	– An analysis that tries to estimate w<b>hich variables from a set</b> have a <i>similar latent structure on a purely statistical basis</i>, with <b>no</b> room for possible theories. (Multivariate Models)
Factor Analysis	– An analysis capable of testing a theory regarding a <b>latent structure underlying a set of variables</b>. Unlike PCA above, there is <i>room for theory here</i>. (Multivariate Models)
Matrix Algebra	- uses a group of numbers as a single entity<div>- its not possible to divide matrices</div>
(3x2) Matrix:	"<div><img src=""Bildschirmfoto 2017-10-10 um 17.28.56.png"" /></div>A set of numbers with at least two rows (horizontal) and columns (vertical).&nbsp;<div>- This is a (3x2) matrix as there are a three rows and two columns.&nbsp;</div><div>- The first number always reflects the number of rows, the second always reflects number of columns.&nbsp;</div><div>- The notation is like A, both a <b>capital letter </b>and<b> bold</b></div>"
(3x1) Vector:	"<div><img src=""Bildschirmfoto 2017-10-10 um 17.29.46.png"" /></div>One column of potentially unlimited numbers.&nbsp;<div>- As this vector has three 3 numbers, it’s a 3x1 matrix.&nbsp;</div><div>- The difference between a vector and a matrix is that a vector has just one column, while a matrix has more than one.&nbsp;</div><div>- A matrix with just one row is called a<i> transposed vector</i></div><div>- The notation for a vector is a, a <b>small letter</b>, but still <b>bold</b>.</div>"
(1x1) Scalar:&nbsp;	"<div><img src=""Bildschirmfoto 2017-10-10 um 17.30.22.png"" /></div>A number like any other.&nbsp;<div>- Most wouldn’t call this a matrix, as it consists of just one number</div><div>- The notation is a, <b>small letter </b>and&nbsp;<b>italics</b>.&nbsp;</div><div>- Sometimes this notation is also used to point out one value of a matrix.&nbsp;</div><div><br /></div><div>For instance, you could point to the 3 on the left-bottom site of the matrix above with “a 31 ”, as it is the scalar of matrix “A”, on the third row, first column.</div>"
Transposed:	"To transpose a matrix is to turn each row into a column, and each column into a row:<div><img src=""Bildschirmfoto 2017-10-10 um 17.33.20.png"" /></div><div>- First row becomes first colum (1,2,3)</div><div>-&nbsp;notation of a transposed vector is <b>a’</b></div><div>- notation of a transposed matrix is <b>A’</b></div>"
Square matrices	"have several unique properties over matrices in general i.e.:<div><u><br /></u></div><div><div style=""text-decoration: underline; ""><u>Main diagonal:</u></div><div>- <b>top left to bottom right</b> (a<sub>11</sub>,a<sub>22</sub>,a<sub>33</sub>)</div><div>- only makes sense in a square matrix</div><div>- important in <i>correlational</i> <i>matrix</i> (diagonal = 1)</div></div><div><br /></div><div><u>Tract:</u></div><div>- <b>Sum of the values</b> of the main diagonal</div><div><img src=""Bildschirmfoto 2017-10-10 um 17.40.36.png"" /></div><div><u><br /></u></div>"
Triangular Matrix:	"Like the name says, the values are all in triangular formation. This means that the <b>main diagonal</b>, and <font color=""#0000ff"">only</font> <b>one of the sides</b> of the diagonal <i>has values besides 0</i>.&nbsp;<div>- The other side only has scalars of 0.&nbsp;<div><br /></div><div>Two examples:<div><img src=""Bildschirmfoto 2017-10-10 um 17.42.52.png"" /></div></div></div>"
Symmetric Matrix:	"In mathematical terms, a symmetric matrix is <b>any square matrix that doesn’t change when transposing it</b>.&nbsp;<div>- This would mean both sides of the main diagonal are mirrors of each other, so that the <u>first row is equal to the first column</u>, the <font color=""#0000ff"">second row is equal to the second column</font>, and so on.&nbsp;</div><div>- A well-known example is a correlation matrix.&nbsp;<div><img src=""Bildschirmfoto 2017-10-10 um 17.43.24.png"" /></div><div>-&nbsp;Symmetric matrices are common in MANOVA, as every SSCP-matrix, covariance matrix and correlation matrix is symmetric.</div></div>"
Diagonal Matrix:	"A special case of a symmetric matrix, where <b>every value besides the main diagonal is 0</b>.<div>- As only the scores of the diagonal are different from 0, giving this matrix the name “diagonal” makes sense.<div><img src=""Bildschirmfoto 2017-10-10 um 17.44.34.png"" /></div></div>"
Scalar Matrix:	"A special case of a diagonal matrix, where <b>every value of the main diagonal is the same</b>, and every <b>value not on the main diagonal is 0</b>.<div>- As the scalar is just one number, and this matrix has only one number besides 0, the name makes sense too.<div><img src=""Bildschirmfoto 2017-10-10 um 17.45.28.png"" /></div></div>"
Identity Matrix:	"A special case of a Scalar Matrix. Identity means <b>all values on the main diagonal are equal to 1</b>, while the <b>values not on the main diagonal are equal to 0</b>.&nbsp;<div>Examples:<div><img src=""Bildschirmfoto 2017-10-10 um 17.45.50.png"" /></div></div><div>-&nbsp;Identity matrix are useful in many formulas, as <i>multiplying with an identity matrix doesn’t change the values but might change the size of a matrix</i></div>"
Summation and Subtraction of Matrices:	"<div>1) Addition and subtraction works the same way as with normal numbers</div><div>2) Addition and subtraction is <u>only</u> <font color=""#0000ff"">allowed</font> when <b>both matrices, vectors or scalars have the same number of rows and the same number of columns.</b></div><div><img src=""Bildschirmfoto 2017-10-10 um 17.50.51.png"" /></div><div>In both cases the two scalars on the same position are being summed or subtracted. This means A + B is always <u>exactly the same </u>as B + A, just like 2 + 3 and 3 + 2 show the same result.</div>"
Multiplication of Matrices:	"<b>Each row of the first matrix is multiplied with each column of the second matrix</b><div>-&nbsp;also means that <font color=""#0000ff"">only the length of the rows of the first matrix needs to be equal to the length of the columns in the second matrix</font>.&nbsp;</div><div><u><br /></u></div><div><u>So the main rule here is:</u></div><div><div>1.) Length of rows in first matrix = Length of columns in second matrix</div><div>2.) Number of columns in first matrix = Number of rows in second matrix</div><div><br /></div><div>An example:</div></div><div><img src=""Bildschirmfoto 2017-10-10 um 17.52.57.png"" /></div>"
Importance of order and equality in Matrix multiplication:	"<div>Differs from example for A*B:</div><img src=""Bildschirmfoto 2017-10-10 um 17.53.48.png"" /><div><br /></div><div>When the number of columns of the first matrix is <b>not equal</b> to the number of rows in the second matrix, the following problem happens:</div><div><img src=""Bildschirmfoto 2017-10-10 um 17.55.02.png"" /></div><div>-&nbsp;we can multiply both matrices if we take the <b>transpose</b> of A:</div><div><img src=""Bildschirmfoto 2017-10-10 um 17.58.20.png"" /></div><div>Every row on the left needs to be multiplied by every column up top. This would lead to:</div><div><img src=""Bildschirmfoto 2017-10-10 um 17.58.58.png"" /></div><div><img src=""Bildschirmfoto 2017-10-10 um 17.59.11.png"" /></div><div>- this shows that matrices or vectors needn´t have the exact same number of rows and columns to multiply them</div><div>- in fact,&nbsp;<b>except</b> for square matrices, having two matrices with the same number of rows and columns don’t work for multiplication (i.e. both have 4 rows and 2 columns, then the number of columns of the matrix is not equal to the number of rows of the second matrix)</div><div><br /></div><div>The size of the matrix <b>after</b> <b>multiplication</b>&nbsp;is <u>equal</u> to the <i>number of rows of the first matrix</i>, and <i>equal to the number of columns of the second matrix</i>. This can be shown with a small vector:</div><div><img src=""Bildschirmfoto 2017-10-10 um 20.37.56.png"" /></div><div>We had 2 rows in the first vector and 2 columns in the second vector, so the end result is a 2x2 matrix. As a side note: multiplying a vector by its transpose always leads to a <i>symmetrical matrix</i>. This is also why covariance-variance matrices are necessarily symmetrical</div><div><br /></div><div>If we multiply <b>a’ </b>by<b> a</b>, we get something different:</div><div><img src=""Bildschirmfoto 2017-10-10 um 20.40.38.png"" /></div><div>We had 1 row in the first vector and 1 column in the second vector, so the end result is a 1x1 matrix, or a scalar. <i>Multiplying the transpose of a vector by itself always leads to a scalar</i>.</div>"
Division of Matrices:	"- it is impossible with matrices<div>- but&nbsp;dividing by a number is the <font color=""#0000ff"">same as multiplying</font> by its <b>inverse </b>(for many but not all square matrices one can find the inverse)&nbsp;</div><div>-&nbsp;The <b>inverse</b> of a particular number that <i>if you multiply the inverse with that number, you’d get exactly 1 </i>(0.5 for 2)<img src=""Bildschirmfoto 2017-10-10 um 20.53.12.png"" /></div><div><br /></div><div><br /></div><div>-<u> inverses only exist for square matrices&nbsp;</u></div><div><br /></div>"
Inverse of a square Matrix:	-&nbsp;is a <i>matrix of equal size</i> that if <u>multiplied by the original matrix</u>, will lead to an<b> identity matrix of again the same size</b> (1 for each value of main diagonal, 0 for all other values)<div>-&nbsp;like the inverse of 1 = 1, the inverse of an identity matrix is an identity matrix</div><div><br /></div><div>(for the <u>exam</u>: important to check if two matrices are their inverse, therefore multiply them, if you get an identity matrix they are each other´s inverse)</div>
In order for Matrices to be multiplyable:	the number of <b>columns</b> of the <u>first</u> matrix need to be identical to the number of <b>rows</b> of the <u>second</u> matrix
The size of the matrix after multiplication is equal to?	the number of <b>rows</b> of the<u> first</u> matrix, and equal to the number of <b>columns</b> of the <u>second</u> matrix (<i>multiplying a vector will always give a symmetrical matrix</i>)
Multiplying the transpose of a vector by itself:	-&nbsp;always leads to a <b>scalar</b><div>(1 row in the first vector and 1 column in the second vector, so the end result is a 1x1 matrix, or a scalar)</div>
Determinant	"can theoretically be understood as a <b>single value</b> to <b>represent the matrix as a whole</b>. For a scalar (1x1 matrix), the determinant is equal to the scalar. For a 2x2 matrix, we can calculate the determinant like this:<div><img src=""Bildschirmfoto 2017-10-10 um 21.20.22.png"" /></div><div>So for example:</div><div><img src=""Bildschirmfoto 2017-10-10 um 21.21.22.png"" /></div>"
Using the Determinant to calculate the Inverse	"<img src=""Bildschirmfoto 2017-10-10 um 21.22.08.png"" /><div><div>We need to perform three steps to calculate the inverse for a 2x2 matrix:</div><div><br /></div><div>1) <b>Switch</b> the <i>places</i> of a<sub>11</sub>(4) and a<sub>22</sub>(8)</div><div>2) <b>Switch</b> the <i>sign</i> of a<sub>12</sub>(6) and a<sub>21</sub>(5 (positive numb</div><div>er becomes negative, and vice versa)</div><div>3) <b>Divide</b> all numbers by the <i>determinant</i> (<b>|A| </b>= 2)</div><div><img src=""Bildschirmfoto 2017-10-10 um 21.24.32.png"" /></div></div><div><br /></div><div><br /></div><div><br /></div><div><u>Testing the procedure</u> by multiplying&nbsp;<b>A </b>by<b> A´</b></div><div><img src=""Bildschirmfoto 2017-10-10 um 21.25.14.png"" /></div><div>(I<sub>2</sub>&nbsp;because of 2 ones in the matrix)</div><div><img src=""Bildschirmfoto 2017-10-10 um 21.26.30.png"" /></div>"
Three steps to calculate the inverse: 2x2	<div>1) <b>Switch</b> the <i>places</i> of a<sub>11</sub>(4) and a<sub>22</sub>(8)</div><div>2) <b>Switch</b> the <i>sign</i> of a<sub>12</sub>(6) and a<sub>21</sub>(5) – (positive number becomes negative, and vice versa)</div><div>3) <b>Divide</b> all numbers by the <i>determinant</i> (<b>|A|&nbsp;</b>= 2)</div>
If the determinant equals 0	no inverse can be formed
SSCP-matrix &amp; Covariance matrix contain information about:	-&nbsp;the <b>spread</b> of the <b>scores</b> for <u>each variable</u>, and the <i>degree of association between multiple variables</i><div>- both of them are necessarily <i>symmetric</i> matrices, as the covariance between variable 1 &amp; 2 = covariance between variable 2 &amp; 1, like with a correlation matrix</div>
Steps to calculate a covariance Matrix:	"The <b>first</b> step is to find the <u>differences between each observed score and the mean of that particular variable</u>, similar to the red, bolded part of this formula:<div><img src=""Bildschirmfoto 2017-10-10 um 21.45.04.png"" /></div><div>The <b>second</b> step is to <u>multiply this matrix of difference scores with itself</u>. As stated before, we can only multiply two matrices if the number of columns from the first matrix is equal to the number of rows of the second matrix. We can’t multiply the matrix by itself in its current shape, as 5 is not equal to 2. But we can <b><font color=""#0000ff"">transpose</font></b> X to fix this:</div><div><br /></div><div><br /></div><div>The <b>third</b>&nbsp;step is to divide the <u>SSCP-matrix by the degrees of freedom</u>, in this case n – 1, as can be seen in the formula for variance. We still can’t divide with matrices, but we may multiply the <b><font color=""#0000ff"">inverse</font></b>. This number is a <i>scalar</i>, which is unique in that a matrix may be freely multiplied by a scalar regardless of the size of the matrix. This multiplication may be done by multiplying each value of a matrix by the scalar. In this case, n – 1 = 5 – 1 = 4, which has an inverse of 0.25.</div>"
Step 1 in calculating a Covariance Matrix:	"<div>(<b>Variance</b>)</div><div><br /></div>find the differences between each observed score and the mean of that particular variable, similar to the red, bolded part of this formula:<div><img src=""Bildschirmfoto 2017-10-10 um 21.45.04.png"" /></div><div>(The variable mean was subtracted from each observed value)</div>"
Step 2 in calculating a Covariance Matrix:&nbsp;	"<div>(<b>SSCP</b> - Matrix)</div><div><br /></div>is to <font color=""#0000ff"">multiply this matrix of difference scores with itself</font>. As stated before, we can only multiply two matrices if the number of columns from the first matrix is equal to the number of rows of the second matrix. We can’t multiply the matrix by itself in its current shape, as 5 is not equal to 2. But we can transpose X to fix this:<div><br /></div><div><img src=""Bildschirmfoto 2017-10-10 um 21.48.10.png"" /></div><div><br /></div><div><b>Multiplying the transpose</b> with the original matrix of difference scores is equal to squaring all difference scores in the original formula:&nbsp;</div><div><img src=""Bildschirmfoto 2017-10-10 um 21.49.25.png"" /></div><div><font color=""#0000ff"">Sum of Squares</font> is literally the sum of the squares of the difference scores, and <font color=""#0000ff"">Cross-Products</font> are literally products of cross equations.</div>"
Step 3 in calculating a Covariance Matrix:	"<div>(<b>Covariance </b>Matrix)</div><div><br /></div>to <font color=""#0000ff"">divide the SSCP-matrix by the degrees of freedom</font>, in this case n – 1, as can be seen in the formula for variance. We still can’t divide with matrices, but we may multiply the <b>inverse</b>. This number is a scalar, which is unique in that a matrix may be freely multiplied by a scalar regardless of the size of the matrix. This multiplication may be done by multiplying each value of a matrix by the scalar. In this case, n – 1 = 5 – 1 = 4, which has an inverse of 0.25.<div><img src=""Bildschirmfoto 2017-10-10 um 21.52.06.png"" /></div><div><br /></div>"
How to interpret a Covariance Matrix? (example case)	"Example:&nbsp;<div><img src=""Bildschirmfoto 2017-10-10 um 21.56.55.png"" /></div><div>covariance, and by extension the correlation, are equal to 0. When all <b>covariances are equal to 0, all variables are independent</b> from each other.&nbsp;</div>"
How to recognize a perfect correlation between variables?	"<img src=""Bildschirmfoto 2017-10-10 um 21.57.55.png"" /><div><div>These two variables have a correlation of 1, which can be shown in two ways:</div><div><br /></div><div><u><b>1) Another formula from Statistics 1A:</b></u></div></div><div><img src=""Bildschirmfoto 2017-10-10 um 21.58.55.png"" /></div><div><div>All of these numbers can be found in the matrix, therefore: (<font color=""#0000ff"">square variance</font>!)</div><div>Covariance = 2, SD<sub>1</sub> = 1, SD<sub>2</sub> =√4&nbsp;=2</div></div><div><img src=""Bildschirmfoto 2017-10-10 um 21.59.45.png"" /></div><div>(With this formula, a standardized degree of linear association can always be calculated based on the covariance between both variables and the variances or standard deviations of both variables.)</div><div><br /></div><div><br /></div><div><u><b>2) If correlation = 1, then determinant will be 0:</b></u> (1 * 4) – (2 * 2) = 4 – 4 = 0</div><div><br /></div><div><br /></div>"
The Determinant of a Covariance Matrix is known as?	<b>Generalized Variance</b>
Generalized Variance (caution!)	"<i>the generalized variance decreases when the covariance (or correlation)</i> <i>increases, and is equal to 0 when both variables perfectly correlate</i><div>- it might be tempting to think of it as SSE or MSE. But generalized variance is something else entirely</div><div><br /></div><div><u>Example</u>:</div><div>SSE and MSE are dependent on the dependent variable, and will always be equal or smaller than the total sum of squares (SST) or variance of the dependent variable (MST). The <b>determinant</b>, however, may be <b>larger</b> than the variance of the dependent variable:</div><div><img src=""Bildschirmfoto 2017-10-10 um 22.05.20.png"" /></div><div>Variance of the second variable = 11. Determinant = 6.50 * 11 – 0 * 0 = 71.50, which is clearly larger</div><div><br /></div><div>-&nbsp;This means that<font color=""#0000ff""> generalized variance</font> is more of a <i><u>general measure of association between all variables</u></i>, independent of what is chosen as independent and dependent variable, while <u>MSE and SSE</u> show the part of the variance that is <b>not</b> explained by the model</div><div>-&nbsp;Only by dedicating a covariance matrix to the error and total variance, calculating the generalized variances of both and dividing the one from the error matrix by the one of the total matrix, can we get a measure of unexplained (generalized) variance. This is exactly how Wilks’ Lambda is found</div>"
T-test: <i>Purpose</i>, <i>Formula</i>	"- used to <i>compare</i> the scores of <b>two groups</b> on a <b>single dependent variable</b><div>- It also uses the <i>pooled standard deviation</i>, which means both groups are assumed to have an equal standard deviation in the population:</div><div><img src=""Bildschirmfoto 2017-10-11 um 14.56.21.png"" /></div>"
T-test:&nbsp;<i>Assumptions</i>	<div>1) <b>Independence</b>: Every measurement should be measured in equal circumstances and be otherwise unrelated. If this is not true, a relationship between scores will, on average, bring them closer together. This causes the standard deviation, and by extension the p-value, to decrease, so that the actual α is larger than the nominal α.</div><div><br /></div><div>2) <b>Homoscedasticity</b>: As we can see in the formula, the pooled standard deviation is being used. This means that we fill in the same value of <i>s<sub>p</sub></i> for both groups, which obviously only works if the standard deviation for both groups is reasonably similar. If this is violated, the <i>s<sub>p</sub></i> is a biased estimator of the real standard deviation, leading to inaccurate p-values.</div><div><br /></div><div>3) <b>Normality</b>: We divide the difference between the means by the standard error to get a t- value, which we are able to translate to a p-value through the t-distribution. This t- distribution is rather normally distributed, so if the actual sample means aren’t normally distributed, estimating a p-value based on the t-distribution is inaccurate.</div><div><br /></div><div>4) <b>No measurement error</b>: While observing which group of a categorical variable someone belongs to usually happens without error, the same can’t be said for a continuous variable, especially when measured with questionnaires. Even though no test has a 100% reliability, we still pretend that what we’ve measured is the real score of that person. This is fine when reliability is high, but if it’s low it’s another source of error (and maybe even bias) on top of the unexplained variance we already have for our model, therefore decreasing accuracy.</div>
Relationship T-test and ANOVA	- when doing the independent sampes t-test using the pooled standard deviation, the<i> t value</i> may be <b>squared</b> to find the <i>F value</i> that would be given if the groups are compared through ANOVA<div>-&nbsp;also works in reverse if the ANOVA has two groups (not with more groups)</div><div>-&nbsp;t-test can be seen as a “special case” of ANOVA for two groups (added benefit of immediately telling us which group is larger through t-values, as they, unlike F values, <i>can be negative</i>)</div>
oneway&nbsp;ANOVA: <i>Assumptions</i>	Independence<div><br /></div><div>Normality</div><div><br /></div><div>Homoscedasticity</div><div><br /></div><div>No measurement error</div>
oneway&nbsp;ANOVA:&nbsp;<i>H<sub>o</sub>&nbsp;hypothesis</i>	"µ<sub>1</sub>&nbsp;= µ<sub>2</sub>&nbsp;= ... = µ<sub>k</sub><div><sub><br /></sub></div><div><i>y</i><sub style=""font-style: italic; "">ij</sub>&nbsp;= µ<sub style=""font-style: italic; "">total</sub>&nbsp;<i>+ e<sub>ij</sub></i></div><div><i><sub><br /></sub></i></div><div><sub>States that all group means are equal, and by extension equal to&nbsp;µ</sub><sub style=""font-style: italic; "">total</sub></div><div><sub style=""font-style: italic; "">- </sub><sub>this is why <i>ai </i>is left out from the Null hypothesis, as it would be 0 for every group (useless addition)</sub></div><div><sub><br /></sub></div>"
oneway&nbsp;ANOVA:&nbsp;<i>H<sub>a</sub>&nbsp;hypothesis</i>	"""<b>At least one of the group means is different from one or more of the other group means</b>""<div>- so necessarily at least one group mean is different from µ<sub>total</sub>&nbsp;so <i>a<sub>j</sub>&nbsp;</i>is needed to correctly account for that difference in group means<br /><div><br /></div><div><i>y</i><sub style=""font-style: italic; "">ij</sub>&nbsp;= µ<sub style=""font-style: italic; "">total</sub>&nbsp;+&nbsp;<i>a<sub>j</sub>&nbsp;+ e<sub>ij</sub></i></div><div><i><sub><br /></sub></i></div><div><i><sub><br /></sub></i></div><div><i><sub>&nbsp;µ<sub style=""font-style: italic; "">total is the grand means of all observed scores</sub></sub></i></div><div><i></i><i>&nbsp;y</i><sub style=""font-style: italic; "">ij</sub>&nbsp;<sub>is an observed value of the dependent variable</sub></div><div><i>&nbsp;a</i><sub><i>j is the difference between the mean of group </i>j and grand mean&nbsp;</sub></div><div><i><sub style=""vertical-align: sub; "">&nbsp;</sub>e<sub style=""vertical-align: sub; "">ij is the residual for each individual</sub></i></div></div>"
oneway ANOVA Assumption: <i>Independence </i>(meaning, assessment, correction)	- no relationship between the individual measurements (when variables are dependent the SD, and therefore p-value will decrease, so actual alpha is larger than the nominal alpha)<div><br /></div><div>- measure it through autocorrelation between each observed value and the value measured before that</div><div><br /></div><div>- lower the nominal alpha (get the actual back to .05); of lack of independence is due to design RM-(M)ANOVA or multilevel analysis can be used</div>
oneway&nbsp;ANOVA Assumption:&nbsp;<i>Normality&nbsp;</i>(meaning)	- as the F-test is based on a normal distribution, violation may lead to bias and inaccurate p-values (as MSE is part of every F-test of ANOVA, the assumption of normality mainly concerns the <i>residuals</i>)<div><br /></div><div>- residuals are assumed to follow <i>N(0, sigma); </i>if the distribution is too flat, the p-value will be estimated too low (it´s possible to reject the null hypothesis when it shouldn´t have been) if the distribution will be estimated too high, the p-value will be estimated too high (it´s possible not to reject the null when it should have been)</div><div><br /></div><div>- <i>Skewness</i>&nbsp;to either side can potentially in/- decrease the p-value depending on how the groupmeans are distributed (makes it even more difficult to predict what will happen to the p-values)</div><div><br /></div><div>- <i>Central limit theorem</i>&nbsp;makes sure the ANOVA is robust against violations (with larger <i>n</i>&nbsp;increasing its resistance)</div>
Skewness	to either side can potentially increase and decrease the p-value depending on how the group means are distributed, which makes it even more difficult to predict what happens to a p-value when this assumption is violated<div><br /></div>
oneway&nbsp;ANOVA Assumption:&nbsp;<i>Normality&nbsp;</i>(checking)	Graphical:<div>- residuals can be pictured in a <b>histogram</b>, so that we can see whether a normal pattern is followed. (bellshape)</div><div>- or by means of a<b> P-P plot</b> of residuals (should be close to the line)</div><div><br /></div><div><br /></div>
oneway&nbsp;ANOVA Assumption: <i>Skewness and Kurtosis</i>	-&nbsp;<b>Skewness</b> shows how asymmetrical the distribution is<div>- <b>Kurtosis</b> shows whether the distribution is too flat or a peak that’s too high</div><div><br /></div><div>-&nbsp;Similar to other calculations of standard error, skewness and kurtosis are considered significant when the absolute value of the statistic is over <b>twice as high as the SE</b></div><div><br /></div><div>-&nbsp;sample size heavily influences the SE, so, ironically, when one increases sample size to decrease concerns about normality due to the Central Limit Theorem, you actually increase the chance to conclude that there’s a significant difference from normality</div><div><br /></div><div>- graphs are the preferred mehtod (S&amp;K work great as descriptives)</div>
<i>Skewness </i>interpretation:	<div><b>Skewness &lt; 0</b> means the distribution is left skewed, which means the longer tail is on the left, which means the peak is to the right of the centre.</div><div><br /></div><div><b>Skewness = 0</b> means the distribution is symmetrical.</div><div><br /></div><div><b>Skewness &gt; 0</b> means the distribution is right skewed, which means the longer tail is on the right, which means the peak is to the left of the centre.</div>
<i>Kurtosis&nbsp;</i>interpretation:	<div><b>Kurtosis &lt; 0</b> means that the peak is too low and the distribution is too flat, so there aren’t enough values near the centre, while there are too many in both tails of the distribution</div><div><br /></div><div><b>Kurtosis = 0</b> means that the relative amount of values in the peak and tails of the distribution are equal to a normal distribution</div><div><br /></div><div><b>Kurtosis &gt; 0 </b>means that the peak is too high and the tails are too low, so there are too many values near the centre, while there are not enough values in both tails of the distribution</div>
Skewness and Kurtosis: <i>Statistical Test</i>	"-&nbsp;also suffer from easily rejecting the assumption with a <i>large sample size</i>, so be careful when using them in that case<div>-&nbsp;null hypothesis for any statistical test surrounding any assumption is “<i>This assumption has been met</i>”. This is probably the single time where a non-significant result is always preferred</div><div><img src=""Bildschirmfoto 2017-10-11 um 15.56.04.png"" /></div><div>-&nbsp;distribution of the dependent variable for all separate groups were tested, which is identical to testing whether the residuals are normally distributed</div><div>-&nbsp;No distributions were significantly different from the normal distribution. This means it should be safe to assume normality for this data</div>"
oneway&nbsp;ANOVA: <i>What to do&nbsp;when normality is violated?</i>	-&nbsp;If it’s caused by <b>outliers</b>, they can be deleted as long as deletion of cases can be backed up theoretically<div>-&nbsp;<b>transform</b> the scores in such a way that the transformed variable follows a more normal distribution</div><div>-&nbsp;increasing <b>sample size</b> will also increase resistance to non- normality, thereby increasing accuracy of the result</div><div>-&nbsp;a <b>model</b> that does not assume normality can be chosen, like the logistic multilevel model</div>
oneway&nbsp;ANOVA:&nbsp;<i>Homoscedasticity </i>(meaning)	- means that the <b>variance and standard deviations of the residuals are equal</b> for each group (<i>pooled standart deviation</i>&nbsp;which&nbsp;is basically a weighted mean of the standard deviations of all groups)<div><br /><div>- this&nbsp;means large groups have more influence on it than small groups. A group with 1000 participants has about 10 times as much influence on the pooled standard deviation than a group with 100 participants&nbsp;</div></div><div><br /></div><div>- If the group with 1000 participants has the higher SD, it will drag the pooled standard deviation up with it, often leading to an <u>overestimation of MSE</u> (estimated p-values are too high, so an actual α smaller than the nominal α)</div><div>-&nbsp;If the group with 1000 participants has the lower SD, it will drag the pooled standard deviation down with it, often leading to an <u>underestimation of MSE</u> (estimated p-values are too low, so an actual α higher than the nominal α)</div><div><br /></div><div>- a balanced design on the other hand is more robust against a violation of homoscedasticity</div>
oneway&nbsp;ANOVA:&nbsp;<i>Homoscedasticity&nbsp;</i>(checking)	"<div><u>The rule of thumb is:</u></div><div>“Largest standard deviation should be smaller than 2 times the smallest standard deviation”</div><div><br /></div><div><b>Levene´s significance test</b>, with the <font color=""#0000ff"">null hypothesis that the standard deviation of all groups are equal </font>(sensitive to sample size,&nbsp;for large sample sizes the null hypothesis almost always gets rejected)&nbsp;</div><div>-&nbsp;if the test is<b> not significant</b>, don´t reject the null hypothesis that the groups have equal SD, so it´s save to not reject homoscedasticity (if it´s significant we would violate homoscedasticity)</div>"
oneway&nbsp;ANOVA:&nbsp;<i>Homoscedasticity, what to do if violated?</i>	-&nbsp;<b>Outliers</b> may influence the standard deviation (remove)<div>-&nbsp;<b>transform</b> the scores so that the standard deviations are more similar to each other</div><div>-&nbsp;use a method that <b>doesn’t assume </b>homoscedasticity, like Kruskal-Wallis</div>
oneway&nbsp;ANOVA:<i>&nbsp;No measurement error</i>	- need for high reliability of tests
oneway&nbsp;ANOVA:<i>&nbsp;Outliers</i>	- rule of thumb: <b>univariate outlier 3SD´s +/- from the mean</b> (though this might be acceptable for larger samples <i>n</i>&nbsp;= 500)<div><br /></div><div>-&nbsp;<u>Cook’s Distance</u> (CD &lt; 1 = not influential, CD ≥ 1 = influential) and&nbsp;<u>Leverage</u> to look for bivariate outliers (each measurement can be tested for a significant Leverage at a default of α = 0.001)</div>
oneway&nbsp;ANOVA:<i>&nbsp;Sum of Squares Between Groups (SSG)=</i>	"<b>Variance</b> in scores <i>explained</i> by the <b>difference between the group means and the overall mean</b>, so the variance we <b><font color=""#0000ff"">can</font></b> explain based on this model. We usually want this to be as large as possible.<div><img src=""Bildschirmfoto 2017-10-11 um 16.44.29.png"" /></div>"
oneway&nbsp;ANOVA:&nbsp;<i>Sum of Squares Within Groups (SSE) =</i>	"<b>Variance</b> in scores <u>explained</u> by the <b>difference between the observed value and the mean of the group they belong to</b>, so the variance we <b><font color=""#0000ff"">cannot</font></b> explain based on this model. We usually want this to be as small as possible.<div><img src=""Bildschirmfoto 2017-10-11 um 16.44.32.png"" /></div>"
oneway&nbsp;ANOVA:&nbsp;<i>Sum of Squares Total (SST) =</i>	"<b>All</b> <b>variance</b> in scores on the dependent variable (not s², but all variation), so the sum of the squared difference scores between the overall mean and all individual scores.<div><img src=""Bildschirmfoto 2017-10-11 um 16.44.35.png"" /></div>"
oneway&nbsp;ANOVA:&nbsp;<i>Degrees of Freedom Between Groups (DFG) =</i>	"<b>Degrees of Freedom dependent on the number of groups that take part in the analysis.</b><div><img src=""Bildschirmfoto 2017-10-11 um 16.45.35.png"" /></div><div><br /></div><div>(the number of degrees of freedom can be defined as the minimum number of independent coordinates that can specify the position of the system completely)</div>"
oneway&nbsp;ANOVA:&nbsp;<i>Degrees of Freedom Within Groups (DFE)=</i>	"Degrees of Freedom <b>dependent</b> on the<b> total number of participants and groups</b> that take part in the analysis. Also used as the DF for each possible follow-up t-test that uses the pooled standard deviation<div><img src=""Bildschirmfoto 2017-10-11 um 16.45.37.png"" /></div>"
oneway&nbsp;ANOVA:&nbsp;<i>Degrees of Freedom Total (DFT) =</i>	"Degrees of Freedom <b>dependent</b> on the <b>total number of participants</b> that take part in the analysis<div><img src=""Bildschirmfoto 2017-10-11 um 16.45.44.png"" /></div>"
oneway&nbsp;ANOVA:&nbsp;<i>Mean Square Between Groups (MSG) =</i>	"Simply SSG/DFG, there is nothing else this value is needed for besides being a stepping stone between SSG/DFG and the eventual F-value &amp; p-value.<div><img src=""Bildschirmfoto 2017-10-11 um 16.47.11.png"" /></div>"
oneway&nbsp;ANOVA:&nbsp;<i>Mean Square Within Groups (MSE) =</i>	"<b>(Pooled standard deviation)²</b> = Pooled variance.&nbsp;<div><br /></div><div>-Useful for multiple comparisons &amp; contrasts, as both used the pooled standard deviation by default.<div><img src=""Bildschirmfoto 2017-10-11 um 16.42.29.png"" /></div></div>"
oneway&nbsp;ANOVA:&nbsp;<i>Mean Square Between Groups (MST) =</i>	"Variance of the dependent variable (<b>so this is s²</b>).<div><img src=""Bildschirmfoto 2017-10-11 um 16.43.03.png"" /></div>"
oneway&nbsp;ANOVA:&nbsp;<i>F =</i>	"F-value, a test statistic to help translate the Mean Squares into a certain p-value, given that the assumptions are not violated.<div><img src=""Bildschirmfoto 2017-10-11 um 16.43.36.png"" /></div>"
oneway&nbsp;ANOVA: <i>p =</i>	"p-value, the <b>chance that we find this result, or a more extreme result, given that the null hypothesis is true</b>.&nbsp;<div>- In this case, that we find these differences or bigger differences between the groups, given that all group means are equal in the population. If p &lt; α, it’s statistically significant.<div><img src=""Bildschirmfoto 2017-10-11 um 16.43.52.png"" /></div></div>"
oneway&nbsp;ANOVA:&nbsp;<i>General Information</i>	-&nbsp;oneway-ANOVA is often used to compare <b>more than two groups</b> of <b>one independent variable</b> on a <b>dependent variable</b><div><br /></div><div>-&nbsp;core of the idea behind ANOVA in general is to <u>divide all variance in the dependent variable</u> (SST) <u>into smaller parts</u> (for oneway-ANOVA this means SSG and SSE)</div><div>-&nbsp;If the variance between groups clearly exceeds the error variance, so if F is far above 1, the differences between the groups probably aren’t random, which means the groups really are different from each other</div><div><br /></div><div>- F is never a negative value (t<sup>2</sup>=F)</div><div>-&nbsp;means that unlike the z-test &amp; t-test, we can’t draw conclusions about the direction of an effect from an F-value itself, just that there is one (therefore: post hoc, and contrasts)</div><div><br /></div>
Confidence interval (CI):	"in general is: “<b>A range of values so defined that there is a specified probability that the value of a parameter lies within it</b>”<div><br></div><div>-&nbsp;So for the mean of a group, a 95% CI means: ”<font color=""#0000ff"">A range of values so defined that there is a 95% chance that the mean of the group in the population lies within it</font>”</div><div><br></div><div>-&nbsp;This means that when two confidence intervals do not or only slightly overlap (rule of thumb is 25% overlap and below), we’re reasonably certain the means of the groups are different in the population</div>"
Post Hoc: <i>Multiple Pairwise Comparisons</i>	- multiple t-tests fall for <b>chance capitalization</b><div><i>k * (k - 1)/2; at alpha .05 this means: .95<sup>6</sup>=.735&nbsp;for k = 4</i></div><div>i.e. alpha for 6 tests is .265</div><div><i><br /></i></div><div><i><br /></i></div><div>- therefore use of LSD &amp; Bonferroni</div><div>- LSD is more liberal than Bonferroni</div><div>- Bonferroni often to conservative</div><div>- use LSD for <i>k&lt;3</i>&nbsp;and Bonferroni for more than 3 groups</div>
Post Hoc:&nbsp;<i>LSD</i>	"-&nbsp;effective with small numbers of groups (<b>i&nbsp;&lt; 3</b>)<div>-&nbsp;By relying on the general principle that an ANOVA result has to be significant before proceeding with these Post-Hoc tests, and by using the MSE and DFE from the ANOVA table instead of just the two groups it is comparing, it limits α based on theory</div><div>-&nbsp;maintains the power of the t-tests</div><div>- but alpha increases too much with i greater 3</div><div><br /></div><div>Example:</div><div><img src=""Bildschirmfoto 2017-10-11 um 17.05.01.png"" /></div><div><br /></div>"
Post Hoc:&nbsp;<i>Bonferroni</i>	<u>Bonferroni takes the number of pairwise comparisons into account:</u><div><br /><div>1.)&nbsp;can be computed by either multiplying the p-value by the number of pairwise comparisons, so you can judge at the level of nominal α (SPSS)</div><div>2.)&nbsp;by dividing the nominal α by the number of pairwise comparisons, so you can judge the calculated p-values at the level of the new, lower level of α (Statistics 2)</div></div><div><br /></div><div>-&nbsp;Confidence intervals are also affected (use new, lower alpha), therefore, wider in Bonferroni</div><div><br /></div>
Post Hoc: <i>Contrasts</i>&nbsp;(general information)	"-&nbsp;<b>test a few specific combinations of groups for differences</b> (1 vs. 4)<div>-&nbsp;means we don’t need to correct for chance capitalization (not so many tests)</div><div>- maintain power</div><div>-&nbsp;have a limited number (= DFG) of contrasts to work with</div><div>-&nbsp;also make use of the pooled standard deviation and DFE, so results from a repeated and simple contrast, which are also pairwise comparisons, completely overlap with the LSD method from multiple comparisons</div><div><br /></div><div>Example:</div><div><img src=""Bildschirmfoto 2017-10-11 um 17.29.44.png"" /></div><div>- group1 is sign. different from the overall mean (p &lt; .001)</div><div>-&nbsp;negative contrast estimate and 95% CI show that the mean with the negative coding was larger than the mean with positive coding</div><div>- i.e.&nbsp;mean of group 1 in the population is probably lower than the overall mean in the population</div>"
Post Hoc:&nbsp;<i>Contrasts</i>&nbsp;(default contrasts)	<b>Simple, Deviation, Helmert, Difference, Repeated</b><div><br /></div><div>-&nbsp;default contrasts always have one group that gets a +1, while the group or groups they’re being compared to spread -1 equally over themselves</div><div>-&nbsp;may not be readily apparent with Deviation contrast as it contains no +1 or -1, but keep in mind that the deviation group compares a single group (+1) to the mean of all groups</div><div>-&nbsp;Simple &amp; Deviation contrast need a reference group (-)</div>
Post Hoc:&nbsp;<i>Contrasts</i>&nbsp;- simple	"Compares all group means to the mean of the reference group:<div><img src=""Bildschirmfoto 2017-10-11 um 17.26.13.png"" /></div>"
Post Hoc:&nbsp;<i>Contrasts</i>&nbsp;- deviation	"Compares all group means (except the reference group) to the grand overall mean:<div><img src=""Bildschirmfoto 2017-10-11 um 17.26.42.png"" /></div>"
Post Hoc:&nbsp;<i>Contrasts</i>&nbsp;- helmert	"Compares each group mean with the mean of all groups that follow:<div><img src=""Bildschirmfoto 2017-10-11 um 17.27.25.png"" /></div>"
Post Hoc:&nbsp;<i>Contrasts</i>&nbsp;- difference	"Compares each group mean with the mean of all previous groups:<div><img src=""Bildschirmfoto 2017-10-11 um 17.27.45.png"" /></div>"
Post Hoc:&nbsp;<i>Contrasts</i>&nbsp;- repeated	"Compares each group mean with the mean of the next group:<div><img src=""Bildschirmfoto 2017-10-11 um 17.28.06.png"" /></div>"
Post Hoc:&nbsp;<i>Contrasts</i>&nbsp;vs. <i>Multiple Comparison</i>	-&nbsp;A huge argument in favour of contrast is that <b>sets of group can be compared</b> instead of just pairwise comparisons<div>-&nbsp;contrasts don’t need to be corrected for increased levels of α</div><div>-&nbsp;A major downside to contrasts is that <i>not every possible difference is tested</i>, unless you want to risk increasing α to dangerous levels</div><div><br /></div><div>-&nbsp;LSD and Bonferroni do test everything, but LSD is often too liberal, leading to increased α, and Bonferroni is often too conservative, leading to increased ß</div>
oneway ANOVA:&nbsp;<i>Effect Size&nbsp;</i>	-&nbsp;is a measure for ho<b>w different the groups are, independent of sample size</b> (η² (eta squared))<div>-&nbsp;theoretically identical to R², but while R is between continuous/binary variables, eta reflect the degree of association between a categorical and continuous variable, like with ANOVA</div><div><br /></div><div>-&nbsp;η², like R², reflects the proportion explained variance (<b>SSG/SST</b>)</div><div>-&nbsp;η² is especially useful to help give insight to how large an effect really is in smaller samples, as they are rarely statistically significant unless the effect is especially huge, or with large samples as nearly any effect is statistically significant there</div>
Twoway-ANOVA (Factorial ANOVA): <i>General Information</i>	-<b>&nbsp;null</b> <b>hypothesis</b>, <b>assumptions</b> and ideas behind the <b>calculations</b> are identical to oneway-ANOVA<div>-&nbsp;now we have to watch for <b>multicollinearity</b></div><div>-&nbsp;that we have two or more independent variables, <b>interaction</b> effects between independent variables may now be added to the model</div>
Twoway-ANOVA (Factorial ANOVA):&nbsp;<i>Multicollinearity</i>	"- strong correlation between two independent variables (one fairly accurately predicts the other)<div>-&nbsp;Only when you care about the <b>unique</b> <b>explained</b> <b>variance</b> of each variable (which is admittedly quite often), does multicollinearity matter</div><div>- ""singular"" completely explained by other IV (thrown out)</div><div>- <b><font color=""#0000ff"">VIF</font></b> checks for multicollinearity:&nbsp;</div><div><img src=""Bildschirmfoto 2017-10-11 um 17.55.10.png"" /></div><div>(R<sup>2</sup>&nbsp;is the proportion explained variance of other independent variables for variable j, square of the correlation between the two)</div><div>- Rule of thumb&nbsp;is that VIF &lt; 4 (or <i>R<sup>2</sup><sub>j</sub></i>&nbsp;&lt; .75) is fine, and VIF ≥ 4 (or&nbsp;<i>R<sup>2</sup><sub>j</sub></i>&nbsp;≥ .75) is not, but of course, in general we want the multicollinearity to be as low as possible, leading to a VIF of 1 or&nbsp;<i>R<sup>2</sup><sub>j</sub></i>&nbsp; of 0 if we care about the effects of each separate independent variable</div><div>- high VIF still allows (M)ANOVA, but try to compute with/- out variable of highest multicollinearity</div><div>- don´t remove more than one at the same time</div><div><br /></div><div><br /></div>"
Twoway-ANOVA (Factorial ANOVA):&nbsp;<i>Multicollinearity with only <b>categorical variables</b></i>	"-&nbsp;in that case it completely depends on sample size<div>-&nbsp;When the design is balanced (table 1) or proportional (table 2), there is no multicollinearity. When it is unbalanced (table 3), there will be multicollinearity</div><div><img src=""Bildschirmfoto 2017-10-11 um 18.01.27.png"" /></div><div>-&nbsp;If correlation between two variables exist, it means we can use the score on the first variable to say something about the likelihood of various values on the second variable</div>"
Twoway-ANOVA (Factorial ANOVA): <i>Calculations</i>	- the ANOVA table has expanded to test two more effects; both the second independent variable and the interaction effect between the first and second independent variable
Twoway-ANOVA (Factorial ANOVA):&nbsp;<i>Main Effect</i>	If we want to know the main effect for factor A, then we compare the three levels of A as if B didn’t even exist. Just imagine all people from both A1B1 and A1B2 forming a super group of A1, being compared to A2 and A3. The main effect for factor B will compare B1 and B2, as if factor A wasn’t even in the model<div><br /></div><div>- important for multicollinearity</div>
Twoway-ANOVA (Factorial ANOVA):&nbsp;<i>Interaction Effect</i>	-&nbsp;Consider the possibility that for the condition B1, A1 has the smallest mean, A2 the largest, and A3 is about halfway between the two. Then for B2, A1 has the largest mean, A2 the smallest, and A3 is about halfway between the two again. This is what an interaction effect is about.&nbsp;<div><br /></div><div>- The pattern of means for A1 is dependent on the level of B. Graphically, after making a mean plot, we can easily see an interaction effect when the lines for both levels of B aren’t exactly parallel<div><br /></div><div>(parrallel lines are an assumption of ANCOVA)</div></div>
Twoway-ANOVA (Factorial ANOVA):&nbsp;<i>Simple Main Effect</i>	(simple = one IV, one DV)<div><br /></div><div>- in this case we don’t compare A1, A2 and A3 in general like with a main effect, but we compare them within one level of B1. So an example would be comparing group A1B1, A2B1, and A3B1 to get the simple main effect of A within B1. Another example is to compare the groups A1B2, A2B2, and A3B2 to get the simple main effect of A within B2. A difference between these simple main effects for A within B1 and B2 indicates that an interaction effect exists</div>
Twoway-ANOVA (Factorial ANOVA):&nbsp;<i>Table (SPSS)</i>	"<img src=""Bildschirmfoto 2017-10-12 um 12.10.43.png"" /><div>-<b> Corrected Model</b> = SSM, DFM, MSM values, which are usually reserved for Regression</div><div><br /></div><div>-&nbsp;Unlike the variables themselves, SSM + SSE = SST is always true as all <i>multicollinearity was removed</i> after the predicted scores were calculated</div><div><br /></div><div>-&nbsp;If there is no multicollinearity, SSA + SSB + SSAB is equal to SSM, but now that there is, it won’t be equal with SSM &gt; SSA + SSB + SSAB</div><div><br /></div><div>- ""Intercept"" and ""Total"" may be ignored</div>"
Twoway-ANOVA (Factorial ANOVA):&nbsp;<i>Sum of Squares </i>(Formulas for variable A and B)	"<img src=""Bildschirmfoto 2017-10-12 um 12.13.11.png"" />"
Twoway-ANOVA (Factorial ANOVA):&nbsp;<i>Degrees of Freedom&nbsp;</i>(Formulas for variable A and B)	"<img src=""Bildschirmfoto 2017-10-12 um 12.13.41.png"" />"
Twoway-ANOVA (Factorial ANOVA):&nbsp;<i>Mean Square </i>(formulas for variable A and B)	"<img src=""Bildschirmfoto 2017-10-12 um 12.14.45.png"" />"
Twoway-ANOVA (Factorial ANOVA):&nbsp;<i>F-test&nbsp;</i>(formulas for variable A and B)	"<img src=""Bildschirmfoto 2017-10-12 um 12.15.08.png"" />"
Twoway-ANOVA (Factorial ANOVA):&nbsp;<i>p-value&nbsp;</i>(formulas for variable A and B)	"<img src=""Bildschirmfoto 2017-10-12 um 12.15.27.png"" />"
Blocking	-&nbsp;adding another categorical variables big blocks are divided into smaller blocks, a process they called “blocking”<div>-&nbsp;blocking is like an ANCOVA in that both of them add a variable to the model to remove bias and error from the dependent variable (but &nbsp;ANCOVA is for continuous variables, <b>blocking is for grouping variables</b>)</div><div>-&nbsp;While a second variable is usually added to test whether that variable is related to the dependent variable, this is not the main reason for adding a variable when blocking</div><div><br /></div><div>– most importantly for RM-ANOVA:</div><div>- the model will be blocked for each subject, so that the differences between participants can be removed from the error when analysing the variables of interest (every single observation will have the mean of the participant it belonged to subtracted from it, so that only the <i>variance within subjects remains</i>)</div><div>-&nbsp;these scores are used as the new dependent variable for a normal ANOVA, with the variables of interest as independent variables (<b>removing between-subjects error, increasing&nbsp;η² and power</b>)</div><div><br /></div><div>– <i>Randomized Block Design</i>: performed before the analysis with random assignment</div><div>– <i>Post-hoc Blockting</i>: afterwards, look for similar sample sizes</div>
ANCOVA: <i>General Information</i>	-&nbsp;purpose is identical to adding a blocking factor (usually <b>continuous</b> covariate)<div><br /></div><div>-&nbsp;ANCOVA as a concept is to only add one or two continuous variables called covariates, and no interactions, to correct for bias and/or error in the model</div><div>-&nbsp;whenever there is an independent categorical variable, an independent continuous variable, and maybe even an interaction between the two, ANCOVA can be used just as well as multiple linear regression to estimate these effects</div><div><br /></div><div>- the process of linear regression followed by ANOVA can also be reversed to test the significance of the covariate. First, do an ANOVA to remove all the variance explained by groups, then take the residuals of the ANOVA and use them as dependent variable in a linear regression with the covariate as a predictor</div><div><br /></div><div>-&nbsp;don’t add more than one or two covariates, and don’t add covariates that don’t bring something unique to the table to take away error or bias, as they don’t contribute to the model (Adding too many covariates means they might obscure real effect, especially when dealing with natural groups. Even if we find significance in this case, one has to wonder if that’s due to differences in the actual groups, or due to the covariates correcting each other in such a way they accidentally cause significant group differences to happen)</div>
ANCOVA:&nbsp;<i>H<sub>0/a</sub>&nbsp;hypothesis </i>when using ANCOVA as a <b>concept</b>	"- since&nbsp;the groups of the independent variables are being corrected for the covariate, we compare whether or not these adjusted means are equal to each other rather than the original means:<div><img src=""Bildschirmfoto 2017-10-12 um 12.35.46.png"" /></div><div><br /></div><div>-&nbsp;the alternative being that not all adjusted group means are equal to each other. As with ANOVA, we can write this down in another way:</div><div><img src=""Bildschirmfoto 2017-10-12 um 12.36.14.png"" /></div><div><br /></div><div><br /></div><div>As stated before, we already “know” the covariate and dependent variable are related, hence the “ß<sub>1</sub><i>x</i>” term that represents this relationship is present in the null hypothesis. What we are interested in, is whether the adjusted means are different from the overall mean, which is what <i>a<sub>j</sub></i> reflects.</div>"
ANCOVA:&nbsp;<i>H<sub>0/a</sub>&nbsp;hypothesis&nbsp;</i>when using ANCOVA as an&nbsp;<b>analysis</b>	"ANCOVA as an analysis also tests the covariate for significance:<div><br /></div><div>-&nbsp;the relationship between the covariate and dependent variable, after correcting for differences between groups, will automatically be tested as well:</div><div><img src=""Bildschirmfoto 2017-10-12 um 12.39.50.png"" /></div>"
ANCOVA: <i>Assumptions</i>	-&nbsp;All assumptions for ANOVA are also present here<div><br /><div>-&nbsp;additional assumption of “<b>There is a linear relationship between the covariate and dependent variable</b>” (by using correlation - linear)</div><div>-&nbsp;every pair needs to be linearly related for correlation to estimate the relationship properly</div><div><br /></div></div><div>-&nbsp;Because the concept of ANCOVA is to add a covariate without adding an interaction effect, there is another assumption “<b>The relationship between the covariate and dependent variable is equal for all groups</b>” (graphically as parallel lines)</div><div>-&nbsp;test this statistically by simply adding the interaction effect between the covariate and independent variable to the model and check for significance (should be not significant)</div><div><br /></div><div>-&nbsp;both assumptions may be checked by creating a scatterplot between the covariate and dependent variable, showing separate lines for each group (linear, parallel pattern)</div>
ANCOVA:&nbsp;<i>Calculations</i>	"-&nbsp;simulate the results we see for the independent variable of an ANCOVA model by <b>first</b> computing a linear regression between the covariate and the dependent variable (solely explain as much variance as possible)<div>-&nbsp;<b>residuals</b> will then be used as the dependent variable of a follow-up ANOVA, comparing the means of the residuals for each group (means of the ""new"" dependent variable are now adjusted)</div><div><br /></div><div>-&nbsp;We can calculate these adjusted means with the full regression model</div><div><img src=""Bildschirmfoto 2017-10-12 um 13.09.54.png"" /></div><div>With µ<sub>i</sub><sup>*</sup> = Adjusted mean for group i, <i>b<sub>0</sub></i> = Intercept, and <i>b<sub>1</sub></i> =&nbsp;<i>b<sub>2</sub></i>&nbsp;=&nbsp;<i>b<sub>3</sub></i>&nbsp;= Slope for given variable</div><div>-&nbsp;Dummy’s should be filled in with either 0 or 1, based on the coding and the group you’re calculating, and “Covariate” should be filled in with the overall mean of the covariate each time.</div><div><br /></div><div><br /></div>"
ANCOVA: <i>Adjusted Means</i>	<b>Experimental</b> groups are usually completely independent from covariates due to random assignment in groups, so their adjusted means will not differ much, if any, from their regular means.&nbsp;<div><b>Natural</b> groups are often related to their covariate, so as part of correcting bias their adjusted means could be drastically different from their original mean.&nbsp;</div><div><br /></div><div>- ANOVA and ANCOVA could therefore lead to differing, or even reversed conclusions. It could be that one shows a significant difference while the other doesn’t, or that the group with the highest original mean also has the lowest adjusted mean.</div>
ANCOVA:&nbsp;<i>Lord´s Paradox</i>	-&nbsp;when the correction of an ANCOVA doesn’t just remove bias, but adds bias to an analysis<div>_____________________________________</div><div><br /></div><div><br /></div><div><br /></div>
Missing Values: <i>Pattern</i>	"<img src=""Bildschirmfoto 2017-10-12 um 13.33.05.png"" />"
Missing Values:&nbsp;<i>MCAR</i>	<b>Missing Completely At Random</b>, it basically boils down to the missing data being completely unrelated to any variable, both measured and unmeasured. Obviously, this is easier to assume than it is to prove. This can rarely be assumed in practice and there are people advocating only using MAR and MNAR because there’s no real way to prove MCAR.&nbsp;<div>- makes handling missing data a lot easier</div>
Missing Values:&nbsp;<i>MAR</i>	<b>Missing At Random</b>.&nbsp;<div><br /></div><div>It’s related to other measured <u>independent</u> variables, but not to the <u>dependent</u> variable(s).&nbsp;</div><div><br /></div><div>- The clearest example of this is that there’s a control and experimental condition, and a higher percentage of people in the experimental condition quit. This means that there is a correlation between condition and whether someone has a missing value or not, but it does not necessarily mean that the people who are missing would score differently relative to their group on average. If they do, it would not be missing at random. If they don’t, it’s missing at random.</div>
Missing Values:&nbsp;<i>MNAR</i>	<b>Missing Not At Random</b>. This one is the most dangerous, as apparently people missing is not completely based on the variables in the model.&nbsp;<div>- For instance, if one would be holding a general survey to try and predict anxiety based on several independent variables, people with high anxiety would probably be less inclined to fill in the survey than people with low anxiety. Now, the people who are missing have a strong relation with what we are trying to predict so it is no longer random. Whether someone answers or not is determined by intangibles which are not measured like they are for MAR. This make it impossible to account for them and no longer random.</div>
Missing Data; <i>Case Deletion</i>	<div><b>Listwise</b>: Delete all people from the dataset with one or more missing values</div><div><br /></div><div><b>Pairwise</b>: Check every calculation separately, then use everyone who is available for that specific calculation</div><div><br /></div><div>- easiest but least preferred</div><div>- works for MCAR</div><div>- creating bias with MAR, MNAR</div>
Missing Data;&nbsp;<i>Weighting</i>	Assigns a certain weight to each outcome, so the data as a whole reflects the results it would probably have with complete cases<div>-&nbsp;If univariately or monotonic missing (page 70), this could provide decent results, but not for arbitrary</div><div>-&nbsp;One clear advantage is that this method is non-parametric, so it doesn’t depend on assumptions, even though it requires a model for the probabilities of a response.</div>
Missing Data;&nbsp;<i>Single Imputation</i>:&nbsp;Unconditional Mean Imputation&nbsp;	(only&nbsp;<b>MCAR</b>)<div>-&nbsp;just filling in the mean of the variable for whatever value is missing, which has a huge theoretical problem of reducing the SD of that variable when it shouldn’t be reduced</div><div>- power will be retained</div><div>- but produces too liberal tests</div>
Missing Data;&nbsp;<i>Single Imputation</i>:&nbsp;Hot Deck	(only <b>MCAR</b>)<div><br /></div><div>-&nbsp;consider the observed values of the variable as a sample from which you randomly draw one. As the drawing is random, both the mean and SD should be similar to the original data</div><div>- best MCAR only technique</div><div>-&nbsp;like mean imputation, it doesn’t take relationships with other variables into account</div>
Missing Data;&nbsp;<i>Single Imputation</i>:&nbsp;Conditional Mean Imputation	-&nbsp;like unconditional mean imputation, this one fills in mean values for each missing data<div>-&nbsp;takes into account other independent variables, thereby turning it into MAR</div><div><br /></div><div>-&nbsp;there is still an unwanted side effect of reducing the SD</div>
Missing Data;&nbsp;<i>Single Imputation</i>:&nbsp;Predictive Distribution Imputation&nbsp;	(<b>MAR</b>)<div><br /></div><div>-&nbsp;these imputes values based on other independent variables, while also adding a<b> random error</b> (based on SD) to simulate the SD of the variable that is being imputed</div><div><br /></div><div>-&nbsp;most complicated of the single imputation methods, but also the best in pretty much any case</div><div>-&nbsp;When it’s choosing a random error for each variable, this error probably isn’t the right one</div><div>-&nbsp;solution is a technique that repeats this calculation multiple times to get closer to the real population parameters</div>
Missing Data;&nbsp;<i>Multiple Imputation, Maximum Likelihood</i>: Information	-&nbsp;<b>single imputation</b> tends to underestimate the variance of a variable<div>-&nbsp;<b>Predictive Distribution Imputation</b> relies on the variance staying equal by adding a random component to the guessing of missing values, but there is no guarantee that this error is correct</div><div><br /></div><div>-&nbsp;<b>Multiple Imputation </b>solves this problem by imputing multiple times, so we have a number to link to this random fluctuation in the value between imputations</div><div>-&nbsp;<b>Maximum Likelihood </b>is an alternative method that doesn’t try to estimate the values to complete the dataset, it just uses all available data to estimate the requested parameters through various algorithms; step of getting a complete dataset is skipped, in favour of calculating the outcomes directly&nbsp;(multilevel analysis is an example)&nbsp;</div>
Missing Data;&nbsp;<i>Maximum Likelihood</i>: Information	-&nbsp;A<b> linear model is estimated </b>based on the cases that are <i>available</i>, which is <b>used to estimate all missing values</b> as well<div>-&nbsp;the model is estimated again now that all missing values are imputed, to increase accuracy of the model</div><div>-&nbsp;this new model is used again to improve the accuracy of the missing data imputations</div><div>-&nbsp;cycle continues until the estimated values for the missing data, along with the parameters of the linear model,<b> remain constant</b></div><div><br /></div><div>-&nbsp;biggest disadvantage is that maximum likelihood model assumes a linear model</div><div>-&nbsp;no complete dataset will be produced by using this method, meaning that you’re stuck with more complicated analyses which might be harder to interpret</div>
Missing Data;&nbsp;<i>Bayesian multiple imputation</i>: Information	-&nbsp;works a lot like Predictive Distribution Imputation (the best single imputation method), but multiple times instead of just once<div>-&nbsp;it’s possible to compute a value that properly reflects the extra randomness due to imputing values</div><div><br /></div><div>-&nbsp;go-to method for most computer programs because it’s a technique that can always be used, when <b>MAR</b> or <b>MCAR</b> may be assumed</div><div>-&nbsp;it gives multiple imputations, so the entire range of possible values for a single missing value may be explored</div><div><br /></div><div>-&nbsp;disadvantage is that it’s pretty hard to work with when being given many different datasets</div><div>-&nbsp;One may find clearly significant results with one imputation but completely no effect with another, if the proportion of missing values is large enough, like 10% or more</div><div><br /></div><div>-&nbsp;Averaging all imputations eliminates this problem, but then you have to take the extra error from the different imputations into account</div>
Multivariate Tests	- have <b>multiple dependent variables</b><div><br /></div><div>- more suited to find significant differences between groups</div><div>-&nbsp;especially if the dependent variables are <i>moderately related</i></div><div>- also keeping the chance of <i>type I error steady at .05</i></div><div>-&nbsp;using all available data, hence<i> increasing power</i></div><div><br /></div><div><br /></div><div>-&nbsp;It is always recommended to keep the number of variables to a bare minimum</div><div>-&nbsp;Adding new dependent variables might obscure group differences for other dependent variables</div><div>-&nbsp;Power will decrease by including bad variables</div><div>-&nbsp;as with any statistical test, that with increased flexibility comes decreased specificity of the results</div>
oneway -&nbsp;MANOVA: <i>H<sub>0</sub>&nbsp;hypothesis</i>	"<img src=""Bildschirmfoto 2017-10-13 um 20.01.27.png"" /><div>-&nbsp;Notice the first number represents DV, adding another DV would place it below the others in a vector The second number represents Group, adding another Group would add a new vector to the right</div><div><br /></div><div><b>“There is no linear combination of the four dependent variables for which the three groups of the independent variable are different from each other” </b>(clear)</div><div><b><br /></b></div><div><i>H<sub>a</sub>:&nbsp;“There is a linear combination of the four dependent variables for which the three groups of the independent variable are different from each other” &nbsp;</i>(unclear)</div><div>-&nbsp;Which dependent variables were needed for the linear combination? Which groups are different for this linear combination?</div><div><br /></div><div>Follow up:</div><div><img src=""Bildschirmfoto 2017-10-13 um 21.11.53.png"" /></div><div><i><br /></i></div><div><i><br /></i></div>"
oneway -&nbsp;MANOVA: setup	2 or more groups, 2 or more dependent variables
T<sup>2</sup>-test: setup	2 groups, 2 or more dependent variables
Discriminant: setup	Provides information about the linear combinations used by MANOVA
ANOVA: setup	2 or more groups, 1 dependent variable
Multiple Comparison: setup	2 groups, 1 dependent variable
Contrasts: setup	2 or more groups, 1 dependent variable (but only specific comparisons, not all)
Hotelling’s T²: <i>H<sub>0/a&nbsp;</sub>hypothesis</i>	"(Not the same as Hotelling’s Trace in MANOVA output)<div><br /></div><div>The null hypothesis for T² is also identical to MANOVA, except that we can only have two groups for T². If we again presume to have four dependent variables:</div><div><img src=""Bildschirmfoto 2017-10-13 um 21.29.50.png"" /></div><div><br /></div><div><i>H<sub>a</sub>:&nbsp;</i><img src=""Bildschirmfoto 2017-10-13 um 21.31.01.png"" /></div><div><br /></div><div><div>H<sub>0</sub>&nbsp;: “<b>There is no linear combination of the four dependent variables for which both group means differ from each other</b>”.</div><div><br /></div><div>H<sub>a</sub> : “<b>There is a linear combination of the four dependent variables for which both group means differ from each other</b>”.</div></div>"
Hotelling’s T²:&nbsp;<i>Formula</i>	"This analysis is great at <b>differentiating two groups from each other on multiple dependent variables</b>, but at the same time is limited to doing just that. This might not be surprising considering this is called a T²-test, but the formula is literally the squared formula for the t-test, modified for having multiple dependent variables<div><br /></div><div><img src=""Bildschirmfoto 2017-10-13 um 21.33.46.png"" /></div><div>-&nbsp;when the differences between the vectors increase, the value of T² will increase along with it</div><div>-&nbsp;When <b><i>S</i></b> increases, <i><b>S<sup>-1</sup></b></i>&nbsp;decreases, therefore the value of T² will also decrease.</div><div>-&nbsp;Increasing sample size will also increase T², as the multiplication above the break line will increase faster than the addition below the break line.</div>"
Hotelling’s T²:&nbsp;<i>Formula transformation (F)</i>	"After filling in the formula to calculate the value of T², this T² value can be transformed into an F-value so a p-value can be found afterwards. This can be done using the following formula, with <b>p</b><i> representing the number of dependent variables</i> and<b> n</b> <i>representing sample size</i>:<div><img src=""Bildschirmfoto 2017-10-13 um 21.37.35.png"" /></div><div><br /></div><div>- shows why t² = F for the univariate case.&nbsp;</div><div>- filling in p = 1 makes the part above and below the break line exactly equal, resulting in F = T²</div><div>- this formula only works for two groups</div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div>SPSS:</div><div>There is no specific T²-test button in SPSS, but it can be simulated by selecting two groups and running a MANOVA. Like with ANOVA compared to t-test, a MANOVA with 2 groups will give the same F-value (thanks to that formula above) and p-value as the T²-test. With this, we have set the final step towards a “proper” MANOVA analysis.</div>"
oneway - MANOVA &amp; T²:&nbsp;<i>Assumptions</i>	-&nbsp;<b>Independence</b> of all measurements<div><br /></div><div>- Multivariate <b>Normality</b></div><div><br /></div><div>- The (<u>Within</u>) <b>Covariance matrix is equal for all groups</b></div><div><br /></div><div>- No measurement <b>error</b></div><div><br /></div><div>- There is a <b>linear relation between all dependent variables</b> (not assumed for T²)</div><div><br /></div><div><br /></div>
oneway -&nbsp;MANOVA &amp; T²:&nbsp;<i>Assumptions</i>: <u>Multivariate Normality:</u>	"-&nbsp;very strict assumption<div>-&nbsp;Not only do the <b>separate dependent variables need to be normally distributed</b>, but <b>every possible linear combination of dependent variables needs to be normally distributed</b> as well</div><div>-&nbsp;when there is perfect multivariate normality, each separate dependent variable and each linear combination of two dependent variables will be normally distributed as well, so can at least test those</div><div>-&nbsp;Checking dependent variables separately is done through the same methods as ANOVA (Shapiro-Wilk, Skewness/Kurtosis, PP/QQ-plot)</div><div>-&nbsp;For comparing two dependent variables we can make a <b><font color=""#0000ff"">3D-plot</font></b>, or <b><font color=""#0000ff"">scatterplots</font></b> between the two. If the variables are normally distributed, we’ll see either a <i>circle</i> (r = 0) or <i>ellipsis</i> (r ≠ 0)</div><div><br /></div><div>- central limit theorem</div>"
oneway -&nbsp;MANOVA &amp; T²:&nbsp;<i>Assumptions</i>:&nbsp;<u>Multivariate Normality:</u>&nbsp;Violation	-&nbsp;<b>Increasing sample size </b>to increase normality through the central limit theorem, transforming scores so they follow a more normal distribution, and removing potential outliers all increase normality<div>- if the non-normality is caused by the dependent variable not being continuous, take another approach like a <i>multivariate logistic regression</i></div>
oneway -&nbsp;MANOVA &amp; T²:&nbsp;<i>Assumptions</i>:&nbsp;<u>Equality of (within) covariance matrices</u>	-&nbsp;is an expansion of homoscedasticity<div>- test for by using the <b>Box’s M test</b>:&nbsp;sensitive to non-normality, so keep this in mind when concluding something based on this test when you know multivariate normality is violated</div><div><br /></div><div><br /></div><div>-&nbsp;If the (within) covariance matrices aren’t equal, we could transform the data to make them more equal or use a method that doesn’t assume these matrices are equal, like some varieties of the multilevel model</div>
oneway -&nbsp;MANOVA &amp; T²:&nbsp;<i>Assumptions</i>:&nbsp;<u>Lack of measurement error</u>	-&nbsp;assumed that whatever we measure is the true score of someone<div>-&nbsp;high levels of reliability</div>
oneway -&nbsp;MANOVA &amp; T²:&nbsp;<i>Assumptions</i>:&nbsp;<u>Linear relationship between all dependent variables</u>	"-&nbsp;For MANOVA, the linear combination is based on the relationship between dependent variables, so to create a valid linear combination, we need to have measured the relationships accurately<div>-&nbsp;For T², the linear combination is always “y1 – y2” regardless.</div><div><br /></div><div><br /></div><div>-&nbsp;We don’t care what the correlation between the two measurements is, we always take the <b>difference scores</b>. For three or more groups, taking difference scores is inefficient, as the number of difference scores increases exponentially. This means we <u>only</u> take this approach for two groups (T²) and RM-MANOVA, so in those two cases we don’t care about this assumption</div><div><img src=""Bildschirmfoto 2017-10-14 um 11.41.22.png"" /></div><div>-&nbsp;<i>Group</i> shows us whether there is a linear combination of the four dependent variables for which the three groups are different from each other, and given p &lt; α, it appears there is as we can safely reject the null hypothesis</div>"
oneway -&nbsp;MANOVA &amp; T²:&nbsp;<i>Assumptions</i>:&nbsp;<u>Linear relationship between all dependent variables:</u>&nbsp;Different Tests in a Table:	"<img src=""Bildschirmfoto 2017-10-14 um 11.41.22.png"" /><div><u>Wilks’ Lambda as default:</u></div><div>- ratio between the <b>determinant</b> of the<font color=""#0000ff""> Within-SSCP matrix</font> and the <b>determinant</b> of the <font color=""#0000ff"">Total-SSCP matrix</font></div><div>-&nbsp;As the determinant of an SSCP matrix can be interpreted as the “generalised variance”, Wilks’ Lambda gives us the “<b>proportion unexplained (generalised) variance</b>”</div><div><img src=""Bildschirmfoto 2017-10-14 um 11.43.07.png"" /></div><div>- for two groups the F test is&nbsp;completely accurate and identical for each method</div>"
oneway -&nbsp;MANOVA &amp; T²: <i>Follow up analysis to find out which groups are different for which linear combination</i>	- ANOVA<div>- Multiple Comparison</div><div>- Contrasts</div>
oneway -&nbsp;MANOVA &amp; T²:&nbsp;<i>Roy-Bargmann Stepdown Analysis</i>	-&nbsp;check for which dependent variables the groups are significantly different<div>- to find the set of dependent variables that <b>explain</b> the <b>most variance</b> with the least number of variables, this stepdown analysis can be performed</div><div><br /></div><div><u>First</u>, compute a <b>univariate ANOVA</b> with the <i>most significant DV (Y1)</i> (if this isn’t significant, stop here, because no DV is significant by itself; if the DV is significant, it will become a covariate in the following model)</div><div><br /></div><div><u>Next</u>, compute an ANCOVA with the second most significant DV (<i>Y2</i>) and <i>Y1</i> as a covariate (if this isn’t significant, stop here and conclude that Y1 by itself is the best model; if this is significant, Y1 and Y2 are both useful additions)</div><div><br /></div><div><u>Continue</u> this process until either all DV’s are present in the model (like now for this example) or until a non-significant result is encountered. The final model is the model that only contains the crucial DV’s needed for the observed effect</div>
oneway -&nbsp;MANOVA &amp; T²:&nbsp;<i>Follow up</i>: Contrasts	"<img src=""Bildschirmfoto 2017-10-14 um 12.15.06.png"" /><div>In the table above, the results of two contrasts (Group 1 vs. Group 3 &amp; Group 2 vs. Group 3) are given for both dependent variables. This shows that for the first dependent variable, group 1 &amp; 3, and group 2 &amp; 3 are both significantly different from each other. In both cases the mean of group 3 is higher, as the value of the contrast estimate is negative. When computing a simple contrast, SPSS uses “µ1 – µ3 ” and “µ2 – µ3 ”, so if this equation results in a negative number, µ3 &gt; µ1 or µ3 &gt; µ2 depending on which contrast. For the second dependent variable, µ3 &gt; µ2 again as we find a significantly negative contrast estimate, but now we can’t reject the null hypothesis that µ3 = µ1 anymore. The means of group 1 and 3 probably about the same, while the mean of group 3 is larger than 2</div><div><br /></div><div>- to test 1 vs. 2 use Bonferroni (more conservative) or LSD</div>"
oneway -&nbsp;MANOVA &amp; T²: <i>LSD</i>	-&nbsp;LSD is basically a t-test, using the <b>pooled standard deviation √MSE and degrees of freedom DFE</b> from the ANOVA table, instead of just the two groups being compared<div>-&nbsp;The fact that the ANOVA test needs to be significant before LSD may be computed, protects LSD from inflation of type I error, but still actual α is usually larger than the nominal α, hence the test is liberal</div>
oneway -&nbsp;MANOVA &amp; T²:<i>&nbsp;Bonferroni</i>	- Bonferroni is identical to LSD in every way, except that SPSS will multiply th<b>e calculated p-value by the number of pairwise comparisons</b> to compensate for inflation of type I error.&nbsp;<div>- This usually leads to the actual α being smaller than the nominal α, hence the test is conservative.</div>
twoway - MANOVA – Two independent variables (Factorial MANOVA): <i>Important to look for?</i>	- with&nbsp;two independent variables, we need to think about <b>multicollinearity</b> between both independent variables<div>- assumptions remain the same</div>
twoway - MANOVA – Two independent variables (Factorial MANOVA): <i>H<sub>o</sub>&nbsp;hypothesis</i>	"Group (3 groups), Factor (2 factors) and 2 dependent variables:<div><img src=""Bildschirmfoto 2017-10-14 um 12.30.37.png"" /></div><div><br /></div><div>This would mean there is no effect at all, so <b>no</b> main effect of Group, <b>no</b> main effect of Factor, and <b>no</b> interaction effect. The null hypothesis for just the main effect of Factor is like a oneway-MANOVA:</div><div><img src=""Bildschirmfoto 2017-10-14 um 12.33.37.png"" />so as can be seen, group is irrelevant for the main effect of Factor.</div>"
twoway - MANOVA – Two independent variables (Factorial MANOVA):&nbsp;<i>SPSS table:</i>	"<img src=""Bildschirmfoto 2017-10-14 um 12.36.42.png"" /><div>-&nbsp;<b>Group</b> is the only significant effect in our model (p &lt; .001) with the proportion unexplained generalised variance equal to 3.4%, which is very little</div><div>-&nbsp;<b>Factor</b> is not significant (p = .618) with 95.9% unexplained generalised variance, which is a lot</div><div>-&nbsp;<b>Wilks</b>’ <b>Lambda</b> statistic for the interaction effect (just 76.1% unexplained generalised variance) makes it seem like there might be an effect, but due to the small sample size it isn’t significant (p = .170)</div>"
twoway - MANOVA – Two independent variables (Factorial MANOVA):&nbsp;<i>Effect size:</i>	"-&nbsp;MANOVA uses <b>η<sup>2</sup> </b>(eta squared) for measure of effect size, with the same interpretation<div>-&nbsp;<b>Wilks’ Lambda</b> can be interpreted as the<b> proportion unexplained variance</b>, and η<sup>2</sup> is the proportion explained variance</div><div><img src=""Bildschirmfoto 2017-10-14 um 12.41.44.png"" /></div><div><br /></div><div><br /></div><div>- due to&nbsp;multicollinearity, simply summing η<sup>2</sup> doesn’t equal the effect of the entire model (could exceed 1)&nbsp;</div><div>-&nbsp;To counteract this, the “partial η<sup>2</sup>” can be calculated, to remove multicollinearity from the η<sup>2</sup> so that η<sup>2</sup> can’t exceed 1:</div><div><img src=""Bildschirmfoto 2017-10-14 um 12.44.41.png"" /></div><div><i>s&nbsp;= either ""hypothesis df"" or # of DV</i> (take the&nbsp;smaller value of the two</div><div><br /></div><div>Example:&nbsp;</div><div>The sum of these effects is .816 + .021 + .128 = .965, which is smaller than 1. This shows partial η<sup>2</sup> is mostly useful to learn about the effect size of the entire model, and to learn more about the unique effects of each variable, without overlap from other variables.</div><div><img src=""Bildschirmfoto 2017-10-14 um 12.48.46.png"" /></div>"
MAN<b>C</b>OVA: <i>Assumptions</i>	"<div><b>- Independence</b></div><div><b>- No measurement error</b></div><div><b>- Equality of Covariance matrices</b></div><div><b>- <font color=""#0000ff"">Homogenity</font> of slopes</b></div><div><b>- Linear relationship between all <font color=""#0000ff"">continuous</font> variables</b></div><div><br /></div>- the&nbsp;only difference worth explicitly mentioning is that the MANOVA-assumption that all dependent variables are linearly related, and the ANCOVA-assumption that the covariate and dependent variable are linearly related, are combined into one giant “<b>all covariates and dependent variables should be linearly related</b>”<div>- i.e.&nbsp;“All continuous variables should be linearly related” works for (M)AN(C)OVA</div><div><br /></div><div><br /></div><div>- nice example from p.60 onwards</div>"
MAN<b>C</b>OVA:&nbsp;<i>H<sub>0</sub>&nbsp;hypothesis</i>	"<div><img src=""Bildschirmfoto 2017-10-14 um 12.54.26.png"" /></div><div>H<sub>0</sub>: “<b>There is no linear combination of the four dependent variables for which the three <font color=""#0000ff"">adjusted</font> group means are different from each other</b>”</div><div><br /></div><div>Ha: “<b>There is a linear combination of the four dependent variables for which the three <font color=""#0000ff"">adjusted</font> group means are different from each other</b>”</div>"
MAN<b>C</b>OVA:&nbsp;<i>Assumptions</i>: Independence	Just like every other test until now, we assume that the measurements of all participants are independent from each other, outside of the grouping variables we’re measuring, and that the participants didn’t influence each other.&nbsp;<div><br /></div><div>(This assumption is gone for Repeated Measures after this, as having more than measurement per participant means the measurements are related)</div>
MAN<b>C</b>OVA:&nbsp;<i>Assumptions</i>:&nbsp;No measurement error:&nbsp;	Just like all the tests before, we assume no measurement error was made when measuring some continuous score of the participants.
MAN<b>C</b>OVA:&nbsp;<i>Assumptions</i>:&nbsp;Multivariate Normality:&nbsp;	Similar to MANOVA, each separate <b>dependent variable</b> and <b>all linear combinations of the dependent variables</b> need to be normally distributed.&nbsp;<div><br /></div><div>We can test this with univariate (<b>Shapiro-Wilk, Skewness/Kurtosis, PP/QQ-plot, Histogram</b>) and bivariate (<b>3D-plot, scatterplot</b>) methods.</div>
MAN<b>C</b>OVA:&nbsp;<i>Assumptions</i>:&nbsp;Equality of Covariance matrices:&nbsp;	Similar to MANOVA, it’s assumed that the (Within) covariance matrix for each group is equal. We can test this with the <b>Box’s M test</b>.
MAN<b>C</b>OVA:&nbsp;<i>Assumptions</i>:&nbsp;Homogeneity of slopes:&nbsp;	Similar to ANCOVA, the<b> relationship between the covariate and dependent variables may not differ between groups</b>, because then an interaction effect would exist. Interaction effects with covariates are still disallowed in this conceptual idea behind MANCOVA.&nbsp;<div><br /></div><div>- This can be tested by adding the <i>interaction effect</i> to the model, or by creating a <i>scatterplot</i> with a fit line for each group.</div>
MAN<b>C</b>OVA:&nbsp;<i>Assumptions</i>:&nbsp;Linear relationship between all continuous variables:&nbsp;	Similar to MANOVA, we want there to be a linear relationship between all dependent variables, <b>so a valid linear combination can be produced</b>. Similar to ANCOVA, we want the relationship between all covariates and all dependent variables to be linear, so that the coefficient measuring this relationship is properly estimated. This can be checked through a <i><u>scatterplot</u></i> between <b>all separate pairs of continuous variables.</b>
Canonical Correlation: <i>Setup</i>	- linear relationship between two sets of continuous (or binary) variables
Multiway Frequency Models:&nbsp;<i>Setup</i>	"- relationship between two or more categorical variables<div><br /></div><div>- only takes categorical variables into account (nominal/ordinal)</div><div>- <font color=""#0000ff"">""goodness of fit"" </font>test is performed</div><div>-&nbsp;<b>test whether there is still a significant portion of unexplained variance that could be explained next to the predicted model</b></div><div><br /></div>"
Factor Analysis: <i>Setup</i>	-&nbsp;a technique used to s<b>ummarize many continuous variables in just a few factors</b>. These factors will be computed based on which factors are most related to each other
Discriminant Analysis:&nbsp;<i>Setup</i>	-&nbsp;a technique used to <b>predict group membership based on multiple continuous variables</b><div>(opposite of MANOVA, in that it has multiple continuous independent variables and a single categorical dependent variable)</div>
<i>Discriminant Analysis, Factor Analysis, and Canonical Correlation</i>, all share a mathematical foundation:	-&nbsp;All three use <u>linear combinations</u> of the continuous variables in the model<div>(were first commonly used by multiple linear regression, for which multiple independent variables were combined into one model, which was used to compute predicted scores)</div><div>- we&nbsp;<b>now</b> make more than one linear combination based on the continuous variables</div><div>- therefore,&nbsp;<b>Eigenvectors</b></div>
<b>eigenvectors</b> and <b>eigenvalue</b>: <i>Calculation</i>	"<i>For every square matrix, like SSCP-matrices or covariance matrices, it is possible to compute an eigenvector with an associated eigenvalue.</i><div><i><br /></i></div><div>- we define a matrix as A, an eigenvector as u, and an eigenvalue as λ (<i>Au </i>=&nbsp;λ<i>u</i>)</div><div><img src=""Bildschirmfoto 2017-10-15 um 11.59.32.png"" /></div><div>-&nbsp;There is one eigenvector and eigenvalue for each row (or column) of the square matrix. So a 2x2 matrix will have 2 eigenvectors, a 3x3 matrix will have 3 eigenvectors, etc.</div><div>-&nbsp;a covariance matrix or SSCP-matrix will have one row (or column) for each continuous variable in the model</div><div><br /></div><div>-&nbsp;Combining these two points, the <b>general rule</b> that we can calculate one eigenvector and eigenvalue for each continuous (or binary) variable, suddenly makes sense.</div>"
<b>eigenvectors</b>&nbsp;and&nbsp;<b>eigenvalue</b>:&nbsp;<i>Definition</i>	Let <b>A </b>be an <i>n x n </i>matrix. A scalar&nbsp;<b>λ </b>is called an eigenvalue of <b>A </b>if there is a non zero vector<b> x </b>such that <b>Ax </b>=&nbsp;<b>λx</b>.<div>Such a vector <b>x</b>&nbsp;is called an <u>eigenvector</u> of <b>A </b>corresponding to&nbsp;<b>λ</b></div><div><b><br /></b></div><div><u>Note</u>: If&nbsp;<b>λ </b>is an eigenvalue of <b>A</b>, and <b>x</b>&nbsp;is an eigenvector belonging to&nbsp;<b>λ</b>, any non-zero multiple of <b>x</b>&nbsp;will be an eigenvector</div>
<b>eigenvectors</b>&nbsp;and&nbsp;<b>eigenvalue</b>:&nbsp;<i>Usage</i>	-&nbsp;used in the same vein as correlation, but for multiple continuous variables<div>-&nbsp;Based on these eigenvectors, each <u>variable is assigned a particular weight</u> as part of a linear combination, comparable to the slopes of a linear regression</div><div>-&nbsp;Using these weights and the scores of each subject, the score on the linear combination of these continuous variables may be calculated for each subject, similar to the predicted value for linear regression</div><div><br /></div><div>This linear combination has different names:</div><div><b>Linear regression</b>: <i>Model</i>&nbsp;</div><div><b>Discriminant Analysis</b>: <i>Function</i>&nbsp;</div><div><b>Canonical Correlation</b>: <i>Dimension</i>&nbsp;</div><div><b>Factor Analysis</b>: <i>Factor</i>&nbsp;</div><div><b>Component Analysis</b> (subgroup of Factor Analysis): <i>Component</i></div><div><i><br /></i></div><div>-&nbsp;<i>in all these cases the linear combination that minimises unexplained variance and maximises explained variance is estimated</i></div>
<b>eigenvectors</b>&nbsp;and&nbsp;<b>eigenvalue</b>:&nbsp;<i>Limit for all linear combinations&nbsp;</i>	"<b>The number of possible linear combination is equal to the number of possible eigenvectors, so it is equal to the <font color=""#0000ff"">number</font> of continuous (or binary) variables that are part of the linear combination</b><div>-&nbsp;Discriminant &amp; Canonical, two linear combinations are calculated for two different sets of variables simultaneously (in this case, the linear combination with the smallest number of continuous variables defines the number of eigenvectors that could be calculated)</div><div><br /></div><div><b>The second linear combination for the same set of continuous variables is calculated the same way as the first linear combination, but instead of using the original data, it uses the <font color=""#0000ff"">residuals</font> from the first linear combination</b></div><div>-&nbsp;As residuals are always completely independent from the model, the second linear combination will be completely <b>independent</b> from the first one</div><div>-&nbsp;this second linear combination will never be able to explain a higher proportion of explained variance (first already expl. max.)</div>"
<b>eigenvalue</b>: Meaning	"-&nbsp;one thing that’s always true, is that a higher eigenvalue means a higher<b><u><i> proportion explained variance</i></u></b><div><br /></div><div><b>Discriminant &amp; Canonical:</b>&nbsp;an eigenvalue means the <font color=""#0000ff"">ratio between explained and unexplained variance</font>, so an eigenvalue of 1 would mean equal explained and unexplained variance, so that 50% is (un)explained by the linear combination</div><div><br /></div><div><b>Factor &amp; Component Analysis:</b>&nbsp;we could <i>divide the eigenvalue by the number of variables</i> in the model to calculate the <font color=""#0000ff"">propor</font><font color=""#0000ff"">tion explained variance</font> of all variables in the model.</div>"
<b>eigenvector </b>and<b> eigenvalue</b>: SPSS interpretation	"<u>SPSS will always give the eigenvalues for all three analyses, but it will not show the eigenvector</u><div>-&nbsp;it will always provide us with the weights (<b>slopes</b>) used to calculate the optimal linear combination(s).</div><div>-&nbsp;they will show the standardized weights by default, but it can also always show the unstandardized weights as desired (<b>read the table carefully</b>)</div><div><br /></div><div>-<b><font color=""#0000ff""> standardized weight</font></b> can be interpreted like the ß for regression</div><div>-&nbsp;<b><font color=""#0000ff"">unstandardized weight</font></b> is like b for regression</div><div>(on the basis of these weights, we can calculate the definite score of each factor / component / dimension / function for each subject, just like we calculated the predicted score based on the model with linear regression)</div><div><br /></div><div><u>SPSS will give&nbsp;a structure matrix (= factor matrix = loading matrix = component matrix) is computed</u>.&nbsp;</div><div>- This matrix shows the correlation between the calculated linear combination and all separate continuous variables that were part of this linear combination.&nbsp;</div><div>- figure out which continuous variables are related to a particular linear combination, to interpret what exactly every linear combination is based on.</div>"
<b>eigenvector&nbsp;</b>and<b>&nbsp;eigenvalue</b>: SPSS calculated linear combinations, their usage&nbsp;depends on the method:	<div><b>Canonical</b>: Use the linear combinations to <u>calculate the linear degree of association between two sets.</u></div><div><br /></div><div><b>Discriminant</b>: Use the linear combinations to<u> predict which group subjects belong to.</u></div><div><br /></div><div><b>Factor</b>: Use the linear combinations as factors to <u>summarise the continuous variables in the model.&nbsp;</u></div><div><b><br /></b></div><div><b>Component</b>: Use the linear combinations as components to <u>summarise the continuous variables in the model.</u></div>
The size of the matrix after multiplication is equal to:	the number of rows of the first matrix, and equal to the number of columns of the second matrix.
Bivariate Correlation r:	Correlation between a single continuous/binary variable and another single continuous/binary variable
Multiple Correlation R:	Correlation between a <b>set</b> of <i>continuous/code variables </i>and a <b>single</b> <i>continuous/binary variable</i>
Canonical Correlation:	Correlation between a <b>set</b> of <i>continuous/binary </i>variables and another<b> set</b> of <i>continuous/binary variables</i><div><br /></div><div>-&nbsp;Because the canonical correlation between two sets can consist of the linear relationship between multiple linear combinations (= dimensions for canonical), the canonical correlation may be written as a vector instead of just a number.</div><div><br /></div><div>Example p.115</div>
Canonical Correlation: <i>Finding the optimal linear combination</i>:	-&nbsp;is done through the <b>eigenvectors</b> and <b>eigenvalues</b><div>- on the basis of these vectors, a particular dimension (= linear combination) is created for both sets, maximising the correlation between these sets (measured by <i>r</i>)</div><div><br /></div><div>-&nbsp;<u>Next</u>, <b>two new dimensions</b> that are completely <i>separate from the first two dimensions</i> are created, again trying to maximise the correlation between both sets with the residuals of the first two dimensions</div><div>-&nbsp;<i>number of dimensions we end up with is equal to the number of continuous variables in the smallest set</i></div>
Canonical Correlation:&nbsp;<i>Assumptions</i>	- <b>Linearity</b><div>- <b>Normality</b></div><div>- <b>Homoscedasticity</b></div><div><br /></div><div>Because of robustness, the assumptions aren’t that strict, so it deals well with small to medium violations, especially with large sample sizes. Only with large violations for relatively small sample sizes, or with a clear violation of linearity, problems will occur if proper action isn’t taken.</div>
Canonical Correlation:&nbsp;<i>Assumptions</i>: <u>Linearity</u>	We measure, as with every variety of correlation, the <b>degree of linear relationship</b>.&nbsp;<div>- If a quadratic relationship exists between the variables, it won’t be found when simply looking for a linear relationship. These variables would then need to be <i>transformed</i> to a linear relationship before canonical correlation (or any other type of correlation) could accurately pick up on this relationship.</div>
Canonical Correlation:&nbsp;<i>Assumptions</i>:&nbsp;<u>Normality</u>	The <b>test for significance </b>of the correlation only works if the scores of every dimension are normally distributed.&nbsp;<div><br /></div><div>However, this is the only part of this analysis which needs normally distributed dimensions. So it isn’t required to accurately measure the strength of the linear relationship. Also, the test is quite robust, so a small violation of normality does not cause problems.</div>
Canonical Correlation:&nbsp;<i>Assumptions</i>:&nbsp;<u>Homoscedasticity</u>	The <b>variance of a variable is constant over all levels of combinations of other variables.</b>&nbsp;<div><br /></div><div>This one is also mostly important for significance testing, but like with normality, the test is quite robust, so a small violation of homoscedasticity does not cause problems.<div><br /></div></div>
SPSS - Canonical Correlation: <i>Output table</i>	"<img src=""Bildschirmfoto 2017-10-15 um 16.26.28.png"" /><div><u>Dependent</u>:&nbsp;Theory questions (TheoryScore), Application questions (ApplyScore), and Insight questions (InsightScore)</div><div><u>Predictor</u>:&nbsp;Number of study hours (StudyTime), a score that quantifies motivation for academia (Motivation), and an attractiveness score (Attractiveness)</div><div><img src=""Bildschirmfoto 2017-10-15 um 16.27.37.png"" /></div><div>-&nbsp;in the first dimension, the second set can explain 63.4% of the variance in the first set, and also the other way around</div><div>-&nbsp;om the right side of the table, we learn that the first dimension is significant (p &lt; .001), while the second dimension (p = .220), and third dimension (p = .980) are not. This means we have the best ratio between the number of dimensions and explained variance with one dimension, so our final model is simply the correlation between the first linear combinations of both sets, so <i>r<sub>canon</sub></i>= .796</div>"
SPSS - <b>Unstandardized Canonical Correlation</b>:&nbsp;<i>Output table</i>	"<img src=""Bildschirmfoto 2017-10-15 um 16.31.37.png"" /><div>These tables show the unstandardized weights (b) for each variable in both sets.&nbsp;</div><div><br /></div><div>Given that a subject scores 30 on TheoryScore, 20 on ApplyScore, and 10 on InsightScore, then their score for dimension 1 is:</div><div><img src=""Bildschirmfoto 2017-10-15 um 16.32.08.png"" /></div><div><br /></div><div>Given that a subject scores 20 on StudyTime, 40 on Motivation, and 30 on Attractiveness, their score for dimension 2 is:</div><div><img src=""Bildschirmfoto 2017-10-15 um 16.32.55.png"" /></div><div><br /></div><div>-&nbsp;From these tables, we can see how to exactly calculate the dimension value for each individual, but because these scores are unstandardized, we can’t conclude which variables are the most important for creating the dimension (especially with very different SD´s)&nbsp;</div>"
"SPSS -&nbsp;<b>""Structure Matrix</b>/Canonical Loadings<b>"" Canonical Correlation</b>:&nbsp;<i>Output table</i>"	"<img src=""Bildschirmfoto 2017-10-15 um 16.34.04.png"" /><div>-&nbsp;shows the correlation between each dimension created for a particular set of variables, and each variable in that set</div><div><u><br /></u></div><div><u>First set:</u>&nbsp;all three variables are strongly related to the first dimension, Theory &amp; Insight mainly correlate with the second dimension, and Apply correlates with the third dimension</div><div><u>Second set:</u>&nbsp;StudyTime and especially motivation correlate with it, and they also mostly define the second dimension.&nbsp;Only the third dimension leans heavily on attractiveness. As you can probably tell at this point, it doesn’t quite matter if the loadings are negative or positive, only that they are as different from 0 as possible, as 0 implies no relationship between the dimension and the variable in the set.</div><div><br /></div><div>You can get all “by Self” values by squaring the values of your dimension of choice in the canonical loadings for each variable, and then summing them, and dividing by the number of variables. For instance, we can find the value of the first dimension of “Set 1 by Self”:</div><div><img src=""Bildschirmfoto 2017-10-15 um 16.46.35.png"" /></div>"
"SPSS - ""Proportion of Variance Explained""&nbsp;<b>Canonical Correlation</b>:&nbsp;<i>Output table</i>"	"<img src=""Bildschirmfoto 2017-10-15 um 16.40.47.png"" /><div>""How well the various dimensions are capable of explaining their own respective set of variables (by Self) and how well they can explain the other set of variables""</div><div><br /></div><div><div>“Set 1 by Self” shows the proportion of variance of the individual variables of Set 1 that can be explained by the dimensions based on Set 1.</div><div><br /></div><div>“Set 1 by Set 2” shows the proportion of variance of the individual variables of Set 1 that can be explained by the dimensions based on Set 2.</div><div><br /></div><div>“Set 2 by Self” shows the proportion of variance of the individual variables of Set 2 that can be explained by the dimensions based on Set 2.</div><div><br /></div><div>“Set 2 by Set 1” shows the proportion of variance of the individual variables of Set 2 that can be explained by the dimensions based on Set 1.</div></div><div><br /></div><div><br /></div>"
Discriminant Analysis: <i>General Information</i>	"-&nbsp;an analysis to <b>predict in which of the groups defined by the dependent variable</b> someone <b>belongs</b> to on the <b>basis</b> of a set of <b>continuous independent variables</b><div><br /></div><div>Discriminant analysis allows <i>multiple continuous independent variables to be combined</i> into a few l<b>inear combinations</b>, which can be used as the predictors, creating an efficient model</div><div>-&nbsp;we use the <font color=""#0000ff""><u>smallest number of predictors</u> </font>(linear combinations) to<font color=""#0000ff""><u> maximise the proportion explained variance</u> </font>(being able to correctly predict which group subjects belong to for as many subjects as possible)</div><div>-&nbsp;create these linear combinations (= functions for discriminant analysis) by first calculating the eigenvector, as was explained in the introduction. This also means that the functions (= linear combinations) for this analysis are completely <b>independent</b> from each other</div>"
Discriminant Analysis:&nbsp;<i>Overview of Procedure</i>	- The discriminant analysis automatically <b>transforms</b> the <i>categorical dependent variable</i> into (number of groups – 1) <b>dummy variables</b>, after which the <i>canonical correlation</i> between the <i>set of continuous independent variables</i> and the <i>set of dummy variables</i> is being calculated.<div><br /></div><div>This is why the maximum number of functions for discriminant analysis is equal to the smallest of either “<i>number of groups – 1</i>” or the number of continuous independent variables</div><div>-&nbsp;We have “number of groups – 1” <i>dummy variables</i>, so it’s basically the same rule we had for canonical correlation, that the number of dimensions could not exceed the number of variables in the smallest set.</div>
<b>Descriptive</b> Discriminant Analysis	Descriptive is meant to be a <b>follow-up for a MANOVA</b>, to be used <b>if</b> the value for the <u>Wilks’ Lambda is significant</u>.&nbsp;<div><br /></div><div>This means we reject the null hypothesis that there is no linear combination for which the groups differ, so we know there is some linear combination out there that might help explain the differences between groups. By using discriminant analysis, we can gather more information about this linear combination</div>
<b>Predictive</b>&nbsp;Discriminant Analysis	Predictive is meant as a stand-alone analysis, to check whether a set of continuous independent variables is able to accurately predict which group of the dependent variable they belong to.
Discriminant Analysis: <i>Assumptions</i>	Mathematically the discriminant analysis is exactly equal to the MANOVA, only the output we see is completely different. This means that the<b> assumptions of MANOVA</b> are all assumptions for discriminant analysis as well, meaning that discriminant analysis is a rather strict test, especially when compared to its closest competitor: logistic regression<div><br /></div>
Discriminant Analysis:&nbsp;<i>Significance Test</i>	"A significance test is performed for only one part of the discriminant analysis.&nbsp;<div><br /></div><div>That is to test <b><font color=""#0000ff"">whether or not the various functions created from the continuous independent variables predict a significant amount of variance of the dependent variable</font></b>.&nbsp;</div><div><br /></div><div>- Predicting a significant amount of variance of the dependent variable would, in this case, mean that the function helps accurately predict group membership.<div><br /></div><div>Example p.119</div></div>"
Discriminant Analysis:&nbsp;<i>SPSS output </i>Eigenvalues:	"(from MANOVA we saw that&nbsp;there is at least one linear combination (function) in the data for which the groups are different (p &lt; .001) - therefore discrimination analysis)<div>-&nbsp;dependent variable is “Education” with the groups “Low, Medium, High”</div><div>- continuous independent variables are three aspects that can be tested for an exam: Theory questions (TheoryScore), Application questions (ApplyScore), and Insight questions (InsightScore)<br /><div>________________________________________</div><div><img src=""Bildschirmfoto 2017-10-15 um 17.28.54.png"" /></div><div><u>First Function:</u></div><div>This table shows two functions were made. This is now our maximum, as the dependent variable had three groups, so two dummy variables were created from that. The eigenvalue of 3.802 means the<i><u> proportion explained variance is 3.802 as large as the proportion unexplained variance</u></i></div><div>-&nbsp;Using the <b>canonical correlation</b>, we can see that the proportion explained variance is .890² = .792, which would make the proportion unexplained variance equal to 1 – .792 = .208. 0.792 / 0.208 is equal to about 3.802, so it all fits</div></div><div><br /></div><div><u>Second Function:</u></div><div>the eigenvalue is .294, with a canonical correlation of .476. This is way less than the first function, but still decent. We only had 20.8% unexplained variance after the first function, and of this 20.8%, the second function explains .476² = .227 = 22.7% of the variance. This means that of the total explained variance, .208 * .227 = .047 = 4.7% is explained by the second function</div><div><br /></div><div>That means the total explained variance by <u>both</u> <u>functions</u> is: proportion explained variance function 1 + proportion explained variance function 2 = .792 + .047 = .839 = 83.9%, which is very high.</div>"
Discriminant Analysis: <i>Wilks´ Lambda </i>(total explained variance)	"Wilks’ Lambda is the <b>proportion unexplained variance</b>, and here we can see that function 1 and 2 together leave 16.1% unexplained variance behind, which would mean 100 – 16.1 = 83.9% variance is explained<div><u><br /></u></div><div><img src=""Bildschirmfoto 2017-10-15 um 17.40.58.png"" /></div><div><u>Note:</u>&nbsp;also notice that the Wilks’ Lambda value below for 1 through 2 is equal to the Wilks’ Lambda value for the MANOVA (no coincidence, as the first value for Wilks’ Lambda will always be equal, regardless of the number of functions)</div>"
"Discriminant Analysis:&nbsp;SPSS&nbsp;""<i>Peel-off test</i>"""	"<u>First</u>: we test the significance of every function combined, after which we continuously peel off the first function (so the one that explains most variance) from the model<div><br /><div><u>Next</u>: we test if the remaining variables are still significant predictors are still related to the grouping variables. If “1 through 2” is significant, we know that at least function 1 is significant, but we can’t say anything about function 2 yet, as it explains less than function 1, so we don’t know whether it’s enough to be significant</div><div>-&nbsp;We need to test that one separately from the first function to conclude whether or not it’s significant. In this case, both functions are found to be significant (p &lt; .001, p = .001), so both functions are decent predictors of group membership.</div><div><img src=""Bildschirmfoto 2017-10-15 um 17.40.58.png"" /></div></div>"
Discriminant Analysis:&nbsp;SPSS - Canonical Discriminant Function/ Standardized Canonical Discriminant	"<img src=""Bildschirmfoto 2017-10-15 um 17.47.18.png"" /><div>shows the <i>unstandardized weights (b)</i> for each function. Given that a subject scores 30 on TheoryScore, 20 on ApplyScore, and 10 on InsightScore, then their score for dimension 1 is:</div><div><img src=""Bildschirmfoto 2017-10-15 um 17.47.33.png"" /></div><div><br /></div><div>This shows these <b>coefficients</b> are <i>excellent for calculating the score for each function</i>, but as they are<u> not standardized</u>, we <b>can’t use them to say anything about which value was most important </b>in creating the function itself. That’s why we need the next table with the standardized coefficients:</div><div><img src=""Bildschirmfoto 2017-10-15 um 17.48.49.png"" /></div><div><b>standardized coefficients</b>, we can estimate their relative importance for estimating the function itself.&nbsp;</div><div>For function 1, Theory &amp; Insight were the most important.&nbsp;</div><div>For function 2, Theory was a strongly negative predictor, while Apply and Insight were two fairly positive predictors. All in all, all variables contribute to the functions created by the discriminant analysis, so no functions or variables are considered for removal. If anything, Theory seems to have the most influence on creating the functions, with Insight close behind, and Apply as the least influential.</div>"
Discriminant Analysis:&nbsp;SPSS - Structure Matrix	"<img src=""Bildschirmfoto 2017-10-15 um 17.52.58.png"" /><div><b><font color=""#0000ff"">This table shows the correlations between the functions and all separate independent variables.&nbsp;</font></b></div><div><br /></div><div><u>Function 1</u> was by far the most important for predicting group membership, and we can see here that Insight and Theory are most strongly related to this function.&nbsp;</div><div><u>Function 2</u> was not as good, but still significant, and Theory is most related to this function, with Insight as a second, and Apply as the least related to the function.&nbsp;</div><div><br /></div><div>In this case, the standardized weights and correlations were rather similar, but this isn’t necessarily the case, so always analyse these separately. This all means that Insight and Theory are probably more important in differentiating between the different groups. But given that the correlation with Apply is still decent, Apply is not useless in differentiating between groups either.</div>"
Discriminant Analysis:&nbsp;SPSS - Functions at Group Centroids (<i>table</i>)	"<img src=""Bildschirmfoto 2017-10-15 um 17.56.37.png"" /><div><div>We can calculate the score on function 1 for all people who score “Low” on Education, with the coefficients we gathered from the “Canonical Discriminant Function Coefficients” table.&nbsp;</div><div>The mean score on function 1 of the group “Low” is shown in the table above: -2.320.&nbsp;</div><div>For “Medium” and “High” we can do the same thing, and find the mean for “Medium” and “High”, which are –0.015 &amp; 2.335, respectively. <font color=""#0000ff"">The fact that –2.320 – 0.015 + 2.335 sums up to 0 is because</font> the <i>mean score of all individuals is always exactly 0</i>, and now that we have equal sample sizes for each group, the unweighted mean is equal to the weighted mean = 0.&nbsp;</div><div>For function 2 we can repeat all these calculations, and the table above also shows us those means.</div><div><br /></div><div>This means that for the group “Low”, their mean score on function 1 is –2.320, and their mean score on function 2 is 0.377. These are the coordinates on the x-axis (function 1) and y-axis (function 2) of the Group Centroid for “Low” in the graph below. The same can be said for the Group Centroids of “Medium” and “High”. For every individual, <b>the difference between it and all group centroids is mathematically calculated with Mahalanobis Distance</b>.&nbsp;</div><div><font color=""#0000ff"">The one with the smallest distance is the group a subject is predicted to be a part of. As we can see in the graph below, the differences between centroids, especially for function 1, are so big that subjects are usually predicted correctly.</font></div><div><img src=""Bildschirmfoto 2017-10-15 um 17.57.00.png"" /></div></div>"
Discriminant Analysis:&nbsp;SPSS - Classification Results (table and graph combined)	"<div><img src=""Bildschirmfoto 2017-10-17 um 11.36.59.png"" /></div><div>The combination of the table and graph show that function 1 distinguishes the different groups pretty well, especially “Low” and “High” education. Function 2 doesn’t differentiate between “Low” and “High” at all, but it does distinguish both of them from “Medium”, so less mistakes are made for points around “Medium” and one of the other levels. These two functions together predict group membership pretty well, as we can see in this classification table:</div><img src=""Bildschirmfoto 2017-10-15 um 17.57.44.png"" /><div>If the model was useless, we would still randomly guess 33.33% of the group memberships right. So increasing that to 86.7% through this model is an excellent result, so this model is very able to accurately predict whether people received “Low”, “Medium” or “High” educations. All people in the “High” group were even accurately predicted! So if we are looking to improve the model even further, we need something to differentiate between Low and Medium slightly better, as most mistakes are in that area. Though all in all, 86.7% is a very satisfying result</div>"
Factor Analysis:&nbsp;<i>Theory</i>	"- goal of a factor analysis is to <b>summarize a number of continuous variables</b> <u>into </u>a <b>smaller number of factors or components</b><div>-&nbsp;<b>no </b>real independent or dependent variable for this test, just a bunch of continuous variables that we’re exploring for an underlying link, so we may summarize them in a few components or factors representing these underlying links</div><div><br /></div><div>There are many different ways to perform this analysis, but there are three default ways we need to know for the current exam:</div><div><img src=""Bildschirmfoto 2017-10-16 um 17.02.52.png"" /></div>"
Factor Analysis: <i>Difference between component analysis and common factor analysis</i>	"<b>component analysis (PCA)</b> <font color=""#0000ff"">tries to optimally summarize variables as a whole</font><div><b><br /></b></div><div><b>common factor analysis (CFA)</b> <font color=""#0000ff"">splits the variance of each variable into a part that overlaps with other variables (<b>Communality</b>) and a part that doesn’t overlap (<b>Unique</b>)</font></div><div><br /></div><div><br /></div><div>-&nbsp;The Unique part is ignored, as with Factor analysis, we only care about the part that overlaps to find the underlying link between the variables</div><div>- good models, with much overlap between the continuous variables, the choice between CFA and CA won’t matter much, as they will probably arrive to (almost) the same conclusion, as we could see during the lectures</div>"
Factor Analysis: <i>D</i>ifference between Exploratory and Confirmatory	"<b>Exploratory</b> literally explores the data, just to check <font color=""#0000ff"">what does and does not relate to each other</font>, and how to <font color=""#0000ff"">optimally summarize the variables in several factors or components.&nbsp;</font><div><b><br /></b></div><div><b>Confirmatory</b> literally <font color=""#0000ff"">confirms a model that was created beforehand</font>, so it tests whether this model actually fits the observed data or not</div>"
Factor Analysis:&nbsp;<i>For the whole variable (PCA) or the overlapping, communality part (CFA), we again use</i>	<b>eigenvectors</b> to estimate the best linear combination (= factor for CFA, or component for CA)<div><br /></div><div>-&nbsp;These <i>maximise the explained variance</i> of all variables in the model <u>within one linear combination</u></div><div>-&nbsp;Next, another<u> optimal linear combination</u> is calculated for the <u>residuals of the first linear combination</u></div><div>-&nbsp;cycle continues until there are as many linear combinations as there are continuous variables in the model</div><div><br /></div><div><br /></div><div>There is no definitive cut-off point to decide whether or not a variable should be included, and you’re allowed to set that point yourself, but a general <u>rule of thumb</u> is that <b>only linear combinations with an eigenvalue greater than 1 should be part of the final model.</b></div>
"PCA: <i>SPSS - output</i>; Example ""Total Variance Explained"""	"The variables are the three aspects that can be tested for an exam: Theory questions (TheoryScore), Application questions (ApplyScore), and Insight questions (InsightScore).<div>Second set of the canonical correlation are added as well: Number of study hours (StudyTime), a score that quantifies motivation for academia (Motivation), and an attractiveness score (Attractiveness)</div><div><img src=""Bildschirmfoto 2017-10-16 um 17.53.55.png"" /></div><div><u>First</u>, we see a table showing us <i>how much variance each component explains in all continuous variables</i>, and how many components are used for our model.</div><div>-&nbsp;two components with an <u>eigenvalue larger than 1</u>, so the optimal model with the least amount of components explaining the most variance, is two components</div><div>-&nbsp;For <b>PCA</b> the order of % explained variance is always from highest to lowest for <i>Initial Eigenvalues &amp; Extraction</i>, but that may change after Rotation, even though in this case the order is still correct. In total, 65% of variance is explained by these two components, which is a decent result. (scores with eigenvalue larger 1)</div><div><br /></div><div>-&nbsp;There is some logic behind this rule of thumb of only including variables when their eigenvalue is larger than 1. There are 6 components, and if you sum the numbers below “Total” you will find they sum to 6. Each variable on their own explains “1”. This means that if a component explains less than “1” of the model, it explains less than a continuous variable by itself would, so it is no longer efficient to add components.</div>"
PCA:&nbsp;<i>SPSS - output</i>; Communalities	"<img src=""Bildschirmfoto 2017-10-16 um 17.56.23.png"" /><div>“<b>Initial</b>” represents the<font color=""#0000ff""> <i>proportion of variance that is used by each variable</i></font>. As <u>PCA</u> always uses variables in their entirety, “Initial” will always be equal to 1, which basically <u>never</u> happens with <u>CFA</u></div><div>- That is how one could <b>differentiate</b> <i>between PCA and CFA</i>.</div><div><br /></div><div>""<b>Extraction""</b> is the <i><font color=""#0000ff"">proportion of explained variance by both components for each of the separate variables</font></i>.&nbsp;</div><div>- The <u>sum of the Extraction values</u> is <u>equal</u> to the <u>sum of the two eigenvalues</u> of the two relevant components.</div>"
PCA:&nbsp;<i>SPSS - output</i>; Scree Plot	"The Scree Plot is a plot where the <b>initial eigenvalues</b> of the first table can be seen in a graph, so that we may also visually inspect the data to figure out how many components we would like to add:<div><img src=""Bildschirmfoto 2017-10-16 um 18.00.37.png"" /></div>"
PCA:&nbsp;<i>SPSS - output</i>; Component Matrix/ Factor Matrix&nbsp;or Loading Matrix in general, or <u>Structure Matrix</u>	"It shows the <b>correlation between each component and the separate variables</b>. On the basis of this table, we could interpret which variables strongly correlate with each component, so we better understand what each component consists of.<div><img src=""Bildschirmfoto 2017-10-16 um 18.01.34.png"" /></div><div><u>Component 1</u> is mostly related to Theory, Apply, Insight, StudyTime, and Motivation</div><div><u>Component 2</u> is mostly related to StudyTime &amp; Attractiveness. The intention behind the data was for Attractiveness to be completely alone, but apparently StudyTime is negatively related to Attractiveness, so component 2 is negatively related to StudyTime.</div><div><br /></div><div>Also, the <u>correlations between the separate variables and a component may be squared</u>, then summed to find the exact value of the <b>eigenvalue</b> of that component:</div><div><img src=""Bildschirmfoto 2017-10-16 um 18.01.48.png"" /></div><div><i>When we divide this eigenvalue of a component by the number of variables, we end up with the proportion explained variance of that component:</i></div><div><img src=""Bildschirmfoto 2017-10-16 um 18.01.50.png"" /></div><div>We can <b>sum</b> the proportion explained variance of both components to calculate the <u>total proportion explained variance</u>, as all components or factors of PCA and CFA are always <i>independent</i> as long as<i> no oblique rotation</i> is performed.</div><div><br /></div><div>The <b>loadings</b> (correlations between variables and components) for each variable on both components are already quite polarized to -1, 0 and 1, without rotating them. This means we can already decently interpret each component without rotating the values</div><div>-&nbsp;it is very clear which component each variable belongs to, except maybe for StudyTime which highly correlates with both components</div>"
Rotating the matrix:	"Is a procedure to get the <b>loadings for each variable as close as possible to -1, 0 and 1</b>, to ease interpretation.&nbsp;<div>In theory, there are infinite ways to rotate data, as it can be rotated for any number of degrees between 0 and 360.</div><div>- there are automatic procedures capable of finding the optimal rotation for you</div><div>- roughly estimate the perfect angle, then subtly change until the values can’t be pushed towards -1, 0 and 1 anymore</div><div>- changes the proportion of explained variance for each separate component, so much so that it is possible for the first component to explain less variance than the second component, but the <u>total amount of explained variance always remains equal</u>.</div><div><div><br /></div><div>Major possibilities for rotating data are orthogonal rotation (<b>Varimax</b>) and oblique rotation (<b>Oblimin</b>)</div><div>- In most cases, orthogonal rotation is preferred, as it maintains independence between all components.</div><div>- Oblique rotation tries to push the values of the component matrix to -1, 0, and 1 even more rigorously (sacrifices independence between the components – difficulty of calculating the unique explained variance for each component)</div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-16 um 18.12.32.png"" /></div><div>Sometimes, Varimax can’t find a proper solution as there is no great solution by maintaining independence. In those cases, Direct Oblimin is superior as it at least allows us to interpret the components in some way, even though they aren’t independent.</div><div><br /></div><div>Varimax method:&nbsp;</div><div>rotation barely changed anything, as the values of the original Component Matrix were already relatively close to -1, 0 and 1, so there wasn’t much to improve upon. Therefore, the interpretation remains the same as for the original component matrix</div></div>"
Rotating the matrix: <i>Graph</i>	"Here we can see that Insight, Apply, Theory, and Motivation all fit well together, with StudyTime mostly differing a little from them on Component 2, while Attractiveness is pretty much on its own planet. StudyTime only seems to be far away from the other points due to being randomly related with Attractiveness, while Attractiveness isn’t close to the other points in any component, so that variable truly seems to be separate from the others.<div><img src=""Bildschirmfoto 2017-10-16 um 18.13.08.png"" /></div>"
PCA/CFA: SPSS - output; to calculate the score of an individual on a specific component, by using the table below:	"<img src=""Bildschirmfoto 2017-10-16 um 18.15.12.png"" /><div>Given that a subject scores 30 on TheoryScore, 20 on ApplyScore, and 10 on InsightScore, 20 on StudyTime, 0 on Attractiveness, and 100 on Motivation, then their score for component 1 is:</div><div><img src=""Bildschirmfoto 2017-10-16 um 18.16.28.png"" /></div>"
Common Factor Analysis: SPSS - output:	"<i>Exploratory CFA will give exact same tables as PCA</i>,&nbsp;but most values within the tables will be different as only the common (Communality) part is optimized instead of the variables as a whole<div><img src=""Bildschirmfoto 2017-10-16 um 18.24.14.png"" /></div><div><b>Initial</b> is clearly lower than 1, as <i>only the common </i>(Communality) part is now being analysed.&nbsp;</div><div>This is a case for which exploratory CFA isn’t great, as large parts of each variable are now unique, and therefore missing.&nbsp;</div><div>- Also, StudyTime has a weirdly high Extraction of 0.999.&nbsp;</div><div>- But regardless, we continue with our analysis, because we can pretend like all our values are perfect.&nbsp;</div><div>- The question in practice would be<b> how accurate our calculations would be now</b>, and if we would even be able to generalize to the population.&nbsp;</div><div>- But in the context of this example, that doesn’t matter as much. Such perks to having fake data!</div>"
Common Factor Analysis: SPSS - output: Total Variance Explained	"Now that we work with CFA, only the <b>initial eigenvalues table</b> is in order from high to low, both of the others can change, as is readily apparent for the <i>Extraction</i> <i>part</i> of the table above.<div>- Here, we have a quite extreme case of factor 1 barely having any communality, while factor 2 had a lot, meaning its eigenvalue ended up higher than factor 1. After rotating, Factor 1 is again higher than Factor 2, so natural order is restored in the kingdom of factors.<div><img src=""Bildschirmfoto 2017-10-16 um 18.24.55.png"" /></div></div>"
Common Factor Analysis: SPSS - output: Scree Plot	"it will look exactly the same as it did with PCA, as it displays the Initial eigenvalues that are always exactly the same as the PCA table:<div><img src=""Bildschirmfoto 2017-10-16 um 18.25.40.png"" /></div>"
Common Factor Analysis: SPSS - output: Factor Matrix	"<img src=""Bildschirmfoto 2017-10-16 um 18.26.23.png"" /><div>From this table we see that&nbsp;</div><div>Factor 1, StudyTime is probably a measurement error due to its weirdly high score, and there’s Theory who still has a decent loading. For&nbsp;</div><div>Factor 2, Motivation, Insight, Apply, Theory, and to a lesser extent Attractiveness all score high.&nbsp;</div><div><br /></div><div>- This is clearly different from the results of PCA, as in this case it’s mostly StudyTime that’s left out, while Attractiveness hides under the radar. We can clearly see in this case that imperfect data leads to different conclusions for both methods.</div>"
Common Factor Analysis: SPSS - output: Rotating the Matrix	"rotating will save this Exploratory CFA, so that weird loading for StudyTime disappears:<div><img src=""Bildschirmfoto 2017-10-16 um 18.27.09.png"" /></div><div><u>Now we see something that resembles <i>PCA</i> more closely</u></div><div>- Everything, except for Attractiveness, scores high on Factor 1, and StudyTime &amp; Attractiveness score (relatively) high on Factor 2.</div><div><br /></div><div>The exact values are still different, but the interpretation in general is the same for both rotated matrices for PCA and CFA.</div>"
Common Factor Analysis: SPSS - output: Graphical representation of Rotation Matrix	"Because the values for the matrices are rather similar, the graphs are rather similar as well. The difference between them is that now it’s StudyTime that’s furthest away from the group of scores, while Attractiveness is now a little closer, so these two kind of switched places. But we already know by now those two variables are exceptional variables, and that it’s the other 4 that mainly form a common factor or component. These 4 variables are closely related in the results for both PCA and CFA.<div><img src=""Bildschirmfoto 2017-10-16 um 18.27.56.png"" /></div>"
Common Factor Analysis: SPSS - output: <b>Goodness-of- fit Test</b>	"Now that we only use the <i>communality part</i> for creating factors, it is important that <i>whatever we estimate actually fits the data</i> as a <b>whole</b> and not just the communalities themselves.<div>- The <font color=""#0000ff"">null hypothesis of this test is that the model fits the observed values</font>.&nbsp;</div><div>(<i>we’d prefer to not reject the null hypothesis, otherwise we would need to add more factors to improve the model, or switch to another type of factor analysis like PCA</i>)<div><img src=""Bildschirmfoto 2017-10-16 um 18.30.19.png"" /></div><div>- p-value is as close to being significant as possible, so there is probably enough room to improve on this model</div><div>- we could tell it wasn’t perfect as Attractiveness and especially StudyTime were estimated rather weirdly, but apparently it was still good enough to (barely) not reject the null hypothesis, so that the model fits the data well enough.</div></div>"
Confirmatory Factor Analysis by:	-&nbsp;use the two exploratory methods above to confirm a model<div>-&nbsp;Simply let SPSS calculate the optimal model and check to see if that model fits the expectations. If it does, then that mostly confirms the model for your data, too. If it does not, an (alternative) rotation or a change in the number of components/factors could make the difference to get the model we expected to show up and confirm our model anyway.</div>
Confirmatory Factor Analysis:&nbsp;“official” confirmatory common factor analysis	"where one could enter the model directly. The main idea is that you have to<u> indicate which variables you expect to be related beforehand</u><div>- Imagine there’s a theory that says Theory, Apply, Insight and Motivation belong together in a factor, and that StudyTime &amp; Attractiveness are most important for a second factor</div><div>- The model can then be filled in, in such a way that all variables get a 0 on the factor they don’t belong to:<div><img src=""Bildschirmfoto 2017-10-16 um 18.32.30.png"" /></div><div>This way we guarantee the variables have no chance to contribute to factors they shouldn’t belong to, so that we truly test the model we’ve created based on the theory that was known to us. This is the best way to recognize Confirmatory CFA compared to Exploratory CFA. Compared to PCA, this technique still doesn’t use variables as a whole, so the communalities table will still not be filled with 1 on initial like it is for PCA.</div><div><br /></div><div>By using the <b>eigenvectors</b> and <b>eigenvalues</b> based on the overlapping (Communality) part of the variance, the <u><i>question marks</i></u> will be optimally estimated</div><div>- If these are far from 0, so close to -1 and 1, much of the variance in these continuous variables is explained by the factors, so the model indeed fits the theoretical model we’ve made beforehand</div><div>- If these are close to 0, they barely explain any variance, and so the model is probably wrong or the data is extremely crappy. If the data is crappy, nothing can be done except starting again or increasing sample size</div><div>- If the model is wrong and has to be developed again, an Exploratory CFA or PCA can be computed for the current data to check what the optimal model for our data is</div><div><br /></div><div>&nbsp;This is especially useful to find any potential differences between the theoretical model and our current data, so we may identify the problem with our theoretical model.</div></div>"
What is the difference in Multivariate designs (compared to univariate designs?)	We have more than one dependent variable<div>--&gt; we can measure model associations between dependent variables</div>
What are the advantages of adding another dependent variable?	1. Some treatments (factors) affect subjects in more than one way<div><br /></div><div>2. Several criterion measures will provide a more complete and detailed description of the phenomenon under investigation</div>
How do we write the H0 in MANOVA?	we have one vector per group containing a mean for each dependent variable<div><br /></div><div>H0: vector group 1 (containing e.g. µ<sub>11</sub>, µ<sub>21</sub> when we have two DV) = vector group 2 (µ<sub>21</sub>, µ<sub>22</sub>)</div><div><br /></div><div>µ<sub>jg</sub> the population mean on variable j in group g (first DV, second group)</div><div><br /></div>
When getting SPSS output, where do we have to look in order to retain/reject H0?	Look for the F statistic for the <b>Hotelling's T </b>and see whether this is significant.<div><br /></div><div>reject = there are differences between the two vectors of population means</div>
Why do we use multivariate analysis instead of multiple t-tests? Reason 1	1. Multiple univariate tests inflate overall Type I error rate<div><br /></div><div>if alpha = 0.05 for one test, for 4 tests the overall alpha is = 1-(0.95)^4 = 0.19 (maximum, assuming the tests are independent)</div><div><br /></div><div>--&gt; too many errors, too often falsely reject H0</div><div><br /></div><div>--&gt; <b>Capitalization on chance</b></div>
Why do we use multivariate analysis instead of multiple t-tests? Reason 2	2. Univariate Analyses ignore important information:<div><i>Association between dependent variables</i> (correlation)</div><div><br /></div><div>- Seperate tests reanalyze same variance (shared variance analyzed several times)</div><div><br /></div><div>- Individual variables may show no significant effect, while jointly the variables do have an effect</div><div><br /></div><div>--&gt; <b>Power</b>: Multivariate tests may have more statistical power to detect the effect of interest</div>
Why do we use multivariate analysis instead of multiple t-tests? Reason 3	The use of a total score (which consists of several subtest scores): may not reveal significant effects due to a <b>canceling out effect</b><div><br /></div><div>e.g. over-/underestimating biases -&gt; cancel each other out</div><div><br /></div><div>don't use a total score!</div>
"Reasons for <font color=""#fc3832"">not</font> performing Multivariate analyses (or rather downsides of it)"	"1. The techniques do not answer all questions; Still need univariate tests to <b>follow up</b> significant results (get a more complete picture by using a combination)<div><br /></div><div>2. Small or negligible differences on <b>""badly chosen"" variables</b> may obscure real differences on other (more important) variables (makes generalizability difficult)</div><div>--&gt; Parsimony!</div><div><br /></div><div>3. Arbitrarily chosen variables (with even up to moderate <b>correlations between DVs</b>) can decrease the power of multivariate tests</div><div>--&gt; high shared variance = instability in model parameters</div><div><br /></div><div>=&gt; Carefully select the variables you include!</div>"
Assumptions for Multivariate tests	"<b>vectors y1 and y2 have a multivariate normal distribution&nbsp;</b><div><b>with means mu1 and mu2 and covariance matrix M</b></div><div>(so for each vairable that composes the multivariate distribution, scores are <font color=""#0000ff"">Normally distributed</font>)</div><div><br /></div><div><b>M1 = M2 </b>(M is constant across groups)</div><div><br /></div><div><b>two sample sizes n1 and n2</b></div><div><b><br /></b></div><div>(we assume that the<font color=""#0000ff""> matrix with variances and covariances coincides</font> in both groups)<br /><div><div><br /></div><div><br /></div></div></div>"
Look up 2b slides 17,18 to understans how the t-test, F-test and the Hotelling's T<sup>2</sup>&nbsp;are related	"software transforms T<sup>2</sup>&nbsp;into F for us, but this transformation is not exact anymore for difficult designs<div><br /></div><div>When looking at the formula one can see that <b>if p=1 -&gt; F = T<sup>2</sup></b></div><div><b><sup><br /></sup></b></div><div><b>p = dependent variable</b></div><div><b><br /></b></div><div>F and T<sup>2 </sup>give the same p-value</div><div><br /></div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-23 um 12.01.31.png"" /><img src=""Bildschirmfoto 2017-10-23 um 12.01.34.png"" /></div><div></div><div></div><div><sup><br /></sup></div><div><sup><br /></sup></div><div></div><div></div>"
"<font color=""#fc3832"">Formulas:</font><div><br /></div><div>Multivariate computation of test statistic in two-groups case <b>(slide 22)</b></div>"	"We don't need to know how to compute an inverse!<div><br /></div><div>BUT:</div><div><br /></div><div>we need to know the formula for the ""multivariate sp"", which is S</div><div><br /></div><div>Best to look a the slide:</div><div><br /></div><div>Hints:</div><div>S1 = Matrix in Group 1 (variance-covariance matrix)</div><div>S2 = "" Group 2</div><div><br /></div><div>p = nr of DV in each group</div><div><br /></div><div>Degrees of freedom</div><div><br /></div><div>N - p - 1<img src=""Bildschirmfoto 2017-10-23 um 12.04.44.png"" /></div>"
What does a significant overall effect mean?	<i>There is at least one linear combination of dependent variables for which at least some of the groups differ in population means</i><div><i><br /></i></div><div>this linear combination of means seperates the groups (slide 24) so in a scatterplot one could see a clear difference between the groups</div>
What to do after a significant MANOVA?	Follow-up:<div><br /></div><div>Which variable(s) and/or group(s) cause the effect?</div><div><br /></div><div><u>Variable</u>:&nbsp;</div><div>Each seperate variabel -&gt; <b>univariate ANOVA</b></div><div>Which linear combinations -&gt; <b>Discriminat analysis</b></div><div><br /></div><div><u>Groups</u> (Lecture 3a)</div><div><b>Post-hoc</b> procedures or <b>contrasts</b></div><div><b>Visual inspection</b> (preferably with CIs)</div><div><br /></div>
PCA is aimed at	<b>constructing linear combinations</b> of the observed variables with <b>maximum variance</b> (called principal components).&nbsp;<div>- All the variance of the observed variables is distributed among the principal components.&nbsp;</div><div>- The solution to ﬁnding the principal components is based on a decomposition of the correlation (or covariance) matrix of the observed variables.</div>
FA is differs from PCA	"is diﬀerent because it conceptualizes the <b>division</b> of the<i> total variance of a variable in two parts</i>:<div>1.) A<font color=""#0000ff""> common part</font> which is shared with at least one other variable in the dataset (called the communality of the variable)&nbsp;</div><div>2.) and a<font color=""#0000ff""> unique part </font>which is uncorrelated with all the remaining variables.&nbsp;</div><div>- This unique part is typically a mix of measurement error and speciﬁc (reliable) variance that is uncorrelated with the rest of the variables.&nbsp;</div><div><br /></div><div>An FA solution is based on ﬁnding a decomposition of the correlation (or covariance) matrix of the observed variables with the diagonal values typically smaller than 1 (or than the variances when using the covariance matrix).&nbsp;</div><div>These diagonal values are precisely the communalities.</div>"
Rule of Thumb for loadings: (Component Matrix)	For interpretation, items are considered to load on a factor when the<b> loading is larger than .32</b><div><br /></div>
Difference orthogonal (Varimax) and oblique (Oblimin) rotation:	"Any <b>orthogonal</b> rotation of the principal components (using varimax or any other orthogonal procedure)<font color=""#0000ff""> preserves the total percentage of explained variance</font>.&nbsp;<div>- However, the rotation reshuﬄes the explained variance among the components<div><br /></div><div>This property is no longer valid for <b>oblique</b> rotations. In this case the<font color=""#0000ff""> rotated components share variance</font> (because they correlate), so one cannot just sum the explained variances across all components in order to ﬁnd the total explained variance. This problem resembles the similar issue in regression analyses and the multicollinearity property.</div></div>"
Multiway Frequency Models: <i>General</i>	-&nbsp;completely unrelated to eigenvalues<div>-&nbsp;a multivariate model, with the difference that these are all <b>categorical variables </b>(nominal and ordinal)</div><div>-&nbsp;alternative name for this analysis is “log-linear models”, because to calculate the<i> predicted score of</i>, in this case, the <b>natural <i>logarithm</i></b> of the <b>expected value</b>, we use a <i>linear</i> model</div><div><br /></div>
Multiway Frequency Models:&nbsp;<i>Rules surrounding calculus with logarithms</i>	"<u>First:</u><div><u><img src=""Bildschirmfoto 2017-10-17 um 15.00.24.png"" /></u></div><div><u><br /></u></div><div><u>Second:</u></div><div>If no base value is given, so <i>log(y)</i> = x , we may always assume that the natural logarithm (LN) was used, so that it has base level e: <i>log<sub>e</sub>(y) = x</i>&nbsp;.&nbsp;</div><div>(This means that on the exam, if you find yourself needing to calculate anything “log”, always press the “LN” or “e<sup>x</sup> ” button, rather than “log”)</div><div><br /></div><div><u>Third</u>: these rules are always true, independent of the chosen base of log:</div><div><img src=""Bildschirmfoto 2017-10-17 um 15.02.07.png"" /></div><div><br /></div><div>- the log of a value may be infinitely positive or infinitely negative</div><div>- the log of a number larger than one is always positive, and the larger this number is, the closer the log of that number gets to positive infinity. The logarithm of a number between 1 and 0 is negative, and the closer this number gets to 0, the closer the log gets to negative infinity.</div>"
Logarithm Rules: <i>if log<sub>a</sub>(y) = x, then:</i>	<i>a<sup>x</sup>&nbsp;= y</i>
Logarithm Rules:<i>&nbsp;log (a * b) =</i>	<i>log(a) + log(b)</i>
Logarithm Rules:<i>&nbsp;log (a<sup>b</sup>) =</i>	<i>b* log(a)</i>
Logarithm Rules:<i>&nbsp;</i><div><i><br /></i></div><div><i>log (a/b) =</i></div>	<i>log(a * b<sup>-1</sup>) = log(a) - log(b)</i>
Logarithm Rules:<i>&nbsp;</i><div><i><br /></i></div><div><i>log(1) =</i></div>	0, as anything to the power of 0 = 1
Logarithm Rules:<i>&nbsp;</i><div><i><br /></i></div><div><i>log (0) =</i></div>	Undefined, as the log of every negative number
The log of a number larger than one is always positive, and the larger this number is	the closer the log of that number gets to positive infinity
The logarithm of a number between 1 and 0 is	is negative, and the closer this number gets to 0, the closer the log gets to negative infinity.
Two categorical variables (Pearson Chi-Square &amp; Expected Value)	-&nbsp;compare the number of time we see any event occurring, so the frequencies<div><br /></div>
Two categorical variables (Pearson Chi-Square &amp; Expected Value): <i>Assumptions</i>	"<div>-&nbsp;<b>assumptions</b>&nbsp;made are that every result is measured <font color=""#0000ff"">independently</font>, and that there are at least<b> five times </b>as many people as there are cells in the table</div><div><img src=""Bildschirmfoto 2017-10-17 um 15.16.25.png"" /></div>"
Two categorical variables (Pearson Chi-Square &amp; Expected Value):&nbsp;<i>H<sub>0</sub>&nbsp;hypothesis</i>	"<img src=""Bildschirmfoto 2017-10-17 um 15.16.46.png"" /><div><div>Or in words (both null hypotheses, as the alternative only adds the word “not”):</div><div><br /></div><div>H<sub>0</sub> : “The type of animal is unrelated to what food they prefer”</div><div><br /></div><div>H<sub>0</sub> : “Relatively speaking, both animals love cat and dog food the same amount”</div></div>"
Two categorical variables (Pearson Chi-Square &amp; Expected Value): <i>Calculation</i>	"<div><img src=""Bildschirmfoto 2017-10-17 um 15.16.25.png"" /></div>To test whether the type of animal is independent of the food they prefer, we can calculate the value of X² by using the following formula:<div><br /><div><img src=""Bildschirmfoto 2017-10-17 um 15.17.58.png"" /></div><div><img src=""Bildschirmfoto 2017-10-17 um 15.18.19.png"" /></div></div>"
Pearson Chi-Square &amp; Expected Value: <i>df</i>	"<img src=""Bildschirmfoto 2017-10-17 um 15.24.09.png"" />"
Odds Ratio: General	"<div>-&nbsp;when we have a 2x2 table</div><div>- odds themselves are a reflection of how likely it is to get the outcome you mention, rather than the alternative</div><div>- odds-ratio reflects how two groups of one variable compare on their odds of the other variable</div><div><img src=""Bildschirmfoto 2017-10-17 um 15.27.36.png"" /></div><div>Calculating the odds-ratio may seem like a burden, but fortunately there is a formula that should work every time the table is structured normally:</div><div><img src=""Bildschirmfoto 2017-10-17 um 15.28.24.png"" /></div><div><br /></div><div><br /></div><div><br /></div><div>""For cats, the odds are 5/25 = 0.2. For dogs, the odds are 35/10 = 3.5. The odds-ratio would then be 3.5/0.2 = 17.5. This means the odds are 17.5 as large for a dog to prefer dog food, compared to the odds for a cat to prefer dog food. Similarly, you could say the odds-ratio is 0.2/3.5 = 0.057 = 1 / 17.5. This means the odds are 17.5 as small for a cat to prefer dog food, compared to the odds for a dog to prefer dog food.""</div>"
Three categorical variables (Multiway Frequency Model &amp; Expected value): <i>Calculation</i>:	"- extending the formula of Chi sqaure:<div><img src=""Bildschirmfoto 2017-10-17 um 15.32.14.png"" /></div><div><br /></div><div>(Adding Gender as Categorical variable – unrelated to type of animal and food)</div><div><img src=""Bildschirmfoto 2017-10-17 um 15.33.25.png"" /></div><div><img src=""Bildschirmfoto 2017-10-17 um 15.35.20.png"" /></div>"
Three categorical variables (Multiway Frequency Model &amp; Expected value):&nbsp;<i>What makes multiway frequency model more powerful than the chi-square test?</i>	"while the chi- square test was perfectly functional, it is limited to testing the <i>independence</i> of two variables.<div>- With multiway frequency modelling, you’re free to define your own model. This not only includes picking the main effects you’re interested in, but you could even include interaction effects!</div><div><br /></div><div>The expected value when there is an interaction effect can be calculated as follows:</div><div><img src=""Bildschirmfoto 2017-10-17 um 15.39.48.png"" /></div><div>In this case, the interaction between “Animal type” and “Food type” is included.</div><div><img src=""Bildschirmfoto 2017-10-17 um 15.40.56.png"" /></div><div><br /></div><div>Now we can calculate the expected values for each cell, using the model with an interaction term:</div><div><img src=""Bildschirmfoto 2017-10-17 um 15.41.17.png"" /></div><div><br /></div>"
Three categorical variables (Multiway Frequency Model &amp; Expected value): SPSS - multiple interaction: Parameter Estimation:	"This is where we can finally see how multiway frequency models use a linear combination. By properly filling in the model below, we obtain the <b>natural logarithm</b> of any cell we are interested in. Unfortunately, SPSS is a pain in this regard by not properly specifying which group is 1 and which is 2, so I will have to add this myself:<div><img src=""Bildschirmfoto 2017-10-17 um 15.49.13.png"" /></div><div><br /></div><div>We can fill in for any cell:</div><div><img src=""Bildschirmfoto 2017-10-17 um 15.51.10.png"" /></div><div><br /></div><div>For instance, for Cat &amp; Cat Food, Male:</div><div><img src=""Bildschirmfoto 2017-10-17 um 15.51.26.png"" /></div><div><br /></div><div>Or we could fill in Dog &amp; Cat Food, Female (Gender effect is so small, it’s practically 0):</div><div><img src=""Bildschirmfoto 2017-10-17 um 15.51.39.png"" /></div>"
The end goal of multiway frequency models is:	"that you can test different models, then decide on the model that has the best balance between number of effects and keeping the model as close to the observed values as possible.&nbsp;<div>- This means that rather than just testing to check for independence between two categorical variables, you have the flexibility to <b>test the strength of the contribution for any main effect and any interaction effect</b>.&nbsp;</div><div>- That is why there is no consistent null hypothesis, as it depends on the effects that are in the model.&nbsp;</div><div>- This can range from a model without any effect to testing every possible effect between all variables.<div><br /></div></div><div>The only consistent part is that in every case, the<font color=""#0000ff""> observed values are compared with the expected values</font>.&nbsp;</div><div><b>- The null hypothesis is that they are equal, and the alternative is that they are not equal</b>.</div><div>- Since we look for the model where the expected values are rather close to the observed values, this is one of the few tests we like to see non-significant</div><div>(In this case, gender was independent from type of animal and the food they prefer, so their expected and observed values are equal, meaning that X² = 0. That means this model is perfect, and we don’t need to include further interactions to improve the model.)</div>"
Multiway Frequency Models: <i>To define exactly which model we are testing, we can use the following terms:</i>	<div>Food = [A]&nbsp;</div><div>Animal = [B]&nbsp;</div><div>Gender = [C]</div><div><br /></div><div>In our example, we had the effects of FoodxAnimal [AB] and Gender [C]. If we take an interaction- effect [AB] we also always have to include the main effects that are part of this interaction, so [A] and [B]. This means the final model has the main effects of A, B and C, and the interaction-effect [AB], so [A][B][C][AB], or [AB][C] for short.</div><div><br /></div>
Multiway Frequency Models: <i>df</i>	<div>For the degrees of freedom of this model, we need to look closely at how the model is specified. We always start with the total number of cells, then always subtract 1 because at the very least, you are always aware of the total sample size of all groups. This is similar to how there is always an intercept in the regression model. Next, we need to subtract “number of groups – 1 = i – 1” for each main effect, “<b>(i – 1)(j – 1)</b>” for each twoway interaction, and “<b>(i – 1)(j – 1)(k – 1)</b>” for each threeway interaction, and so on. In this regard, the rules for degrees of freedom are identical to ANOVA.</div><div><br /></div><div>Total number of cells: 2 * 2 * 2 = 8&nbsp;</div><div>Subtract 1 for knowing the total sample size/constant: 7&nbsp;</div><div>Groups A – 1 = 2 – 1 = 1 therefore 6 left&nbsp;</div><div>Groups B – 1 = 2 – 1 = 1 therefore&nbsp;5 left&nbsp;</div><div>Groups C – 1 = 2 – 1 = 1 therefore&nbsp;4 left&nbsp;</div><div>AB = (2 – 1) * (2 – 1) = 1 therefore&nbsp;3 left</div><div><br /></div><div>So the degrees of freedom for this model = 3.</div>
Multiway Frequency Models in SPSS to find the best model	-&nbsp;computer programs are capable of automatically selecting this model by using a forward (not in SPSS) or backward-analysis (instead of deciding on the test beforehand – example)<div><br /></div>
Multiway Frequency Models in SPSS to find the best model: <i>Backwards Analysis</i>	"<u>A backward analysis starts with all possible effects, then <b>continuously removes the least significant one</b> until only significant predictors remain.</u><div>- Note that the rule that states we can’t remove main effects that are still part of an interaction effect in the model is still true here.</div><div>- For our example, it would start with [ABC], or fully written: [A][B][C][AB][AC][BC][ABC].</div><div>- For categorical variables, this guarantees 100% perfect estimation of every observed value.</div><div>- Now, we <i>start removing the highest order interaction</i>, [ABC], to test whether or not it’s significantly contributing to the model. If it is, we can’t remove it without ruining the predictive quality of the model, so we won’t remove it.</div><div>- If it isn’t, which is often the case, we will remove it and move on to two-way interactions.<div><br /></div><div><u>[AB], [AC], and [BC] are all tested simultaneously.</u></div><div>- If they all explain a significant part of the model, then the procedure stops here and the best model is the one with all twoway-interactions.</div><div>- If they aren’t all significant, the one with the highest p-value is removed.</div><div>- After that, the model with the remaining interactions is tested again, to check whether something can be deleted.</div><div>- This whole process continues until no variable remains.</div><div>- The example above was entered in SPSS, and a backwards analysis was computed.</div><div>- The output will be shown on the next page:</div><div><img src=""Bildschirmfoto 2017-10-17 um 16.15.54.png"" /></div><div><img src=""Bildschirmfoto 2017-10-17 um 16.17.29.png"" /></div><div>For step 0 we have: [A][B][C][AB][AC][BC][ABC] as our model&nbsp;</div><div>For step 1 we have: [A][B][C][AB][AC][BC] as our model&nbsp;</div><div>For step 2 we have: [A][B][C][AB][AC] as our model&nbsp;</div><div>For step 3 we have: [A][B][C][AB] as our model&nbsp;</div><div>For step 4 we have: [A][B][AB] as our model&nbsp;</div><div>After that it finds nothing else to delete, so our final model was the model specified at step 4.</div><div><img src=""Bildschirmfoto 2017-10-17 um 16.18.03.png"" /></div><div>Because the backwards analysis removed gender, we have gained one degree of freedom since our calculation by hand. Because gender didn’t contribute to accurately estimating the expected values in any way, we didn’t gain any error when we removed gender from our model. As long as the p-value is above .05, our final model has no significant loss of error compared to the full (step 0) model.</div><div>(Likelihood Ratio &amp; Pearson are both equally valid tests, but their p-values will not always be identical. Likelihood ratio seems slightly more accurate, but as Casper literally mentioned during the lectures they were both equally valid, I don’t think he’ll make you choose for the exam.)</div><div><br /></div><div>The fact that animal gender contributes absolutely nothing to the model, means we can collapse on gender. This sounds rather fancy, but it simply means we’re forgetting that variable that exists. So instead of:</div><div><img src=""Bildschirmfoto 2017-10-17 um 16.18.55.png"" />&nbsp;</div><div><br /></div><div>And now, if we want, we can run the analysis again for this model. We may only collapse for variables when [ABC] is not significant, and [AC] and/or [BC] isn’t significant either, or else the frequencies would be biased by pretending that variable doesn’t exist.</div></div>"
"Multiway Frequency Models in SPSS to find the best model:&nbsp;<i>Backwards Analysis</i><div><i><br /></i></div><div><i>Finally, we will test the final table with Odds-Ratio testing for differences in gender. This is only possible for a 2x2x2 model, so we can compare the odds-ratios of two groups, like men and women:</i></div><div><i><img src=""Bildschirmfoto 2017-10-17 um 16.21.55.png"" /></i></div>"	"<b>Odds-ratio </b>(Animal, Food) for women (A):&nbsp;<div>(Cat, Cat Food / Cat, Dog Food) * (Dog, Dog Food / Cat, Dog Food) = (25 / 5) * (35 / 10) = 17.5&nbsp;<div><b>Odds-ratio</b> (Animal, Food) for men (B):&nbsp;</div><div>(Cat, Cat Food / Cat, Dog Food) * (Dog, Dog Food / Cat, Dog Food) = (25 / 5) * (35 / 10) = 17.5</div></div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-17 um 16.22.09.png"" /></div><div><br /></div><div>No significant difference at all, though that was obvious by the fact both OR’s were exactly equal.</div><div><br /></div>"
Multiway Frequency Models: <i>Residuals</i>	"The residuals for this model is still equal to the <b>difference between the observed &amp; expected value</b>, similar to linear regression.<div>This difference may be standardised with the following formula:<div><img src=""Bildschirmfoto 2017-10-17 um 16.22.52.png"" /></div><div><div><br /></div><div>The notation in the slides uses<b> r<i><sub>ijk</sub></i></b> , instead of z, to emphasize the r of residuals, but the outcome is a z-value and r is pretty well-known as correlation, so I chose to use z for my notation. The letter doesn’t matter for the formula, though, but now at least you know what it means.</div><div><br /></div><div>These standardised residuals can be calculated for each cell, so lack of model fit can be tested for each of them. The z-value may be compared to the absolute critical value of |z*| = 1.96. If the absolute value of the residual is higher than 1.96, the model doesn’t fit well for this particular cell, and adding a variable that increases the accuracy of the expected values of this particular cell should be considered. If all residuals are lower than 1.96, the model appears to be fine.</div></div></div>"
In general, we are only interested in the difference between conditions within subjects (<b>within-subjects variance</b>), and not whether or not someone has a tendency to score higher in general.&nbsp;<div>There are three main ways to<i> remove between-subjects variance </i>that are being used by the techniques we use during the course:</div>	1.) Difference scores between measurements in time (<b>Matched Pairs t-test &amp; MANOVA</b>)<div><br /></div><div>2.) Enter “Subject” in a model as a random blocking variable (<b>ANOVA &amp; Multilevel</b>)</div><div><br /></div><div>3) Take the pre-measurement as a covariate (<b>ANCOVA</b>)</div>
3) Take the pre-measurement as a covariate (ANCOVA)	By entering the <b>pre-measurement as a covariate</b>, the mean of each group that’s part of the ANCOVA will be equal at that point in time. Also, the pre-measurement will have the opportunity to explain as much as variance as it can in the post-measurement. Whatever remains, is how much each group mean changed between the pre- and post-measurement.<div>- These group means may then be compared, to check if there were any differences in how they changed.</div>
2) Enter “Subject” in a model as a random blocking variable (<i>ANOVA</i> &amp; <i>Multilevel</i>)	"We’ve learned that with ANOVA, we can block by entering a (<i>categorical</i>) variable into the model to remove error or bias from that model.&nbsp;<div>This also happens when entering subject as a blocking variable.&nbsp;</div><div><br /></div><div>“Subject” will get the chance to explain as much variance as possible in the model so that <i>all between-subjects variance will be removed</i>.&nbsp;</div><div><br /></div><div>The <b>residuals</b> can then be used as the <font color=""#0000ff"">new dependent variable</font>, in a model to compare the different conditions over time.</div>"
1) Difference scores between measurements in time (Matched Pairs t-test &amp; MANOVA)	By taking the difference scores, it <b>only matters how much a subject improved over time, so their original or final score doesn’t matter anymore.&nbsp;</b><div>A subject that increases their score from a -2 to a 2, will have the same difference score as a subject that increases from 8 to 12.&nbsp;<div><br /></div><div>The between-subjects variance, that the second person scores 10 points higher in both measurements, is no longer there in the difference score.</div></div>
the effect size (η²) works	the same way for RM-ANOVA, RM-MANOVA and the repeated measures variant of ANCOVA as they did for ANOVA, MANOVA and ANCOVA respectively.&nbsp;<div><br /></div><div>For matched pairs t-test &amp; Multilevel, no effect size is mentioned during the lectures.<div><br /></div></div>
Matched Pairs t-test &amp; ANOVA (Gain Score)	The <b>Matched Pairs t-test is specialised in comparing two measurements in time</b>, but that is all it can do.<div>- It corrects for between-subjects variance by taking the <i>difference score between the pre- and post-measurement</i>.</div><div>- Next, it tests whether or not the mean of the difference score is significantly different from 0, as 0 would mean nothing has changed over time.</div><div>- ANOVA (Gain Score) does the same thing, but also allows comparing (between-subjects) groups on the difference score, to check for a potential interaction-effect.</div>
ANCOVA	Specialised in checking whether two or more groups have changed in varying amounts between a<i> pre- and post-measurement.&nbsp;</i><div><br /></div><div>- Similar to ANOVA (Gain Score), but uses the pre-measurement as a covariate instead of taking difference scores.&nbsp;</div><div>- Therefore, unlike ANOVA, it can’t test whether the mean of all difference scores is 0, but it’s the best model for comparing groups on how much they’ve changed over time.</div>
RM-ANOVA	"The first model with a wide variety of uses, though it <b>can’t deal with missing data</b>.&nbsp;<div><br /></div><div>- Corrects for between-subjects variance by <font color=""#0000ff"">blocking for subjects</font>, by adding “subject” to the model as a random factor. After removing the effect of subject, a regular ANOVA is computed.&nbsp;</div><div>- Because we have just one dependent variable regardless of how many measurements in time we’ve done, we have to be able to assume <b>sphericity</b> of our data.</div><div>- If we can safely assume sphericity, RM-ANOVA is generally the most powerful test of all.</div>"
RM-MANOVA	The second model with a wide variety of uses, though it also can’t deal with missing data.<div><br /><div>- Corrects for between-subjects variance by<b> transforming X measurement in time to (X – 1) code variables</b>, like taking difference scores of each consecutive pair, like the Matched Pairs t-test.</div><div>- Next all code variables are entered in the model as dependent variables, after which a MANOVA is computed as usual.</div><div>- Now that we don’t have just one dependent variable anymore, the assumption of sphericity has disappeared.</div></div>
Multilevel Modelling	"<div>Is the most flexible model of all, and is even able to<i> deal with missing data</i>. Like RM-ANOVA, it <b>corrects for between-subjects variance by blocking for subjects</b>, by<font color=""#0000ff""> adding them as a random variable </font>in the model. Multilevel analysis is an umbrella term for many different models. Depending on the model, the output and assumptions will be different. This will be explained extensively in this part of the summary.</div><div><br /></div><div>The flexibility of multilevel allows one, in contrary to the other five mentioned models, to create the entire model themselves. This increases the difficulty of comparing the different methods directly, like stating which of these has the strictest assumptions, as the answer depends on how the multilevel model is specified. It can be either stricter than RM-ANOVA, or even less strict than RM- MANOVA as it doesn’t even need complete data. When, in the summary, the three main models are compared, it will always be “in general”, so something that is true for most multilevel models.</div><div>- For instance, “In general” RM-ANOVA has the strictest assumptions out of the three of them.</div>"
Matched Pairs t-test: <i>Information</i>	Matched Pairs t-test can only compare a<b> pre- and post-measurement</b>, and can’t compare any between-subjects variables or interactions when it’s doing that.&nbsp;<div>It calculates the difference score between two measurements, and tests whether they are different from 0.</div>
Matched Pairs t-test:&nbsp;<i>H<sub>0</sub>&nbsp;hypothesis</i>	"<img src=""Bildschirmfoto 2017-10-18 um 09.51.17.png"" />"
Matched Pairs t-test: <i>Assumptions</i>	<u>First</u>, the difference score has to be <b>normally</b> distributed, or the sample size has to be big enough that it doesn’t matter anymore, due to the Central Limit Theorem.&nbsp;<div><u>Second</u>, the difference scores have to be <b>independent</b> from each other.&nbsp;</div><div><br /></div><div><i>- There is no problem of homoscedasticity or linearity here, as the pre- and post-measurement are combined into one scale anyway.</i></div>
Matched Pairs t-test:&nbsp;<i>Example – </i>SPSS	"<img src=""Bildschirmfoto 2017-10-18 um 09.54.19.png"" /><div>Here, the results of the matched pairs t-test are shown. SE was removed from the table for better readability.</div><div><img src=""Bildschirmfoto 2017-10-18 um 09.56.38.png"" /></div><div>If the first two values of B2 weren’t changed, so that B2 = B1 + 2 was true for every value, the SD of the difference score would’ve been 0, so it wouldn’t have been able to calculate anything. The lesson here is that regardless of the source of the difference, any difference will be picked up by the matched pairs t-test and will be tested for significance.</div>"
ANOVA (Gain Score): <i>Information</i>	"This isn’t the “real” RM-ANOVA, but an alternative way to compute repeated measures when you have two measurements of time, which was also shown during the lecture.&nbsp;<div>Similar to matched pairs t-test, difference scores (gain scores) are used as the dependent variable.&nbsp;</div><div><br /></div><div>The <b><font color=""#0000ff""><u><i>intercept</i></u></font></b> of the ANOVA table will show whether or not these difference scores are significantly different from 0:</div>"
ANOVA (Gain Score):&nbsp;<i>H<sub>0 </sub>hypothesis </i>(and addition)	"<img src=""Bildschirmfoto 2017-10-18 um 09.59.29.png"" /><div>the <font color=""#0000ff"">intercept</font> in the ANOVA table is useful, and tests the same hypothesis as the matched pairs t-test above.</div><div>- But in addition to that, you’re free to<font color=""#0000ff""> <u>add a categorical variable as independent variable</u></font>, to test whether the <b>mean difference score</b> is <b>equal</b> across groups.&nbsp;</div><div><br /></div><div>The hypotheses for this are similar to the “normal” ANOVA:</div><div><img src=""Bildschirmfoto 2017-10-18 um 10.00.13.png"" /></div><div>Or in words:</div><div><img src=""Bildschirmfoto 2017-10-18 um 10.00.41.png"" /></div><div><br /></div><div>So with this model, we can test the <b>main</b> <b>effect</b> of time like we can with the matched pairs t-test (Do participants change in general?), and we can test the <b>interaction</b> <b>effect</b> between the different groups and change over time (Does one group change more than another?). On the next page, an example will be shown, with “CDifference” as the dependent variable, and “Group” as the independent, grouping variable.</div>"
ANOVA (Gain Score): <i>Assumptions</i>	normaliy, homoscedasticity, independence
ANOVA (Gain Score): <i>Example – SPSSS&nbsp;</i>	"“CDifference” as the dependent variable, and “Group” as the independent, grouping variable.<div><img src=""Bildschirmfoto 2017-10-18 um 10.09.39.png"" /></div><div><img src=""Bildschirmfoto 2017-10-18 um 10.09.59.png"" /></div><div><b><font color=""#0000ff"">Intercept</font></b> shows whether or not the <u>mean</u> of all difference scores was significantly different from 0, so that people in general score significantly different on both measurements in time. In this case, we see that it is (p &lt; .000), so <i>either participants significantly improved or declined over time</i>. ANCOVA also has an intercept, but as ANCOVA doesn’t use difference scores, the intercept is once again useless for that model.</div><div><br /></div><div><b><font color=""#0000ff"">Group</font></b> shows whether or not there is a significant <u>interaction</u> effect between Group and the time measurements. In this case, there appears to be an interaction effect (p = .015). To check whether the participants improved in general and which group changed differently from the others, we can compute Multiple Comparisons as a follow-up analysis. As we have three groups, the <i>LSD</i>-procedure is chosen</div><div><img src=""Bildschirmfoto 2017-10-18 um 10.11.57.png"" /></div><div><img src=""Bildschirmfoto 2017-10-18 um 10.12.00.png"" /></div><div>The table of <b>means for Group</b> display the means of the difference scores for each group. All of them are positive, which means the participants in each group scored better on the post-measurement than on the pre-measurement, on average.</div><div>Also, from the <b>multiple comparisons table</b>, we can see that group 3 improved the most out of all groups, having a significantly higher mean than group 1 (p = .005) and group 2 (p = .033). Group 1 and group 2 don’t seem to differ significantly from each other, so we can’t tell which group improved more in the population.</div>"
ANCOVA: <i>Information</i>	"The only goal of an ANCOVA is always to compare groups, in this case after they are<i> corrected for a covariate</i>.&nbsp;<div><br /></div><div>But in this case, the covariate happens to be the <u>pre-measurement</u>, and the dependent variable is the <u>post-measurement</u>, which means you’d expect a pretty strong correlation between the two.&nbsp;</div><div>Adding the pre-measurement as a <font color=""#0000ff"">covariate</font>, means <b>any difference between group means on the pre-measurement will be removed.&nbsp;</b></div><div>Next, the three groups are compared on the post- measurement, as that is now the dependent variable.&nbsp;</div><div>A significant difference shows that the change between both points in time is different for at least one group, compared to the other groups.<div><br /></div><div>Lord’s Paradox might be present for repeated measures, as was already shown with the example comparing weights of men and women at pre-measurement &amp; post-measurement. When we corrected for the pre-measurement of weight, we were adding bias, instead of removing it. So with natural groups, be very careful using this repeated measures test.</div></div>"
(RM)ANCOVA:&nbsp;<i>H<sub>0</sub>&nbsp;hypothesis</i>	"<img src=""Bildschirmfoto 2017-10-18 um 10.17.05.png"" />"
(RM)ANCOVA: <i>Difference to regular ANCOVA</i>	"So the only difference between a regular ANCOVA and this ANCOVA is the fact that a <b>pre- measurement is used as the covariate</b>, instead of a different variable, but that doesn’t change anything in practice or even in the maths behind it<div><br /></div><div>Like ANOVA &amp; matched pairs, it can only be used for two time points, as adding a potential third invalidates the analysis, regardless of whether it’s considered a dependent variable or covariate. So the only thing it can do is compare rate of improvement over different groups for<b><font color=""#0000ff""> two time points</font></b>, which seems awfully limited as ANOVA (Gain Score) can do that too. But as it does this in a very unique way, it is always the best way unless one of the assumptions is violated or Lord’s Paradox threatens to happen for your data</div>"
(RM)ANCOVA:&nbsp;<i>Example </i>– SPSS	"<img src=""Bildschirmfoto 2017-10-18 um 10.30.23.png"" /><div>If A1 and A2 are compared for the three groups:</div><div><img src=""Bildschirmfoto 2017-10-18 um 10.30.59.png"" /></div><div>A2 = 1.5 * A1, so A1 already explains 100% of the variance of A2. This is what makes ANCOVA unique among all repeated measures test. Using any other method to analyse this data, the absolute difference between measurements would be tested similar to how matched pairs t-test and ANOVA did it, and it would conclude that scores increase in general, and that group 3 increases more than the other groups.</div><div><br /></div><div>ANCOVA isn’t limited to the difference scores (A2 – A1), but it is allowed to freely change the weight of A1 to best estimate A2 (A2 – 1.5*A1), so all variance in A2 can already be explained by A1 and all change scores, including the differences between groups, disappear. This will happen as long as change scores are proportional, and ANCOVA is the only method that takes that into account.</div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-18 um 10.57.05.png"" /></div><div><div>Thanks to the first two cases (5-6 &amp; 5-8), there is still a little unexplained variance in the model. However, again all differences been groups have already been explained by the pre-measurement. The matched pairs t-test was significant as the post-measurement was 2 points higher on average, but the ANCOVA doesn’t care about that and just explains what it can with the pre-measurement, including that main effect of time. ANCOVA only measures the interaction effect well, and as every group increased by 2 on average, there is no interaction effect, hence SS Group = 0.</div><div><br /></div><div>The significance of B1 shows that there is a very strong linear relationship between B1 and B2. Given that these are a pre-measurement and post-measurement, you’d expect this relationship to be at least decent.</div></div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-18 um 10.57.53.png"" /></div><div>Now, the differences are a little random, so both the covariate and the groups are now significant. This means the differences weren’t proportional like with A, or equal like with B, but that there really is a (more random) difference in how the groups changed over time. This means we can use multiple comparisons as a follow-up analysis to find exactly where these groups differ that can’t just be explained away by the pre-measurement.</div><div><img src=""Bildschirmfoto 2017-10-18 um 10.58.07.png"" /></div><div><img src=""Bildschirmfoto 2017-10-18 um 11.00.16.png"" /></div><div>Unlike the ANOVA for Gain scores previously, the means in the “Estimates” table aren’t the difference scores, but the adjusted means of the post-measurement after correcting for the pre- measurement. Though also in this case, all the general conclusions remain the same, though ANCOVA is probably more accurate given that any bias between groups due to differences on the pre-measurement is removed.</div><div><br /></div><div>Group 3 has the highest adjusted mean of all groups, having a significantly higher mean than group 1 (.005) and group 2 (.023). The means we see are the means on the post-measurement after being corrected for the pre-measurement, so while the mean itself represents their score on the post- measurement, their differences are completely due to differences in change over time, as they all use “19.2” (shown right below the “Estimates” table) as a pre-measurement score. Group 1 and 2 don’t seem to differ significantly (.216).</div>"
(RM)ANCOVA: <i>Conclusion</i>	ANCOVA is only useful for comparing differences between two time points for various groups.<div>- By allowing the pre-measurement to explain as much as it can in the <i>covariate</i>, the calculations aren’t bound to (A2 – A1), but the <b>weight of A1 </b>can change to anything, for instance (A2 – 1.5 * A1).</div><div>- It will then compare the differences in change between groups, something which ANCOVA is superior in as long as there’s no Lord’s Paradox or violated assumption.</div><div>- ANOVA with Gain Scores, RM-ANOVA &amp; RM-MANOVA can all test differences between groups through as well, but in essence they all take difference scores between two time points as a default, like the matched pairs t-test did.</div><div>- RM-ANOVA &amp; RM-MANOVA allow for contrasts, but finding the optimal estimator of A1 yourself is nearly impossible.</div>
RM-ANOVA: <i>Information</i>	"this analysis can include <i>more than two measurements in time</i>, <i>more than one within- subjects variable</i>, an<i>d between-subjects variables</i> in a single model, instead of just the effect of “Time” and an interaction-effect.<div><br /></div><div>-&nbsp;<b>splits the variance between and within subjects</b> (like Multilevel Analysis)</div><div><br /></div><div>-&nbsp;allows RM-ANOVA to <i>use different variances</i> depending on which effects need to be tested&nbsp;</div><div><br /></div><div>-&nbsp;We are only interested in <b>differences</b> <b>between the measurements within subjects</b>, we don’t care about some people generally getting higher scores than others when their change in score (30 – 40 vs. 0 – 10) is the same</div><div><br /></div><div>-&nbsp;RM-ANOVA corrects for this by adding “<i>Subject</i>”, or whatever name is used for the variable that links each measurement to each subject, as a<font color=""#0000ff""> random variable to the model </font>(This effect will be calculated as part of the model, so the variance it explains will be <u>removed</u> from all other parts of the model)</div><div><br /></div><div>-&nbsp;Because subjects are randomly selected from a population, it’s a random variable, unlike “condition” which usually isn’t a random sample from a population of conditions. Adding “Subject” is what separates RM-ANOVA from “normal” ANOVA</div><div><br /></div><div>-&nbsp;we are allowed to add as many measurements, within-subjects &amp; between-subjects variable as we please</div><div><br /></div><div>- RM-ANOVA will generally have the most power, given that no assumptions are violated (RM-ANOVA, RM-MANOVA, Multilevel)</div>"
RM-ANOVA:&nbsp;<i>Dis / - Advantages</i>	"RM-ANOVA has the <b>most power</b> and provides us with much readily usable information, but also has the strictest assumptions:<div><br /></div><div>-&nbsp;we expect the scores between subjects to be <b>independent</b> (so not all measurements, as we already know repeated measures are related, and that’s fine), and we assume <b>normally</b> <b>distributed</b> <b>residuals</b></div><div><br /></div><div>-&nbsp;lack of measurement <b>error</b></div><div><br /></div><div>-&nbsp;If we add a<font color=""#0000ff""> <b>between-subjects variable</b></font> to the RM-ANOVA, we even get the assumption of <i><b>homoscedasticity</b></i> again, so that the different groups have the same SD in the population.&nbsp;</div><div>- For <b><font color=""#0000ff"">within-subjects variables</font></b>, there is the (new) assumption of <b><u>sphericity</u></b>. This one is also about variance, similarly to homoscedasticity, but as it’s now a <i>within-subjects variable</i> we need to look at it in a slightly different way.</div>"
RM-ANOVA:&nbsp;<i>Sphericity </i>(Assumption)	<u>in RM-ANOVA&nbsp;every score from each time point is combined into one dependent variable:</u><div><br /></div><div>-&nbsp;a pretty strong assumption to just say that all of these measurements from different moments in time are actually all the same variable</div><div>-&nbsp;can be checked by <i>comparing the variances</i> of all possible pairs of difference scores, which should all be equal</div><div>-&nbsp;a consequence of the more technical actual assumption that the (<u>transformed</u>)<i> covariance matrix</i> only contains covariances of 0, and all variances are equal to each other</div><div><br /></div><div>(in case of violation: RM-MANOVA, Multilevel model)</div>
RM-ANOVA and RM-MANOVA have extra limitations:	"-&nbsp;RM-ANOVA and RM-MANOVA only work for<b> <font color=""#0000ff"">complete data</font></b>, while all Multilevel models can deal with missing values as all parameters are calculated through the Maximum Likelihood procedure<div><br /></div><div>-&nbsp;RM-ANOVA and RM-MANOVA, like their non-RM counterparts, use <b>categorical independent variables</b></div><div>(This means that when adding a “Time” variable, it has to be a categorical variable, such as “pre-measurement, post-measurement, follow- up” while it can’t be “Time in days after start of research”.&nbsp;</div><div>- Multilevel methods is <i>based on linear regression</i>, we’re free to <b>add continuous variables </b>like “Time in days after start of research” to the model as a predictor/independent variable.)</div><div><br /></div><div><u>In brief</u>: When there is no fixed set of measurements over time or when you have missing data, Multilevel is superior. When you do have a fixed set of measurements and (almost) no missing data, RM-ANOVA is used when you can assume sphericity, and RM-MANOVA when sphericity is violated.</div>"
Three different effects can be tested with RM-ANOVA:	<b>Between-subjects</b> effects,<div><br /></div><div><b>within-subjects</b> effects,&nbsp;</div><div><br /></div><div><b>interaction</b> effect</div>
RM-ANOVA: <i>Test for Sphericity</i>	"SPSS will automatically test for sphericity using<b> Mauchly’s W test</b>.<div><img src=""Bildschirmfoto 2017-10-18 um 11.56.59.png"" /></div><div>Right below the table it says “Tests the null hypothesis that our data has perfect sphericity”, but with more technical terms.&nbsp;</div><div>Like with all other significance tests for assumptions, <b>we would like this to be non-significant</b>, because then we don’t have to reject the null hypothesis that the assumption is met. (violated here)</div>"
RM-ANOVA:&nbsp;<i>How to deal with violation of Sphericity</i>	"within RM-ANOVA, by <i>correcting the degrees of freedom of the F-test:</i>&nbsp;<div><br /></div><div>This correction is computed by multiplying the DF with Epsilon (ε):&nbsp;<div><b>Greenhouse-Geisser</b> (too <i>conservative</i>) or&nbsp;<b>Huynh- Feldt</b> (too <i>liberal</i>)</div></div><div><br /></div><div><u>The rule of thumb is:</u></div><div>- to <font color=""#0000ff"">use<i> Greenhouse-Geisser</i></font> when the mean of both epsilons is<u> lower than 0.7</u>,</div><div>- to <font color=""#0000ff"">use <i>Huynh-Feldt</i></font><i> </i>at<u> 0.7 or higher</u>.&nbsp;</div><div><br /></div><div>The mean here is (0.528 + 0.696) / 2 = 0.612, so lower than 0.7, so the Greenhouse-Geisser correction is used.</div><div><img src=""Bildschirmfoto 2017-10-18 um 12.09.00.png"" /></div>"
RM-ANOVA:&nbsp;<i>SPSS </i>– Example	"The first RM-ANOVA table given to us by SPSS after computing repeated measures, shows both the<b> within-subjects effects</b> and the<b> interaction effects </b>with at least one within-subjects effect, as they all use the within-subjects error<div><img src=""Bildschirmfoto 2017-10-18 um 12.18.11.png"" /></div><div><u><font color=""#0000ff"">“Measurement”</font></u> is the<b> within-subjects</b> <i>main effect</i>, testing whether the four time points of C1, C2, C3 or C4 all have the same mean (<b>Test of Flatness </b>- when there is no main effect of time, the lines in a graph would all be flat)</div><div><div>The hypotheses are:</div><div><img src=""Bildschirmfoto 2017-10-18 um 12.18.41.png"" /></div></div><div><div>-&nbsp;For two measurements, the p-value of this test is equal to that of a matched pairs t-test, or ANOVA with gain scores (As it checks for differences between “the differences between groups”, it’s hard to write an algebraic null hypothesis for it, unless there are just two time points)</div></div><div><br /></div><div><br /></div><div><br /></div><div><font color=""#0000ff""><u>“Measurement * Group”</u> </font>is the <i>interaction</i> <i>between</i> the within-subjects and between-subjects effect, which shows if the general pattern of time is the same for all three groups (<b>Test of Parallelism</b>&nbsp;- when there is no interaction, the lines in a graph would all be parallel).</div><div>-&nbsp;As soon as one part of the interaction is a <i>within-subjects effect</i>, it will always be in the within-subjects table</div><div>For two, we use the same <u>null hypothesis</u> as the ANOVA with Gain Scores had:</div><div><img src=""Bildschirmfoto 2017-10-18 um 12.24.34.png"" /></div><div><br /></div><div><br /></div><div><u>Greenhouse-Geisser correction:</u></div><div><div>GG-correction has a p-value of .007 for <b>Measurement</b>, which shows that there is a <i>significant difference between the time points</i>. This means we reject the idea that the mean score of each time point is equal for each time point in the population. As with normal ANOVA, we can’t tell which mean is different, but we now know there’s at least one.</div><div><br /></div><div>The interaction-effect shows a p-value of .323, meaning that no significant <b>interaction</b>-<b>effect</b> was found based on the data. This means we <i>can’t reject the idea that there is a difference in their pattern in the population.</i></div></div><div><br /></div><div>-&nbsp;So now that we know there is a main effect and no interaction-effect, we could do several follow-ups to get a better view of what exactly is going on, like make a <b>graph</b>:</div><div><img src=""Bildschirmfoto 2017-10-18 um 12.27.55.png"" /></div><div>- hints at main effect with <i>measurement 2</i> higher than the other three in time,&nbsp;and measurement 1 seemingly having the lowest mean (clear differences between the patterns, especially with group 3 increasing more)</div>"
RM-ANOVA: <i>Graph analysis:</i>	"<img src=""Bildschirmfoto 2017-10-18 um 12.27.55.png"" /><div>-&nbsp;<b>main effect</b>, with measurement 2 having a higher mean than the other three measurements in time, and measurement 1 seemingly having the lowest mean</div><div>-&nbsp;clear differences between the <b>patterns</b>, especially with group 3 increasing more between measurements 1 and 2, and decreasing more between measurements 2 and 3, compared to the other groups</div><div><br /></div><div>A significant <u style=""color: rgb(0, 0, 255); "">quadratic trend</u> would mean that the <i>scores would clearly rise between two time measurements</i>, but also clearly drop between two other time measurements.&nbsp;</div><div>- This happens pretty clearly for our data, with the massive increase between measurements 1 and 2 and the clear decrease between measurements 2 and 3.</div><div>- This means we will probably find a significant quadratic trend.</div><div>-&nbsp;also indicates which <b>trends</b> could potentially be significant.</div><div><br /></div><div>A significant<u><font color=""#0000ff""> linear trend</font></u> would lead to a <i>clear difference between the first and last measurement</i>.&nbsp;</div><div>- Though lines at measurement 4 are slightly higher than measurement 1, the difference isn’t large, so there is probably no significant linear trend for this data</div><div><u><br /></u></div><div>A significant&nbsp;<u><font color=""#0000ff"">cubic trend</font></u> means the scores rise-fall-rise, or fall-rise-fall.&nbsp;</div><div>- We kind of see this pattern emerging for group 2, and because the fall between measurements 2 and 3 doesn’t continue between measurements 3 and 4, as the effect straightens out.&nbsp;</div><div>- This means there is a small cubic effect, mostly depending on sample size and significance level to conclude whether it’s significant or not.</div><div><br /></div><div>A significant trend for the<u><font color=""#0000ff""> interaction-effect </font></u>means that there is a difference between groups with regards to the trend.</div><div>- A significant linear interaction trend points to one group having a strong linear trend, while another does not.</div><div>- Or one might have a positive linear trend, while another has a negative trend.</div><div>- These help provide some nuance to the general trends provided by the main effect, so that we may provide some information about each separate group of the model.</div>"
"RM-ANOVA:&nbsp;<i>Graph trend:&nbsp;</i>main effect<div><img src=""Bildschirmfoto 2017-10-18 um 12.27.55.png"" /></div>"	<div><b>main effect</b>, with measurement 2 having a higher mean than the other three measurements in time, and measurement 1 seemingly having the lowest mean.</div><div>- There are reasonably clear differences between the patterns, especially with group 3 increasing more between measurements 1 and 2, and decreasing more between measurements 2 and 3, compared to the other groups.</div>
"RM-ANOVA:&nbsp;<i>Graph trend: </i>Linear Trend<div><img src=""Bildschirmfoto 2017-10-18 um 12.27.55.png"" /></div>"	<div>- A significant<b> linear trend would lead to a clear difference between the first and last measurement.</b></div><div>- Though lines at measurement 4 are slightly higher than measurement 1, the difference isn’t large, so there is probably no significant linear trend for this data.</div>
"RM-ANOVA:&nbsp;<i>Graph trend:&nbsp;</i>Quadratic Trend<div><img src=""Bildschirmfoto 2017-10-18 um 12.27.55.png"" /></div>"	<div>would mean that the <b>scores would clearly rise between two time measurements, but also clearly drop between two other time measurements.</b></div><div>- This happens pretty clearly for our data, with the massive increase between measurements 1 and 2 and the clear decrease between measurements 2 and 3.</div><div>- This means we will probably find a significant quadratic trend.</div>
"RM-ANOVA:&nbsp;<i>Graph trend:&nbsp;</i>Cubic Trend<div><img src=""Bildschirmfoto 2017-10-18 um 12.27.55.png"" /></div>"	<div>means the scores<b> rise-fall-rise, or fall-rise-fall</b>.</div><div>- We kind of see this pattern emerging for group 2, and because the fall between measurements 2 and 3 doesn’t continue between measurements 3 and 4, as the effect straightens out.</div><div>- This means there is a small cubic effect, mostly depending on sample size and significance level to conclude whether it’s significant or not.</div>
"RM-ANOVA:&nbsp;<i>Graph trend:&nbsp;</i>Interaction Effect<div><img src=""Bildschirmfoto 2017-10-18 um 12.27.55.png"" /></div>"	<div>trend for the interaction-effect means that there is a<b> difference between groups with regards to the trend</b>.</div><div>- A significant linear interaction trend points to one group having a strong linear trend, while another does not.</div><div>- Or one might have a positive linear trend, while another has a negative trend.</div><div>- These help provide some nuance to the general trends provided by the main effect, so that we may provide some information about each separate group of the model.</div>
RM-ANOVA: <i>Table Trend analysis: </i>(within-subjects)	"<img src=""Bildschirmfoto 2017-10-18 um 12.39.34.png"" /><div>The <b>quadratic trend</b> of Measurement was the strongest, and clearly significant (p &lt; .001), there was a smaller, but still reasonable <b>cubic trend</b> of Measurement which turned out to be barely significant (p = .043), and a<b> linear trend</b> that was mostly absent (p = .539).&nbsp;</div><div><br /></div><div>For both linear and cubic, there does not seem to be a difference between groups, but quadratic is around the level of α, indicating a potential small effect. We could see this from the graph too, with the increase and decrease around measurement 2 being larger for group 3 than for the other groups, though in the end it wasn’t found to be significant (p = .057).&nbsp;</div><div><br /></div><div>Even if we did find significance in this table specifically, it wouldn’t be wise to reject the idea that there are no differences between the quadratic trends in the population, as the general interaction effect we tested two pages back wasn’t significant either (p = .323).</div>"
RM-ANOVA:&nbsp;<i>Table Trend analysis:&nbsp;</i>(between-subjects) – SPSS	"<b>between-subjects effect</b> (<i>Test of Difference in Levels</i>)&nbsp;<div>- A between-subjects effect would look like one line being above the other in a graph, hence the name.</div><div>- This is exactly like the normal ANOVA, in that it doesn’t take away variance between subjects, and just compared several groups on the dependent variable, or in this case the averages of all measurements per subject.</div><div>- This also means the assumption of&nbsp;<b>sphericity</b> is gone for testing this specific effect, and is replaced by “the usual” <b>homoscedasticity</b>.&nbsp;<div><br /></div><div>From the graph, we could see that group 3 had the highest mean, followed by group 2, and that group 1 had the lowest mean. But is this a significant difference? That’s what we can find out here. The hypotheses are:</div><div><img src=""Bildschirmfoto 2017-10-18 um 12.48.03.png"" /></div><div><br /></div><div>Because this between-subjects variable has 3 groups, we use the LSD correction for the multiple comparison follow-up. As these three groups are compared on the average level of all four measurements, the mean differences will be different from when we did this as part of the ANOVA (Gain Score) and ANCOVA examples before.</div><div><img src=""Bildschirmfoto 2017-10-18 um 12.48.20.png"" /></div><div>The top table shows that there is indeed a significant difference between the three groups, so we may reject the idea that the mean of all three groups is equal in the population.</div><div>- But from just that table, we can’t conclude which group is different from the other groups.</div><div>- From the graph we know which group has the highest and lowest mean, but we don’t know whether they are all significantly different from each other or if only the groups with the lowest and highest mean are different from each other.&nbsp;</div><div>- To this end, we can use the <b>Multiple Comparisons table</b> to provide us with the answers to all these questions.&nbsp;</div><div><br /></div><div>Both group 2 (8.12 points higher) and group 3 (12.23 points higher) have a significantly higher mean than group 1, but group 2 and group 3 do not differ significantly (p = .127).</div></div>"
Difference between&nbsp;RM-MANOVA and RM-ANOVA:	The main difference is that <i>RM-ANOVA assumed <u>sphericity</u></i>, while <b>RM-MANOVA does not</b><div><br /></div><div>MANOVA has <b>multiple dependent variables</b>, while ANOVA only has one</div><div><br /></div><div>Multiple measurements in time are all considered to be one dependent variable for RM-ANOVA, while multiple measurements in time are considered to be<b> separate dependent variables for RM- MANOVA</b></div><div><br /></div><div>But if we were to add the four measurements in time as our dependent variables, they wouldn’t be corrected for between-subjects variance. To solve this, the <b>difference scores </b>between measurements in time are used, and due to having more than two measurements in time we can use the logic of <i>code variables</i> for linear regression on our dependent variables to test specific effects.</div>
RM-MANOVA: Example (dependent) code variables	"<img src=""Bildschirmfoto 2017-10-18 um 14.18.05.png"" /><div>proceed to create three code variables (<i>always one less than number of measurements</i>) to compare various groups. Depending on the code we choose, we will test different attributes or effects. For instance, if you would take dummy coding with C4 as reference group, then every group will be compared to C4. However, dummy coding isn’t one of the two most commonly used ones.&nbsp;</div><div><br /></div><div>They are: <b>Repeated Contrast</b></div><div><img src=""Bildschirmfoto 2017-10-18 um 14.26.58.png"" /></div><div>This is like computing<i> multiple matched pairs t-tests</i> after each other, as for all three contrasts we compare two measurements in time. That is why an RM-MANOVA for just two measurements in time will have the exact same p-value as a matched pairs t-test would have.</div><div><br /></div><div>&nbsp;The other common contrast is the <b>Polynomial</b> <b>Contrasts</b>, to test for<i> linear, quadratic, cubic, … trends</i>. This one is especially useful for effects over time:</div><div><img src=""Bildschirmfoto 2017-10-18 um 14.42.00.png"" /></div>"
RM-MANOVA: Example; <i>Multivariate Tests</i> (SPSS)	"<div>A MANOVA for both contrast types will now be computed (R = <i>Repeated</i>, P = <i>Polynomial</i>):</div><img src=""Bildschirmfoto 2017-10-18 um 14.42.33.png"" /><div>-&nbsp;different code variables have<b> no impact on the total explained variance of the model</b> (Repeated &amp; Polynomial contrasts will show the same general effect)</div><div><u><img src=""Bildschirmfoto 2017-10-19 um 11.34.20.png"" /></u></div><div><u><img src=""Bildschirmfoto 2017-10-19 um 11.36.26.png"" /></u></div><div><u><font color=""#0000ff""><b>Intercept</b></font>:</u></div><div>for Contrasts, we want to know whether the contrast estimate differs from 0, and the intercept is a test to compare a value such as the grand mean or, in this case, contrast estimate to 0, so they coincide</div>"
RM-MANOVA: Example;&nbsp;<i>Repeated/Polynominal Table for the contrasts:</i>	"<div>From the <b><font color=""#0000ff"">Repeated table</font></b> we learn that there is a significant difference between measurements 1 and 2 (p &lt; .001), which we also saw in the graph for RM-ANOVA, which showed a clear increase from measurement 1 to measurement 2. After that the lines went down more gradually, so the differences between measurements 2 and 3 (p = .101) and measurements 3 and 4 (p = .504) were not found to be significant.</div><img src=""Bildschirmfoto 2017-10-18 um 14.46.46.png"" /><div><br /><div>_____________________________________</div><div>From the <b><font color=""#0000ff"">Polynomial table</font></b> we can see whether we have a <b>linear</b> trend (no, p = .536), a <b>quadratic</b> trend (yes, p &lt; .001), and <b>cubic</b> trend (almost, p = .053).&nbsp;</div><div>(<i>Hey, wait! These look like the p-values we found for the RM-ANOVA, the within-subjects contrasts table with these trends to be precise! Surprise: Both times we’ve tested the same effect, but in a different way. Any differences between these results and the ones in that table are rounding errors</i>)</div><div><img src=""Bildschirmfoto 2017-10-18 um 14.46.49.png"" /></div><div><br /></div><div><br /></div><div>But there is another interesting point to these tables. There are <i>no predictors</i> in our model now, so the entire model, Intercept &amp; Error, for observed effects is shown above. Our model is literally:</div><div><img src=""Bildschirmfoto 2017-10-18 um 14.48.45.png"" /></div><div>Observed value Y at time t of subject i = Intercept (Mean) of time T + Error at time t of subject i</div><div><br /></div></div><div><br /></div><div><u>This is the secret to why RM-MANOVA has so few assumptions</u>.</div><div>- The only thing we assume is that there is a mean for each time point, all variance between the scores besides that mean is included in the (random) error.</div><div>- This technically means <b>we explain 0% variance</b>, as the intercept isn’t part of the explained variance, so 100% is unexplained.</div><div>(The multilevel analogue to this RM-MANOVA model is called the “fully multivariate model”.&nbsp;This doesn’t change anything about RM-MANOVA itself, but it’s useful to know for the Multilevel part of this course, so keep this in mind for the Multilevel section)</div>"
This is the secret to why RM-MANOVA has so few assumptions:	"The only thing we assume is that there is a mean for each time point, all variance between the scores besides that mean is included in the (random) error. This technically means we explain 0% variance, as the intercept isn’t part of the explained variance, so 100% is unexplained<div><img src=""Bildschirmfoto 2017-10-18 um 14.48.45.png"" /></div><div>-&nbsp;<b>Multivariate</b> <b>Normality</b> is still an assumption here, as even the intercept is tested with an F-test.</div><div>- we also have the assumptions of <b>independence</b> between subjects</div><div>-&nbsp;<b>no measurement error</b></div><div><b><br /></b></div><div>The final assumption of ‘normal’ ANOVA, linear relationship between dependent variables, is <u>gone</u> as the dependent variables are now all code variables. As always, we only need a linear relationship between continuous variables, as there is no sense in trying to find linear relationships between codes.</div>"
RM-MANOVA:<i>&nbsp;H<sub>0 </sub>Hypothesis</i>	"<img src=""Bildschirmfoto 2017-10-18 um 15.00.53.png"" />"
RM-MANOVA:&nbsp;<i>SPSS&nbsp;</i>– output	"<img src=""Bildschirmfoto 2017-10-18 um 15.01.03.png"" /><div><img src=""Bildschirmfoto 2017-10-18 um 15.00.53.png"" /></div><div><br /></div><div>- hopefully they won’t use this example for the exam, as the answer whether or not it’s significant depends on the chosen MANOVA-method</div><div>-&nbsp;<b><font color=""#0000ff"">Wilks’ Lambda</font></b>, we can conclude that the interaction effect is not significant, as the difference between the patterns in the observed data is just barely not big enough to generalise to the population with certainty (if it was, we could use the difference in trends to help us pinpoint where this difference is, most likely to the difference in quadratic effect around measurement 2)</div><div>-&nbsp;The main effect is significant, similar to RM-ANOVA, which means at least one time point is different from the others on average</div><div><br /></div>"
RM-MANOVA: <i>Follow up Analysis</i>	RM-ANOVA,&nbsp;<div><br /></div><div>They share their complete follow-up analysis, with no difference anywhere, so it will not all be repeated again</div>
For two measurements in time, with no between-subjects variables	p-value of <b>matched pairs t-test</b> = p-value of <b>RM-ANOVA</b> = p-value of <b>RM-MANOVA</b>
For two measurements in time with one or more between-subjects variables	"<font color=""#0000ff"">Intercept</font> <b>ANOVA</b> (Gain Scores) = <font color=""#0000ff"">Main Effect Time</font> <b>RM-ANOVA</b> = <font color=""#0000ff"">Main Effect Time</font> <b>RM-MANOVA&nbsp;</b><div><br /></div><div><font color=""#0000ff"">Group effect</font> <b>ANOVA</b> (Gain Scores) = <font color=""#0000ff"">Interaction</font> <b>RM-ANOVA </b>= <font color=""#0000ff"">Interaction</font> <b>RM-MANOVA</b></div>"
Carry-over effect	is a phenomenon that with<b> repeated measures, the previous conditions influence the conditions after it</b>, for instance due to drugs staying in blood circulation.&nbsp;<div><br /></div><div>This might be hard to prevent, like with experimental drugs, but is always unwanted. To counter this, increasing the time between conditions might help, though that allows patients to change more between measurements, and randomizing the order might help to counter-balance any carry-over effect.</div>
Matched Pairs t-test has a unique advantage	in using a t-distribution, meaning that the <b>direction of an effect becomes immediately clear from it being positive or negative.&nbsp;</b><div><br /></div><div>RM-ANOVA &amp; RM-MANOVA use F-values, that don’t show this direction. Except for that, RM-ANOVA &amp; RM-MANOVA are complete replacements, so if you understand RM-ANOVA and RM-MANOVA, you’ll never have to compute matched pairs t-test or ANOVA (Gain Scores) again! ANCOVA and multilevel remain unique, due to the covariate at the pre-measurement and the insane flexibility of Multilevel Analysis.</div>
Multilevel Modelling: <i>Assumptions</i>	<b>normality</b> &amp; <b>independence</b> of (all) residuals (like RM-MANOVA)
What&nbsp;Multilevel analysis essentially does:	summarizes the distribution of scores into:&nbsp;<div><br /></div><div><b>grand</b> <b>mean</b> of all, and <b>variance</b> <b>scores</b> to indicate the spread in scores.</div>
Multilevel analysis vs. linear regression (example 1)	"<u><b>Linear regression without an independent variable:</b></u><div><img src=""Bildschirmfoto 2017-10-19 um 15.00.54.png"" /></div><div><br /></div><div><br /></div><div><b>Independent</b> <b>continuous</b> and <b>code</b> <b>variables</b> can be added to this model, to test to which degree they reduce the error in estimating the observed values. The proportion explained variance can be measured with<b> R²</b>. The higher this number is, the more proportion of variance is explained</div><div><br /></div><div><u>Multilevel also allow for multilevels:</u></div><div><img src=""Bildschirmfoto 2017-10-19 um 15.11.08.png"" /></div><div>The <u>error</u> of all <i>individual measurements</i>, which we saw for linear regression, is now replaced by<b> two separate error terms</b></div><div>-&nbsp;Both <b><i>b<sub>0j</sub></i> </b>and<b> <i>e<sub>ij</sub></i> </b>are unexplained variances in this model.</div><div>- this additional error term&nbsp;means that we can make variables target one error term specifically. We can have it attempt to reduce error in level 2, level 1, or both, depending on what we expect a certain variable to do</div><div><br /></div><div><br /></div><div>It’s important to have these <u>subgroups</u> whenever necessary, as we have<b> assumed independent residuals</b> for every test we’ve learned about, including multilevel models. When subjects are part of different groups that score differently on the dependent variable(s), and these different groups aren’t part of the model, this assumption is violated</div><div>(<i>Imagine checking how well students perform on a physics test in secondary school, and we don’t take into account that this group of students have two different teachers. When both teachers are equally competent, there is no problem as then the mean score for both teachers would be the same. The model for each student would then look like:</i>)</div><div><img src=""Bildschirmfoto 2017-10-19 um 16.15.59.png"" /></div><div><br /></div><div>The teachers being exactly equal isn’t very likely though, so it is wise to <u>block</u> the effect of “<b>Teacher</b>” to remove that part of the error from the model. In this case, we could also use ANOVA to compare both teachers. However, a linear regression model with “teacher” as a<b> code variable </b>takes this difference into account in an identical way. The codes will be –0.5 and +0.5, so contrast coding, for the sake of consistency in interpretation:</div><div><img src=""Bildschirmfoto 2017-10-19 um 16.16.49.png"" /></div><div><br /></div><div><div>Note how the alternative notation of the ANOVA hypotheses returns for linear regression. For the <b>null hypothesis</b> (both teachers are equal), <i>b<sub>1</sub></i> is not part in the model. Now that there is a mean difference for both teachers, so the <b>alternative hypothesis</b>, <i>b<sub>1</sub></i> is part of the model.</div><div><br /></div><div>We can also write down the model above with multilevel notation:</div></div><div><img src=""Bildschirmfoto 2017-10-19 um 16.18.08.png"" /></div>"
Essential differences between linear regression and multilevel modelling	The only difference is that “<i><b>b<sub>1</sub>C<sub>j</sub></b></i>” from the regression model is replaced by “<i><b>b<sub>oj</sub></b></i>” for the multilevel model.&nbsp;<div><i><br /></i></div><div><i>- b<sub>1</sub></i> shows us the differences between teachers, and automatically test this difference for significance as part of the linear regression, which is useful.<div><br /></div><div><br /></div></div>
Multilevel analysis vs. linear regression (example 2)	"The test scores for a physics test are also related to intelligence, so it is decided to also measure IQ. This also makes the comparison between teachers more fair, as one teacher may have students with a higher average intelligence, thus causing the difference between teachers. At this point, we could do an ANCOVA with intelligence as a covariate, but for this case we may also use linear regression. IQ is centered to create IQc, to keep the interpretation as consistent as possible:<div><img src=""Bildschirmfoto 2017-10-19 um 16.41.43.png"" /></div><div><div>Note how the alternative notation for ANCOVA-hypotheses returns for linear regression. For the<b> null hypothesis</b> of <i>b<sub>2</sub></i>&nbsp;, that IQ is unrelated to test score, it is not part of the model, like on the previous page. Now that we expect IQ to be related to test score, so <i><b>H<sub>a</sub></b></i> , it is part of the model.</div><div><br /></div><div>The above model may again be rewritten in multilevel style:</div></div><div><img src=""Bildschirmfoto 2017-10-19 um 16.42.17.png"" /></div><div><br /></div><div>With regards to notation, multilevel analysis is now starting to be superior. As you might have noticed, the first number after any sign indicates which parameter of student <i><b>i</b></i> it’s affecting, and the second number which parameter for teacher<b><i> j</i></b> it’s affecting.&nbsp;</div><div><i>-<b> b<sub>00</sub></b></i>&nbsp;is the overall mean, so the intercept for both groups.</div><div>-&nbsp;<b><i>b<sub>0j</sub></i> </b>is still related to the intercept for students, as that depends on the mean of the teacher they belong to, but the teachers are free to differentiate.</div><div>-&nbsp;<i><b>b<sub>10</sub></b></i> doesn’t influence teacher scores directly, because it’s not his/her IQ we’re dealing with, but it is part of the model for the individual level of students.</div><div>- For them, it’s slope <i>b<sub>1</sub></i> , a slope to reflect the relationship between IQ and their physics test score.</div>"
Multilevel analysis vs. linear regression (example 3)	"Adding an interaction effect for teacher * IQ<div><img src=""Bildschirmfoto 2017-10-19 um 16.52.45.png"" /></div><div><br /></div><div>The above model may again be rewritten as a multilevel model:</div><div><img src=""Bildschirmfoto 2017-10-19 um 16.53.01.png"" /></div>"
Multilevel analysis vs. linear regression (example 4)	"Adding Teachers to the model (now 8 in total)<div><br /></div><div><u>Linear regression:&nbsp;</u></div><div><img src=""Bildschirmfoto 2017-10-19 um 17.00.28.png"" /></div><div><br /></div><div><u>The above model may again be rewritten as a multilevel model:</u></div><div><img src=""Bildschirmfoto 2017-10-19 um 17.00.58.png"" /></div><div>This model is identical to the model for two teachers! This is one of the two biggest strengths of multilevel analysis, how it can summarize various effects of large quantities of groups with just the <b>mean</b> and <b>variance</b>, instead of the testing each difference in full detail with the linear regression approach. It’s specificity and attention to detail is a great strength of linear regression for simpler models, but now the more general approach of Multilevel is more useful. Multilevel wins this one!</div>"
Multilevel analysis vs. linear regression (example 5)	"Adding ""experience in years"" of the teacher to the model:<div><br /></div><div>- Linear regression stops working</div><div><br /></div><div>Multilevel models gleefully continuous in multilevel form, because as stated before, the official notation is really clear:&nbsp;</div><div><img src=""Bildschirmfoto 2017-10-19 um 17.05.36.png"" /></div><div><div><u>All possibilities for testing effects are displayed in the model above:</u></div><div><b>Intercept</b> or Overall mean:&nbsp;<i>y<sub>00</sub></i>&nbsp;</div><div><b>Main</b> effect for students:&nbsp;&nbsp;<i>y<sub>10</sub></i>&nbsp;</div><div><b>Main</b> effect for teachers:&nbsp;&nbsp;<i>y<sub>01</sub></i>&nbsp;</div><div><b>Interaction-effect</b> between teachers and students:&nbsp;&nbsp;<i>y<sub>11</sub></i></div><div><i><sub><br /></sub></i></div></div><div><br /></div><div><div>Note how <i>y</i> is used for each <b>fixed factor</b> (<i>u</i> = unknown, <b>random</b>), and that the first number shows what it means for students, and the second number shows what it means for teachers.</div><div><br /></div><div><b>Unexplained variance</b> between teachers: <i>u<sub>0j</sub></i></div><div><b>Unexplained variance </b>in the slope for IQ between teachers: <i>u<sub>1j</sub></i></div><div><br /></div><div>Differences between teachers in general translate to a different group mean for different students, so that’s why unexplained variance between teachers starts with a 0: <i><b>u<sub>0</sub></b></i>, like <b><i>b</i><sub>0</sub></b> for linear regression. Differences between the slopes of IQ between teachers means it’s related to the variance in <i><b>y<sub>10</sub></b></i>&nbsp;, so to symbolize this, the first number is a 1: <i><b>u<sub>1</sub></b></i></div></div><div><u><br /></u></div><div><i><sub><br /></sub></i></div><div><i><sub>Multilevel model is the only technique we’ve learned about, at this point, that can include both a level 2 effect (experience) and a level 1 effect (IQ), and can simultaneously calculate separate valid coefficients for both effects. This is the second major strength of a Multilevel model, as we are allowed to take every effect into account when calculating the other effects.</sub></i></div>"
Multilevel analysis vs. linear regression (example 6) MISSING p.104	"Teachers and all their related effects will now be completely removed from the model, so we end up with a simple model that linear regression can handle again:<div><img src=""Bildschirmfoto 2017-10-19 um 17.23.47.png"" /></div><div>Now let’s see what happens when every student repeats this test multiple times over a year so we can track their progress:</div>"
Multilevel Model:&nbsp;<i>Theory</i>	- we can have more than one sample, which may be a subgroup of the other sample<div><br /></div><div>- therefore, more than one error, which we add as another random variable</div><div><br /></div><div><b>Aggregation</b>, only testing on level 2 (hospitals, teachers), works well for a small number of groups and a relatively large number of level 1 units by including it as a <b>fixed factor</b>, as we’ve seen in the previous pages. However, this does mean we lose most information on level 1, which might not always be desirable</div><div><br /></div><div><b>Disaggregation</b>, so<i> ignoring level 2 and only testing level 1</i>, is only allowed if there are no differences between the groups at level 2, or the assumption of independence, present for every test, will be violated</div><div><br /></div><div><b>Two-stage regression</b>, a<i> linear regression separately for each group at level 2</i>. Works fine statistically, but is a lot of work when the number of groups increases, and means you have to somehow combine results to reach a general conclusion</div><div><br /></div><div><b>RM-(M)ANOVA</b> is a valid alternative that is even preferred for complete, fitting data, but only works for repeated measures and 2 levels, with separate measurements in time on level 1 and subjects on level 2.&nbsp;This means it’s not as generally applicable as multilevel is.&nbsp;</div><div><br /></div><div><u><i>Multilevel</i></u> is also the only one that can handle a continuous variable to indicate the time a measurement took place.</div>
Multilevel Model:&nbsp;<i>Random Intercept</i>	"<img src=""Bildschirmfoto 2017-10-19 um 17.44.28.png"" /><div>Individuals at <u>level 1</u> have different intercepts, depending on which group<b><i> j</i> </b>they belong to.</div><div>- This follows from the notation, as the intercept is shown with a <b>0 </b>in “<i><b>ß<sub>0j</sub></b> </i>”, and its dependence on <b><i>j</i></b> is shown as the <b><i>j</i></b> in “<i><b>ß<sub>0j</sub></b> </i>”.&nbsp;</div><div>- All else is error in level 1 “<i><b>e<sub>ij</sub></b></i>”</div><div><br /></div><div>For<u> level 2</u>, we can see that the intercept of level 1 is dependent on the overall mean (<i>y<sub>00</sub></i>) that very fittingly includes two 0’s, as it is also the intercept of level 2, and the error term defined as the difference between the overall mean and the mean of each separate group.</div><div><br /></div><div>As we can see here, both level 1 and level 2 have their own error. <i><b>u<sub>0j</sub></b></i> is the variance between the different means of each group at level 2, so the randomness of the intercept we use for level 1. That is what makes this the “random intercept model”. Adding <i>u<sub>0j</sub></i> to the model means we expect the means of each group to be different.</div>"
Multilevel Model:&nbsp;<i>Random Intercept model with a slope</i>	"Let’s go back to the example of 8 teachers with students, but divide the students into two groups with “old style learning” and “new style learning”. We can add this effect to the model through using <b>dummy coding</b>, for instance giving old style a 0 and new style a 1, similar to linear regression.<div><img src=""Bildschirmfoto 2017-10-19 um 17.55.36.png"" /></div><div>The bottom part shows why this is <font color=""#0000ff"">not</font> considered a random slope formula, as the slope is fixed at <i><b>y<sub>10</sub></b></i>, as no (random) component is added to define changes between groups. This means we assume that the mean difference between old and new style is the same for each teacher, which is quite strict. If you think this assumption may be violated, it’s smart to add a random component to check:</div>"
Multilevel Model:&nbsp;<i>Random Intercept &amp; Random Slope</i>	"<img src=""Bildschirmfoto 2017-10-19 um 18.00.50.png"" /><br /><div>Note how a “<b><i>j</i></b>” was added to <i><b>ß<sub>1</sub></b></i> to reflect the effect of learning style now changes depending on which teacher <b><i>j</i></b> an individual is part of.&nbsp;</div><div>- Now that the difference between both groups is free to vary for each teacher, we no longer assume that the difference between the groups is equal for each teacher.</div><div>- This shows that it is possible to add or change parameters in your model, to increase complexity but reduce assumptions of a particular model.</div>"
Multilevel Model:&nbsp;<i>Repeated Measures</i>	"With repeated measures, we consider the <b>sample of all measurements to be at level 1</b>, and a <b>sample of subjects at level 2</b>.&nbsp;<div>- Because we now assume the measurements to be a <i><u>random sample</u></i> belonging to a subject, similar to a class of students “belonging” to a teacher, it more logically follows that not every sample of measurements within subjects needs to be equal in size, similar to how not every class has an equal size.&nbsp;</div><div>- Just like some teachers have 8 students, and others have 5, now some subjects have 8 measurements, and others have 5. Also, to reflect we now work with repeated measures, the official notation changes from “individual i, group j” to “measurement t, individual i”.&nbsp;</div><div><br /></div><div><u>This is simply convention, and has no influence on how the model is defined. So the model above:</u><div><img src=""Bildschirmfoto 2017-10-19 um 18.05.54.png"" /></div><div><u>Turns into (given that the dummy is now used to distinguish groups of measurements):</u></div><div><img src=""Bildschirmfoto 2017-10-19 um 18.06.10.png"" /></div><div>Multilevel is most similar to RM-ANOVA with regard to how it deals with<i> between-subjects variance</i>. RM-ANOVA has a set of measurements, from which the between-subjects variance (<i>u<sub>0i&nbsp;</sub></i>for multilevel), is removed from the error as a whole.</div><div>- As we can see from computing both tests in SPSS, the random intercept model and RM-ANOVA will use the exact same error for testing the differences between measurements in time, which also leads to identical F and p-values.</div><div><br /></div><div>The <u><i>difference</i></u> is that multilevel can handle data in a more flexible manner, including adding a parameter to create a random slope model.&nbsp;</div><div>- It doesn’t require each subject to have had the same number of measurements, and it doesn’t even require the measurements to be defined by a categorical variable.</div><div>- Because the parameters are estimated through Maximum Likelihood, it can also deal well with missing data.</div><div>- But maximum likelihood also has a drawback, we can´t calculate how much explained “variance” a model has, only how much is still unexplained (compare the unexplained variance of our model to an empty model where everything is unexplained)</div><div>- We may then compare both unexplained variances, to determine the proportion explained variance by our model.&nbsp;</div><div>This empty model is called the “fully multivariate model”:</div><div><img src=""Bildschirmfoto 2017-10-19 um 18.19.01.png"" /></div><div><br /></div><div>For the record, the lecture says “<i>saturated model</i>” as a reference to that now there is no individual error (<i>e<sub>ti</sub></i>) anymore, but only error part of the model, defined as <i>u<sub>ti</sub></i>.</div><div>- This is also the reason it is referred to as the “fully multivariate” model, as every observed value can be found without fail with this model, meaning e<sub>ti</sub> is 0. As this model is completely random, it explains 0% of the variance, making it a nice reference.</div><div><br /></div><div><div>Just like we choose different code variables for RM-MANOVA to test different effects, like the Repeated Contrast &amp; Polynomial Contrast, we can test several models for Repeated Measures.</div><div><br /></div><div>A <b>linear</b> relationship between two or more measurements in time:</div></div><div><img src=""Bildschirmfoto 2017-10-19 um 18.21.31.png"" /></div><div><img src=""Bildschirmfoto 2017-10-19 um 18.22.40.png"" /></div><div><br /></div><div>So the difference between each time point is exactly <i>ß<sub>1i</sub></i> meaning its predicted increase is linear. Of course, not everything in practice has a linear relationship, as we could even see in this very summary when only quadratic and cubic were (almost) significant, but it is the only one that definitely needs to be understood for the exam, so learn it well. The next ones are probably not part of the exam, but might help to increase insight:</div><div><br /></div><div>A <b>quadratic</b> relationship between two or more measurements in time:</div><div><img src=""Bildschirmfoto 2017-10-19 um 18.23.46.png"" /></div><div>With the quadratic term (<i>ß<sub>2i</sub></i>) testing for a potential quadratic relationship over time.</div><div><br /></div><div>A <b>Piecewise linear function</b>, given that we have 12 measurements (t<sub>1</sub> to t<sub>12</sub>), divided into 3 equal parts:</div><div><img src=""Bildschirmfoto 2017-10-19 um 18.24.33.png"" /></div><div><br /></div><div><div>These examples of piecewise linear function and quadratic relationship are to show that it is possible to test pretty much anything as part of multilevel models. The greatest strength of multilevel models is flexibility. But what is most important for the exam, is being able to understand and write down the model for a linear relationship.</div><div><br /></div><div>When comparing linear regression vs. Multilevel we could see all the different types of variables we could add to a multilevel model, such as a level 2 variable, level 1 variable and interaction between both of them. In repeated measures, this would mean a between-subjects effect, within-subjects effect and interaction between both of them, respectively. After that, we’ve learned the other notation where we split the regression model in a level 1 and level 2 section. Finally, we’ve learned a view basic models and notations for Repeated Measures, and how it is linked to RM-ANOVA and RM- MANOVA. Now, as the final part of this summary, we will look at the SPSS output for multilevel analysis, and we’ll be completely done!</div></div></div>"
Multilevel Model:&nbsp;<i>Repeated Measures</i>;&nbsp;A linear relationship between two or more measurements in time:	"<img src=""Bildschirmfoto 2017-10-19 um 18.25.36.png""><div>So the difference between each time point is exactly ß<sub>1i</sub> meaning its predicted increase is linear. Of course, not everything in practice has a linear relationship, as we could even see in this very summary when only quadratic and cubic were (almost) significant, but it is the only one that definitely needs to be understood for the exam, so learn it well. !!!!!!!</div>"
Multilevel Model:&nbsp;<i>Repeated Measures</i>;&nbsp;SPSS output	"<img src=""Bildschirmfoto 2017-10-19 um 18.26.29.png"" /><div>The model we use to analyse this is the random intercept &amp; random slope model</div><div><img src=""Bildschirmfoto 2017-10-19 um 18.26.51.png"" /></div><div><br /></div><div>The null hypothesis for multilevel modelling: all parameters are being compared to 0, similar to linear regression:</div><div><img src=""Bildschirmfoto 2017-10-19 um 18.27.07.png"" /></div><div><br /></div><div>The SPSS output is:</div><div><img src=""Bildschirmfoto 2017-10-19 um 18.27.40.png"" /></div><div><div>Every coefficient is now called “Estimate” as it is merely estimated through maximum likelihood. Multilevel, unlike linear regression and ANOVA, doesn’t work through ordinary least squares. The fixed effects are tested the same way they are with linear regression, by calculating a t-value (Estimate / SE) to then convert into a p-value depending on the DF. The random effects, variances and possibly covariances, will now also be tested against 0 (unlike all previous models) with the Wald Z test (Estimate / SE).</div><div><br /></div><div>In this case, the linear effect of Measurement (<i>y<sub>10</sub></i>) is significant (p = .014), but all other parameters are not. From that we can conclude the grand mean doesn’t differ significantly from 0 (<i>y<sub>00</sub></i>), and doesn’t change significantly between different subjects (<i>u<sub>0i</sub></i>), that this linear relationship we found doesn’t change much between subjects (<i>u<sub>1i</sub></i>), but that the linear slope in general (<i>y<sub>10</sub></i>)probably does differ from 0 in the population. Finally the individual error that remains (<i>e<sub>ti</sub></i>) is also not significant, meaning that this model explains a lot as it is. But with just 18 measurements, that’s a pretty normal result to find.</div></div>"
Bonus – Example of the 3-level RM-model, with a linear effect of time as a coefficient, that is different for different groups (Random intercept &amp; slope model):	"<img src=""Bildschirmfoto 2017-10-19 um 18.29.12.png"" />"
Variance / Covariance Matrix (3 variables):	"<img src=""Bildschirmfoto 2017-10-19 um 18.31.14.png"" />"
Correlation (between variables A and B):	"<img src=""Bildschirmfoto 2017-10-19 um 18.31.33.png"" />"
SSCP Matrix (Sum of Squares – Cross Products, 3 variables):	"<img src=""Bildschirmfoto 2017-10-19 um 18.32.05.png"" />"
Contrast (4 groups, a = weight, µ = group mean):	"<img src=""Bildschirmfoto 2017-10-19 um 18.32.17.png"" />"
Determinant of a (1 x 1 or 2 x 2) Matrix	"Determinant of a scalar (1 x 1 Matrix) is equal to the number itself: So Det[5] = 5<div><br /></div><div><img src=""Bildschirmfoto 2017-10-19 um 18.32.37.png"" /></div>"
Wilks’ Lambda	"<img src=""Bildschirmfoto 2017-10-19 um 18.32.50.png"" />"
Degrees of Freedom ANOVA:	"<img src=""Bildschirmfoto 2017-10-19 um 18.33.01.png"" />"
Regression model used in ANCOVA	"<img src=""Bildschirmfoto 2017-10-19 um 18.33.21.png"" />"
Corrected / Adjusted means in ANCOVA	"<img src=""Bildschirmfoto 2017-10-19 um 18.33.38.png"" />"
Null hypotheses	"<img src=""Bildschirmfoto 2017-10-19 um 18.33.56.png"" />"
Null Hypotheses	"<img src=""Bildschirmfoto 2017-10-19 um 18.36.21.png"" /><div><img src=""Bildschirmfoto 2017-10-19 um 18.36.31.png"" /></div>"
Binomial Distribution Function:	"<img src=""Bildschirmfoto 2017-10-19 um 18.37.04.png"" />"
Multinomial Distribution Function (optional):	"<img src=""Bildschirmfoto 2017-10-19 um 18.37.16.png"" />"
Basic mathematical formulae concerning logarithms:	"<img src=""Bildschirmfoto 2017-10-19 um 18.37.32.png"" />"
Formula for computing expected values for 2 variables:	"<img src=""Bildschirmfoto 2017-10-19 um 18.37.44.png"" />"
Formula for computing expected values for 3 variables:	"<img src=""Bildschirmfoto 2017-10-19 um 18.37.56.png"" />"
Formula for computing degrees of freedom for 2 variables:	"<img src=""Bildschirmfoto 2017-10-19 um 18.38.07.png"" />"
How to calculate degrees of freedom for 3 variables:	<div>For the degrees of freedom of this model, we need to look closely at how the model is specified. We always start with the total number of cells, then always subtract 1 for knowing the total sample size, even if we have no other variables in the model. Next, we need to subtract “number of groups – 1 = i – 1” for each main effect, “(i – 1)(j – 1)” for each twoway interaction, and “(i – 1)(j – 1)(k – 1)” for each threeway interaction.</div><div><br /></div><div>In our example, we had the effects of FoodxAnimal [AB] and Gender [C]. If we take an interaction- effect [AB] we also always have to include the main effects that are part of this interaction, so [A] and [B]. This means the final model has the main effects of A, B and C, and the interaction-effect [AB], so [A][B][C][AB], or [AB][C] for short.</div><div><br /></div><div>Total number of cells: 2 * 2 * 2 = 8&nbsp;</div><div>Subtract 1 for knowing the total sample size: 7&nbsp;</div><div>Groups A – 1 = 2 – 1 = 1 therefore 6 left&nbsp;</div><div>Groups B – 1 = 2 – 1 = 1 therefore 5 left&nbsp;</div><div>Groups C – 1 = 2 – 1 = 1 therefore&nbsp;4 left&nbsp;</div><div>AB = (2 – 1) * (2 – 1) = 1 therefore&nbsp;3 left</div><div><br /></div><div>So the degrees of freedom for this model = 3.</div>
Null hypotheses:	"<img src=""Bildschirmfoto 2017-10-19 um 18.39.06.png"" />"
SPSS calculated linear combinations, their usage depends on the method:&nbsp;<b>Canonical</b>:&nbsp;	<div>Use the linear combinations to&nbsp;<u>calculate the linear degree of association between two sets.</u></div><div><u><br /></u></div>
SPSS calculated linear combinations, their usage depends on the method:&nbsp;<b>Discriminant</b>:&nbsp;	<div>Use the linear combinations to<u>&nbsp;predict which group subjects belong to.</u></div><div><u><br /></u></div>
SPSS calculated linear combinations, their usage depends on the method:&nbsp;<b>Factor</b>:&nbsp;	<div>Use the linear combinations as factors to&nbsp;<u>summarise the continuous variables in the model.&nbsp;</u></div><div><u><br /></u></div>
SPSS calculated linear combinations, their usage depends on the method:&nbsp;<b>Component</b>:&nbsp;	Use the linear combinations as components to&nbsp;<u>summarise the continuous variables in the model.</u>
Which tests can we use for a repeated measures design with k = 2?	<b>paired t-test</b><div>or</div><div><b>ANCOVA</b></div><div><br /></div><div>k=2 would e.g. be a pre-test, post-test design</div><div><br /></div>
Which test can we use for a within subjects design with k &gt; 2?	<b>Within-subjects ANOVA</b><br /><br />e.g. pre-test, post-test, follow-up
EX of RM: Does a treatment work? How would the design look like?	Performance across k conditions<div><br /></div><div>simple design:</div><div>k=2: pre- and post-test measurement of one-group sample</div><div><br /></div><div><u>Remember:</u> Within-subjects design and single group repeated measures are different terms for this same model</div>
EX of RM: Performance across time. How would the design/research question look like?	How does the effect of a treatment develop over time?<div><br /></div><div>at least k= 3 time points!</div>
What would be an example of a Mixed Between-Within Subjects design?	Does the effect of therapy from pretest to posttest differ between men and women?
Does the effect of therapy from pretest to posttest differ between men and women?<br />What would be the Between and what the within factor, and how many levels do they have?	Between factor: Gender (2 levels)<div><br /></div><div>Within factor: Time<br /><br />One within design and one between design</div>
Does the effect of therapy from pretest to posttest depend on gender and educational level?<div>How many (Between/Within) factors and levels do we have?</div>	Between factor: Gender, Educational level<div><br /></div><div>Within factor: Time</div><div><br /></div><div>We do not know how many levels each factor has from the description alone&nbsp;</div><div><br /></div>
What is the problem when using multiple paired t-test for each pair of time points? And under which conditions is it ok to do this?	ok for k=2&nbsp;<div><br /></div><div>not ok for k&gt;2,&nbsp;because:</div><div>- multiple hypothesis testing (namely k-1 tests) -&gt; inflated alpha</div><div><br /></div><div>-reduced power (also when adjusting alpha)</div><div><br /></div><div>-disregarding association between more than two measures</div><div><br /></div><div>=&gt; Use Within-subjects ANOVA or profile analysis</div><div><br /></div>
What is the H0 for a pre-test post-test deisgn when having only one group (no between factor)?	H0: µ(difference) = 0<div><br /></div><div>population mean of difference scores is 0</div><div><br /></div><div>equivalent to a matched (paired) t-test and within subjects ANOVA with 1 within subjects effect</div>
What do we use as a covariate in a repeated measures ANCOVA?	the pre-test<div><br /></div><div>the post-measure is regressed on the pre-measure</div><div><br /></div><div>--&gt; implies working with a corrected mean</div><div><br /></div><div>--&gt; the post-test mean µ<sub>1</sub> is corrected for the pre-test mean µ<sub>0&nbsp;</sub>using linear regression</div>
When using difference scores, what is assumed for ß<sub>1</sub>?	we assume&nbsp;ß<sub>1</sub>&nbsp;to be = 1<div><br /></div><div>but this is usually not the case.</div><div><br /></div><div>In ANCOVA,&nbsp;ß<sub>1</sub>&nbsp;is estimated optimally, this <i>reduces</i> the<b> error variance </b>and <b>increases power</b> (keep in mind that ANCOVA cannot always be used!)</div>
When is it ok to use ANCOVA and when shall we use difference scores? <b>Lord's paradox</b>	<div>- when it is an experimental design (<b>random allocation</b> to groups)&nbsp;</div><div>- at the population level no difference in pre-measures between groups</div><div>- when data is <i>MCAR</i></div><div>&gt;1 group: equality of regression slopes</div><div>-&gt; <b>use ANCOVA</b></div><div><br /></div><div>ANCOVA and gain score analysis:</div><div>- test same hypothesis and estimate same group differences</div><div>- ANCOVA provides more power and precision than ANOVA on gain scores, because the error variance is smaller (thus preferred)</div><div><br /></div><div>__________________________________________________________________________________________________________________</div><div>if we have an observational design/quasi-experimental design/Natural groups and/or missing data which is not MCAR</div><div>-mean pre-measures are not necessarily the same</div><div>-ANOCVA compares groups assuming that they are equivalent on pre-test (therefore problematic!)</div><div>-difference score analysis compares groups as is (leads to differenct results than ANCOVA here)</div><div>&nbsp;-&gt; use <b>difference scores!</b></div><div><b><br /></b></div><div><b>The crucial question to ask yourself: Is group memebership unrelated to pre-test scores?</b></div><div>YES - ANCOVA</div><div>NO - Difference score analysis</div>
Understanding output: How does the output look like when we test H0: µ(difference)= 0?	A Paired t-test was used testing whether the mean difference score is 0 (no difference).<div><br /></div><div>If the test is significant, we know that there is a significant mean change (e.g. difference between pre- and post-test scores)</div>
The sum of the Extraction values is equal to	the sum of the two eigenvalues of the two relevant components.
Understanding output: How does the output look like when we test H<sub>0</sub>: µ(d1) = µ(d2) = µ(d3) = µ(d4)?	"Four group analysis, ANOVA on difference scores (Between subjects ANOVA)<div><br /></div><div>Look at <b><font color=""#0000ff"">intercept</font></b>: the intercept tests if the population mean of the outcome variable is 0 (which is our time effect!)</div><div><br /></div><div>Look at the <b><font color=""#0000ff"">category</font></b>(e.g. viewcategory is sesame street example), if this is significant, we know that at least one group differs</div>"
Understanding output: How does the output look like when we test H<sub>0</sub>: µ1* = µ2* = µ3* = µ4* and which method was used?	Four group analyisis ANCOVA<div><br /></div><div>the post-test score is <b>outcome</b> variable and the pre-test score is our <b>predictor</b></div><div><br /></div><div>if viewcat (our groups, between factor) is no significant, we reject the&nbsp;H<sub>0</sub>: µ1* = µ2* = µ3* = µ4*&nbsp;</div><div><br /></div><div><br /></div>
How does a mixed design k=2 time points look like?	We have a<b> within subject factor </b>with k = 2 levels and a <b>between subject factor </b>(group)<div><br /></div><div>g groups (g&gt;1) - mixed design:</div><div><br /></div><div>we can use <u>ANOVA</u> on difference scores testing two hypotheses:</div><div><br /></div><div>H0: µ(diff) = 0 (time effect)</div><div>H0: µ(d1) = µ(d2)..= µ(dg): group * time effect</div><div><br /></div><div><br /></div><div><u>Equivalent to within-subjects ANOVA</u>, testing 1 within-subject effect and 1 (or &gt;1) between subject effect(s)</div>
Understanding output: Mixed design k=1<div>Where to look to which:</div><div><div>H0: mu(diff) = 0&nbsp;</div><div>H0: mu(d1) = mu(d2)..= mu(dg) ?</div></div>	<b>Intercept</b> is our <u>within</u> subject (time effect), if significant - reject H0: mu(diff) = 0<div><br /></div><div>viewcat(<b>groups</b>) is our <u>between</u> subject effect, if significant - reject&nbsp;H0: mu(d1) = mu(d2)..= mu(dg)</div>
How does a Mixed design, k&gt;2 time points look like? And which model is appropriate?	We have <i>within</i> subject factor with k&gt;2 levels&nbsp;and <i>between</i> subject factor(s)<div><br /></div><div>Possible analyses:</div><div><br /></div><div>either <b>within-subject ANOVA</b></div><div>- consider repeated measures as a block-design</div><div>-blocking factor subject</div><div><br /></div><div>or:</div><div><b>Profile analysis </b>(L4)</div><div><b>Multilevel analyses</b> (L5 and further)</div>
How does a block design work?	"We block the <b>subjects</b> to <font color=""#0000ff"">remove within-subjects variability from error variance</font><div><br /></div><div>we consider different sample means across conditions (e.g. across 4 different drugs)</div><div><br /></div><div><u>and</u></div><div><br /></div><div>differences btw the subjects (which we want to kick out)</div>"
Why can't we use a between subjects ANOVA for a within-subjects design (although it would work in SPSS)?	Imagine you have 5 subjects and each of them is treated with 4 drugs<div>-&gt; we have a dependency between our observations within one subject, due to the specific properties of that subject.</div><div><br /></div><div>Subject <b>must</b> be regarded as a (<b>blocking</b>, i.e. random) factor!</div><div><br /></div><div>SPSS does not know this --&gt; we would have less power</div>
How does the within-subjects ANOVA work?	"We consider subjects as a seperate factor: <font color=""#0000ff"">blocking</font> (we then have two factors!)<div><br /></div><div>The univariate approach splits within-groups variability SS<sub>sK&nbsp;</sub>into two parts:</div><div><br /></div><div>1) <b>Interaction</b> individual differences with treatment <b>SSsk</b></div><div><br /></div><div>2) Individual differences due to subject <b>SS<sub>s</sub></b></div><div><sub><br /></sub></div><div><sub><br /></sub></div><div>we run an ANOVA and add e.g. drug as a factor as well as subject</div><div><br /></div><div>the <b><u><i>error term</i></u></b> is the<font color=""#0000ff""> interaction effect</font> between treatment&amp;subject</div><div><br /></div>"
Comparing Between- and within-subjects ANOVA?<div><br /></div><div>How are the SS partitioned?</div>	<u>Between-subjects ANOVA:</u><div><br /></div><div><b>SS<sub>total</sub>= SS<sub>k</sub> + SS</b><sub><b>S(K)</b> &nbsp;</sub>=&nbsp;Between +within</div><div><br /></div><div><b>SS<sub>total</sub>= SS<sub>k</sub> + SS<sub>s</sub> +SS<sub>sk &nbsp;</sub></b>= Between + individual differences + intercation individual differences with treatments</div><div><br /></div><div><i>interaction term treated as error term</i></div><div>we only have a single combination of subject&amp;treatment&nbsp;</div>
Understanding output: Within-subjects ANOVA with factor Subject	<b>Factor S</b> (<i>Subject SS</i>): measures consistend differences between subjects that affect subject means<div>-&gt; if Factor S is significant, the average reaction time differes across subjects - if this effect is 0, the within subject ANOVA is the same as a regular ANOVA</div><div><div><br /></div><div><b>Factor K</b> (<i>Treatment SS</i>): within-subject effect and therefore required within-subject error term</div><div><br /></div><div><b>Error MS</b>:<i> Interaction MS</i>, relfect the extent to which subjects respond differently to treatments</div><div><br /></div><div><br /></div></div>
Assumptions in RM ANOVA	- <b>Independent</b> observations (i.e. across subjects)<div><br></div><div>- <b>Normality</b> of residuals</div><div><br></div><div>- F k&gt;2 (only more than two measurement occasions involved): <b>Sphericity</b>: At the population level it holds that for all Difference variables between all pairs of k repeated measures, the variances are equal</div><div><br></div><div>Example:</div><div><br></div><div>we have 3 drugs, therefore we have the Difference scores</div><div>1-2</div><div>2-3</div><div>1-3&nbsp;</div><div>the variances of all these scores need to be equal!</div><div><br></div><div><br></div><div><br></div><div><br></div>
How can we test the Sphericity Assumption?	<b>Mauchly's Test</b><div><b><br /></b><div>tests the H0 that sphericity holds (we hope to <u>not</u> reject)</div><div><br /></div></div>
What are the problems with the Mauchly's test?	<b>Sensitive</b> to departures from Normality<div><br /></div><div>Lack of <b>sensitivity</b> to small violations</div>
What to do when Sphericity is violated in RM ANOVA?	"F would be too liberal (rejecting falsely too often)<div><br /></div><div>1) Use a <b>within-subjects</b> ANOVA (univariate ANOVA) with<font color=""#0000ff""> <b>epsilon correction</b></font></div><div><br /></div><div>or</div><div><br /></div><div><b>Profile analysis</b> (L4)</div><div><b>RM Multilevel analysis</b> (L5)</div>"
What does the epsilon correction in RM Anova do?	"it<font color=""#0000ff""> adjusts the degrees of freedom</font><div><br /></div><div>2 methods: (µ 0.7)</div><div>- Greenhouse &amp; Geisser</div><div>- Huyn &amp; Feldt</div><div><br /></div><div>epsilon is the extent to which the covariance matrix deviates from sphericity: dfs of F are multiplied by epsilon</div><div><br /></div>"
When to use Greenhouse &amp; Geisser vs. Huynh &amp; Feldt?	GG: correction is quite conservative (df become too small)<div><br /></div><div>HF: correction is quite liberal (df become too large)</div><div><br /></div><div>For large n, they are usually the same</div><div><br /></div><div>For small n, GG is safer</div>
<div>RM-ANOVA assumes:</div>	Sphericity<div><br /></div>
<div>Sphericity violated (in RM-ANOVA)?</div>	<div>RM-ANOVA with epsilon correction,&nbsp;</div><div><u><br /></u></div><div><u>or</u>:</div><div><br /></div><div>Profile analysis =&nbsp;Repeated Measures <b>M</b>ANOVA</div><div><br /></div>
<div>RM-ANOVA – tests provided by SPSS</div><div><br /></div>	"<img src=""Bildschirmfoto 2017-10-23 um 08.58.09.png"" />"
<div>RM-ANOVA – correct tests</div><div><br /></div>	"<img src=""Bildschirmfoto 2017-10-23 um 08.59.02.png"" />"
<div>Profile analysis – types of designs</div><div><br /></div>	"<div><u>1 within-subject factor (e.g., time)</u></div><div>Test of <b>Flatness</b> <span class=""Apple-tab-span"" style=""white-space:pre""> </span>(= main effect of time)</div><div><br /></div><div><u>1 within-subject factor (e.g., time) and 1 between-subject effect (e.g., gender)</u></div><div>Test of <b>Flatness</b> <span class=""Apple-tab-span"" style=""white-space:pre""> </span>(= main effect of time)</div><div>Test of <b>Parallelism</b> <span class=""Apple-tab-span"" style=""white-space:pre""> </span>(= interaction time x gender)</div><div>Test of <b>Difference in Levels&nbsp;</b>(= main effect of gender)&nbsp;</div><div><br /></div>"
Examples of profiles (graphs)	"<img src=""Bildschirmfoto 2017-10-23 um 09.00.37.png"" />"
<div>Profile analysis - 1 within-subject factor</div>	"<div>Profile analysis with 1 within-subject factor&nbsp;</div><div><b>equals</b>&nbsp;</div><div>analyzing &nbsp;k – 1 transformed measurements</div><div>with MANOVA</div><div><br /></div><div><i>Cf. t</i> test for dependent samples (paired samples):</div><div>Analyze difference scores di = &nbsp;yi1 – yi2</div><div><img src=""Bildschirmfoto 2017-10-23 um 09.01.04.png"" /></div>"
<div>Transformed measurements&nbsp;</div>	<div>MANOVA on the (k – 1) transformed variables</div><div>– Particular linear combination of k original measurements</div><div>H<sub>0</sub>: means of the transformed variables equal to 0</div><div>e.g.,: T1 =Y1 - Y2: T2 =Y3 - Y2; μ(T1)=μ(T2)=0</div><div><br /></div><div>– k – 1 transformed variables may or may not be dependent, hence it is not assumed that the transformation takes care of all dependence between measurement contributed by one subject</div><div><br /></div><div><br /></div>
<div>Transformed variables</div>	"<div>– Which k-1 transformed variables have to be used?</div><div>– Many equivalent choices, not all orthonormal,&nbsp;</div><div><br /></div><div>some via dummy contrasts:</div><div>- <i>polynomial</i> transformations (contrasts) are standard in SPSS</div><div>- <i>difference scores</i> of consecutive time points</div><div>– invariance property: multivariate test statistic is the same for equivalent choices</div><div><br /></div><div><u>Example:</u></div><div><div>– 3 repeated measures:</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span><b>Polynomial</b> transformations</div><div>– Coefficients <font color=""#0000ff"">orthonormal</font>? Yes, <u>because</u>…</div><div>1. <i>Cross-product</i>: (–0.707) * 0.408 + 0 * (–0.816) + 0.707 * 0.408 = 0</div><div>2. <i>Length of coefficients</i>:</div><div>(–0.707)2 + 0.7072 = 1&nbsp;</div><div>0.4082 + (–0.816)2 + 0.4082 = 1</div><div style=""text-decoration: underline; ""><br /></div></div>"
Assumptions in RM-MANOVA	<div>– RM-MANOVA is MANOVA on transformed variables</div><div>– So, if you know the assumptions of MANOVA, you know the assumptions of RM-MANOVA</div><div><br /></div><div>… back to assumptions of MANOVA</div><div><br /></div>
<div>Profile analysis with between-subject factor</div><div><br /></div>	"<div><u>Example</u>: Differential Effectiveness of treatments for Panic disorder</div><div><br /></div><div>– DV: SCL90</div><div><i>1 between-subject factor treatment </i>(3; cgt, ssri, combi)</div><div><i>1 within-subject factor time</i> (4; pre, mid, post, fu)</div><div>– Research questions:</div><div><u>A. Does the SCL score decrease across time</u>?</div><div>- test of flatness</div><div><u>B. Which treatment is most effective</u>?</div><div>- test of parallelism (interaction time*treat)</div><div><img src=""paste-5403068858757.jpg"" /></div><div><br /></div>"
<div>RM-(M)ANOVA - technique to choose depending on Sphericity Assumption</div>	"<img src=""Bildschirmfoto 2017-10-23 um 09.18.49.png"" />"
(M)ANOVA on transformed variable - technique to choose depending on Sphericity Assumption	"<img src=""Bildschirmfoto 2017-10-23 um 09.19.36.png"" />"
Hierarchical Linear model (HLM)	"<div>Multilevel = special regression model</div><div>- Clustered or hierarchically nested data</div><div><img src=""paste-93325344374960.jpg"" /></div><div><br /></div><div>Not necessarily the same amount of observations per group</div><div><br /></div><div>-&nbsp;More levels possible</div><div><br /></div><div><br /></div>"
Multilevel model	<div>– Samples are drawn at two (or more) levels&nbsp;</div><div>- Observations are <b>nested</b>:</div><div>- Level 1 observations are <i>dependent within</i> level 2 units</div><div>- Assumption of <u>independent</u> observations is violated</div><div>Model relations between groups</div><div>Model relations within groups</div><div><br /></div><div>– Represent <b>within-group <u><i>and</i></u> between-group </b>relations in a single model:&nbsp;</div><div>- Conceive of the unexplained variation within and between groups as random variability: random coefficients</div><div><br /></div>
Back to basics: Linear regression&nbsp;	"<img src=""Bildschirmfoto 2017-10-23 um 10.53.22.png"" />"
<div>Recall: Assumptions in linear regression&nbsp;</div><div><br /></div>	<div><b>Independent</b> observations</div><div><br /></div><div><b>Linear relation</b> between y and x&nbsp;</div><div><br /></div><div>Error term has <b>constant variance</b> σ2</div><div><br /></div><div>Error term e is <b>normally distributed</b> with mean 0 and variance σ2, independent of x</div><div><br /></div><div>Error term represents<b> random differences</b> between observations, summarized by the variance</div><div><br /></div>
Multilevel model Graph	"<img src=""Bildschirmfoto 2017-10-23 um 10.54.16.png"" /><div><div>Notation (for 2 levels)</div><div>j = 1, …, N groups (level 2 units)</div><div>i = 1, …, nj individuals in groups (level 1 units)</div><div>Dependent variable &nbsp;y<sub>i</sub> &nbsp; &nbsp;y<sub>ij</sub></div><div>Predictor at level 1 (individuals) x<sub>i</sub> &nbsp; &nbsp;x<sub>ij</sub></div><div>!!<img src=""Bildschirmfoto 2017-10-23 um 10.54.38.png"" />!!</div></div>"
Alternative methods?	"<div><b>Aggregation</b>: analyze means at <font color=""#0000ff"">level 2</font> (ignore level 1)</div><div>&nbsp;- Statistically OK if sample sizes at level 1 large</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>Research question is completely at the higher level (loss of information, shift of meaning)</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span><u><i>Ecological fallacy</i></u>&nbsp; = &nbsp;fallacy of aggregation (Alker, 1969);&nbsp;</div><div>using aggregated data to infer at individual level</div><div><b><br /></b></div><div><b>Disaggregation</b>: analysis of all variables at<font color=""#0000ff""> level 1</font>&nbsp;(ignore level 2)&nbsp;</div><div>- NOT OK</div><div>Ignoring dependence structure leads to overestimating n and underestimation of standard errors (and incorrect tests)</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span><u><i>Atomistic fallacy</i></u> &nbsp;(Hox, 2002);&nbsp;</div><div>using individual data to infer at aggregated level</div><div><br /></div><div><div><b>Two-stage regression analysis:</b></div><div>- OK</div><div>1 – For each group (level 2 unit) <font color=""#0000ff"">separate regression</font></div><div>2 – Analyze the group-dependent coefficients</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>However, inefficient: small n per level 2 unit, loss of precision</div><div><br /></div><div><b>Analysis of variance</b> (repeated measures):</div><div>- OK&nbsp;</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>Less flexible: needs balanced design, <font color=""#0000ff"">no more than 2 levels</font></div></div><div><br /></div><div><br /></div>"
Multilevel is ‘ideal’ solution	"<div>– Not separate regressions per group j, but one model in which differences in <b>coefficients</b> (for groups) are <font color=""#0000ff"">modeled using random coefficients</font></div><div>- Coefficients are <i>fixed</i> or <i>random</i></div><div>- Explained variance at two levels</div><img src=""Bildschirmfoto 2017-10-23 um 10.56.35.png"" />"
Random intercept model	"<img src=""Bildschirmfoto 2017-10-23 um 10.57.22.png"" /><div><br /></div><div><br /></div><div><br /><div><img src=""Bildschirmfoto 2017-10-23 um 10.57.17.png"" /></div><div><div><br /></div><div>1.Differences <u>between</u> <b>individuals</b></div><div>2. Differences <u>between</u> <b>groups</b></div><div>- <b>β<sub>0j</sub></b>: Intercepts vary over groups</div><div>- <b>γ<sub>00</sub></b>: <i>Mean</i> <i>intercept</i> in population of groups</div><div>- <b>var</b><sub style=""font-weight: bold; "">(β0j)</sub>=&nbsp;<b>var<sub>(u0j)</sub></b>: <i>Variance</i> of<i> intercept</i> reflects range of differences across groups in intercepts</div><div><br /></div></div><div><br /></div></div>"
Random slope model	"<img src=""Bildschirmfoto 2017-10-23 um 10.58.22.png"" /><div><br /></div><div><br /></div><div><br /><div><img src=""Bildschirmfoto 2017-10-23 um 10.58.35.png"" /></div><div><div>1. Differences between <font color=""#0000ff"">individuals</font></div><div>2. Differences between <font color=""#0000ff"">groups</font></div><div>-<b> β<sub>0j</sub> </b>and<b> β<sub>1j</sub></b>: <i>Intercepts</i> and <i>slopes</i> vary over groups</div><div>- <b>γ<sub>00</sub> </b>and <b>γ<sub>10</sub></b> : Mean intercept and slope in population of groups</div><div>- var<b>(β<sub>0j</sub></b>)=var(<b>u<sub>0j</sub></b>) and var<b>(β<sub>1j</sub></b>)=var<b>(u<sub>1j</sub>):</b>&nbsp;</div><div>Variance of intercept and slope indicate ‘range’ of plausible differences</div><div>- Also cov(<b>β<sub>0j,</sub> β<sub>1j</sub></b>): Covariance between intercept and slope</div></div><div><img src=""Bildschirmfoto 2017-10-23 um 10.59.08.png"" /></div></div>"
<div>Multilevel model (graphs)</div>	"<img src=""Bildschirmfoto 2017-10-23 um 10.59.31.png"" /><div><img src=""Bildschirmfoto 2017-10-23 um 10.59.42.png"" /></div><div><img src=""Bildschirmfoto 2017-10-23 um 10.59.53.png"" /></div>"
Random intercept and random slope model	"<img src=""Bildschirmfoto 2017-10-23 um 11.00.24.png"" /><div><div>Assumptions:&nbsp;</div><div>(u<sub>0j</sub>, u<sub>1j</sub>) and <b>e<sub>ij</sub></b> <font color=""#0000ff"">independent</font></div><div>u<sub>0j</sub>~N(0,τ<sub>0</sub><sup>2</sup>) <span class=""Apple-tab-span"" style=""white-space:pre""> </span> u1j~N(0,τ<sub>1</sub><sup>2</sup>) <span class=""Apple-tab-span"" style=""white-space:pre""> </span> eij ~N(0,σ<sub>e</sub>)</div><div><br /></div><div>Which parameters are being estimated?</div><div><br /></div></div>"
Two Formulations of a multilevel model	"<img src=""Bildschirmfoto 2017-10-23 um 11.33.23.png"" />"
Predictors in multilevel analysis (example)	"<div>Example: <i>pupils (level 1) nested within classes (level 2)</i></div><div><br /></div><div><u>Predictor at Level 1</u>: x<i><sub>ij</sub></i></div><div>e.g., age, sex, IQ</div><div><br /></div><div><u>Predictor Level 2</u>: z<sub>j</sub></div><div>- e.g., years of experience of teacher, number of pupils within classes,&nbsp;</div><div>- special: mean score of level 1 variabele&nbsp;</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>(e.g., mean IQ score in class)</div><div><br /></div><div><br /></div><div><b>random slope model</b> to predict language test scores (Y) from IQ (X)</div><div><img src=""Bildschirmfoto 2017-10-23 um 11.45.02.png"" /><img src=""paste-95468533055801.jpg"" /></div><div><br /></div>"
Statistical Tests in the multilevel model	"<div><b>Fixed</b> regression coefficients</div><div>Usual t-test: (estimate/standard error)</div><div>or Likelihood Ratio test</div><div><br /></div><div><b>Random</b> coefficients</div><div>Likelihood Ratio test = deviance test</div><div>Only for nested models</div><div><img src=""Bildschirmfoto 2017-10-23 um 11.46.24.png"" /></div>"
Fixed or random effects: <i>example</i>	<div><u>Example: employees nested within companies&nbsp;</u></div><div>A. 500 employees from 40 companies</div><div>B. 500 employees from 3 companies</div><div><br /></div><div><u>Multilevel analysis?</u></div><div><b>A</b>. Yes&nbsp;</div><div>- or ANOVA with company as random factor</div><div><b>B</b>. No&nbsp;</div><div>- use ordinary regression&nbsp;</div><div>- or ANOVA, with company as a fixed factor</div><div><br /></div><div><br /></div>
Fixed or random effects:&nbsp;<i>depends on</i>	<div>– focus of statistical inference (research question)</div><div>– the nature of the set of N groups (generalizability)</div><div>- pupils within schools</div><div>- inhabitants within countries</div><div><br /></div>
Fixed or random effects:<i>&nbsp;limited by</i><div><br /></div>	<div>– sample sizes at all ‘random effects levels’</div><div>- e.g., 2 levels, n<sub>j</sub> individuals within I (i=1,…,I) groups:</div><div><br /></div><div>1. number of groups&nbsp;</div><div>2. magnitudes of the groups sample sizes n<sub>j</sub></div><div><br /></div>
<div>Two-level structure of measurements within individuals:</div><div><br /></div>	<div><u>Level 1: measurements</u></div><div>- <i>Equal occasions across individuals, or different time points</i></div><div>- Explanatory variables: <b>time</b> and<b> time-dependent variables</b></div><div><br /></div><div><u>Level 2: individuals</u></div><div>- Explanatory variables: <b>individual characteristics</b></div><div><br /></div><div><u>Cross-level interactions</u>:</div><div>-<b>  time by individual characteristic</b></div><div>- Do males show a different pattern across time than females?</div><div><br /></div>
Research questions	<div><u>Typically involving change/development</u></div><div>–<i> Level 1 </i>(intra or within-individual)</div><div>- <b>How does outcome change/develop over time</b>?</div><div>–<i> Level 2</i> (inter or between-individual)</div><div>- <b>Can differences in the changes be modeled or predicted</b>?</div><div><br /></div><div><u>How many measurements?</u></div><div>– Minimally 2</div><div>- Depending on research interest</div><div><br /></div><div><br /></div>
From subjects-groups to  time points-subjects	"<img src=""Bildschirmfoto 2017-10-23 um 18.29.56.png"" />"
Composite model – time points-subjects	"<img src=""Bildschirmfoto 2017-10-23 um 18.38.25.png"" />"
Random slope model vs.  fully multivariate model	"<img src=""Bildschirmfoto 2017-10-23 um 18.38.53.png"" />"
<div>(M)ANOVA Repeated Measures vs. Multilevel Analysis</div>	"<img src=""Bildschirmfoto 2017-10-23 um 18.39.56.png"" />"
Fixed part - random part	<div><u>Fixed part:&nbsp;</u></div><div>Model for µ<sub>t</sub>, i.e., mean at time point t</div><div>Possibly depending on covariates &nbsp;e.g., µ<sub>tg</sub> with g=1,2 group</div><div> </div><div><u>Random part:&nbsp;</u></div><div>Model for <b>within-covariance matrix of time points</b></div><div>Possibly depending on covariates within-covariance matrices (e.g., random group effect)</div><div><br /></div>
 Fixed part of Multilevel model for RM 	"<div><u>Equal measurement occasions</u></div><div>– Equal measurement occasions</div><div>- e.g., pretest, posttest, follow-up</div><div>– Modeling via <font color=""#0000ff"">dummy coding</font></div><div>&nbsp;</div><div><u>Unequal measurement occasions</u></div><div>– Varying time points, but associated via time</div><div>- e.g., body length, measured at various time points between 2-10 years of age</div><div>– Modeling via<font color=""#0000ff""> functions of time</font></div><div>&nbsp;</div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div>"
Functions of time	"<u>Model</u>:&nbsp;<img src=""paste-1185410973741.jpg"" /><div><br /></div><div><div><br /></div><div><u>Population of curves</u></div><div>– Data are ordered according to some underlying dimension (here: time)</div><div>– Statistical modeling</div><div>- Determine adequate class of functions Fi&nbsp;</div><div>- Investigate how they depend on explanatory variables</div><div><br /></div><div><div><u>Example</u>: Linear function of time, random intercept and slope, no explanatory variables</div><div><img src=""paste-1215475744813.jpg"" /></div><div><br /></div><div>Linear function often inappropriate</div><div>Use of Polynomial functions (with r&lt;m)</div></div></div><div><img src=""paste-1232655614007.jpg"" /></div>"
Different Classes of Functions	"<div><b>Polynomial functions &nbsp;</b>(with linear function as a special case)</div><div><br /></div><div><b>Piecewise linear function</b></div><div>linear function at given interval, with &gt;1 interval used</div><div><img src=""Bildschirmfoto 2017-10-23 um 18.46.19.png"" /></div><div><br /></div><div><br /></div>"
Random part of Multilevel model for RM	"<img src=""paste-1498943586347.jpg"" /><div><div>1. Compound symmetry = random intercept model</div><div><i>Assumption</i>: <font color=""#0000ff"">all variances of and covariances between measurements are equal</font></div><div><br /></div><div>Example:</div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-23 um 18.48.58.png"" /></div><div><br /></div><div>Note: Compound symmetry is stricter than sphericity&nbsp;</div><div><br /></div><div><br /></div></div>"
Random slopes model	"<img src=""paste-1632087572523.jpg"" /><div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span></div><div>– Individual-dependent <font color=""#0000ff"">deviations</font> <b>u<sub>0i</sub></b> &nbsp;and Individual-dependent rate of <font color=""#0000ff"">increase</font> <b>u<sub>1i</sub></b></div><div>– In between Compound symmetry and fully multivariate model</div><div><u><br /></u></div><div><u>Example</u>:</div></div><div><img src=""Bildschirmfoto 2017-10-23 um 18.52.02.png"" /></div><div><img src=""Bildschirmfoto 2017-10-23 um 18.52.08.png"" /></div>"
Fully multivariate model	"<div><u>Saturated model:&nbsp;</u></div><div>perfect fit of covariance matrix</div><div>use as a benchmark</div><div>No level 1 variance</div><div><img src=""Bildschirmfoto 2017-10-24 um 08.50.27.png"" /></div><div><u>Example</u>:</div><div><img src=""Bildschirmfoto 2017-10-24 um 08.50.22.png"" /></div>"
"Random intercept and slope:&nbsp;<div><br /></div><div><u>Example</u>:<div><div>Sample of 103 children, born into low-income families</div><div><i>Dependent</i> variable: cognitive performance (<b>COG</b>)</div><div><i>Independent</i> variables:&nbsp;<b>PROGRAM</b> (0 = no program; 1= yes program)  intensive intervention program to increase cognitive performance&nbsp;</div><div><br /></div><div><b>AGE</b> (measured time points: at 1, 1.5, and 2 of age)</div><div>Modelled as a variable occasion design, with a linear function</div><div>In the model, (AGE–1) is used, for interpretation purposes</div></div><div><br /></div><div><div><u>Questions</u>:</div><div>How does the individual cognitive performance change over time: Is there a time effect?</div><div><br /></div><div>2.<span class=""Apple-tab-span"" style=""white-space:pre""> </span>Are there differences in change between children in both groups with and without intervention: Is there a program effect over time?</div></div><div><br /></div></div>"	"<img src=""Bildschirmfoto 2017-10-24 um 08.51.22.png"" /><div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>t = 1, 2, 3 time points (at age 1, 1.5, and 2)</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>i = 1, … , 103 children</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>Random <font color=""#0000ff"">intercept</font> (<b>β<sub>0i</sub></b>) for child i: depends on PROGRAM&nbsp;represents estimated value of COG of child i at age 1</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>Random <font color=""#0000ff"">slope</font> <b>β<sub>1i</sub></b> for child i: depends on PROGRAM&nbsp;represents estimated rate at which child i changes over time</div><div> </div></div><div><div><u>Fixed effects</u></div><div><b>γ<sub>00</sub></b>:<span class=""Apple-tab-span"" style=""white-space:pre""> </span>population average of individual <font color=""#0000ff"">intercepts</font> in 'no program population'</div><div><b>γ<sub>10</sub></b>:<span class=""Apple-tab-span"" style=""white-space:pre""> </span>population average of individual <font color=""#0000ff"">slopes</font> in &nbsp;'no program population'</div><div><br /></div><div><b>γ<sub>01</sub></b>:<span class=""Apple-tab-span"" style=""white-space:pre""> </span>difference between population average of individual <font color=""#0000ff"">intercepts</font> in 'no program population' and 'yes program population'</div><div><b>γ<sub>11</sub></b>:<span class=""Apple-tab-span"" style=""white-space:pre""> </span>difference between population average of individual <font color=""#0000ff"">slopes</font> in 'no program population' and 'yes program population'</div><div>&nbsp;</div><div>Model on level 1:</div><div><img src=""Bildschirmfoto 2017-10-24 um 08.53.29.png"" /></div><div>Model on level 2:</div><div><img src=""Bildschirmfoto 2017-10-24 um 08.53.54.png"" /></div><div><br /></div></div><div><br /></div>"
<div><div><b>Null hypotheses</b></div></div><div><br /></div><div><u>Example</u>:<div><div>Sample of 103 children, born into low-income families</div><div>Dependent variable: cognitive performance (COG)</div><div>Independent variables:</div><div>PROGRAM (0 = no program; 1= yes program) intensive intervention program to increase cognitive performance&nbsp;</div><div><br /></div><div>AGE (measured time points: at 1, 1.5, and 2 of age)</div><div>Modelled as a variable occasion design, with a linear function</div><div>In the model, (AGE–1) is used, for interpretation purposes</div></div></div><div><br /></div>	"<div><u>On the fixed part of the model</u></div><div><br /></div><div>1.<b> Between subjects</b>: effect of <i>PROGRAM</i> at age of 1&nbsp;</div><div>There is no PROGRAM effect at age 1, H0: γ01 = 0</div><div>No difference in intercepts between groups</div><div><br /></div><div>2. <b>Within subjects</b>: effect of time (<i>AGE</i>)</div><div>There is no time effect for No program, H0: γ10 = 0</div><div>No difference in slopes: horizontal lines (over time)</div><div><br /></div><div>3.<b> Within subjects</b>: <i>interaction</i> effect</div><div>There is no interaction effect, H0: γ11 = 0</div><div>Effect of time is the same for both groups</div><div><img src=""Bildschirmfoto 2017-10-24 um 08.55.29.png"" /></div><div><img src=""Bildschirmfoto 2017-10-24 um 08.58.35.png"" /></div>"
Discrete dependent variables	<div>– So far: <b>linear</b> multilevel regression (MR), for <b>continous</b> data, normally distributed level 1 residuals</div><div><br /></div><div>– Also available</div><div>- logistic MR, for dichotomous data</div><div>- poisson MR, for count data</div><div>…</div><div>- But, more complicated than linear MR</div><div>&nbsp;</div><div><br /></div>
Which test to use?	<div><u>Identify design of the study</u></div><div><b>Between</b>-subject factor(s), <b>within</b>-subject factor(s)</div><div><b>Covariate</b>(s) (= continuous predictor)</div><div><b>Dependent</b> variable(s) (DVs)</div><div><u><br /></u></div><div><u>Decide which aspect(s) from 1. | to include in one analysis</u></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div>
Univariate, Covariate (X), Between-subject effect only:&nbsp;	ANOVA
Univariate, Covariate (√ - assumptions hold), Between-subject effect only:&nbsp;	ANCOVA
Univariate, Covariate (√ - assumptions violated), Between-subject effect only:&nbsp;	"<div><b>Regression model</b>, with group (via <font color=""#0000ff"">dummy’s</font>) and <font color=""#0000ff"">covariate</font> as predictor, possibly with interaction between both</div><div><br /></div>"
Univariate, Covariate (√ - assumptions violated), Between-subject effect + possibly between-subject effect	<div>RM-Multilevel model</div><div><br /></div>
Univariate, Covariate (√ - assumptions hold), Between-subject effect + possibly between-subject effect	<div>RM-ANCOVA or  RM-MANCOVA, or RM-Multilevel model</div><div><br /></div>
Univariate, Covariate (X), Between-subject effect + possibly between-subject effect	<div>RM-ANOVA or  RM-MANOVA, or  RM-Multilevel model</div><div><br /></div>
Multivaraite, Covariate (X), Between-subject effect + possibly between-subject effect	not treated in the course
Multivaraite, Covariate (√ assumptions hold<sup>1</sup>), Between-subject effect + possibly between-subject effect<div><br /></div><div><sup>1</sup>Linear relationship and equality of regression lines across groups</div><div><br /></div>	not treated in the course
Multivariate, Covariate (√ assumptions violated), Between-subject effect + possibly between-subject effect	not treated in the course
Multivaraite, Covariate (√ assumptions violated), Between-subject effect only	<div>Multilevel regression  (not treated)</div><div><br /></div>
Multivaraite, Covariate (√ assumptions hold<sup>1</sup>), Between-subject effect only<div><br /></div><div><div><sup>1</sup>Linear relationship and equality of regression lines across groups</div></div><div><br /></div>	MANCOVA
Multivariate, Covariate (X), Between-subject effect only	MANOVA
"<div>Structure Analyses - <b>no</b> RM</div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-24 um 09.40.31.png"" /></div>"	"<img src=""Bildschirmfoto 2017-10-24 um 09.40.44.png"" />"
"<div>Structure Analyses -&nbsp;<b>no</b>&nbsp;RM</div><div><img src=""Bildschirmfoto 2017-10-24 um 09.45.48.png"" /></div><div><br /></div>"	"<img src=""Bildschirmfoto 2017-10-24 um 09.46.02.png"" />"
"<div>Structure Analyses -&nbsp;Repeated Measures</div><div><img src=""Bildschirmfoto 2017-10-24 um 09.46.37.png"" /></div>"	"<img src=""Bildschirmfoto 2017-10-24 um 09.46.47.png"" />"
MANOVA: H<sub>0</sub>&nbsp;(example)	"<div>– 3 DV’s,  1 between-subject factor, with 2 levels (e.g, gender)</div><div>– Test of main effect of gender  </div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span></div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-24 um 09.47.46.png"" /></div><div><br /></div><div><br /></div><div>with µ<sub>jg</sub> the population mean on <span class=""Apple-tab-span"" style=""white-space:pre""> </span>test j (j = 1,2,3) for gender g (g = 1,2)</div><div><br /></div><div><br /></div>"
RM-(M)ANOVA: H<sub>0</sub>&nbsp;(example 1)	"<div>– 1 Dv  </div><div>– 1 within-subject factor, with 4 levels (e.g., Drug)</div><div>– Test of main effect Drug:&nbsp;</div><div><img src=""Bildschirmfoto 2017-10-24 um 09.48.24.png"" /></div><div>with &nbsp;µ<sub>Tj</sub> the population mean on <span class=""Apple-tab-span"" style=""white-space:pre""> </span>a properly Transformed variable<span class=""Apple-tab-span"" style=""white-space:pre""> </span>of Drug j (see lecture 4B)</div>"
RM-(M)ANOVA: H<sub>0</sub>&nbsp;(example 2)	"<div>1 Dv  </div><div>1 within-subject factor, with 4 levels (e.g., Drug)</div><div><div>1 Dv  1 within-subject factor, with 4 levels (e.g., Drug)</div><div><br /></div><div><br /></div><div><u>Test of main effect Drug:&nbsp;</u></div></div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span><img src=""Bildschirmfoto 2017-10-24 um 09.50.38.png"" /></div><div><br /></div><div>with µ<sub>Tj</sub> the population mean on <span class=""Apple-tab-span"" style=""white-space:pre""> </span>a properly Transformed variable of Drug j (see lecture 4B)<span class=""Apple-tab-span"" style=""white-space:pre""> </span></div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div><div><br /></div><div><div><u>Test of main effect Gender:&nbsp;</u></div></div><div><img src=""Bildschirmfoto 2017-10-24 um 09.52.07.png"" /></div><div>with µ<sub>F </sub>the population mean of females across all four levels of drugs, and µ<sub>M</sub> of males</div><div><br /></div><div><div><u>Test of interaction Drug and Gender:&nbsp;</u></div></div><div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span><img src=""Bildschirmfoto 2017-10-24 um 09.53.02.png"" /></div><div>with &nbsp;µ<sub>Tj</sub>,<sub>F</sub> the population mean on <span class=""Apple-tab-span"" style=""white-space:pre""> </span>a properly Transformed variable<span class=""Apple-tab-span"" style=""white-space:pre""> </span>of Drug j of the Females<span class=""Apple-tab-span"" style=""white-space:pre""> </span></div></div><div><br /></div>"
<div>Multilevel model for change</div>	"<div>– <b>Regression model </b>to address two different questions about change simultaneously</div><div><br /></div><div>– Modeling on two levels</div><div>- <u>Level 1 model</u>: Individual growth model</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>How does outcome change over time? (<font color=""#0000ff"">within-subjects</font>)</div><div>- <u>Level 2 model</u>: Model for difference between individuals</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span>Can we explain differences in changes over time? (<font color=""#0000ff"">between-subjects</font>)</div><div>- <u>Parameters</u>: fixed or random, and interpretation</div><div><br /></div>"
<div>Example – Lab class: Willet &amp; Singer: <b>Research</b>&nbsp;<b>Questions</b></div><div>______________________________________________</div><div><div>- Sample of 82 children</div><div>- Dependent variable: alcohol use (<b>ALCUSE</b>)</div><div>- Independent variable: no/yes alcoholic parent (<b>COA</b>: 0/1)</div><div>- Three measured time points: age 14, 15, and 16, centered at (<b>AGE_14</b>)</div><div><br /></div><div>‘The research question here is whether individual trajectories of alcohol use during adolescence differ according to the history of parental alcoholism.’</div></div>	"<div><u>Questions</u>:</div><div>1.<span class=""Apple-tab-span"" style=""white-space:pre""> </span>How does the individual alcohol use change over time:</div><div><i><span class=""Apple-tab-span"" style=""white-space:pre""> </span>Is there a time (age) effect? (<font color=""#0000ff"">Main effect time</font>)</i></div><div>2.<span class=""Apple-tab-span"" style=""white-space:pre""> </span>Are there differences in change between children with and children without an alcoholic parent:</div><div><span class=""Apple-tab-span"" style=""white-space:pre""> </span><i>Is there a ‘parent’ effect over time? (<font color=""#0000ff"">Interaction Level2</font>)</i></div><div><br /></div>"
<div>Example – Lab class: Willet &amp; Singer:&nbsp;<b>Level 1: Model for individual change</b></div><div><br /></div><div><div>‘<i>9.2. Formulate the level 1 component of the multilevel model: the individual growth model assuming that there is a linear relationship between AGE_14 and alcohol use. Give an interpretation of the parameters</i>.’</div></div><div><br /></div><div>______________________________________________</div><div><div>- Sample of 82 children</div><div>- Dependent variable: alcohol use (<b>ALCUSE</b>)</div><div>- Independent variable: no/yes alcoholic parent (<b>COA</b>: 0/1)</div><div>- Three measured time points: age 14, 15, and 16, centered at (<b>AGE_14</b>)</div><div><br /></div><div>‘The research question here is whether individual trajectories of alcohol use during adolescence differ according to the history of parental alcoholism.’</div></div>	"<div><i>i</i> = 1, …, 82 children; <i>j</i> = 1, …, 3 measurements (at 14, 15, 16 years)</div><div><br /></div><div><br /></div><div>Model the change over time (<b>AGE</b>) for each individual (<b>child</b>):</div><div><img src=""Bildschirmfoto 2017-10-24 um 10.04.44.png"" /></div><div><br /></div><div><i><font color=""#0000ff"">Intercept</font></i> <b>β<sub>0i </sub></b>(for child i): <u>population value</u> (according to model) of <u>ALCUSE</u> at age 14</div><div><br /></div><div><i><font color=""#0000ff"">Slope</font></i><b> β<sub>1i</sub> </b>(for child i): <u>population rate </u>&nbsp;(according to model) at which child i changes over time</div><div><br /></div><div><i><font color=""#0000ff"">Assumption</font></i>: epsilon<sub>ij </sub>~ N(0, σ<sub>epsilon</sub><sup>2</sup>) (sometimes briefly σ<sup>2</sup>)</div><div><br /></div>"
<div>Example – Lab class: Willet &amp; Singer:&nbsp;<b>Level 2: Model for difference in change</b></div><div><br /></div><div><div><i>‘9.3. Formulate &nbsp;the level 2 component of component of the multilevel model: &nbsp; the model for interindividual differences in change (i.e., differences between individuals),  assuming that the intercept and the slope of the level 1 model have a linear relationship with COA. Give an interpretation of the parameters.’</i></div></div><div><br /></div><div>______________________________________________</div><div><div>- Sample of 82 children</div><div>- Dependent variable: alcohol use (<b>ALCUSE</b>)</div><div>- Independent variable: no/yes alcoholic parent (<b>COA</b>: 0/1)</div><div>- Three measured time points: age 14, 15, and 16, centered at (<b>AGE_14</b>)</div><div><br /></div><div>‘The research question here is whether individual trajectories of alcohol use during adolescence differ according to the history of parental alcoholism.’</div></div>	"<img src=""Bildschirmfoto 2017-10-24 um 10.08.00.png"" /><div><div><b><br /></b></div><div><b>γ<sub>00</sub></b>: initial alcohol use at age 14 for COA = 0 (population average)</div><div><b><br /></b></div><div><b>γ<sub>10</sub></b>: rate of change for COA = 0 (population average)</div><div><b><br /></b></div><div><b>γ<sub>01</sub></b>: difference in initial use at age 14 between COA = 1 and COA = 0</div><div><b><br /></b></div><div><b>γ<sub>11</sub></b>: difference in rate of change between COA = 1 and COA = 0</div></div><div><br /></div><div><div><b>u<sub>0i</sub></b>: deviation between population intercept and individual intercept</div><div><b><br /></b></div><div><b>u<sub>1i</sub></b>: deviation between population slope and individual slope</div><div>Note: u0i and u1i may be dependent:</div><div><img src=""Bildschirmfoto 2017-10-24 um 10.11.43.png"" /></div></div>"
<div>Example – Lab class: Willet &amp; Singer: <b>H<sub>0</sub>&nbsp;to test</b></div><div>______________________________________________</div><div><div>- Sample of 82 children</div><div>- Dependent variable: alcohol use (<b>ALCUSE</b>)</div><div>- Independent variable: no/yes alcoholic parent (<b>COA</b>: 0/1)</div><div>- Three measured time points: age 14, 15, and 16, centered at (<b>AGE_14</b>)</div><div><br /></div><div>‘The research question here is whether individual trajectories of alcohol use during adolescence differ according to the history of parental alcoholism.’</div></div>	<div>- General form: ‘H<sub>0</sub>: γ.. = 0’</div><div>- What does it mean?</div><div>e.g., γ<sub>10</sub>: rate of change for COA = 0&nbsp;</div><div>If γ<sub>10</sub> = 0, then for COA = 0  the rate of change is 0,  so no time effect</div><div><br /></div><div><br /></div>
"<div>Example – Lab class: Willet &amp; Singer:&nbsp;<b>Single composite model</b></div><div><b><br /></b></div><div><div><i>‘9.3. Combine the level 1 and level 2 models algebraically into one single composite model by substituting the constant term and slope term in the level 1 model by the model specifications of the level 2 model.’</i></div><div style=""font-weight: bold; ""><br /></div></div><div><b>______________________________________</b>________</div><div><div>- Sample of 82 children</div><div>- Dependent variable: alcohol use (<b>ALCUSE</b>)</div><div>- Independent variable: no/yes alcoholic parent (<b>COA</b>: 0/1)</div><div>- Three measured time points: age 14, 15, and 16, centered at (<b>AGE_14</b>)</div><div><br /></div><div>‘The research question here is whether individual trajectories of alcohol use during adolescence differ according to the history of parental alcoholism.’</div></div>"	"<img src=""Bildschirmfoto 2017-10-24 um 10.14.02.png"" /><div><img src=""Bildschirmfoto 2017-10-24 um 10.14.16.png"" /></div>"
<div>Example – Lab class: Willet &amp; Singer:&nbsp;</div><div>Example -&nbsp;<b>Testing fixed effects</b></div><div><b>______________________________________</b>________</div><div><div>- Sample of 82 children</div><div>- Dependent variable: alcohol use (<b>ALCUSE</b>)</div><div>- Independent variable: no/yes alcoholic parent (<b>COA</b>: 0/1)</div><div>- Three measured time points: age 14, 15, and 16, centered at (<b>AGE_14</b>)</div><div><br /></div><div>‘The research question here is whether individual trajectories of alcohol use during adolescence differ according to the history of parental alcoholism.’</div></div>	"<div>Note: SPSS estimates parameter for COA=0</div><div><img src=""Bildschirmfoto 2017-10-24 um 10.15.20.png"" /></div><div><br /></div>"
<div>Example – Lab class: Willet &amp; Singer:&nbsp;</div><div>Example -&nbsp;<b>Testing random effects</b></div><div><b>______________________________________</b>________</div><div><div>- Sample of 82 children</div><div>- Dependent variable: alcohol use (<b>ALCUSE</b>)</div><div>- Independent variable: no/yes alcoholic parent (<b>COA</b>: 0/1)</div><div>- Three measured time points: age 14, 15, and 16, centered at (<b>AGE_14</b>)</div><div><br /></div><div>‘The research question here is whether individual trajectories of alcohol use during adolescence differ according to the history of parental alcoholism.’</div></div>	"<img src=""Bildschirmfoto 2017-10-24 um 10.17.19.png"" />"
<div>Equal measurement occasions</div>	"<div>– Equal measurement occasions</div><div>e.g., pretest, posttest, follow-up</div><div><br /></div><div>– Modeling via<font color=""#0000ff""> dummy coding</font></div><div><font color=""#0000ff"">&nbsp;</font></div><div><br /></div>"
<div>Unequal measurement occasions</div>	"<div>– Varying time points, but associated via time</div><div>- e.g., body length, measured at various time points between 2-10 years of age</div><div><br /></div><div>– Modeling via<font color=""#0000ff""> functions of time</font></div><div><br /></div>"
<div>Example – Lab class: Willet &amp; Singer:&nbsp;<b>Functions of Time</b></div><div>____________________________________________</div><div><div>- Sample of 82 children</div><div>- Dependent variable: alcohol use (<b>ALCUSE</b>)</div><div>- Independent variable: no/yes alcoholic parent (<b>COA</b>: 0/1)</div><div>- Three measured time points: age 14, 15, and 16, centered at (<b>AGE_14</b>)</div><div><br /></div><div>‘The research question here is whether individual trajectories of alcohol use during adolescence differ according to the history of parental alcoholism.’</div></div>	"<div>Three measured time points: age 14, 15, and 16</div><div><br /></div><div>Function of time:</div><div><img src=""Bildschirmfoto 2017-10-24 um 10.19.50.png"" /></div><div><br /></div><div><br /></div><div><br /></div>"
<div>Example – Lab class: Willet &amp; Singer:&nbsp;<b>Dummy Coding</b></div><div>____________________________________________</div><div><div>- Sample of 82 children</div><div>- Dependent variable: alcohol use (<b>ALCUSE</b>)</div><div>- Independent variable: no/yes alcoholic parent (<b>COA</b>: 0/1)</div><div>- Three measured time points: age 14, 15, and 16, centered at (<b>AGE_14</b>)</div><div><br /></div><div>‘The research question here is whether individual trajectories of alcohol use during adolescence differ according to the history of parental alcoholism.’</div></div>	"<div>Three measured time points: age 14, 15, and 16</div><div>D1: value 1 for age 15, 0 otherwise; </div><div>D2: value 1 for age 16, 0 otherwise</div><div><br /></div><div><img src=""Bildschirmfoto 2017-10-24 um 10.22.36.png"" /></div><div><br /></div><div><i><font color=""#0000ff"">Intercept</font></i><b> β<sub>0i</sub></b> : value for child i of ALCUSE at age 14</div><div><i><font color=""#0000ff"">Slope</font></i> <b>β<sub>1i </sub></b>(for child i): rate of change for child i of ALCUSE between age of 14 and 15</div><div><i><font color=""#0000ff"">Slope</font></i> <b>β<sub>2i </sub></b>(for child i): rate of change for child i of ALCUSE between age of 14 and 16</div><div><br /></div><div><br /></div><div><br /></div><div><br /></div>"
Key issues for an Analysis plan	"<div><b>Sampling design: nested data?</b></div><div>– Analyse as Fixed or random effects??</div><div><b><br /></b></div><div><b>Outcome(s) of interest: DV(s)</b></div><div>&gt; 1 DVs?&nbsp;</div><div>- A univariate analysis per DV, or jointly in a multivariate model?</div><div><b><br /></b></div><div><b>Predictor(s) of interest</b></div><div>– Confirmatory: Primary interest, hypothesis driven<span class=""Apple-tab-span"" style=""white-space:pre""> </span></div><div>– Exploratory&nbsp;</div><div>– Type of relationship between predictors in analysis?</div><div><b><br /></b></div><div><b>Missing data&nbsp;</b></div><div>– Causes, mechanism(s) (NMAR, MCAR, MAR),  threat to generalizability?&nbsp;</div><div><br /></div><div><br /></div>"
How does word2vec work?	"Word2vec learns a vector representation of a word from text corpus. It is a shallow neural network, that tries to create similar vectors for words in close neighbourhood with each other (5-15 words apart), and dissimilar vectors for words that do not cooccur. It does so by adding a tiny bit of a vector from one word to the other when pulling closer and, of the opposite vector when pulling apart.&nbsp;<div><img src=""word2vec.png"" /></div>"
What is Adam, how does it work?	"Adam is an extension of stochastic gradient descent, which combines the advantages of AdaGRAD and RMSProp, it is adaptive moment estimation (adaptive learning rate for each parameter, based on the history of it's previous gradients mean and variance (first and second moments). It makes learning faster.&nbsp;<div><img src=""Comparison-of-Adam-to-Other-Optimization-Algorithms-Training-a-Multilayer-Perceptron.png"" /></div>"
What is the difference between analytic and numerical gradient? How are they computed?&nbsp;	The numerical gradient is an approximate form of the gradient, without actually computing a derivative of a function. It is computed simply by picking a small constant&nbsp;&nbsp;Δ, which is added to a function as so: numerical_gradient = f(x+&nbsp;Δ) - f(x) /&nbsp;&nbsp;Δ . By doing this we find the approximate direction and rate of the function change. To find the exact direction for a particular x_i, we need to compute the derivative and substitute values of x_i in a formula. &nbsp;This is not always possible (some functions, like hinge loss for example, are not differentiable. So, we compute the subgradient, which is a form of analytic gradient.&nbsp;
What is the difference between GRU and LSTM?	GRU doesn't have a separate cell state.&nbsp;
Learning	improvement with experience E at some task T with respect to performance measure P	
Least Mean Square Rule	finding target function that optimizes mean square error<br>1. Select training example at random<br>2. Calculate value of learned function V'(b)<br>3. Compute error E = V_train(b) - V'(b)<br>4. Update weight for each board feature:<br>w_i = w_i + epsilon + E	
Design choices	training experience, target function, representation of learned function, learning algorithm	
Data mining	- needed to supply examples (labeled, typical, adequately distributed, not show clutter) for learning<br>1) hybrid systems: explicit modeling + ML<br>2) learn as much as possible from unsupervised learning -> only few labeled examples <br>- visualization/accesibility	
Concept	boolean function that is true for appropriate entities<br>Concept learning ~ binary classification (see Lecture 08)	
Learning task	"- Instances X: e.g. days/mins ...<br>- Target function c (boolean)<br>- Training examples D<br>- Hypothesis (representation) h<br>--> need: h elem H such that: ""all x elem D: h(x) = c(x)"""	
Inductive Learning Hypothesis	any hypothesis found to approximate the target function well over a sufficiently large set of training examples, will also approximate the target function well over other examples	
Generality	h2 is more general than h1 if every instance that is classified positive by h1, is also classified positive by h2	
Find-S	1. h = most specific hypothesis (o)<br>2. for each positive example x: <br>- if attribute ai not satisfied by h -> replace ai in h by next most general constraint that is satisfied by x<br>3. Output h	
Find-S complaints	- learns only from pos examples<br>- when is learning finished/target learned?<br>- might get several possible h, depending on order of examples<br>- no detection of inconsistent training data<br>+ maximally specific h picked<br>- INDUCTIVE BIAS: specific h preferred AND hypothesis renders all examples negative unless unless the opposite is entailed by its prior knowledge -> very strong!! no use of neg examples	
Consistency	a hypothesis h is consistent with a set of training examples D of target concept c, iff h(x) = c(x) for all training examples	
Version Space	version space VS_HD with respect to hypothesis space H and training examples D is the subset of hypotheses from H consitstent with all training examples in D	
List-then-eliminate	Find hypothesis by listing all possibilities and eliminating inconsistent ones<br>1. VS <- list all hypotheses<br>2. For each (x, c(x)) in D:<br>- if(h(x) != c(x)) -> remove h from VS<br>2. Output VS	
List-then-eliminiate properties	- only applicable for finite VS<br>- enumeration annoying<br>- computes complete VS<br>- if remaining VS big -> need other measure to pick h<br>- VS empty -> inconsistent examples<br>- IMPRACTICAL<br>- INDUCTIVE BIAS??	
General Boundary	G of VS_HD is set of maximally general members	
Specific Boundary	S of VS_HD set of maximally specific members	
Candidate Elimination	- define version space by two boundaries (G,S)<br>- G learns from negative, S from positive examples<br>- add minimal generalizations (code see folder)<br>- narrows down VS gradually -> size = missing info<br>- VS can be consulted to select most informative examples (50:50 pos:neg)	
Inductive Bias	- minimal set of assertions needed for a system to inductively infer b from a <br>- B is knowledge necessary to deductive inference not from examples but a priori knowledge<br>D_c ^ x_i >> L(x_i, D_c) ==<br>*B* ^ D_c ^ x_i |= L(x_i, D_c)	
Entropy - formula	E(S) = -p+ * log_2(p+) - p- * log(p-) <br>-> p* proportion of pos examples<br><br>c different values:<br>E(S) = - sum(i=1 ... c) p_i * log(p_i)	
Entropy	"- measure of ""impurity""<br>- number of bits needed to encode class (+ or -)<br>- optimal code: p*log(p) bits"	
Gain - formula	Gain(S,A) = E(S) - sum(v elem values(A)) E(S_v) * |S_v|/|S|<br><br>-> E(S): before evaluation<br>-> sum: after evaluation <br>-> fraction: proportions of examples belonging to S_v	
Gain	want to maximize gain<br>-> minimize Entropy after evaluation to get highest Gain	
Decision Trees	- classify data by sequence of interpretable steps<br>- domain: discrete target function describable as attribute value pairs<br>- branch = conjunction of attribute-values -> disjunctive hypothesis<br>- want smallest tree (use Gain as selection attribute)	
ID3	- find best order of attributes by distribution over the examples<br>- always select attribute with best gain as long as examples not perfectly classified<br>- searches space of possible decision trees<br>- Output: single hypothesis (tree)<br>- no backtracking<br>- local maxima problem<br>- robust against noise<br>- disadvantage: all examples needed for every step<br><br>INDUCTIVE BIAS: short trees preferred (Occams Razor)<br>-> high gain at root preferred<br><br>- pseudo-code see folder	
C4.5	extension of ID3<br>- better against overfitting, for continuous valued attributes, attributes with many values, attributes with cost, missing attributes	
Problems of Decision Trees/ID3	overfitting, continuous valued attributes, attributes with many values, attributes with cost, missing attributes	
Overfitting	fit to training set too high, no generalization anymore<br>- avoid by: stop growing if split not significant anymore<br>- After growing tree: Rule Post Pruning & Reduced Error Pruning	
Rule Post Pruning	- build tree<br>- write down every branch as logical rule<br>- remove any presuppositions that improve performance on test set<br>- sort final rules by accuracy (new order of application)<br>- WHY?: * no entire subtrees -> more sensitive<br>* every attribute (also root) prunable<br>* better readability	
Reduced Error Pruning	- grow tree<br>- while(performance of tree on test data++) {<br>* check all nodes for effect of pruning on test data<br>* remove node with biggest improvement<br>* remove subtree of node and assign most common attribute value as new leaf<br>}<br>* produces smallest version of accurate tree<br>* removes nodes produces by noise<br>* BUT: few data -> better rule post pruning	
GainRatio	- attribute with many values -> gain selects it (e.g. day)<br>- no good generalization<br>- GainRatio = Gain(S,A)/SplitInfo(S,A)<br>- SplitInfo(S,A) = - sum(i=1...n) |Si|/|S| * log2 |Si|/|S|<br>-> Entropy with respect to attribute values<br>-> Si subset of S for which A has value v	
Decision Tree - Missing attributes	- use examples with missing values anyways BUT do: <br>* assign most common value of A to node <br>* assign most common value of A of other examples with same target value<br>* assign probability pi to each possible value vi of A -> assign fraction of pi examples to each missing value-node	
Causes of Outliers	"- technical/measurement errors<br>* Cut off measurement -> high concentration of values at boundaries<br>- unexpected ""true"" effect (model by 2 overlaying distributions)<br>- high variance in data (distribution with high flanks)"	
Outlier detection	- what is normal/in normal range?<br>z-test <br>zi = |xi - mu (or median)| / sigma<br>-> zi > 3 or 3.5 = Outlier<br>* Rosner Test	
Rosner test	while(new outliers found) {<br>* calculate mu/median and sigma<br>* find xi with largest zi<br>* if(zi > 3) {remove xi}<br>}<br>Variation: remove k outliers, ! no new median/mu/sigma calculated for all those	
Missing values	- can't throw data away -> would make much of set useless<br>1) substitute mean/median !ARTIFACTS<br>2) (linear) regression !ARTIFICIAL CLUSTERING ALONG REGRESSION LINE<br>3) estimate distribution of data + generate acc. to distribution !USE ONLY COMPLETE DATA<br>4) EM-Algorithm -> uses complete and incomplete vectors	
EM algorithm	AIM: estimation of hidden values<br>PROBLEM: h depend on unknown distribution theta<br>SOLUTION: * estimate distribution theta_t <br>* maximize Q with respect to theta = averaging over hidden values<br>-> theta_t estimate will converge to local max, that is hopefully close to real theta (problem: local search)<br>-> trade in h dependence of I for theta dependence of Q<br>- CODE: see notes	
Metric	1) symmetry: d_ij = d_ji<br>2) coincidence axiom: d_ij = 0 <=> i=j<br>3) triangle equation: d_ik + d_kj >= d_ij<br>-> imply non-negativity of distances	
Distance measures	approx of semantic relation since only numerics accessible to machines<br>- Euclidean<br>- City Block<br>- Malahanohobis (using covariance matrix C)<br>- Maximum distance (king's moves)<br>- Hamming <br>- p-norm!	
Nominal scales	Problem: other topologies as R^n<br>-> embedding in R^n<br>map nominal attributes to real values<br>{wood, metal, stone} -> {(1,0,0), (0,1,0), (0,0,1)}<br>- Problem of many attribute values n:<br>-> choose random vectors from R^m 1 << m << n<br>-> high dim. likely orthogonal	
Jaccard Index	- used for similarity of binary scales<br>- J(A,B) = # common elem/# all elem<br>= |A ^ B| / |A u B|<br>- distance function: J_d(A,B) = 1 - J(A,B)	
Cluster distance measures	D_min = min d(x, y)<br>D_max = max d(x,y)<br>D_mean = 1/(|X| * |Y|)* sum d(x,y)<br>D_centroid = d(1/|X| * sum x, 1/|Y| * sum y)	
Bias clustering	- all c. algorithms have bias<br>- size/shape of preferred cluster<br>- SHOULD BE: adjustable by model parameters<br>- USUALLY: only algorithm parameters changeable <br>-> bias has to be inferred from algorithm<br>- hierarchical clustering solves scale problem with different scale solutions	
Hierarchical clustering	agglomerative<br>divisive	
Agglomerative Clustering	- every point own cluster<br>- merge clusters recursively bottom-up<br>- PSEUDOCODE see folder<br>- O(n^3), optminized O(n^2)	
Divisive Clustering	- all points one cluster<br>- divide recursively top-dow<br>- O(2^n), optminized O(n^2)	
Linkage criteria	- Single linkage<br>- Complete linkage<br>- Centroid<br>- Ward's min variance<br>- Average linking <br>- Minimum energy	
Single linkage	- shortest distance between two clusters<br>- D_min used	
Complete linkage	- longest distance between two clusters<br>- D_max used	
Average linkage	- average distance between clusters<br>- D_mean	
Centroid clustering	- distance between centroids used (clusters only represented by centroids)<br>-> real valued attributes required for computation<br>-> cluster with more members dominates merged centroid	
Ward's minimum variance	- merge clusters, so that increase of total variance is minimized <br><br>E = sum(all clusters) sum(all points in cluster) (x - mu_i)^2<br>mu_i = 1 /C_i * sum(all points in C_i) x<br><br>-> OPTIMIZATION BASED, but implementable by distance measure<br>D_ward = D_centroid(X,Y)/(1/|X| + 1/|Y|)<br><br>- prefers clusters with same number of members<br>- robust against noise, but not outliers	
Minimum energy clustering	- don't only evaluate inter-cluster difference, but also cluster size (small preferred)<br>- formula on paper <br>D_energy = 2*D_mean(X,Y) - D_mean(X,X) - D_mean(Y,Y)	
Hierarchical clustering - properties	- any distance measure usable<br>- only need distance matrix (not data)<br>- no parameters<br>- resulting dendogram offers alternative solutions (has to be analyzed)<br>- cut off at different levels of dendogram might be necessary for comparable clusters<br>- outliers fully incorporated	
Optimization based Clustering	what should good cluster look like?<br>-> put idea in measure E to assign goodness value to certain partioning of data	
Basic maximization algorithm - optimization based clustering	initialize data in cluster somehow<br>while (stop not reached) {<br>* choose example x at random, denote cluster as C(x)<br>* randomly select target cluster C_i<br>* compute change of goodness function E [...]<br>* if (delta E > 0) put x from C(x) to C_i<br>* else put x from C(x) to C_i with probability e^{beta delta E)<br>* beta increase	
Properties - Basic maximization algorithm	- may be caught in local optima<br>-> escape by prob in else statement<br>- depends on initial clustering<br>- simulated annealing: initially small beta allows downhill steps, increasing beta-> more unlikely	
Optimization functions (more detailed see cards)	MINIMIZE:<br>* tr(W) = sum(i=1...d) lambda_i(W) -> minimize variance (small, round clusters)<br>* det(W) = product(i=1...d) lamda_i(W) -> minimize volume of average cluster, no compactness guaranteed (clusters of similar shape)<br>* product(i=1...n) det(A_i)^|C_i| -> look at individual cluster to avoid identical shape of all clusters<br>-> Problem: for d dimensions, need at least d+1 data/cluster otherwise det=0<br>MAXIMIZE:<br>* tr(BW^-1) = tr((A - W) * W^-1) = tr(AW^{-1} -1)<br>-> small tr(W) yields small clusters<br>-> large tr(B) yields big var of cluster centers	
Clustering and Compression	data set represented only by cluster centers<br>-> transmit cluster centers + for each point only cluster it belongs to	
K-means	- divide data set into K clusters C1 ... CK <br>- clusters represented by means w1 ... 1K<br>- minimize quadradic error: <br>E(D, wi) = 1/|D| * sum(i=1...D) || xi - w_m(xi)||^2<br>with w_m(xi) = arg min(j) || xi - wj || <- best match cluster center<br><br><br>- iterative k-means:<br>* randomly choosen reference vectors<br>* assign data to best match<br>* update reference vector by shifting them to mean of cluster<br>* assign data to best match ....	
K-means properties	- local search, solution not unique<br>- greedy optimization: local optima, depends on initial conditions<br>- worst case: empty cluster<br>- one parameter K = # clusters<br>-> implicitly defines scale/shape of clusters<br>- fast<br>- color compression: 2^{3x8} bit = 16,7 mio colors can be depicted by K=100 (100 colors)	
Soft clustering	- describe data by probability distribution P(x)<br>- data point assigned to cluster using probabilities<br>-> no hard boundaries	
Hard clustering	clusters are sets of data points, described by sets or their means<br>-> disjoint<br>-> each point assigned to single cluster<br>-> no uncertainty	
Mixture of Gaussians	Generating data:<br>(- P(x) as whole)<br>- each Gaussian represents separate cluster: select one Gaussian with probability g_k<br>-> generate random x with prob N(x, mu, Ck)<br><br>a priori probability that random example from D is in Volume V of data space:<br>P(x elem V) = integral(V) P(x) dx<br><br>a priori probability that random example from D belongs to cluster k<br>g_k <br><br>a posteriori probability that given data point belongs to cluster k<br>P*k(x) = g_k * N(x, mu_k, Ck) / sum(i=1...K) gi * N(x, mu_i, Ci) <- BAYES<br><br>find best mixture of gaussians to fit given data set D -> find parameters {g_k, mu_k, C_k} by EM	
Properties - EM for mixture of Gaussians	- local optimum<br>- computationally more expensive than K-means<br>- precautions against collapse of a Gaussian on single data point necessary<br>- K-means can provide useful initialization for mu_k, local PCA for C_k<br>- K! equivalent solutions	
Evaluation of Clustering	- no general method<br>- tests:<br>* different data subsets<br>* distribution of averaged distances in k-neighbor clustering<br>* compare inter- and intra-cluter differences<br>* compare two clusterings: (#pairs seperated in 2 clusterings)/(#all pairs) = probability that randomly choosen pair is treated the same in both clusterings	
Conceptual Clustering	employs idea of clustering and decision tree learning for unsupervised classification/categorization<br>-> classes not a prior fixed, formed by examples<br>-> bias: preference of category formation	
COBWEB	most well known algorithm for conceptual clustering<br>-> unsupervised and incremental learning<br>-> probabilistic representation (gradual assignment to classes)<br>-> no a priori fixed # of categories<br><br>Motivation: (mostly from drawbacks from ID3):<br>* artificial thresholding<br>* disjoint learning (tree building) and application phase<br>* each learning step divides data only along one dimension of attribute space<br>* categories defined by propositional logic	
Principle of Categorization	* category formation strongly connected to prototypical concepts<br>-> Birch more typical tree than palm (for us)<br>* basic level category (middle) acquired first<br>Furniture <- Chair -> Kitchen Chair	
Family resemblence theory	category definition based on similarity in complex way, not by hard necessary/sufficient conditions	
COBWEB realization	Global utility function<br>-> determines # of categories, # of hierarchical levels, assignment of objects to categories<br><br>categories C1 ... CN, attributes Ai with values v_ij:<br>S = 1/N sum(n=1...N) sum(i,j) P(Ai = v_ij) * P(Ai = v_ij | Cn) * P(Cn|Ai = v_ij) <br>-> interpretation see cards<br><br>LEARNING = new example inserted into tree and tree modified in such a way, that S is max	
Curse of Dimensionality	"- combinatorical explosion<br>- n^d points necessary to sample d-dimensionla space -> dense sampling impossible for large d<br>- no real data will ever ""fill"" space<br>- pairs of random vectors likely to:<br>* have similar distances<br>* close to perpendicular<br>- high d: almost all volume on this unit cube surface layer"	
Intrinsic dimensionality	# independent parameters necessary to describe data<br>-> depends on problem, not representation<br>- presence of hidden structure can be recognized from d_intrinsic << d_descriptive<br>- data concentrate along manifold of dimensionality much lower than embedding representation space<br>-> manifold ~ space made from distorted pieces of an euclidean R^n, != subspace	
Descriptive dimensionality	# parameters used in unprocessed data set<br>-> depends on representation	
Aims of dimensionality reduction	- find local dimensionalities in data manifold<br>- new coordinate system to represent (and project) data manifold<br>-> get rid of empty parts of space of descriptive parameters<br>- new parameters more meaningful	
Principle Component Analysis	find subspace that captures most of the data variance<br>- unsupervised<br>- Given data set D = {x1 ...}, xi elem R^d with zero mean <x> = sum(i=1... D) xi = 0<br><br>PCA finds m < d orthonormal vectors p1...pm such that pi are the directions of the largest variance of D<br><br>eigenvectors = principle components<br>-> features, receptive fields, filter kernels,...<br><br>does not create structure, only makes existing structure accessible	
PCA - mathematical basis (formulas see cards)	vectors pi are m eigenvectors of the autocorrelation matrix C with largest eigenvalues lambda_i<br>-> C symmetric and real -> lambda_i are real and there is an orthonormal basis of eigenvectors<br>- expansion of x using all eigenvectors would xield xi without error<br>- obtain approximation zi of xi, only m < d basis vectors are used (Karhunen-Loeve- Expansion) <br><br>expansion after the m<d eigenvectors of largest eigenvalues is optimal linear method to minimzie mean square reconstruction error<br>E = sum(i=1...D) (zi - xi)^2<br><br>approximation z_i of x_i is projection of x_i onto m-dimensional sub-space span{p1 ... pm} of R^d<br><br>residuum is delta*x_i = sum(j = m+1 ... d) a_ij * p_j (left out dimensions/eigenvectors<br><br>variance of residuum is sigma²(delta*x) = sum (i = m+1 ...d) lambda_i, i.e. the mean approximation error is the sum of the left out eigenvalues	
PCA - finding m eigenvectors	look for a jump in spectrum of eigenvalues -> suitable cut-off number<br>PROBLEM: large eigenvalue also possible due to noise/inappropriate scaling	
Local PCA	find cluster centers, then compute PCA individually for each cluster<br>-> better: iteratively improve position of cluster centers and local PCAs<br><br>Problem: for continuous, nonlinear (non-clustered) distributions (e.g. curves) -> local PCA no continuous description of manifold<br>-> BETTER: principle curves<br><br>Problem: different clusterings possible on continuous distribution -> entirely different local projection systems	
Principal Curves	nonlinear extension of PCA<br>- data projected onto principle curve to obtain linear order<br>ISSUES: *find appropriate dimensionality<br>* find appropriate flexibility (parameterization) of the fit function (underfit vs reasonable vs overfit) -> additional smoothness constraints should be used<br><br>generalize approximation of PCA to parameterized surface X(a1, ..., am; w) of m dimensions, vector w summarizes n parameters which determine the shape of the surface<br>-> found by minimizing E = 1/2 * intergral ( x- X(a1, ..., am; w) )² * P(x) dx<br>m parameters ai(x) define point on surface of X, that best matches x and have to be computed for each x individually	
Principal curves - Finding w	e.g by gradient descent<br>-> Problem: each step requires integration over ALL data<br>-> Solution: stochastic approximation = make downhill step only wrt single parameter	
Kohonen adaptation rule	additional smoothness constraint added for adaptation of Principal curves<br>-> delta w_kl = epsilon * (x - w_kl) alone is winner takes it all rule (only best match adapted)<br><br>constraint see flashcards	
Scatterplot Matrix	project on two of the dimensions and display all combinations in a matrix	
Glyphs	map each dimension onto parameters of a geometrical figure<br>- percieved as whole<br>- require training<br>- re-numbering of axes -> new training<br><br>*Star Glyphs<br>*Parralell coordinates (Koordinatensystem)<br>* Chernov Faces: parameters mapped to facial features	
Projection techniques	- don't represent full data, only project to selected dimensions <br>- e.g. PCA for visualization -> Problem: structure of data disregarded, only variance: visualization may be unstructured	
Projection pursuit	-project onto 2-3 directions, where data exhibits interesting structure = variance, non-Gaussian, clusters<br>- procedure: <br>1) select 1-3 dimensions (PCA ...)<br>2) project onto those, get densitiy P(x) of projected data<br>3) compute index function (how interesting P(x)?)<br>4) maximize index function -> search for better directions	
Projection pursuit: Indices	- measure deviation of a distribution (normalized to 0 mean and variance 1) from N(x)<br>MAXIMIZE<br>* Friedman-Turkey: I_FT = integral P²(x) dx<br>-> minimal if P is parabolic function similar to normal <br>* Hermite: I_H = integral (P(x) - N(x))² dx<br>-> minimal if P std normal distribution<br>* Natural Hermite: I_NH = intergal (P(x) - N(x))² * N(x) dx<br>-> like I_H but stronger weighting to center<br>* Entropy: I_E = integral P(x) logP(x) dx<br>-> minimal if P std normal distribution, NOTE: not -p*log(p)	
Index for finding clusters	Clustered distributions:<br>- more short distances between pairs of values (for identical variance)<br>- I(k) = s(k) * p(k) MAXIMIZE<br>-> k = projection vector<br>-> s(k) = std deviation along k (still big variance)<br>-> p(k) = average point distance -> only computed up to certain scale, defined by f(.) and cut off value R	
Projection pursuit: Density computation	Maximization requires estimation of density P(x) of projected data<br>- Kernel density estimation (Parzen windows)<br>- orthonormal function expansion	
Multidimensional scaling	Aim: find manifold of low dimension such that projecting the data onto this manifold PRESERVES THE STRUCTURE as good as possible<br><br>-> what does structure mean?<br>IMPORTANT: distance between points<br><br>Find mapping that distances are well preserved<br><br>Sammon's Stress Measure:<br>-> minimization e.g. by gradient descent with respect to mapping parametes	
Formal neuron	- activity = x (spiking frequency)<br>- d inputs -> x elem R^d<br>- each input x_i weighted by number w_i<br>- weighted inputs summed up to obtain activation s = sum (i=1...d) w_i * x_i = w*x<br>- output y -> sigmoid activation function y = y(s)	
Activation functions	- sigmoid<br>* Fermi<br>* Grossberg<br>*tanh<br>* thresholding	
Unsupervised learning	- no teacher <br>- no labeled examples<br>- effect coded in learning rules	
Supervised learning	- teacher<br>- labeled examples (classes ...)<br>- learning: mapping input to label as output (class)<br><br>weakly/semi-supervised learning popular: pre-structure data by unsupervised, use labeling sparingly after unsupervised	
Reinforcement Learning	"- ""weak teacher""<br>- reaching goal state is being told by teacher<br>- way has to be found on its own"	
Hebbian Learning	"""Cells that fire together, wire together""<br>-> Correlation of firing leads to increase of weight<br>Unsupervised"	
Hebb's rule	increase weight w_i according to the product of the activity of the neuron and the input<br>delta w_i = epsilon * y(x*w) * x (stepsize epsilon)	
Hebb's rule: Limit weight growth	no forgetting, since weights never decrease<br>- Decay term <br>- Dynamic normalization to |w| = 1<br>- Explicit normalization to |w| = 1<br>- Oja's rule uses weight decay ~y² <br>FORMULA see cards<br>- stimulus will be forgotten if not presented anymore, others will become more dominant	
Oja's rule	delta w = epsilon * y(x*w)(x-y(x*w)*w)	
Effect of Hebb Rule on pair of neurons	with decay term<br>after repeated presentation of samples of the same set -> EQUILIBRIUM<br>-> averaged over time steps t w_ij does not change anymore<br><delta w_ij*>t = <eps * y_i * y_j - lambda * w_ij> t = 0<br><w_ij*>t = eps/lamdba * <y_i * y_j>t<br>-> w_ij proportional to correlation of two neurons activity	
Effect of Hebb Rule on weight vector	- converges to eigenvector C with largest eigenvalue <br>-> w along direction of largest variance<br><br>Hebb neuron affected by all input (not like winner takes it all from Kohonen net)<br>-> for |w| small, close input has less effect than same input stretched by c>1: c*x<br>-> w directs itself acc to variance	
Habituation	"Anti-Hebb Rule<br>delta w = - epsilon * y(x^T * w) * x<br>- weight vector becomes orthogonal to a repeated stimulus x -> no activation from this stimulus since x*w = 0<br>- w filters out NEW stimuli<br>- several stimuli x1...xn n<d presented repeatedly -> only w-component orthogonal to span{x1, ..., xn} remains<br>- only stimuli xeV with V orthogonal span{x1, ..., xn} can ""pass"" fiter = activate neuron"	
Extracting more PCs using Hebb's rule	"single Hebb-neuron extracts v_1 (w in direction of most variance)<br>-> want more PCs<br><br>1) successive application of single Hebb neuron<br>* Extract v_1 <br>* Project D to space orthogonal to v_1 <br> x_i' = x_i - (x_i * v_1) * v_1<br>* Extract v_2 by same method ... <br>- each neuron correct input -> single neuron less training <br><br>2) Sanger's method<br>* chain laterally coupled neurons, each Hebbian<br>* only first neuron unfiltered input<br>* second has input ""minus"" direction of first weight vector , third minus first two w ... <br>- each step complete chain trained<br>- beginning: later inputs still with PCs with large eigenvalues in them <br>- BUT: no need to detect end of training of single neuron since all trained together"	
Lateral interaction - Hebb's Rule	Sangers method with chain of neurons<br>- each neuron receives input filtered by predecessors	
Perceptron	- most prominent for neural networks<br>- building block of MLP<br>- supervised learning<br>- Input: x^i <br>- linear activation s<br>- output y as threshold function<br><br>- can only solve linearly separable tasks (on two sides of hyperplane)<br>- small hypothesis space -> more steps until convergence	
Perceptron training rule	- trained iteratively <br> - labeled data set x^n e R^d<br>- target value t^n<br><br>delta w = epsilon * (t - y) x<br><br>-> epsilon learning rate<br>-> convergence if epsilon small and task solvable<br><br>decision surface represented by perceptron: d-1 dim hyperplane orthogonal to w<br>-> positive side: xw > 1<br>-> rest 0<br><br>- rule can be derived from minimizing mean square error by gradient descent	
XOR problem	not linearly separable<br>- solved by distortion of input space -> linear transformation<br>* axis not x1, x2 but f(x1,x2)<br>- solved by adding third dimension x3 = x1 * x2	
Perceptron: Batch and Incremental Mode	batch mode = stochastic approximation of mean square error to get to training rule<br><br>delta w = epsilon * sum(i=1...D) (t^i - y(x_i)) * x_i<br><br>incremental mode: gradient descent only wrt one example at a time<br><br>delta w = epsilon (t^i - y(x_i)) * x_i	
MLP	- input x^i<br>- hidden layers L_H<br>- output layer L_H+1<br>- weights READ BACKWARDS!<br>- Output o_i(k)<br><br>- activation function sigmoid, because linear transform would be substitutable with single linear transform<br>- need soft step, because backpropagation needs differentiability<br><br> error function same as for simple perceptron<br>-> Problem: compute all derivatives from w_ik(m,n) to output layer	
MLP - Squashing	Maps the incoming information to much smaller range	
Backpropagation	"initialize weights randomly<br>while(!stop criterion) {<br>* propagate input x FORWARD to obtain output y<br>* for(all output dimensions i) {<br>-- calculate error between target and actual output<br>}<br>* find weights ""responsible""<br>* update weights<br>}"	
Backpropagation properties	- weight from k to k+1 adapted in proportion to <br>1) activation of neuron in prev layer o_i(k) <br>2) weighted error it causes at the outputs epsilon * delta(k+1)<br><br>- stochastic approximation to gradient descent Error function E (one sample at a time)<br><br>- Minimization: <br>* computationally expensive<br>* suffers from numerous local minima<br>* difficult to terminate (overfitting vs good minimization)<br><br>INDUCTIVE BIAS: smooth interpolation<br>-> given by network architecture and gradient descent search	
Backpropagation - Local minima	Avoid: <br>- repeat training (diff inital random weights)<br>- annealing: add noise, eg.g every n learning steps<br>w_ji(k+1, k) = w_ji(k+1, k) + T * zeta_ji(k+1, k)<br>-> zeta is gaussian random variable with average = 0<br>-> T = temperature denoting amount of noise added (decreased during training)<br>- needs more learning steps with annealing	
Backpropagation - Step size adaptation	- Increase epsilon in flat regions and decrease in steep terrain<br>- use epsilon+ > 1 and epsilon- < 1 for Error < 0 or Error > 0 and multiply with old epsilon	
Momentum	Problems: <br>- minimization stops in local minima due to small epsilon<br>- valleys of E: oscillations due to large epsilon<br><br>solved by momentum<br>- avoids abprubt changes of direction and increases effective step size in flat regions	
Backpropagation - Weight decay	- large weights problematic: make neurons too sensitive to input -> binary activations<br><br>additional quadratic regularization term in error funtion avoids too large weights<br>-> linear weight decay in learning rule	
Funahashi & Cybenko	F: arbitrary bounded continuous mapping can be approximated arbitraily precise by one hidden layer + sigmoid activation function + linear output function<br><br>C: another sigmoid hidden layer -> any function approx	
MLP architecture	First layer defines hyperplanes<br>Second layer defines AND (one class in the other)<br>Third Layer defines convex areas (several classes inside one other)	
Issues with MLP architecture	"How many layers/nodes in each layer?<br>-> no restriction BUT:<br>- intrinsic dim of input will be reduced to min of neurons in a hidden layer<br>- more nodes -> faciliation of better representation, but NO ""invention"" of new info<br>- hidden layers -> discover features of input data"	
Neural architectures	- Fully connected net<br>- Sparsely connected net<br>- Diagonal matrix<br>- Tridiagonal matrix<br>- Lower/Upper triangular matrix<br>- Block-Diagonal Matrix (optional: sparse rest of matrix)<br>- Symmetric (Hopfield)	
Feedforward network	"- Only zero weights in upper triangle<br>- acyclic directed graph<br>- e.g. MLP<br>- output: computed by updating neurons from input to output side<br>- ""timeless"""	
Recurrent network	- connectivity matrix has non-zero weights in both triangles<br>-> CYCLES<br>- impossible to find order of neurons for updating as in ffnetwork<br>- only usable by defining dynamics<br>-> continuous time (diff. equations)<br>-> discrete time steps (synchronous/all neurons at once vs asynchronous updating)<br>- state: vector compromising all neuron activation	
Phase space	space of all possible states of a network (all possible activation vectors)	
Instance based learning/nearest neighbor algorithm	- training = memorize/store training examples<br>- application = for unknown input x, find best match x^n of training samples<br>- Output: t^n<br>- LOCAL	
K- nearest neighbor	Find set S of k nearest neighbors of stored examples<br>- discrete valued output: vote among k nn<br>- real valued output: mean of k nearest neighbors<br>y = 1/k * sum(i elem S) t_i	
Properties of nearest neighbor approach	"- nn: hard boundaries of class assignment (Voroni-tesselation cells)<br>- k-nn: continuous transitions<br>- choice of k depends on local intrinsic data dim<br>- ""Training"" = fast/memory-intensive/no waste of info/no parameters<br>- Application = maybe slow/sensitive to errors and noise"	
Distance weighetd K-NN	nearer neighbors more important<br>- y = 1/ (sum(i elem S) w_i) * sum(i elem S) w_i * t_i<br><br>weight w_i = inverse distance 1/|| x - x_i||	
Locally weighted regression	idea: better approximation of y(x) by compution fit function in area surrounding samples<br><br>-> what fit function? (linear, quadratic...?)<br>-> what error function? <br>* squared error over k-nn S<br>* Error over entire D with error weighted by decreasing distance function K<br>* combination	
Local vs non-local	"- MLP not local (adaption of single weight based on single example might influence entire net)<br>- ""death"" of neuron -> major influence<br><br>LOCAL: wrt input space<br>-> output computed individually for diff regions of input space, adaptations only local effects"	
Radial Basis functions	- global approx of target function by linear combination of local approx<br>-> related to distance weighted regression + neural networks<br>- represent mapping of in- to output (like MLP)	
Architecture of RBFN	"- single layer of neurons<br>- all same input<br>- activation depends on match between input and neuron- weights<br>- activation function unimodal (Gauss...) = Kernel function = ""area of responsibility"" in input space<br>- neurons contribute to vector valued output by their weights<br>-> highly activated = more contribution<br>- output function = local functions with ""compact support"""	
Task of RBNF training	"1. suitable ""centers"" / input weights <br>-> use examples/clustering on input part of examples<br>zeta_i = x_i<br><br>2. suitable radii of influence<br>-> radius = distance to nn controlled by gamma <br>sigma_i = gamma * min (k != i) ||zeta_i - zeta_k||<br><br>3. output weights <br>-> perceptron like training rule:<br>delta w_i = epsilon * (t-y) K_i(||x - zeta_i||)"	
RBF vs MLP	adaptation step:<br>*RBF: only performance in responsible input area affected<br>*MLP: may change all weights/performance on all data <br><br>architectural parameters<br>* RBF: # basis functions<br>* MLP: # layers, #neurons<br><br>adaptation parameters<br>* RBF = clustering, radii, stepsize<br>* MLP: stepsize, momentum ...<br>-> RBF generally easy to interpret	
Self- organizing maps - MOTIVATION	"low level signal data -> abstract, symbolic high level representation<br><br>- concept formation<br>- filtering (relevant vs irrelevant)<br>- finding ""structure"" = relations between concepts/prototypes<br><br>--> topology preserving map from signals to higher level"	
SOM	"- spatial arrangement of neurons <br>- all same input<br>- competition: neuron at location s with best match weights w_s ""wins"" = highest excitation<br>-> adapts weights, lateral interaction causes neighboring neurons to adapt too<br><br><br>Excitation over layer caused by lateral interaction -> unimodal function: <br>h_rs = exp(- |r-s|² / 2*sigma)<br><br>Adaptation rule/Kohonen rule:<br>delta w_r = epsilon * h_rs * (x-w_r)"	
SOM adaptation rule	Adaptation rule/Kohonen rule:<br>delta w_r = epsilon * h_rs * (x-w_r)<br><br>-> Hebb rule with decay term - epsilon*w_r (forgetting) and grid-distance weighting h_rs<br><br>LOCAL	
SOM adaptation procedure	1. get input x randomly<br>2. find best match neuron at s such that w_s*x > w_r*x (r!=s)<br>3. Adaptation<br>* forall r: delta w_r = epsilon * h_rs * (x-w_r)<br>4. decrease step size epsilon and size sigma of adaptation region<br><br>-> more nodes in regions of dense data (lateral interaction = excitation within short range, inhibition over long range)	
SOM practical uses	- principal curves<br>- cluster analysis<br>- visualization	
Semi-supervised learning	- unsupervised learning to find structure in data<br>- subsequent labeling (supervision) of already found structures	
Vision 2.0	simple system, configured by anybody for arbitrary task<br><br>1. capture unlabeled images<br>2. extract standard features of all images<br>3. SOM to find structure in feature space<br>4. Visualize<br>5. label assignment to clusters of related images<br>6. train classifier	
Classification	- assign discrete class to object/fact/person/....<br>- attributes represented by feature vector x elem R^d<br>- output: natural numbers c(x) assigned to |C| different classes<br>- c_i(x) discriminant functions: c(x) = arg max(i) c_i(x)	
Bayes classifier	classify input to minimize expected cost <br>* P(c|x) = N * P(x|c) * P(c)<br>-> N = normalization<br>-> P(x|c) = prob density that class c has features x<br>-> P(c) a priori prob of class c<br><br>- overlapping classes can be represented<br>- unique assignment not possible	
Problems Bayes classifier	- Probabilities unknown -> need to estimate<br>-> complete knowledge might be necessary or not (depending on distribution)<br><br>1.) Estimate P(x|c) and P(c) from data, then do classifier<br>2.) Construct approx of classifier from data	
Euclidean classifier	"discriminant found from center of mass of the classes<br>R(x) = w * x <br>with w = <x+> - <x+><br><br>- linear<br>- not local<br>- fast ""training"" with no parameters<br>- sensitive to outliers"	
LDA	- classes have identical a priori probability<br>- Gaussian distribution with means <x+> and <x-> and covariance matrices ^+ = ^- = ^<br><br>R(x) = w * x<br>with w = ^-1 ( <x+> - <x->)<br>^ = <x*x^t>	
Quadratic, Polynomial Classifier	quadratic/polynomial discriminant<br>-> polynomial almost like MLP	
Nearest neighbor classifier	implicit seperatrix, defined by neighbors<br>- local <br>- no generalization + parameters<br>- no training BUT memory	
Support Vector Machine	1. computes hyperplane (linear separatrix)<br>-> based on: examples (support vectors) close to class boundary<br>-> margin maximized<br>-> Slack variables to deal with overfitting	
SVM Kernel trick	- trick to solve non-linear problems:<br>* project data into higher dimension (every problem linearly seperable)<br>* projection of this hyperplane to original data space is non-linear separatrix<br><br>- only inner product of x_a * x_b needs to be computed without actual represenation of x_a * x_b in H<br>-> Mercers condition	
Mercers condition	- over all range of intergal != infinity <br>- limes can be 0	
Reinforcment Learning	agent within environment that<br>-> has perception<br>-> can perform actions<br><br>aim: perform optimal actions depending on percepts to achieve some goal	
Agent	P erformance<br>E nvironment<br>A ctuators<br>S ensors	
Markov decision process	- discrete states from finite set S<br>- discrete time t<br>- discrete actions A<br><br>successor state and reward depend only on current state and current action, not earlier ones<br><br>s_t+1 = delta(s_t,a_t)<br>with delta = successor function<br>r_t+1 = r(s_t, a_t)	
Steps in developing a machine learning application	Collect data.<br>Prepare the input data<br>analyze the input data<br>Train the algorithm<br>Test the algorithm	
Describe the kNN algorithm.	we have an existing set of example data, our training set. We have labels for all of this data--we know what class each piece of the data should fall into. When we're given a new piece of data without a label, we compare that new piece of data to the existing data, every piece of existing data. We then take the most similar pieces of data (the nearest neighbors) and look at their labels. We look at the top k most similar pieces of data from our known dataset; this is where the k comes from. (k is an integer and it's usually less than 20.) Lastly, we take a majority vote from the k most similar pieces of data, and the majority is the new class we assign to the data we were asked to classify. Should normalize data when dealing with different ranges. Calculate the distance using euclidean norm.	
Describe the decision tree algorithm.	To build a decision tree, you need to make a first decision on the dataset to dictate which feature is used to split the data. To determine this, you try every feature and measure which split will give you the best results. After that, you'll split the dataset into subsets. The subsets will then traverse down the branches of the first decision node. If the data on the branches is the same class, then you've properly classified it and don't need to continue splitting it. If the data isn't the same, then you need to repeat the splitting process on this subset.	
Describe Entropy in Information Theory	"         <div><img src=""quizlet-VFFHC1n1t8tuu-kW9QzZzQ_m.png"" /></div>         "	
What's the difference between bag of word and set of word models?	Bag of word models count the number of occurrence of a token and set of word only count the existence, 1 or 0, of a token.	
Describe Bootstrap Aggregating or bagging	"It is a technique where the data is taken from the original dataset S times to make S new datasets. The datasets are the same size as the original. Each dataset is built by randomly selecting an example from the original with replacement. By ""with replacement"" I mean that you can select the same example more than once. This property allows you to have values in the new dataset that are repeated, and some values from the original won't be present in the new set. After the S datasets are built, a learning algorithm is applied to each one individu- ally. When you'd like to classify a new piece of data, you'd apply our S classifiers to the new piece of data and take a majority vote."	
Why are SVMs called machines?	They're called machines because they generate a binary decision; they're decision machines.	
What is boosting?	Boosting is a technique similar to bagging. In boosting and bagging, you always use the same type of classifier. But in boosting, the different classifiers are trained sequentially. Each new classifier is trained based on the performance of those already trained. Boosting makes new classifiers focus on data that was previously misclassified by previous classifiers. Boosting is different from bagging because the output is calculated from a weighted sum of all classifiers. The weights aren't equal as in bagging but are based on how successful the classifier was in the previous iteration. There are many versions of boosting, but this chapter will focus on the most popular version, called AdaBoost, short for adaptive boosting.	
Describe the AdaBoost algorithm.	AdaBoost is short for adaptive boosting. AdaBoost works this way: A weight is applied to every example in the training data. We'll call the weight vector D . Initially, these weights are all equal. A weak classifier is first trained on the training data. The errors from the weak classifier are calculated, and the weak classifier is trained a second time with the same dataset. This second time the weak classifier is trained, the weights of the training set are adjusted so the examples properly classified the first time are weighted less and the examples incorrectly classified in the first iteration are weighted more. To get one answer from all of these weak classifiers, AdaBoost assigns values to each of the classifiers. The values are based on the error of each weak classifier.<br>The vector D is important. It holds the weight of each piece of data. Initially, you'll set all of these values equal. On subsequent iterations, the AdaBoost algorithm will increase the weight of the misclassified pieces of data and decrease the weight of the properly classified data. D is a probability distribution, so the sum of all the elements in D must be 1.0. To meet this requirement, you initialize every element to 1/m.	
What is a confusion matrix?	A matrix with Actual (rows) vs Predicted (columns) results	
What is a problem with linear regression?	One problem with linear regression is that it tends to underfit the data. It gives us the lowest mean-squared error for unbiased estimators. With the model underfit, we aren't getting the best predictions.	
What is a way to reduce the mean squared error for linear regression?	a technique known as locally weighted linear regression ( LWLR ). In LWLR we give a weight to data points near our data point of interest; then we compute a least-squares regression<br><br>LWLR uses a kernel something like the kernels demonstrated in support vector machines to weight nearby points more heavily than other points. The most common kernel being the Gaussian kernel.	
What's the problem with LWLR?	"The problem with locally weighted linear regression is that you need to ""carry around"" the dataset. You need to have the training data available to make predictions."	
What does it mean for a matrix to not being fully rank?	If we have more features than data points ( n>m )	
Describe Principal Component Analysis.	In PCA , the dataset is transformed from its original coordinate system to a new coordinate system. The new coordinate system is chosen by the data itself. The first new axis is chosen in the direction of the most variance in the data. The second axis is orthogonal to the first axis and in the direction of an orthogonal axis with the largest variance. This procedure is repeated for as many features as we had in the original data. We'll find that the majority of the variance is contained in the first few axes. Therefore, we can ignore the rest of the axes, and we reduce the dimensionality of our data.<br><br>We can get these largest variability values by taking the covariance matrix of the data- set and doing eigenvalue analysis on the covariance matrix. Once we have the eigenvectors of the covariance matrix, we can take the top N. When the PCA is applied to this dataset, we can throw out eigenvectors. The top N eigenvectors one dimension, and the classification problem be- will give us the true structure of the N most important features. We can then multiply the data by the top N eigenvectors to transform our data into the new space.<br><br>Note: Some people use the number of principal components that will give them 90% of the variance or others use the first 20 principal components.	
Inductive learning hypothesis	Any hypothesis that approximates the target function well over a sufficiently large set of training examples will also approximate the target funciton well over the unobserved examples	
Candidate Elimination algorithm convergence	Converges to target concept if no errors exists and target function exists in H	
Inductive bias Find-S	The target concept c is in H and that the solution is a maximally specific hypothesis	
Inductive bias Candidate Elimination	The target concept c is in H	
Entropy	E(S) = sum(-pi*log(pi))	
Information Gain	Gain(S,A) = E(S) - sum( abs(Sv)/abs(S)* E(Sv))	
Recall, Precision	"""Recall = TP / (TP + FN)<br>Precision = TP / (TP + FP)"	
""" ""Suppose a computer program for recognizing dogs in photographs identifies eight dogs in a picture containing 12 dogs and some cats. Of the eight dogs identified, five actually are dogs (true positives), while the rest are cats (false positives). Precision and recall?"""	The program's precision is 5/8 while its recall is 5/12	
Roc Curve	X - FP, y = TP	
ID3, characteristics	"""ID3 searches a complete hypothesis space in an incomplete way<br>Inductive bias in ID3 is preference for smaller trees<br>Overfitting is an important issue and can be avoided with pruning methods"	
""" Bayes Rule"	p(a|b) = p(b|a)p(a)/p(b)	
Learning as probability estimation	p(h|D) = p(B|h)p(h)/p(D)	
hmap, hml	"""hmap = argmax P(D|h)p(h)<br>hml = argmax P(D|h)"	
""" ""Is hmap the most probable classifier for a new instance? """	No it is not, the bayes optimal classifier is.	
Bayes optimal classifier	Bayes optimal classifier = argmaxv sum( p(vi|xi,hi)*p(hi|D))	
Chain Rule probb	P(X1,..Xn) = PI_1^n P(Xi|X1,..Xi-1)	
X is conditionally independent of Y given Z	P(X,Y | Z) = P(X|Y,Z)P(Y|Z)=P(X|Z)P(Y|Z)	
Naive bayes assumption and classifier	"""P(a1,a2...,an|vj,D) = PI p(ai,vj,D)<br>Vnb = argmax P(vj,D)PI p(ai|vj,D)"	
""" NB_Learn(A,V,D)"	"""for each vj in V:<br> p(vj|D) = estimate<br> for each attribute Ak:<br> for each ai in Ak:<br> p(ai|vj,D) = estimate"	
""" Linear least squares solution"	"""(X'X)^-1X'T<br>Assumes gaussian conditional distribution, not robust to outliers"	
""" Fishers criterion"	"""w = Sw^-1(m2 - m1)<br>wo = w'm<br>Sw = sum (xn-m1)(xn-m1)' + sum(xn-m2)(xn-m2)'"	
""" Perceptron training rule"	delta wi = lr (td - od) xi,d	
Logistic regression	"""P(c1|x) = g(w'x+w0)<br>g(t) = 1/ (1+e^-t)"	
""" Linear Basis Function Models"	y(x,w) = w'phi	
Linear regression wml	wml = (phi'phi)^-1phi'T	
Multiclass logistic regression, cross entropy, softmax	"""softmax = e(aj)/sumj(e(aj))<br>Cross ent = - sumn sumk ( tnk * ln(ynk))"	
""" What is a kernel"	"""A distance function k(x,x') >=0<br>typically symmetric and non-negative<br>linear = x'x<br>poly = (bx'x+g)^d<br>rbf/gauss = e(-b|x-x'|^2)<br>sigmoid = tanh(bx'x+g)"	
""" Kernelized regression"	"""primal: w = (X'X-lamdaI)X'T<br>dual: alpha = (XX' + lambdaI)^-1t, w = X'alpha<br>y(x,w) = sum alphai * xi'x = sum alphaik(xi,x)<br>alpha = (K + lambdaI)^-1t"	
""" SVM regression"	min 1/2 ||w||^2 + C * sum( S- + S+) <br>S >0<br>ti <= y(xi,w) + e + S+<br>ti >= y(xi,w) - e - S-	
""" SVM classification"	"""min 1/2 ||w||^2 + CsumS<br>ti(w'x + wo) >= 1 - S"	
""" One versus all, one versus one"	"""One versus all - C binary classifiers<br>One-versus-One: C(C-1)/2 classifiers"	
""" Parametric non parametric"	"""parametric: model has a fixed number of parameters<br>non parametric: number of parametrs grows with amount of data"	
""" Knn"	"""find K nearest neighbours of test input x<br>assign x to the most commont label among the majority of votes"	
""" KNN kernel trick"	||xa - xb ||^2 = xa'xa + xb'xb - 2xa'xb	
Boosting	Boosting: use a 'weak' (or base) learner to build simple rules, then combine these 'weak' rules into a single prediction rule that will be more accurate than each single rule. Ym(x) = sign(sum( alpha_m * ym(x) )	
Adaboost	"""init wn = 1/N<br>for m =1 ... M:<br>Train a weak learning ym(x) with weighted error functon:<br>Jm = sum wn I(ym(xn) != tn)<br>Evaluate em = (sum wn I(ym(xn) != tn) / sum wn<br>alpham = ln ( (1-em)/em)<br>update weights<br>wn = wn exp(alpam I(ym(x) != tn))<br><br>ym(x) = sign(sum alpham * ym(x) )"	
""" Adaboost pros cons"	"""Advantages:<br>fast, simple and easy to program<br>no prior knowledge about base learner is required<br>no parameters to tune (except for M)<br>can be combined with any method for finding base learners theoretical guarantees given su cient data and base learners with moderate accuracy<br>Issues:<br>Performance depends on data and the base learners<br>(can fail with insu cient data or when base learners are too weak) Sensitive to noise"	
""" Cost function neural net"	"""Typically negative log likelihood - Maximum likelihood principle<br>J(theta). = - ln ( p(t|x))<br>with sigmoid: g(t) = 1 / (1+exp(-t)<br>J(theta) = softplus((1-t)a), a=w't + b<br>the softplus only saturates when given correct answer"	
""" softmax"	y = softmax(a) = exp(ai)/sum(exp(ai))	
relu, sigmoid, tanh	"""relu = max(0,a)<br>sigmoid = 1/(1+exp(-a)<br>tanh = 2sigmoid(2a) -1"	
""" backprop"	"""forward:<br>for k =1 to l:<br>a = W*h + b<br>h = f(a)<br>Backward:<br>g = derJy<br>for k = l, l-1, .. 1:<br> g = g x f'(a) - elementwise<br> derb = g<br> derW = g(h^(k-1))'<br> g = W'g"	
""" SGD, SGD momentum,"	"""theta = theta - lr grad J<br>momentum<br>v = gamma*v + lr grad J<br>theta = theta - v"	
""" Nesterov momentum"	"""v = gamma*v + lr grad J(theta-gamma*v)<br>theta = theta - v"	
""" Rmsprop"	"""dW, db<br>Sdw = B2Sdw + (1-B2)dW^2<br>Sdb = B2Sdb + (1 - B2)db^2<br>W = W - lr * dW/sqrt(Sdw + e)<br>b = b - lr * db/sqrt(Sdb + e)"	
""" Wout CNN"	Wout = floor( (Win - f + 2p)/s + 1)	
Properties of CNN	"""Translation invariant - an object can appear anywhere in the image<br>Not transformation invariant - cannot fix rotation, scaling etc, data augmentation<br>Weight sharing"	
""" ""CNN properties Kernel, Padding, Stride, Receptive Field"""	"""Kernel - matrix corresponding to filter<br>Depth - number of filters<br>Stride - step of sliding kernel<br>Receptive field - 2D dimension of kernel"	
""" What does a CNN layer consist of?"	"""A convolution part (kernel and biases)<br>A non linear part (activation function)<br>A pooling part (max-pool)"	
""" Number of parameters in a CNN layer"	(fxfxdepth + bias)nc	
What is PCA used for?	"""dimensionality reduction <br>data compression (lossy) <br>data visualization <br>feature extraction"	
""" PCA steps"	"""To perform PCA in a M-dimensional projection space, with M < D <br>compute the mean of the data x ̄<br>compute covariance matrix of the dataset S<br>find M eigenvectors of S corresponding to the M largest eigenvalues"	
""" PCA variance maximization"	"""xbar = 1/N sum xn<br>variance after projection:<br>(1/N) sum (u1'xn-u1'xbar)^2 = u1'Su1<br>S = (1/N) sum (xn - xbar)(xn - xbar)'<br>max var subject to u1'u1 = 1<br>max u1'Su1 + l1(1-u1'u1), der = 0<br>Su1 = l1u1 -> u1'Su1 = l1"	
""" PCA algorithms"	""" Full eigenvalue decomposition of S (slow)<br>2 E cient eigenvalue decomposition - only M eigenvectors<br>3 Singular value decomposition of centered data matrix X"	
""" Markov property"	"""A- Once the current stat is known, the evolution of the dynamic system does not depend on the history of states, actions and observations<br>- The current state contains all the information needed to predict the future<br>- Future states are conditionally independent of past states and past observations given the current state<br>- The knowledge about the current state makes past, present and future observations statistically independent"	
""" Markov process"	Is a process that has the markov property	
MDP(X,A, s,r)	"""X is a finite set of states<br>A is a finite set of actions<br>s : X x A -> X is a transition function<br>r: X x A -> R is a reward function"	
""" One state MDP Solv"	"""MDP(X0, A, s, r)<br>r(ai) det and known: pi^* = argmax r(ai)<br>r(ai) det and unknown: try all ai then select highest<br>r(ai) non-det and known: pi^*(x0) = argmax E[r(ai)]"	
""" Q-learning training rule"	"""Q(s,a) <- Q(s,a) + alpha[ r + gamma * max Q(s',a') - Q(s,a) ]<br>alpha = 1/ ( 1 + visits(x,a)"	
""" SARSA learning rule"	"""Q(s,a) = """"Q(s,a) <- Q(s,a) + alpha[ r + gamma * Q(s,a) - Q(s,a) ]<br>alpha = 1/ ( 1 + visits(x,a)"	
""""""""		
What is concept learning	"""Inferring a boolean-valued function from training examples<br>c(x) - target function<br>h(x) - estimation of h over x<br>Goal is to find the best hypothesis h that predicts correct values of h(xj) xj not in D"	
""" more_general_than_or_equal_to hk (hj >= hk) iff"	(for all X) (hk(x)=1) -> (hj(x)=1)	
hj is more_general_than hk (hj > hk) iff	(hj >= hk) and (hk not > hj)	
FIND_S	"""Init h to most specific hypothesis in H<br>For each positive training instance x in D<br> For each attr_const ai in h<br> if constrain h in h is satisfied by x do nothin<br> replace ai in h by the next more general constrain that is satisfied by x"	
""" Consistent, Version space"	"""Consisten(h,D) = (for all x in D) h(x)=c(x)<br>Version space: {h in H| consistent(h,D)}"	
""" Candidate Elimination algo"	"""G <- max gen h in H<br>S <- max spec h in H<br>For each train ex d:<br> if d pos:<br> remove fom G any hyp inconsisten with d<br> For each hyp s in S that is not consisten with d:<br> remove s from S<br> Add to S all minimal generalizations h of s such that h consistent with d and some member of G is more general than h<br> if d neg:<br> remove from S any hyp inconsisten with d<br> For ech hyp g in G inconsistent with d:<br> remove g from G<br> add to G all minimal specializations h of g such that h is consistent with d and some member of S is more specific than h<br> remove from G any hyp that is less than general than another hyp in G"	
""" Learning problem"	Improve over task T, with respect to performance measure P base don experience E	
LMS weight update rule	"""error(x)= V(x) - Y(x)<br>wi <- wi + c * fi * error(x)"	
""" Missing attribute decision tree"	"""If node n tests A<br>- assign most common value of A among other examples sorted to node n<br>- assign most common value of A among other examples with same target value<br>- assign prop pi to each possible value vi of A. Assign fraction pi of each examåle to each descendant in tree"	
""" Conditional probability"	P(a|b)=P(a and b)/P(b)= alpha * P(a and b)	
HMM setup	"""HMM(X,Z,pio)<br>transition model P(xt|xt-1)<br>observation model P(zt|xt)<br>initial distribution pi0 0 P(x0)<br>State transition matrix<br>Aij = P(xt=j|xt-1=i)<br>observation model<br>bk(zt) = P(zt | xt= k)"	
""" HMM interference, filtering, smoothing"	"""Filtering<br>P(xT=k|z1:T) = aT^K/sum(aT^j)<br>Smoothing<br>P(xT=k|z1:T) = at^K * bt^k/ sum(at^j * bt^j):""<br>HMM Forward ""at^k = P(xt = k, z1:t)<br>For each state k<br> a0^k = pi0 * bk(z0)<br>For each time t = 1,, T<br> for each state k<br> at^k = bk(zt) sum(a_t-1^j * Ajk)"	
""" HMM Backward"	"""Bt^k = P(z_t+1:T|xt=k)<br>for each state k<br> BT^k = 1<br>for each time t = T-1...1<br> for each state k:<br> Bt^K = sum( B_t+1^j Ajk bj(z_t+1) )"	
""" HMM learning parameters Aij, bk(v)"	"""Aij = |i->j trans| / | i -> * trans |<br>bk(v) = |observe v and state k| / | observe * and state k |"	
""" POMDP"	"""POMPD(X,A,Z,s,r,o)<br>X set of states<br>A set of actions<br>Z set of observations<br>P(x0) prob of initial state<br>s(x,a,x') = p(x'|x,a) prob dist over transitions<br>r(x,a)<br>o(x',a'z') = P(z'|x',a) prob dist over observations"	
Naive Bayes Estimation	"""P(vj|D) = |{....,vj..,}|/|D|<br>P(ai|vj,D) = |{<...,ai,..vj>}|/ |{....,vj..,}|"	
""" Smoothing Kernels"	"""integral k(x)dx = 1<br>integral xk(x)dx = 0<br>integral x^2k(x)dx > 0"	
crosscorrelation convolution	crosscor: g(I,j) = Sum_u=-k^k Sum_v=-k^k h(u,v)f(I+u,j+v)<br>cons: g(I,j) = Sum_u=-k^k Sum_v=-k^k h(u,v)f(I-u,j-v)	
What is filtering and smoothing HMM?	Filtering:<br>asks about the state of the process in the end<br>Smoothing:<br>Asks about a state in the middle of the process	
Logistic regression algorithm iterative least squares	dE(w)= phi'(y-t)<br>H = phi'Rphi<br>R = diagonal with Rn,n =yn(1-yn)<br>w = w - H^-1dE(w)	
What is the expectation maximization algorithm and what is its goal?	given X observed variables and Z hidden variables with joint distribution p(X,Z| theta). The goal is to maximise the likelihood function p(X|theta) = sum_z ( P(X,Z|theta)<br><br>1. init theta<br>2. calculate prob och each possible Z given theta<br>3. use calculated values of Z to better estimate theta<br>repeat until convergence	
Classify new instances Candidate Elimination	Check that it is positive for every h in S<br>Check that it is negative for every h in g	
Expectation maximization means	init h = (u1,...un) random<br><br>E: E[zi] = exp(-(1/2s^2)(xi-uj)^2) / sum exp(-(1/2s^2)(xi-un)^2)<br><br>M: uj' = sum E[zij]xi / sum E[zij]<br><br>replace h with h'	
General EM problem	X, unobs Z, parametrised P(Y| h) where yi = xi U zi and h parameters<br>Goal: find h that maximises E[ln P(Y|h)	
General EM Algo	define likelihood function Q(h',h) which calculates Y = X U Z using X and parameters h to estimate Z<br>Q(h',h) = E[ ln P(Y|h) | h, X]<br><br>E: calc Q(h'|h) using h,X to estimate prob dist over Y<br>Q(h'|h) <- E[ ln P(Y|h)|h,X]<br>M: replace h by h' that maximises Q<br>h <- argmax Q(h'|h)	
What is Regression Analysis?	We are given a number of predictor (explanatory) variables and a continuous response variable (outcome), and we try to find a relationship between those variables that allows us to predict an outcome.	
What is reinforcement Learning?	The goal is to develop a system (agent) that improves its performance based on interactions with the environment. Since the information about the current state of the environment typically also includes a so-called reward signal, we can think of reinforcement learning as a field related to supervised learning. However, in reinforcement learning this feedback is not the correct ground truth label or value, but a measure of how well the action was measured by a reward function. Through the interaction with the environment, an agent can then use reinforcement learning to learn a series of actions that maximizes this reward via an exploratory trial-and-error approach or deliberative planning. A popular example of reinforcement learning is a chess engine.	
Describe the relationship between all types of machine learning and particularly the application of unsupervised.	In supervised learning, we know the right answer beforehand when we train our model, and in reinforcement learning, we define a measure of reward for particular actions by the agent. In unsupervised learning, however, we are dealing with unlabeled data or data of unknown structure. Using unsupervised learning techniques, we are able to explore the structure of our data to extract meaningful information without the guidance of a known outcome variable or reward function.	
What is a typical workflow diagram for using machine learning in predictive modeling?	"         <div><img src=""quizlet-yDOnw49z-5TxCFcfXQQG2w_m.png"" /></div>         "	
What popular idea did Abraham Maslow use in 1966 that relates to classifier selections.	"""I suppose it is tempting, if the only tool you have is a hammer, to treat everything as if it were a nail""<br><br>each classification algorithm has its inherent biases, and no single classification model enjoys superiority if we don't make any assumptions about the task. In practice, it is therefore essential to compare at least a handful of different algorithms in order to train and select the best performing model."	
When was the first perceptron proposed and by whom?	1957 - Frank Rosenblatt. a binary classification task where we refer to our two classes as 1 (positive class) and -1 (negative class) for simplicity. We can then define an activation function that takes a linear combination of certain input values and a corresponding weight vector.	
What is the perceptron update rule?	"         <div><img src=""quizlet-k9CJyARN9hbmD-WewEAXOg_m.png"" /></div>         "	
What is One-vs-All	One-vs.-All (OvA), or sometimes also called One-vs.-Rest (OvR), is a technique, us to extend a binary classifier to multi-class problems. Using OvA, we can train one classifier per class, where the particular class is treated as the positive class and the samples from all other classes are considered as the negative class. If we were to classify a new data sample, we would use our Training a perceptron model on the Iris dataset classifiers, where Training a perceptron model on the Iris dataset is the number of class labels, and assign the class label with the highest confidence to the particular sample	
Describe the ADAptive LInear NEuron (Adaline)	The key difference between the Adaline rule and Rosenblatt's perceptron is that the weights are updated based on a linear activation function rather than a unit step function like in the perceptron. In the case of Adaline, we can define the cost function Minimizing cost functions with gradient descent to learn the weights as the Sum of Squared Errors (SSE) between the calculated outcome and the true class label	
What is one of the key ingredients of supervised machine learning algorithms?	to define an objective function that is to be optimized during the learning process. This objective function is often a cost function that we want to minimize.	
Describe the feature scaling method called standardization	gives our data the property of a standard normal distribution. The mean of each feature is centered at value 0 and the feature column has a standard deviation of 1. For example, to standardize the jth feature, we simply need to subtract the sample mean mu_j from every training sample and divide it by its standard deviation std_j.	
What is stochastic gradient descent?	Sometimes also called iterative or on-line gradient descent. Instead of updating the weights based on the sum of the accumulated errors over all samples, We update the weights incrementally for each training sample: Although stochastic gradient descent can be considered as an approximation of gradient descent, it typically reaches convergence much faster because of the more frequent weight updates. Since each gradient is calculated based on a single training example, the error surface is noisier than in gradient descent, which can also have the advantage that stochastic gradient descent can escape shallow local minima more readily. To obtain accurate results via stochastic gradient descent, it is important to present it with data in a random order, which is why we want to shuffle the training set for every epoch to prevent cycles. Note: In stochastic gradient descent implementations, the fixed learning rate Large scale machine learning and stochastic gradient descent is often replaced by an adaptive learning rate that decreases over time	
Whats a compromise between batch and stochastic gradient descent and what are it's benefits?	A compromise between batch gradient descent and stochastic gradient descent is the so-called mini-batch learning. Mini-batch learning can be understood as applying batch gradient descent to smaller subsets of the training data—for example, 50 samples at a time. The advantage over batch gradient descent is that convergence is reached faster via mini-batches because of the more frequent weight updates. Furthermore, mini-batch learning allows us to replace the for-loop over the training samples in Stochastic Gradient Descent (SGD) by vectorized operations, which can further improve the computational efficiency of our learning algorithm.	
What is the odds ratio?	p / (1 - p)	
What is the logit function?	logit (p) = log ( (p/(1-p)) ) - the log of the odds ratio. It takes input values in the range 0 to 1 and transforms them to values over the entire real number range	
What is the output of the sigmoid function in logistic regression?	Output of the sigmoid function is interpreted as the probability of particular sample belonging to class 1 given its features x parameterized by the weights w.	
What is the Sum Squared Error Function?	"         <div><img src=""quizlet-6Icr6WpBk8iAx0v9M3hAug_m.png"" /></div>         "	
How do you derive the log likelihood cost function for Logistic Regression?	"         <div><img src=""quizlet-.4KzF4QWf.wMdtyyLoOdqA_m.png"" /></div>         "	
How do you derive the cost function from the log likelihood?	"         <div><img src=""quizlet-ptlJTd5eaTR04yjGzJ170g_m.png"" /></div>         "	
What is the update rule for logistic regression?	"         <div><img src=""quizlet-Y1jQo1B9566cxmWtpPKBHA_m.png"" /></div>         "	
Describe variance and bias in what they measure.	Variance measures the consistency (or variability) of the model prediction for a particular sample instance if we would retrain the model multiple times, for example, on different subsets of the training dataset. We can say that the model is sensitive to the randomness in the training data. In contrast, bias measures how far off the predictions are from the correct values in general if we rebuild the model multiple times on different training datasets; bias is the measure of the systematic error that is not due to randomness.	
Describe the benefits of regularization.	One way of finding a good bias-variance tradeoff is to tune the complexity of the model via regularization. Regularization is a very useful method to handle collinearity (high correlation among features), filter out noise from data, and eventually prevent overfitting. The concept behind regularization is to introduce additional information (bias) to penalize extreme parameter weights.	
What is the most common form of regularization?	"The so-called L2 regularization (sometimes also called L2 shrinkage or weight decay), which can be written as follows:         <div><img src=""quizlet-b97DDe5fclBViIYpa1ibvQ_m.png"" /></div>         "	
What's another reason feature scaling is so important?	For regularization to work properly, we need to ensure that all our features are on comparable scales.	
Describe a support vector machine (SVM).	It can be considered as an extension of the perceptron. Using the perceptron algorithm, we minimized misclassification errors. However, in SVMs, our optimization objective is to maximize the margin. The margin is defined as the distance between the separating hyperplane (decision boundary) and the training samples that are closest to this hyperplane, which are the so-called support vectors. The rationale behind having decision boundaries with large margins is that they tend to have a lower generalization error whereas models with small margins are more prone to overfitting.	
What is the slack variable?	Linear constraints need to be relaxed for nonlinearly separable data to allow convergence of the optimization in the presence of misclassifications under the appropriate cost penalization.	
Describe Logistic Regression vs SVM.	In practical classification tasks, linear logistic regression and linear SVMs often yield very similar results. Logistic regression tries to maximize the conditional likelihoods of the training data, which makes it more prone to outliers than SVMs. The SVMs mostly care about the points that are closest to the decision boundary (support vectors). On the other hand, logistic regression has the advantage that it is a simpler model that can be implemented more easily. Furthermore, logistic regression models can be easily updated, which is attractive when working with streaming data.	
What's the basic idea behind kernel methods	to deal with such linearly inseparable data is to create nonlinear combinations of the original features to project them onto a higher dimensional space via a mapping function where it becomes linearly separable.	
What's the motivation for the kernel trick?	To solve a nonlinear problem using an SVM, we transform the training data onto a higher dimensional feature space via a mapping function and train a linear SVM model to classify the data in this new feature space. Then we can use the same mapping function. to transform new, unseen data to classify it using the linear SVM model.<br><br>However, one problem with this mapping approach is that the construction of the new features is computationally very expensive, especially if we are dealing with high-dimensional data. This is where the so-called kernel trick comes into play	
What's the kernel trick?	"In order to save the expensive step of calculating a dot product between two points explicitly using this map to a higher dimension function, we define a so-called kernel function:         <div><img src=""quizlet-IDgjMxoNzqjogQ5tlpq5zA_m.png"" /></div>         "	
Roughly speaking, what can you view the kernel function as?	A similarity function between a pair of samples.	
Decision tree classifiers are attractive models if we care about ...	interpretability	
Give an overview of the decision tree process.	We start at the tree root and split the data on the feature that results in the largest information gain (IG). In an iterative process, we can then repeat this splitting procedure at each child node until the leaves are pure. This means that the samples at each node all belong to the same class.	
Describe maximizing information gain and its function	"         <div><img src=""quizlet-DoItTc1saQY1lbJFdAbI5w_m.png"" /></div>         "	
What is reinforcement Learning?	The goal is to develop a system (agent) that improves its performance based on interactions with the environment. Since the information about the current state of the environment typically also includes a so-called reward signal, we can think of reinforcement learning as a field related to supervised learning. However, in reinforcement learning this feedback is not the correct ground truth label or value, but a measure of how well the action was measured by a reward function. Through the interaction with the environment, an agent can then use reinforcement learning to learn a series of actions that maximizes this reward via an exploratory trial-and-error approach or deliberative planning. A popular example of reinforcement learning is a chess engine.	
Describe the relationship between all types of machine learning and particularly the application of unsupervised.	In supervised learning, we know the right answer beforehand when we train our model, and in reinforcement learning, we define a measure of reward for particular actions by the agent. In unsupervised learning, however, we are dealing with unlabeled data or data of unknown structure. Using unsupervised learning techniques, we are able to explore the structure of our data to extract meaningful information without the guidance of a known outcome variable or reward function.	
What is a typical workflow diagram for using machine learning in predictive modeling?	"         <div><img src=""quizlet-yDOnw49z-5TxCFcfXQQG2w_m.png"" /></div>         "	
What popular idea did Abraham Maslow use in 1966 that relates to classifier selections.	"""I suppose it is tempting, if the only tool you have is a hammer, to treat everything as if it were a nail""<br><br>each classification algorithm has its inherent biases, and no single classification model enjoys superiority if we don't make any assumptions about the task. In practice, it is therefore essential to compare at least a handful of different algorithms in order to train and select the best performing model."	
When was the first perceptron proposed and by whom?	1957 - Frank Rosenblatt. a binary classification task where we refer to our two classes as 1 (positive class) and -1 (negative class) for simplicity. We can then define an activation function that takes a linear combination of certain input values and a corresponding weight vector.	
What is the perceptron update rule?	"         <div><img src=""quizlet-k9CJyARN9hbmD-WewEAXOg_m.png"" /></div>         "	
What is One-vs-All	One-vs.-All (OvA), or sometimes also called One-vs.-Rest (OvR), is a technique, us to extend a binary classifier to multi-class problems. Using OvA, we can train one classifier per class, where the particular class is treated as the positive class and the samples from all other classes are considered as the negative class. If we were to classify a new data sample, we would use our Training a perceptron model on the Iris dataset classifiers, where Training a perceptron model on the Iris dataset is the number of class labels, and assign the class label with the highest confidence to the particular sample	
Describe the ADAptive LInear NEuron (Adaline)	The key difference between the Adaline rule and Rosenblatt's perceptron is that the weights are updated based on a linear activation function rather than a unit step function like in the perceptron. In the case of Adaline, we can define the cost function Minimizing cost functions with gradient descent to learn the weights as the Sum of Squared Errors (SSE) between the calculated outcome and the true class label	
What is one of the key ingredients of supervised machine learning algorithms?	to define an objective function that is to be optimized during the learning process. This objective function is often a cost function that we want to minimize.	
Describe the feature scaling method called standardization	gives our data the property of a standard normal distribution. The mean of each feature is centered at value 0 and the feature column has a standard deviation of 1. For example, to standardize the jth feature, we simply need to subtract the sample mean mu_j from every training sample and divide it by its standard deviation std_j.	
What is stochastic gradient descent?	Sometimes also called iterative or on-line gradient descent. Instead of updating the weights based on the sum of the accumulated errors over all samples, We update the weights incrementally for each training sample: Although stochastic gradient descent can be considered as an approximation of gradient descent, it typically reaches convergence much faster because of the more frequent weight updates. Since each gradient is calculated based on a single training example, the error surface is noisier than in gradient descent, which can also have the advantage that stochastic gradient descent can escape shallow local minima more readily. To obtain accurate results via stochastic gradient descent, it is important to present it with data in a random order, which is why we want to shuffle the training set for every epoch to prevent cycles. Note: In stochastic gradient descent implementations, the fixed learning rate Large scale machine learning and stochastic gradient descent is often replaced by an adaptive learning rate that decreases over time	
Whats a compromise between batch and stochastic gradient descent and what are it's benefits?	A compromise between batch gradient descent and stochastic gradient descent is the so-called mini-batch learning. Mini-batch learning can be understood as applying batch gradient descent to smaller subsets of the training data—for example, 50 samples at a time. The advantage over batch gradient descent is that convergence is reached faster via mini-batches because of the more frequent weight updates. Furthermore, mini-batch learning allows us to replace the for-loop over the training samples in Stochastic Gradient Descent (SGD) by vectorized operations, which can further improve the computational efficiency of our learning algorithm.	
What is the odds ratio?	p / (1 - p)	
What is the logit function?	logit (p) = log ( (p/(1-p)) ) - the log of the odds ratio. It takes input values in the range 0 to 1 and transforms them to values over the entire real number range	
What is the output of the sigmoid function in logistic regression?	Output of the sigmoid function is interpreted as the probability of particular sample belonging to class 1 given its features x parameterized by the weights w.	
What is the Sum Squared Error Function?	"         <div><img src=""quizlet-6Icr6WpBk8iAx0v9M3hAug_m.png"" /></div>         "	
How do you derive the log likelihood cost function for Logistic Regression?	"         <div><img src=""quizlet-.4KzF4QWf.wMdtyyLoOdqA_m.png"" /></div>         "	
How do you derive the cost function from the log likelihood?	"         <div><img src=""quizlet-ptlJTd5eaTR04yjGzJ170g_m.png"" /></div>         "	
What is the update rule for logistic regression?	"         <div><img src=""quizlet-Y1jQo1B9566cxmWtpPKBHA_m.png"" /></div>         "	
Describe variance and bias in what they measure.	Variance measures the consistency (or variability) of the model prediction for a particular sample instance if we would retrain the model multiple times, for example, on different subsets of the training dataset. We can say that the model is sensitive to the randomness in the training data. In contrast, bias measures how far off the predictions are from the correct values in general if we rebuild the model multiple times on different training datasets; bias is the measure of the systematic error that is not due to randomness.	
Describe the benefits of regularization.	One way of finding a good bias-variance tradeoff is to tune the complexity of the model via regularization. Regularization is a very useful method to handle collinearity (high correlation among features), filter out noise from data, and eventually prevent overfitting. The concept behind regularization is to introduce additional information (bias) to penalize extreme parameter weights.	
What is the most common form of regularization?	"The so-called L2 regularization (sometimes also called L2 shrinkage or weight decay), which can be written as follows:         <div><img src=""quizlet-b97DDe5fclBViIYpa1ibvQ_m.png"" /></div>         "	
What's another reason feature scaling is so important?	For regularization to work properly, we need to ensure that all our features are on comparable scales.	
Describe a support vector machine (SVM).	It can be considered as an extension of the perceptron. Using the perceptron algorithm, we minimized misclassification errors. However, in SVMs, our optimization objective is to maximize the margin. The margin is defined as the distance between the separating hyperplane (decision boundary) and the training samples that are closest to this hyperplane, which are the so-called support vectors. The rationale behind having decision boundaries with large margins is that they tend to have a lower generalization error whereas models with small margins are more prone to overfitting.	
What is the slack variable?	Linear constraints need to be relaxed for nonlinearly separable data to allow convergence of the optimization in the presence of misclassifications under the appropriate cost penalization.	
Describe Logistic Regression vs SVM.	In practical classification tasks, linear logistic regression and linear SVMs often yield very similar results. Logistic regression tries to maximize the conditional likelihoods of the training data, which makes it more prone to outliers than SVMs. The SVMs mostly care about the points that are closest to the decision boundary (support vectors). On the other hand, logistic regression has the advantage that it is a simpler model that can be implemented more easily. Furthermore, logistic regression models can be easily updated, which is attractive when working with streaming data.	
What's the basic idea behind kernel methods	to deal with such linearly inseparable data is to create nonlinear combinations of the original features to project them onto a higher dimensional space via a mapping function where it becomes linearly separable.	
What's the motivation for the kernel trick?	To solve a nonlinear problem using an SVM, we transform the training data onto a higher dimensional feature space via a mapping function and train a linear SVM model to classify the data in this new feature space. Then we can use the same mapping function. to transform new, unseen data to classify it using the linear SVM model.<br><br>However, one problem with this mapping approach is that the construction of the new features is computationally very expensive, especially if we are dealing with high-dimensional data. This is where the so-called kernel trick comes into play	
What's the kernel trick?	"In order to save the expensive step of calculating a dot product between two points explicitly using this map to a higher dimension function, we define a so-called kernel function:         <div><img src=""quizlet-IDgjMxoNzqjogQ5tlpq5zA_m.png"" /></div>         "	
Roughly speaking, what can you view the kernel function as?	A similarity function between a pair of samples.	
Decision tree classifiers are attractive models if we care about ...	interpretability	
Give an overview of the decision tree process.	We start at the tree root and split the data on the feature that results in the largest information gain (IG). In an iterative process, we can then repeat this splitting procedure at each child node until the leaves are pure. This means that the samples at each node all belong to the same class.	
Describe maximizing information gain and its function	"         <div><img src=""quizlet-DoItTc1saQY1lbJFdAbI5w_m.png"" /></div>         "	
What are the three main impurity measures or splitting criteria commonly used in binary decision trees.	Gini impurity, entropy, and classification error	
Give the definition of entropy for all non-empty classes.	"         <div><img src=""quizlet-442UJSyGhph32TZyFlUDOg_m.png"" /></div>         "	
Describe the intuition of the Gini Impurity	Intuitively, the Gini impurity can be understood as a criterion to minimize the probability of misclassification	
What should you focus on for impurity measures in practice?	In practice both the Gini impurity and entropy typically yield very similar results and it is often not worth spending much time on evaluating trees using different impurity criteria rather than experimenting with different pruning cut-offs.	
What's the classification error impurity?	I = 1 - max( p(i|t) ), This is a useful criterion for pruning but not recommended for growing a decision tree, since it is less sensitive to changes in the class probabilities of the nodes.	
What is the random forest algorithm	1) Draw a random bootstrap sample of size n (randomly choose n samples from the training set with replacement).<br>2) Grow a decision tree from the bootstrap sample. At each node:<br> - Randomly select d features without replacement.<br> - Split the node using the feature that provides the best split according to the objective function, for instance, by maximizing the information gain.<br>3) Repeat the steps 1 to 2 k times.<br>4) Aggregate the prediction by each tree to assign the class label by majority vote.	
What are some reasonable defaults for the random forest algorithm parameters?	- The sample size of the bootstrap sample is chosen to be equal to the number of samples in the original training set, which usually provides a good bias-variance tradeoff.<br>- For the number of features d at each split, we want to choose a value that is smaller than the total number of features in the training set. A reasonable default that is used in scikit-learn and other implementations is d = sqrt(m), where m is the number of features in the training set.	
Why is a lazy learner called lazy?	It is called lazy not because of its apparent simplicity, but because it doesn't learn a discriminative function from the training data but memorizes the training dataset instead.	
Describe parametric vs nonparametric models	Machine learning algorithms can be grouped into parametric and nonparametric models. Using parametric models, we estimate parameters from the training dataset to learn a function that can classify new data points without requiring the original training dataset anymore. Typical examples of parametric models are the perceptron, logistic regression, and the linear SVM. In contrast, nonparametric models can't be characterized by a fixed set of parameters, and the number of parameters grows with the training data. Two examples of nonparametric models that we have seen so far are the decision tree classifier/random forest and the kernel SVM.	
Describe the KNN algorithm.	- Choose the number of k and a distance metric.<br>- Find the k nearest neighbors of the sample that we want to classify.<br>- Assign the class label by majority vote.	
What do you do instead of regularizations in models where it can't be used?	In models where regularization is not applicable such as decision trees and KNN, we can use feature selection and dimensionality reduction techniques to help us avoid the curse of dimensionality.	
What's a common way to deal with missing numerical values?	Use the mean of that feature or drop the data if it isn't very much.	
What's the difference between nominal and ordinal categorical features?	Ordinal features can be understood as categorical values that can be sorted or ordered. In contrast, nominal features don't imply any order. Ordinal - size of t-shirt, nominal - color of t-shirt	
What is one-hot encoding?	The idea behind this approach is to create a new dummy feature for each unique value in the nominal feature column.	
The smaller the test set ...	the more inaccurate the estimation of the generalization error.	
Most often, normalization refers to...	the rescaling of the features to a range of [0, 1], which is a special case of min-max scaling. (x - x_max) / (x_max - x_min)	
Why is standardization often more practical for many machine learning algorithms?	The reason is that many linear models, such as the logistic regression and SVM, initialize the weights to 0 or small random values close to 0. Using standardization, we center the feature columns at mean 0 with standard deviation 1 so that the feature columns take the form of a normal distribution, which makes it easier to learn the weights. Furthermore, standardization maintains useful information about outliers and makes the algorithm less sensitive to them in contrast to min-max scaling, which scales the data to a limited range of values.	
What is a reason for overfitting and ways to address it:	A reason for overfitting is that our model is too complex for the given training data and common solutions to reduce the generalization error are listed as follows:<br><br>- Collect more training data<br>- Introduce a penalty for complexity via regularization<br>- Choose a simpler model with fewer parameters<br>- Reduce the dimensionality of the data	
What technique of regularization can be used for feature selection?	L1 regularization yields sparse feature vectors; most feature weights will be zero. Sparsity can be useful in practice if we have a high-dimensional dataset with many features that are irrelevant, especially cases where we have more irrelevant dimensions than samples. In this sense, L1 regularization can be understood as a technique for feature selection.	
What's an alternative way to reduce the complexity of the model and avoid overfitting than regularization?	Dimensionality reduction via feature selection.	
What are the two main categories of dimensionality reduction?	feature selection and feature extraction. Using feature selection, we select a subset of the original features. In feature extraction, we derive information from the feature set to construct a new feature subspace.	
What are Sequential feature selection algorithms?	A family of greedy search algorithms that are used to reduce an initial d-dimensional feature space to a k-dimensional feature subspace where k < d.	
Describe the Sequential Backward Selection (SBS) algorithm.	SBS sequentially removes features from the full feature subset until the new feature subspace contains the desired number of features. In order to determine which feature is to be removed at each stage, we need to define criterion function Sequential feature selection algorithms that we want to minimize. The criterion calculated by the criterion function can simply be the difference in performance of the classifier after and before the removal of a particular feature. Then the feature to be removed at each stage can simply be defined as the feature that maximizes this criterion; or, in more intuitive terms, at each stage we eliminate the feature that causes the least performance loss after removal	
How can we use random forests to perform feature selection?	Using a random forest, we can measure feature importance as the averaged impurity decrease computed from all decision trees in the forest without making any assumptions whether our data is linearly separable or not.	
What's an important gotcha concerning random forest feature selection?	If two or more features are highly correlated, one feature may be ranked very highly while the information of the other feature(s) may not be fully captured.	
What is feature extraction?	A method to transform or project the data onto a new feature space. In the context of dimensionality reduction, feature extraction can be understood as an approach to data compression with the goal of maintaining most of the relevant information.	
Describe PCA in a nutshell.	It aims to find the directions of maximum variance in high-dimensional data and projects it onto a new subspace with equal or fewer dimensions that the original one. The orthogonal axes (principal components) of the new subspace can be interpreted as the directions of maximum variance given the constraint that the new feature axes are orthogonal to each other	
Describe the PCA algorithm.	"         <div><img src=""quizlet-Zc8zpUOYQRmcEil-LhNswg_m.png"" /></div>         "	
What represents the principal components?	The eigenvectors of the covariance matrix (the directions of maximum variance), whereas the corresponding eigenvalues will define their magnitude.	
What is the variance explained of an eigenvalue?	lambda_j / SUM ( lambda_i) over all i in set d	
What does LDA stand for?	Linear Discriminant Analysis	
What's the general concept behind LDA?	The general concept behind LDA is very similar to PCA, whereas PCA attempts to find the orthogonal component axes of maximum variance in a dataset; the goal in LDA is to find the feature subspace that optimizes class separability. It is a supervised algorithm whereas PCA is unsupervised.	
Summarize the key steps to the LDA algorithm.	"         <div><img src=""quizlet-d.QPE.q11lZnJDEHzZx.bw_m.png"" /></div>         "	
What are the assumptions for LDA?	The assumptions that we make when we are using LDA are that the features are normally distributed and independent of each other. Also, the LDA algorithm assumes that the covariance matrices for the individual classes are identical.	
What's a mean vector?	Each mean vector stores the mean feature value with respect to the samples of class i.	
How do you compute the within-scatter matrix?	"First note: we want to scale the individual scatter matrices before we sum them up as scatter matrix.<br>Note the covariance matrix is a normalized version of the within-scatter matrix. (1/N)*Sw         <div><img src=""quizlet-GXO1hcRB.AuOJ2akt4iC.Q_m.png"" /></div>         "	
What is the between class scatter matrix?	"         <div><img src=""quizlet-v5hHGzcFQ2zxfKMHy9VMSQ_m.png"" /></div>         "	
What is kernel PCA?	we perform a nonlinear mapping that transforms the data onto a higher-dimensional space and use standard PCA in this higher-dimensional space to project the data back onto a lower-dimensional space where the samples can be separated by a linear classifier (under the condition that the samples can be separated by density in the input space).	
How can you obtain reliable estimates of the model's generalization error?	Using cross-validation techniques such as holdout cross-validation and k-fold cross-validation.	
What is model selection?	Process of tuning and comparing different parameter settings to further improve the performance for making predictions on unseen data.	
What is k-fold cross-validation?	we randomly split the training dataset into k folds without replacement, where k-1 folds are used for the model training and one fold is used for testing. This procedure is repeated k times so that we obtain k models and performance estimates.	
What is the standard value for k in k-fold cross-validation?	10, unless working with small amount of data. In that case, increase k.	
What is stratified k-fold cross-validation?	The class proportions are preserved in each fold to ensure that each fold is representative of the class proportions in the training dataset	
What is a benefit of learning curves?	To diagnose if a learning algorithm has a problem with overfitting (high variance) or underfitting (high bias).	
What are the learning curve plots for high bias, high variance, and a good bias-variance trade-off?	"         <div><img src=""quizlet-GNtT6Ua2aj4n9a5BNc5mbQ_m.png"" /></div>         "	
What are validation curves used for and what are they?	Validation curves are a useful tool for improving the performance of a model by addressing issues such as overfitting or underfitting. Validation curves are related to learning curves, but instead of plotting the training and test accuracies as functions of the sample size, we vary the values of the model parameters	
What would a validation curve look like for a parameter c?	"         <div><img src=""quizlet-YVX1H-kgC8SgpVSPog3gMA_m.png"" /></div>         "	
What is nested cross-validation?	We have an outer k-fold cross-validation loop to split the data into training and test folds, and an inner loop is used to select the model using k-fold cross-validation on the training fold. After model selection, the test fold is then used to evaluate the model performance.	
What is Precision?	TP / (TP + FP)	
What is Recall?	TP / (TP + FN)	
What is F1-Score?	2 * (Precision * Recall) / (Precision + Recall)	
What are Receiver operator characteristic (ROC) graphs useful for?	Selecting models for classification based on their performance with respect to the false positive and true positive rates, which are computed by shifting the decision threshold of the classifier. The diagonal of an ROC graph can be interpreted as random guessing, and classification models that fall below the diagonal are considered as worse than random guessing. A perfect classifier would fall into the top-left corner of the graph with a true positive rate of 1 and a false positive rate of 0. Based on the ROC curve, we can then compute the so-called area under the curve (AUC) to characterize the performance of a classification model.	
Describe micro and macro averaging methods.	"         <div><img src=""quizlet-BB4UndaHPVkg7IU19pk3jg_m.png"" /></div>         "	
What's the goal behind ensemble methods?	The goal behind ensemble methods is to combine different classifiers into a meta-classifier that has a better generalization performance than each individual classifier alone	
What is majority or plurality voting?	Just selecting the class with the most votes (mode) from the learners for the classification. Can use a weighted approach as well as probabilistic.	
Why do ensemble methods work better than individual classifiers alone?	"         <div><img src=""quizlet-01zCClrObLY9ra6vhoTMkg_m.png"" /></div>         "	
What is bagging in the context of ensembles?	Instead of using the same training set to fit the individual classifiers in the ensemble, we draw bootstrap samples (random samples with replacement) from the initial training set, which is why bagging is also known as bootstrap aggregating.	
How does bagging affect bias and variance?	The bagging algorithm can be an effective approach to reduce the variance of a model. However, bagging is ineffective in reducing model bias, which is why we want to choose an ensemble of classifiers with low bias, for example, unpruned decision trees.	
Describe boosting.	In boosting, the ensemble consists of very simple base classifiers, also often referred to as weak learners, that have only a slight performance advantage over random guessing. A typical example of a weak learner would be a decision tree stump. The key concept behind boosting is to focus on training samples that are hard to classify, that is, to let the weak learners subsequently learn from misclassified training samples to improve the performance of the ensemble. In contrast to bagging, the initial formulation of boosting, the algorithm uses random subsets of training samples drawn from the training dataset without replacement.	
What are the four steps to the original boosting algorithm?	"         <div><img src=""quizlet-TmDt0PrNnW6Ks-UJ1iZk.Q_m.png"" /></div>         "	
Describe the basic difference in boosting with AdaBoost?	In contrast to the original boosting procedure as described here, AdaBoost uses the complete training set to train the weak learners where the training samples are reweighted in each iteration to build a strong classifier that learns from the mistakes of the previous weak learners in the ensemble.	
What are the 9 steps to AdaBoost?	"         <div><img src=""quizlet-em8ibMXul1BRNh9W82yhCA_m.png"" /></div>         "	
What is sentiment analysis?	Sentiment analysis, sometimes also called opinion mining, is a popular sub-discipline of the broader field of NLP; it analyzes the polarity of documents. A popular task in sentiment analysis is the classification of documents based on the expressed opinions or emotions of the authors with regard to a particular topic.	
What is the bag of words model?	1) We create a vocabulary of unique tokens—for example, words—from the entire set of documents.<br>2) We construct a feature vector from each document that contains the counts of how often each word occurs in the particular document.	
Describe TF-IDF.	"         <div><img src=""quizlet-bxhYXEbyZMCzgFoAaUdiBA_m.png"" /></div>         "	
What is L2-Normalization?	Returns a vector of length 1 by dividing the un-normalized feature vector v by its L2-Norm	
What is word stemming?	The process of transforming a word into its root form that allows us to map related words to the same stem	
What is Exploratory Data Analysis?	(EDA) is an important and recommended first step prior to the training of a machine learning model. For example, it may help us to visually detect the presence of outliers, the distribution of the data, and the relationships between features.	
What are some EDA methods to use?	1) create a scatterplot matrix that allows us to visualize the pair-wise correlations between the different features in this dataset in one place. <br>2) Create a correlation matrix and maybe create a heat map plotting the correlations	
What is a correlation matrix?	Intuitively, we can interpret the correlation matrix as a rescaled version of the covariance matrix. In fact, the correlation matrix is identical to a covariance matrix computed from standardized data. <br><br>The correlation matrix is a square matrix that contains the Pearson product-moment correlation coefficients (often abbreviated as Pearson's r), which measure the linear dependence between pairs of features. The correlation coefficients are bounded to the range -1 and 1.	
What is a Pearson's correlation coefficient?	Pearson's correlation coefficient can simply be calculated as the covariance between two features Visualizing the important characteristics of a dataset and Visualizing the important characteristics of a dataset (numerator) divided by the product of their standard deviations (denominator):	
What is OLS?	Ordinary Least Squares (OLS) method is to estimate the parameters of the regression line that minimizes the sum of the squared vertical distances (residuals or errors) to the sample points.	
Describe the RANdom SAmple Consensus (RANSAC) algorithm.	Fits a regression model to a subset of the data, the so-called inliers.	
We can summarize the iterative RANSAC algorithm as follows:	1) Select a random number of samples to be inliers and fit the model.<br>2) Test all other data points against the fitted model and add those points that fall within a user-given tolerance to the inliers.<br>3) Refit the model using all inliers.<br>4) Estimate the error of the fitted model versus the inliers.<br>5) Terminate the algorithm if the performance meets a certain user-defined threshold or if a fixed number of iterations has been reached; go back to step 1 otherwise.	
What are residual plots?	Since our model uses multiple explanatory variables, we can't visualize the linear regression line (or hyperplane to be precise) in a two-dimensional plot, but we can plot the residuals (the differences or vertical distances between the actual and predicted values) versus the predicted values to diagnose our regression model. Those residual plots are a commonly used graphical analysis for diagnosing regression models to detect nonlinearity and outliers, and to check if the errors are randomly distributed.	
For a good regression model, what would you expect in the residual plot?	We would expect that the errors are randomly distributed and the residuals should be randomly scattered around the centerline. If we see patterns in a residual plot, it means that our model is unable to capture some explanatory information, which is leaked into the residuals	
What is the Mean Squared Error?	"simply the average value of the SSE cost function.         <div><img src=""quizlet-OT.eoDB8n5Wk7-HUI6vD2g_m.png"" /></div>         "	
What is the coefficient of determination, R^2?	A standardized version of the MSE. In other words, R^2 is the fraction of response variance that is captured by the model. The R^2 value is defined as follows:<br>R^2 = 1 - (SSE / SST), where SST = SUM(y - mu_y)^2, or in other words, it is simply the variance of the response.	
Put R^2 in terms of the MSE.	R^2 = 1 - MSE / Var(y)	
What are the three most popular approaches to linear regression regularization?	Ridge Regression, Least Absolute Shrinkage and Selection Operator (LASSO) and Elastic Net method. <br><br>1) Ridge regression is an L2 penalized model where we simply add the squared sum of the weights to our least-squares cost function<br><br>2) LASSO - can lead to sparse matrix, is L1 penalized model but... a limitation of the LASSO is that it selects at most n variables if m > n<br><br>3) Elastic Net - compromise between the two. A L1 penalty to generate sparsity and a L2 penalty to overcome some of the limitations of the LASSO, such as the number of selected variables.	
What is the Elastic Net regularization cost function?	"         <div><img src=""quizlet-FCT15vl-ZavR71FMj6788w_m.png"" /></div>         "	
Give an example of when polynomial features are not always the best choice for modeling nonlinear relationships.	could propose that a log transformation of a feature variable or a square root may project the data onto a linear feature space suitable for a linear regression fit.	
What other technique could you use to deal with nonlinear relationships other than polynomial or feature transformation?	A random forest, which is an ensemble of multiple decision trees, can be understood as the sum of piecewise linear functions in contrast to the global linear and polynomial regression models. via the decision tree algorithm, we are subdividing the input space into smaller regions that become more manageable.	
What's the only difference between Random Forest classification and regression?	The only difference is that we use the MSE criterion to grow the individual decision trees, and the predicted target variable is calculated as the average prediction over all decision trees.	
What is Prototype-based clustering?	It means that each cluster is represented by a prototype, which can either be the centroid (average) of similar points with continuous features, or the medoid (the most representative or most frequently occurring point) in the case of categorical features.	
What are the 4 steps to the k-means algorithm?	1) Randomly pick k centroids from the sample points as initial cluster centers.<br>2) Assign each sample to the nearest centroid<br>3) Move the centroids to the center of the samples that were assigned to it.<br>4) Repeat the steps 2 and 3 until the cluster assignment do not change or a user-defined tolerance or a maximum number of iterations is reached.<br><br>Note: When we are applying k-means to real-world data using a Euclidean distance metric, we want to make sure that the features are measured on the same scale and apply z-score standardization or min-max scaling if necessary.	
How do we measure similarity between objects?	"We can define similarity as the opposite of distance, and a commonly used distance for clustering samples with continuous features is the squared Euclidean distance between two points x and y in m-dimensional space:         <div><img src=""quizlet-4-wEfP7jbk.lzG2hPZYUkw_m.png"" /></div>         "	
Describe the k-means algorithm as a simple optimization problem.	An iterative approach for minimizing the within-cluster sum of squared errors (SSE), which is sometimes also called cluster inertia.	
What is the k-means++ algorithm?	In concept, k-means but place the initial centroids far away from each other.	
Describe hard vs soft (fuzzy) clusterning.	Hard clustering describes a family of algorithms where each sample in a dataset is assigned to exactly one cluster, as in the k-means algorithm that we discussed in the previous subsection. In contrast, algorithms for soft clustering (sometimes also called fuzzy clustering) assign a sample to one or more clusters.	
What's the difference between k-means and fuzzy C-means	The FCM procedure is very similar to k-means, however, we replace the hard cluster assignment by probabilities for each point belonging to each cluster.	
What is the elbow method?	A graphical technique to estimate the optimal number of clusters k for a given task. Intuitively, we can say that, if k increases, the distortion (within-cluster SSE) will decrease. This is because the samples will be closer to the centroids they are assigned to. The idea behind the elbow method is to identify the value of k where the distortion begins to increase most rapidly,	
What can Silhouette Analysis be used for?	Silhouette analysis can be used as a graphical tool to plot a measure of how tightly grouped the samples in the clusters are.	
How do you calculate the Silhouette coefficient and how do you interpret it?	"         <div><img src=""quizlet-6LUzOIvR-bYWD.YVK3lyzw_m.png"" /></div>         "	
The two main approaches to hierarchical clustering are...	agglomerative and divisive hierarchical clustering	
What is divisive hierarchical clustering from a birds eye view?	In divisive hierarchical clustering, we start with one cluster that encompasses all our samples, and we iteratively split the cluster into smaller clusters until each cluster only contains one sample.	
What is agglomerative hierarchical clustering from a birds eye view?	It takes the opposite approach. We start with each sample as an individual cluster and merge the closest pairs of clusters until only one cluster remains.	
What are the two standard algorithms for agglomerative hierarchical clustering?	single linkage and complete linkage.<br><br>Using single linkage, we compute the distances between the most similar members for each pair of clusters and merge the two clusters for which the distance between the most similar members is the smallest. The complete linkage approach is similar to single linkage but, instead of comparing the most similar members in each pair of clusters, we compare the most dissimilar members to perform the merge.	
What is Density-based Spatial Clustering of Applications with Noise (DBSCAN)?	"         <div><img src=""quizlet-rUJ12Ps9jcxYlQxfeehyMg_m.png"" /></div>         "	
What is Deep learning?	It can be understood as a set of algorithms that were developed to train artificial neural networks with many layers most efficiently.	
Summarize the MLP (Multi-layer perceptron) learning procedure in three simple steps and the evaluation of the model.	1) Starting at the input layer, we forward propagate the patterns of the training data through the network to generate an output.<br>2) Based on the network's output, we calculate the error that we want to minimize using a cost function that we will describe later.<br>3) We backpropagate the error, find its derivative with respect to each weight in the network, and update the model.<br><br>Finally, after repeating the steps for multiple epochs and learning the weights of the MLP, we use forward propagation to calculate the network output and apply a threshold function to obtain the predicted class labels in the one-hot representation,	
What does the feedforward in feedforward artificial neural network mean?	Feedforward refers to the fact that each layer serves as the input to the next layer without loops, in contrast to recurrent neural networks for example.	
What is some intuition for the backpropagation algorithm?	In essence, backpropagation is just a very computationally efficient approach to compute the derivatives of a complex cost function. Our goal is to use those derivatives to learn the weight coefficients for parameterizing a multi-layer artificial neural network.	
What is gradient checking?	It is essentially a comparison between our analytical gradients in the network and numerical gradients, where a numerically approximated gradient =( J(w + epsilon) - J(w) ) / epsilon, for example.	
What's the key idea behind Convolutional Neural Networks (CNNs or ConvNets)?	The key idea behind convolutional neural networks is to build many layers of feature detectors to take the spatial arrangement of pixels in an input image into account. They have extraordinary good performance on image classification tasks. <br><br>In CNNs, we use receptive fields to connect the input layer to a feature map. These receptive fields can be understood as overlapping windows that we slide over the pixels of an input image to create a feature map. The stride lengths of the window sliding as well as the window size are additional hyperparameters of the model that we need to define a priori. The process of creating the feature map is also called convolution.	
What is a pooling layer and how does it tie into CNNs?	In CNNs, a convolutional layer is followed by a pooling layer (sometimes also called sub-sampling). In pooling, we summarize neighboring feature detectors to reduce the number of features for the next layer. Pooling can be understood as a simple method of feature extraction where we take the average or maximum value of a patch of neighboring features and pass it on to the next layer. To create a deep convolutional neural network, we stack multiple layers—alternating between convolutional and pooling layers—before we connect it to a multi-layer perceptron for classification.	
What are Recurrent Neural Networks?	Recurrent Neural Networks (RNNs) can be thought of as feedforward neural networks with feedback loops or backpropagation through time. In RNNs, the neurons only fire for a limited amount of time before they are (temporarily) deactivated. In turn, these neurons activate other neurons that fire at a later point in time. Basically, we can think of recurrent neural networks as MLPs with an additional time variable. The time component and dynamic structure allows the network to use not only the current inputs but also the inputs that it encountered earlier.	
What is the softmax function?	"It is a generalization of the logistic function that allows us to compute meaningful class-probabilities in multi-class settings (multinomial logistic regression). It may help to think of the softmax function as a normalized logistic function that is useful to obtain meaningful class-membership predictions in multi-class settings.         <div><img src=""quizlet-c6pMVcxzyuFhaQMCpwC4aQ_m.png"" /></div>         "	
What is the hyperbolic tangent (tanh) activation function?	It can be interpreted as a rescaled version of the logistic function. (e^z - e^-z) / (e^z + e^-z). The advantage of the hyperbolic tangent over the logistic function is that it has a broader output spectrum and ranges the open interval (-1, 1), which can improve the convergence of the back propagation algorithm	
What are the three main impurity measures or splitting criteria commonly used in binary decision trees.	Gini impurity, entropy, and classification error	
Give the definition of entropy for all non-empty classes.	"         <div><img src=""quizlet-442UJSyGhph32TZyFlUDOg_m.png"" /></div>         "	
Describe the intuition of the Gini Impurity	Intuitively, the Gini impurity can be understood as a criterion to minimize the probability of misclassification	
What should you focus on for impurity measures in practice?	In practice both the Gini impurity and entropy typically yield very similar results and it is often not worth spending much time on evaluating trees using different impurity criteria rather than experimenting with different pruning cut-offs.	
What's the classification error impurity?	I = 1 - max( p(i|t) ), This is a useful criterion for pruning but not recommended for growing a decision tree, since it is less sensitive to changes in the class probabilities of the nodes.	
What is the random forest algorithm	1) Draw a random bootstrap sample of size n (randomly choose n samples from the training set with replacement).<br>2) Grow a decision tree from the bootstrap sample. At each node:<br> - Randomly select d features without replacement.<br> - Split the node using the feature that provides the best split according to the objective function, for instance, by maximizing the information gain.<br>3) Repeat the steps 1 to 2 k times.<br>4) Aggregate the prediction by each tree to assign the class label by majority vote.	
What are some reasonable defaults for the random forest algorithm parameters?	- The sample size of the bootstrap sample is chosen to be equal to the number of samples in the original training set, which usually provides a good bias-variance tradeoff.<br>- For the number of features d at each split, we want to choose a value that is smaller than the total number of features in the training set. A reasonable default that is used in scikit-learn and other implementations is d = sqrt(m), where m is the number of features in the training set.	
Why is a lazy learner called lazy?	It is called lazy not because of its apparent simplicity, but because it doesn't learn a discriminative function from the training data but memorizes the training dataset instead.	
Describe parametric vs nonparametric models	Machine learning algorithms can be grouped into parametric and nonparametric models. Using parametric models, we estimate parameters from the training dataset to learn a function that can classify new data points without requiring the original training dataset anymore. Typical examples of parametric models are the perceptron, logistic regression, and the linear SVM. In contrast, nonparametric models can't be characterized by a fixed set of parameters, and the number of parameters grows with the training data. Two examples of nonparametric models that we have seen so far are the decision tree classifier/random forest and the kernel SVM.	
Describe the KNN algorithm.	- Choose the number of k and a distance metric.<br>- Find the k nearest neighbors of the sample that we want to classify.<br>- Assign the class label by majority vote.	
What do you do instead of regularizations in models where it can't be used?	In models where regularization is not applicable such as decision trees and KNN, we can use feature selection and dimensionality reduction techniques to help us avoid the curse of dimensionality.	
What's a common way to deal with missing numerical values?	Use the mean of that feature or drop the data if it isn't very much.	
What's the difference between nominal and ordinal categorical features?	Ordinal features can be understood as categorical values that can be sorted or ordered. In contrast, nominal features don't imply any order. Ordinal - size of t-shirt, nominal - color of t-shirt	
What is one-hot encoding?	The idea behind this approach is to create a new dummy feature for each unique value in the nominal feature column.	
The smaller the test set ...	the more inaccurate the estimation of the generalization error.	
Most often, normalization refers to...	the rescaling of the features to a range of [0, 1], which is a special case of min-max scaling. (x - x_max) / (x_max - x_min)	
Why is standardization often more practical for many machine learning algorithms?	The reason is that many linear models, such as the logistic regression and SVM, initialize the weights to 0 or small random values close to 0. Using standardization, we center the feature columns at mean 0 with standard deviation 1 so that the feature columns take the form of a normal distribution, which makes it easier to learn the weights. Furthermore, standardization maintains useful information about outliers and makes the algorithm less sensitive to them in contrast to min-max scaling, which scales the data to a limited range of values.	
What is a reason for overfitting and ways to address it:	A reason for overfitting is that our model is too complex for the given training data and common solutions to reduce the generalization error are listed as follows:<br><br>- Collect more training data<br>- Introduce a penalty for complexity via regularization<br>- Choose a simpler model with fewer parameters<br>- Reduce the dimensionality of the data	
What technique of regularization can be used for feature selection?	L1 regularization yields sparse feature vectors; most feature weights will be zero. Sparsity can be useful in practice if we have a high-dimensional dataset with many features that are irrelevant, especially cases where we have more irrelevant dimensions than samples. In this sense, L1 regularization can be understood as a technique for feature selection.	
What's an alternative way to reduce the complexity of the model and avoid overfitting than regularization?	Dimensionality reduction via feature selection.	
What are the two main categories of dimensionality reduction?	feature selection and feature extraction. Using feature selection, we select a subset of the original features. In feature extraction, we derive information from the feature set to construct a new feature subspace.	
What are Sequential feature selection algorithms?	A family of greedy search algorithms that are used to reduce an initial d-dimensional feature space to a k-dimensional feature subspace where k < d.	
Describe the Sequential Backward Selection (SBS) algorithm.	SBS sequentially removes features from the full feature subset until the new feature subspace contains the desired number of features. In order to determine which feature is to be removed at each stage, we need to define criterion function Sequential feature selection algorithms that we want to minimize. The criterion calculated by the criterion function can simply be the difference in performance of the classifier after and before the removal of a particular feature. Then the feature to be removed at each stage can simply be defined as the feature that maximizes this criterion; or, in more intuitive terms, at each stage we eliminate the feature that causes the least performance loss after removal	
How can we use random forests to perform feature selection?	Using a random forest, we can measure feature importance as the averaged impurity decrease computed from all decision trees in the forest without making any assumptions whether our data is linearly separable or not.	
What's an important gotcha concerning random forest feature selection?	If two or more features are highly correlated, one feature may be ranked very highly while the information of the other feature(s) may not be fully captured.	
What is feature extraction?	A method to transform or project the data onto a new feature space. In the context of dimensionality reduction, feature extraction can be understood as an approach to data compression with the goal of maintaining most of the relevant information.	
Describe PCA in a nutshell.	It aims to find the directions of maximum variance in high-dimensional data and projects it onto a new subspace with equal or fewer dimensions that the original one. The orthogonal axes (principal components) of the new subspace can be interpreted as the directions of maximum variance given the constraint that the new feature axes are orthogonal to each other	
Describe the PCA algorithm.	"         <div><img src=""quizlet-Zc8zpUOYQRmcEil-LhNswg_m.png"" /></div>         "	
What represents the principal components?	The eigenvectors of the covariance matrix (the directions of maximum variance), whereas the corresponding eigenvalues will define their magnitude.	
What is the variance explained of an eigenvalue?	lambda_j / SUM ( lambda_i) over all i in set d	
What does LDA stand for?	Linear Discriminant Analysis	
What's the general concept behind LDA?	The general concept behind LDA is very similar to PCA, whereas PCA attempts to find the orthogonal component axes of maximum variance in a dataset; the goal in LDA is to find the feature subspace that optimizes class separability. It is a supervised algorithm whereas PCA is unsupervised.	
Summarize the key steps to the LDA algorithm.	"         <div><img src=""quizlet-d.QPE.q11lZnJDEHzZx.bw_m.png"" /></div>         "	
What are the assumptions for LDA?	The assumptions that we make when we are using LDA are that the features are normally distributed and independent of each other. Also, the LDA algorithm assumes that the covariance matrices for the individual classes are identical.	
What's a mean vector?	Each mean vector stores the mean feature value with respect to the samples of class i.	
How do you compute the within-scatter matrix?	"First note: we want to scale the individual scatter matrices before we sum them up as scatter matrix.<br>Note the covariance matrix is a normalized version of the within-scatter matrix. (1/N)*Sw         <div><img src=""quizlet-GXO1hcRB.AuOJ2akt4iC.Q_m.png"" /></div>         "	
What is the between class scatter matrix?	"         <div><img src=""quizlet-v5hHGzcFQ2zxfKMHy9VMSQ_m.png"" /></div>         "	
What is kernel PCA?	we perform a nonlinear mapping that transforms the data onto a higher-dimensional space and use standard PCA in this higher-dimensional space to project the data back onto a lower-dimensional space where the samples can be separated by a linear classifier (under the condition that the samples can be separated by density in the input space).	
How can you obtain reliable estimates of the model's generalization error?	Using cross-validation techniques such as holdout cross-validation and k-fold cross-validation.	
What is model selection?	Process of tuning and comparing different parameter settings to further improve the performance for making predictions on unseen data.	
What is k-fold cross-validation?	we randomly split the training dataset into k folds without replacement, where k-1 folds are used for the model training and one fold is used for testing. This procedure is repeated k times so that we obtain k models and performance estimates.	
What is the standard value for k in k-fold cross-validation?	10, unless working with small amount of data. In that case, increase k.	
What is stratified k-fold cross-validation?	The class proportions are preserved in each fold to ensure that each fold is representative of the class proportions in the training dataset	
What is a benefit of learning curves?	To diagnose if a learning algorithm has a problem with overfitting (high variance) or underfitting (high bias).	
What are the learning curve plots for high bias, high variance, and a good bias-variance trade-off?	"         <div><img src=""quizlet-GNtT6Ua2aj4n9a5BNc5mbQ_m.png"" /></div>         "	
What are validation curves used for and what are they?	Validation curves are a useful tool for improving the performance of a model by addressing issues such as overfitting or underfitting. Validation curves are related to learning curves, but instead of plotting the training and test accuracies as functions of the sample size, we vary the values of the model parameters	
What would a validation curve look like for a parameter c?	"         <div><img src=""quizlet-YVX1H-kgC8SgpVSPog3gMA_m.png"" /></div>         "	
What is nested cross-validation?	We have an outer k-fold cross-validation loop to split the data into training and test folds, and an inner loop is used to select the model using k-fold cross-validation on the training fold. After model selection, the test fold is then used to evaluate the model performance.	
What is Precision?	TP / (TP + FP)	
What is Recall?	TP / (TP + FN)	
What is F1-Score?	2 * (Precision * Recall) / (Precision + Recall)	
What are Receiver operator characteristic (ROC) graphs useful for?	Selecting models for classification based on their performance with respect to the false positive and true positive rates, which are computed by shifting the decision threshold of the classifier. The diagonal of an ROC graph can be interpreted as random guessing, and classification models that fall below the diagonal are considered as worse than random guessing. A perfect classifier would fall into the top-left corner of the graph with a true positive rate of 1 and a false positive rate of 0. Based on the ROC curve, we can then compute the so-called area under the curve (AUC) to characterize the performance of a classification model.	
Describe micro and macro averaging methods.	"         <div><img src=""quizlet-BB4UndaHPVkg7IU19pk3jg_m.png"" /></div>         "	
What's the goal behind ensemble methods?	The goal behind ensemble methods is to combine different classifiers into a meta-classifier that has a better generalization performance than each individual classifier alone	
What is majority or plurality voting?	Just selecting the class with the most votes (mode) from the learners for the classification. Can use a weighted approach as well as probabilistic.	
Why do ensemble methods work better than individual classifiers alone?	"         <div><img src=""quizlet-01zCClrObLY9ra6vhoTMkg_m.png"" /></div>         "	
What is bagging in the context of ensembles?	Instead of using the same training set to fit the individual classifiers in the ensemble, we draw bootstrap samples (random samples with replacement) from the initial training set, which is why bagging is also known as bootstrap aggregating.	
How does bagging affect bias and variance?	The bagging algorithm can be an effective approach to reduce the variance of a model. However, bagging is ineffective in reducing model bias, which is why we want to choose an ensemble of classifiers with low bias, for example, unpruned decision trees.	
Describe boosting.	In boosting, the ensemble consists of very simple base classifiers, also often referred to as weak learners, that have only a slight performance advantage over random guessing. A typical example of a weak learner would be a decision tree stump. The key concept behind boosting is to focus on training samples that are hard to classify, that is, to let the weak learners subsequently learn from misclassified training samples to improve the performance of the ensemble. In contrast to bagging, the initial formulation of boosting, the algorithm uses random subsets of training samples drawn from the training dataset without replacement.	
What are the four steps to the original boosting algorithm?	"         <div><img src=""quizlet-TmDt0PrNnW6Ks-UJ1iZk.Q_m.png"" /></div>         "	
Describe the basic difference in boosting with AdaBoost?	In contrast to the original boosting procedure as described here, AdaBoost uses the complete training set to train the weak learners where the training samples are reweighted in each iteration to build a strong classifier that learns from the mistakes of the previous weak learners in the ensemble.	
What are the 9 steps to AdaBoost?	"         <div><img src=""quizlet-em8ibMXul1BRNh9W82yhCA_m.png"" /></div>         "	
What is sentiment analysis?	Sentiment analysis, sometimes also called opinion mining, is a popular sub-discipline of the broader field of NLP; it analyzes the polarity of documents. A popular task in sentiment analysis is the classification of documents based on the expressed opinions or emotions of the authors with regard to a particular topic.	
What is the bag of words model?	1) We create a vocabulary of unique tokens—for example, words—from the entire set of documents.<br>2) We construct a feature vector from each document that contains the counts of how often each word occurs in the particular document.	
Describe TF-IDF.	"         <div><img src=""quizlet-bxhYXEbyZMCzgFoAaUdiBA_m.png"" /></div>         "	
What is L2-Normalization?	Returns a vector of length 1 by dividing the un-normalized feature vector v by its L2-Norm	
What is word stemming?	The process of transforming a word into its root form that allows us to map related words to the same stem	
What is Exploratory Data Analysis?	(EDA) is an important and recommended first step prior to the training of a machine learning model. For example, it may help us to visually detect the presence of outliers, the distribution of the data, and the relationships between features.	
What are some EDA methods to use?	1) create a scatterplot matrix that allows us to visualize the pair-wise correlations between the different features in this dataset in one place. <br>2) Create a correlation matrix and maybe create a heat map plotting the correlations	
What is a correlation matrix?	Intuitively, we can interpret the correlation matrix as a rescaled version of the covariance matrix. In fact, the correlation matrix is identical to a covariance matrix computed from standardized data. <br><br>The correlation matrix is a square matrix that contains the Pearson product-moment correlation coefficients (often abbreviated as Pearson's r), which measure the linear dependence between pairs of features. The correlation coefficients are bounded to the range -1 and 1.	
What is a Pearson's correlation coefficient?	Pearson's correlation coefficient can simply be calculated as the covariance between two features Visualizing the important characteristics of a dataset and Visualizing the important characteristics of a dataset (numerator) divided by the product of their standard deviations (denominator):	
What is OLS?	Ordinary Least Squares (OLS) method is to estimate the parameters of the regression line that minimizes the sum of the squared vertical distances (residuals or errors) to the sample points.	
Describe the RANdom SAmple Consensus (RANSAC) algorithm.	Fits a regression model to a subset of the data, the so-called inliers.	
We can summarize the iterative RANSAC algorithm as follows:	1) Select a random number of samples to be inliers and fit the model.<br>2) Test all other data points against the fitted model and add those points that fall within a user-given tolerance to the inliers.<br>3) Refit the model using all inliers.<br>4) Estimate the error of the fitted model versus the inliers.<br>5) Terminate the algorithm if the performance meets a certain user-defined threshold or if a fixed number of iterations has been reached; go back to step 1 otherwise.	
What are residual plots?	Since our model uses multiple explanatory variables, we can't visualize the linear regression line (or hyperplane to be precise) in a two-dimensional plot, but we can plot the residuals (the differences or vertical distances between the actual and predicted values) versus the predicted values to diagnose our regression model. Those residual plots are a commonly used graphical analysis for diagnosing regression models to detect nonlinearity and outliers, and to check if the errors are randomly distributed.	
For a good regression model, what would you expect in the residual plot?	We would expect that the errors are randomly distributed and the residuals should be randomly scattered around the centerline. If we see patterns in a residual plot, it means that our model is unable to capture some explanatory information, which is leaked into the residuals	
What is the Mean Squared Error?	"simply the average value of the SSE cost function.         <div><img src=""quizlet-OT.eoDB8n5Wk7-HUI6vD2g_m.png"" /></div>         "	
What is the coefficient of determination, R^2?	A standardized version of the MSE. In other words, R^2 is the fraction of response variance that is captured by the model. The R^2 value is defined as follows:<br>R^2 = 1 - (SSE / SST), where SST = SUM(y - mu_y)^2, or in other words, it is simply the variance of the response.	
Put R^2 in terms of the MSE.	R^2 = 1 - MSE / Var(y)	
What are the three most popular approaches to linear regression regularization?	Ridge Regression, Least Absolute Shrinkage and Selection Operator (LASSO) and Elastic Net method. <br><br>1) Ridge regression is an L2 penalized model where we simply add the squared sum of the weights to our least-squares cost function<br><br>2) LASSO - can lead to sparse matrix, is L1 penalized model but... a limitation of the LASSO is that it selects at most n variables if m > n<br><br>3) Elastic Net - compromise between the two. A L1 penalty to generate sparsity and a L2 penalty to overcome some of the limitations of the LASSO, such as the number of selected variables.	
What is the Elastic Net regularization cost function?	"         <div><img src=""quizlet-FCT15vl-ZavR71FMj6788w_m.png"" /></div>         "	
Give an example of when polynomial features are not always the best choice for modeling nonlinear relationships.	could propose that a log transformation of a feature variable or a square root may project the data onto a linear feature space suitable for a linear regression fit.	
What other technique could you use to deal with nonlinear relationships other than polynomial or feature transformation?	A random forest, which is an ensemble of multiple decision trees, can be understood as the sum of piecewise linear functions in contrast to the global linear and polynomial regression models. via the decision tree algorithm, we are subdividing the input space into smaller regions that become more manageable.	
What's the only difference between Random Forest classification and regression?	The only difference is that we use the MSE criterion to grow the individual decision trees, and the predicted target variable is calculated as the average prediction over all decision trees.	
What is Prototype-based clustering?	It means that each cluster is represented by a prototype, which can either be the centroid (average) of similar points with continuous features, or the medoid (the most representative or most frequently occurring point) in the case of categorical features.	
What are the 4 steps to the k-means algorithm?	1) Randomly pick k centroids from the sample points as initial cluster centers.<br>2) Assign each sample to the nearest centroid<br>3) Move the centroids to the center of the samples that were assigned to it.<br>4) Repeat the steps 2 and 3 until the cluster assignment do not change or a user-defined tolerance or a maximum number of iterations is reached.<br><br>Note: When we are applying k-means to real-world data using a Euclidean distance metric, we want to make sure that the features are measured on the same scale and apply z-score standardization or min-max scaling if necessary.	
How do we measure similarity between objects?	"We can define similarity as the opposite of distance, and a commonly used distance for clustering samples with continuous features is the squared Euclidean distance between two points x and y in m-dimensional space:         <div><img src=""quizlet-4-wEfP7jbk.lzG2hPZYUkw_m.png"" /></div>         "	
Describe the k-means algorithm as a simple optimization problem.	An iterative approach for minimizing the within-cluster sum of squared errors (SSE), which is sometimes also called cluster inertia.	
What is the k-means++ algorithm?	In concept, k-means but place the initial centroids far away from each other.	
Describe hard vs soft (fuzzy) clusterning.	Hard clustering describes a family of algorithms where each sample in a dataset is assigned to exactly one cluster, as in the k-means algorithm that we discussed in the previous subsection. In contrast, algorithms for soft clustering (sometimes also called fuzzy clustering) assign a sample to one or more clusters.	
What's the difference between k-means and fuzzy C-means	The FCM procedure is very similar to k-means, however, we replace the hard cluster assignment by probabilities for each point belonging to each cluster.	
What is the elbow method?	A graphical technique to estimate the optimal number of clusters k for a given task. Intuitively, we can say that, if k increases, the distortion (within-cluster SSE) will decrease. This is because the samples will be closer to the centroids they are assigned to. The idea behind the elbow method is to identify the value of k where the distortion begins to increase most rapidly,	
What can Silhouette Analysis be used for?	Silhouette analysis can be used as a graphical tool to plot a measure of how tightly grouped the samples in the clusters are.	
How do you calculate the Silhouette coefficient and how do you interpret it?	"         <div><img src=""quizlet-6LUzOIvR-bYWD.YVK3lyzw_m.png"" /></div>         "	
The two main approaches to hierarchical clustering are...	agglomerative and divisive hierarchical clustering	
What is divisive hierarchical clustering from a birds eye view?	In divisive hierarchical clustering, we start with one cluster that encompasses all our samples, and we iteratively split the cluster into smaller clusters until each cluster only contains one sample.	
What is agglomerative hierarchical clustering from a birds eye view?	It takes the opposite approach. We start with each sample as an individual cluster and merge the closest pairs of clusters until only one cluster remains.	
What are the two standard algorithms for agglomerative hierarchical clustering?	single linkage and complete linkage.<br><br>Using single linkage, we compute the distances between the most similar members for each pair of clusters and merge the two clusters for which the distance between the most similar members is the smallest. The complete linkage approach is similar to single linkage but, instead of comparing the most similar members in each pair of clusters, we compare the most dissimilar members to perform the merge.	
What is Density-based Spatial Clustering of Applications with Noise (DBSCAN)?	"         <div><img src=""quizlet-rUJ12Ps9jcxYlQxfeehyMg_m.png"" /></div>         "	
What is Deep learning?	It can be understood as a set of algorithms that were developed to train artificial neural networks with many layers most efficiently.	
Summarize the MLP (Multi-layer perceptron) learning procedure in three simple steps and the evaluation of the model.	1) Starting at the input layer, we forward propagate the patterns of the training data through the network to generate an output.<br>2) Based on the network's output, we calculate the error that we want to minimize using a cost function that we will describe later.<br>3) We backpropagate the error, find its derivative with respect to each weight in the network, and update the model.<br><br>Finally, after repeating the steps for multiple epochs and learning the weights of the MLP, we use forward propagation to calculate the network output and apply a threshold function to obtain the predicted class labels in the one-hot representation,	
What does the feedforward in feedforward artificial neural network mean?	Feedforward refers to the fact that each layer serves as the input to the next layer without loops, in contrast to recurrent neural networks for example.	
What is some intuition for the backpropagation algorithm?	In essence, backpropagation is just a very computationally efficient approach to compute the derivatives of a complex cost function. Our goal is to use those derivatives to learn the weight coefficients for parameterizing a multi-layer artificial neural network.	
What is gradient checking?	It is essentially a comparison between our analytical gradients in the network and numerical gradients, where a numerically approximated gradient =( J(w + epsilon) - J(w) ) / epsilon, for example.	
What's the key idea behind Convolutional Neural Networks (CNNs or ConvNets)?	The key idea behind convolutional neural networks is to build many layers of feature detectors to take the spatial arrangement of pixels in an input image into account. They have extraordinary good performance on image classification tasks. <br><br>In CNNs, we use receptive fields to connect the input layer to a feature map. These receptive fields can be understood as overlapping windows that we slide over the pixels of an input image to create a feature map. The stride lengths of the window sliding as well as the window size are additional hyperparameters of the model that we need to define a priori. The process of creating the feature map is also called convolution.	
What is a pooling layer and how does it tie into CNNs?	In CNNs, a convolutional layer is followed by a pooling layer (sometimes also called sub-sampling). In pooling, we summarize neighboring feature detectors to reduce the number of features for the next layer. Pooling can be understood as a simple method of feature extraction where we take the average or maximum value of a patch of neighboring features and pass it on to the next layer. To create a deep convolutional neural network, we stack multiple layers—alternating between convolutional and pooling layers—before we connect it to a multi-layer perceptron for classification.	
What are Recurrent Neural Networks?	Recurrent Neural Networks (RNNs) can be thought of as feedforward neural networks with feedback loops or backpropagation through time. In RNNs, the neurons only fire for a limited amount of time before they are (temporarily) deactivated. In turn, these neurons activate other neurons that fire at a later point in time. Basically, we can think of recurrent neural networks as MLPs with an additional time variable. The time component and dynamic structure allows the network to use not only the current inputs but also the inputs that it encountered earlier.	
What is the softmax function?	"It is a generalization of the logistic function that allows us to compute meaningful class-probabilities in multi-class settings (multinomial logistic regression). It may help to think of the softmax function as a normalized logistic function that is useful to obtain meaningful class-membership predictions in multi-class settings.         <div><img src=""quizlet-c6pMVcxzyuFhaQMCpwC4aQ_m.png"" /></div>         "	
What is the hyperbolic tangent (tanh) activation function?	It can be interpreted as a rescaled version of the logistic function. (e^z - e^-z) / (e^z + e^-z). The advantage of the hyperbolic tangent over the logistic function is that it has a broader output spectrum and ranges the open interval (-1, 1), which can improve the convergence of the back propagation algorithm	
Chi-Square	-> Chi-Square for Goodness of Fit<br>- Purpose: compare a one-sample proportion to a<br>hypothesized value<br>- Variables: One categorical with two or more<br>categories<br>-> Chi-Square for Independence<br>- Purpose: compare frequencies or proportions<br>between two groups<br>- Variables: Two categorical with two or more<br>categories each	
McNemar's Test	-> Purpose: compare one sample over<br>time (matched, repeated measures,<br>pre-post test)<br>-> Variables: Two categorical variables<br>measuring the presence or absence<br>(presence=1, absence=0) of the same<br>characteristic at Time 1 and Time 2	
Cochran's Q	-> Purpose: compare one sample over time<br>(three or more measurement periods)<br>-> Variables: Three categorical variables<br>measuring the presence or absence<br>(presence=1, absence=0,) of a<br>characteristic at Time 1, Time 2, Time 3,<br>etc.	
Kappa Agreement	-> Purpose: measures the proportion of<br>agreement between two raters/tests<br>-> Variables: Two categorical variables<br>with an equal number of categories<br>(Rater 1 concludes diagnosis [+=1, -<br>=0] and Rater 2 concludes diagnosis<br>[+=1, -=0]).	
Mann Whitney U	-> Purpose: tests for differences between<br>two independent groups on a<br>continuous DV. Used when DV is not<br>normally distributed. Uses the median<br>and converts scores to ranks.<br>-> Variables: One categorical with two<br>groups; one continuous	
Wilcoxin Signed Rank Test	-> Purpose: tests for differences between<br>matched pairs (repeated measures).<br>Used when DV is not normally<br>distributed. Uses the median and<br>converts scores to ranks.<br>-> Variables: One Time-1 continuous and<br>one Time-2 continuous.	
Kruskal-Wallas Test	-> Purpose: tests for differences between<br>three or more independent groups on<br>a continuous DV. Used when DV is not<br>normally distributed. Uses the median<br>and converts scores to ranks.<br>-> Variables: One categorical with three<br>or more groups; one continuous.	
Friedman Test	-> Purpose: tests for differences between<br>three or more time periods (or<br>conditions) in one sample. Uses the<br>median and converts scores to ranks.<br>-> Variables: One group measured at<br>three or more times (or under three or<br>more conditions).	
Descriptive statistics	simply numerical or graphical summaries of data, and may include charts, graphs, and simple summary statistics such as means and standard deviations to describe characteristics of a population sample.	
Inferential statistics	statistical techniques (e.g., chi-square test, the t test, the one-way ANOVA) that allow conclusions to be drawn about the relationships found among different variables in a population sample.	
Explanatory studies	"depend on inferential questions such as: ""Are women who are sedentary during the third trimester of pregnancy more or less likely to have a cesarean operation than women who exercise regularly during the third trimester?"""	
Prediction and control studies	seek to determine which variables are predictive of other variables and to determine causality (e.g., one event causes another to happen). Data for prediction and control studies are typically collected using quasi-experimental or experimental study designs in which researchers introduce an intervention (e.g., change one of the variables being examined) as these types of studies are thought to have better validity, making causal inference more solid than with purely observational study designs	
Randomized control trials (RCTs)	are considered experimental designs because study participants are randomly assigned to an intervention group or a control group and followed forward in time to determine if the intervention impacts on a specific health outcome.	
Descriptive Questions	*What is the level of intention to engage in physical activity among a group of adults who recently joined a fitness facility? <br>*What is the actual level of physical activity among a group of adults that recently joined a fitness facility?	
Inferential Questions	*Does attitude toward exercise affect participation in physical activity? <br>*Does the extent to which participants perceive themselves as able to exercise (perceived behavioral control) affect participation in physical activity? <br>*Do subjective norms affect participation in physical activity? <br>*Does intention to exercise predict physical activity?	
Research Study Design	Is the art and science of conducting studies that maximize reliability and validity of the findings and minimize bias or error.	
Observational Study Designs	Observational studies are those in which a phenomenon is simply observed and no intervention is instituted.	
Quasi-Experimental and Experimental Study Designs	Quasi-experimental and experimental study designs differ from observational study designs in that the researcher is an active agent in the experimental work.	
Description of the Statistical Analysis	"First, the data must be entered into a database on the computer. Second, the data must be ""cleaned."" Third, descriptive statistics are used to describe the sample in terms of demographic characteristics. Fourth, each hypothesis is listed with the inferential test that will be used to test it."	
Cleaning the Data	Cleaning the data involves making certain that all of the variables have valid and usable values.	
Inferential Statistics Used to Test Each Hypothesis	The third step in data analysis is to list the inferential statistics that will be used to test the hypotheses. The hypotheses, including the independent and dependent variables in each hypothesis, should be clearly stated	
Data analytics life cycle.	The overall management of the availability, usability, integrity, and security of the data employed in an organization or enterprise	
Data governance.	The overall management of the availability, usability, integrity, and security of the data employed in an organization or enterprise	
Data normalization.	In a relational database, it is the process of organizing data to minimize redundancy	
Enterprise information management (EIM)	(1) Ensuring the value of information assets, requiring an organization-wide perspective of information management functions; it calls for explicit structures, policies, processes, technology, and controls. <br>(2) The infrastructure and processes to ensure the information is trustworthy and actionable	
Information governance.	The accountability framework and decision rights to achieve enterprise information management (EIM). IG is the responsibility of executive leadership for developing and driving the IG strategy throughout the organization. IG encompasses both data governance (DG) and information technology governance (ITG)	
Information management (IM) life cycle.	Illustrates how information moves from origination to archival and/or deletion. The steps are comprised of design, acquire, process, use, and dispose	
Descriptive	The average age of the students in a statistics class is 21 years.	
Inferential	The chances of winning the California lottery are one chance in twenty-two million.	
Inferential	There is a relationship between smoking cigarettes and getting emphysema	
Inferential	From past figures, it is predicted that 39% of the registered voters in California will vote in the primary.	
When is homogeneity of variance is important?	It assures accurate estimates of the parameters that define the model and significance tests.	
A normal distribution takes the shape of a bell. What does this shape tell the researcher?	The mean, median, and mode are in the middle of the curve.<br><br>68% of the data in a normal distribution lie within +1 SD from the mean.<br><br>It is a probability distribution and demonstrates the likelihood of getting particular outcomes when sampling from a population.	
The central limit theorem surmises that a big enough sample will produce a normal distribution. True or False?	True	
A sample of size (n) is taken from a normally distributed population. What sample size is needed in order to have a normal distribution of sample mean?	n = 5<br><br>n = 10<br><br>n = 500<br><br>All of the above	
A researcher wants to know the average weight of females who are 22 years old. The researcher obtains the average weight of 54 kg, from a random sample of 40 females. Identify if each of the given statements is true or false.	"The average weight of 54 kg in a group of females is a parameter. FALSE<br><br>The group of 40 females is a sample. TRUE<br><br>The average weight of all females who are 22 yrs old is a parameter. TRUE<br><br>The average weight of all females who are 22 yrs old is a statistic. FALSE         <div><img src=""quizlet-iP2fnE2lcp8AgxqDgseHjA_m.png"" /></div>         "	
What characterizes a normal distribution?	A bell shape<br>A mean, median, and mode that are equal<br>A total area under the curve above the x-axis that is 1	
What can a z-score give information about?	The standard deviation (SD) of a distribution	
What does a z-score of 0 correspond to?	Mean	
What is always the 50th percentile?	Median	
When is a sample population curve is more likely to look like the population curve?	When the sample size is greater than 30	
Which properties do the values of a variable have when a nominal level of measurement is used?	They simply represent categories.	
Which statement best describes symmetrical distributions?	They have an equal number of data points that appear to the left and to the right of the center.	
What does skewness refer to?	The extent to which data are not symmetrical about the center	
Statements that best describes a stem-and-leaf display?	It shows the range of values of the variable.<br>It shows the shape of the distribution of the variable.<br>It preserves the individual values of the variable.	
Which statement best describes standard deviation?	It is the average distance of each point from the mean.	
What is true of descriptive statistics?	They are numerical or graphical summaries of data.	
What is true of inferential statistics?	They are used to examine relationships between variables in a data set.<br>They are used to see how well sample data can be generalized to the population.	
measurement scale	Gender -> Nominal<br>Temperature in Celsius -> Interval<br>Wt in pounds -> Ratio<br>Wt in kilograms -> Ratio<br>Age in years -> Ratio<br>Age in Categories (0 to 6 months, 7 to 12 months, 13+ months) -> Ordinal	
In what order are the steps for the knowledge discovery and data mining process completed?	Selection, pre-processing, transformation, data mining, and interpretation and evaluation	
In order to de-identify participants in the data set, what actions must be taken to secure the general information collected in the survey?	Name must be removed from the general information.<br>Street number must be removed from the general information.<br>Phone number and email address must be removed from the general information.	
You want to examine the relationship between the household income and each risk behavior (behavioral risk factor) for adults younger than 65 years old for the year 2010. Which data management processes could be used to examine this relationship?	Retrieve all the variables of behavioral risk factor, age, and education from the year of 2010, select cases for 18≤age<65, then conduct correlation analysis.<br>Retrieve all the variables of behavioral risk factor, age, and education, select cases for 18≤age<65 and year = 2010, and then conduct correlation analysis.	
What is an essential tool for effectively managing and using the data in the database and a structured way of documenting data stored in a database	Data dictionary	
What is NOT a characteristic of central tendency?	Uses numbers as codes representing categories or characteristics, with no order to the categories	
What are characteristics of central tendency?	Represents the middle of a distribution,<br>Provides information about the most typical values,<br>Uses the mean, median, and mode as its measures.	
Heat Map	Plots all data points as a cell for two given variables of interest and, depending on frequency of observations in each cell, provides color visualize high or low frequency.	
Boxplot	Charts the median, 25%, 75%, mean, minimum and maximum values	
Scatterplot	Plots a point for two different numeric variables for each observation of interest	
Dotplot	Similar to a histogram, plots the frequency of observations for a given variable in a data set.	
Histogram	Charts the frequency of data points (y axis) based upon a particular measure of interest (x axis)	
Correlation Mix	Creates a table of numeric variables and, depending on measure of correlation between the variables, the color changes to represent strength	
What should you look at when interpreting a correlation coefficient?	The significance of the correlation coefficient<br><br>The magnitude of the correlation coefficient<br><br>The +/ - sign of the correlation coefficient	
The plus or minus sign in front of the coefficient identifies the direction of the relationships between variables. A plus (+) indicates a positive correlation where the variables either increase or decrease together (parallel). A negative (-) correlation indicates a relationship where one variable increases as the other decreases (inverse). If r is close to zero (0), it means there is no relationship between the variables.	"         <div><img src=""quizlet-K0SVcPdchpapF.suhT2mEQ_m.png"" /></div>         "	
What do correlational studies allow the researcher to do?	Identify the relationship between two variables	
Which statement would be considered a two-tailed hypothesis?	There is a clear relationship between a healthy balanced diet and feelings of well-being.	
There is a perfect positive correlation between two interval/ratio variables. What correlation coefficient would the Pearson's r test give?	+1.	
How much variance has been explained by a correlation of .9?	81%	
What is multicollinearity?	When predictor variables correlate very highly with each other	
Confidence intervals in A, B, and C overlap.	"         <div><img src=""quizlet-j2N8uqaAHtCi2noXQWeV6Q_m.png"" /></div>         "	
"A researcher studied the use of a specific type of inhaler for asthma sufferers. The results summary is as follows: ""Predictors significantly favored inhaler use (adjusted R2 = .38; ρ = .015). Inhaler A was the strongest predictor of improved breathing (β = .39; ρ = .001) followed by inhaler B (β = .28; ρ = .0015)"". What would be the best interpretation of these variables?"	38% of the variation in inhalers	
"A researcher studied the use of a specific type of inhaler for asthma sufferers. The results summary is as follows: ""Predictors significantly favored inhaler use (adjusted R2 = .38; ρ = .015). Inhaler A was the strongest predictor of improved breathing (β = .39; ρ = .001) followed by inhaler B (β = .28; ρ = .0015)"". Which statement is true of these findings?"	62% of the variation in results of inhaler use (A or B) is due to other factors.	
In a study on child educational investment, researchers used a simple linear regression model to study the relationship between child educational expenditure and the number of children in the family. The dependent variable is average child educational expenditure in dollars, and the independent variable is the number of children in the family. The regression coefficient is -2,300. What does the coefficient mean?	The average child educational expenditure decreases by $2,300 with each additional child in the family. *	
Researchers used a simple linear regression model to examine the association between blood lead levels and household soil lead levels. The dependent variable is blood lead level (μg/dL), and the independent variable is soil lead level (mg/kg). The regression coefficient is 0.15. What does the coefficient mean for a child's blood lead levels?	The levels increase by 15μg/dL with every 100 mg/kg increase in soil lead level.	
The sensitivity is 80/100 = 80%, The specificity = 90/100 = 90%	"         <div><img src=""quizlet-41mx1xVeHGkxhNZmicwYoQ_m.png"" /></div>         "	
"T-tests (Student's ""t"")"	 Independent t-test<br>- Purpose: tests for differences in the mean<br>between two groups.<br>- Variables: One categorical IV with two levels<br>(Males, Females); one continuous DV.<br> Paired Samples t-test<br>- Purpose: tests for differences in the mean<br>within one group at different times.<br>- Variables: One categorical IV with two levels<br>(Time 1, Time 2); one continuous DV.	
One-Way ANOVA	Purpose: tests for differences in the<br>mean scores on a DV across three or<br>more groups.<br> Variables: One categorical IV with<br>three or more categories; one<br>continuous DV.<br>Note: One-way means one independent variable (IV)	
One-Way ANOVA with Planned Comparisons	Purpose: tests for differences in the<br>mean scores in specific groups within<br>a project (subsets). Useful when<br>power is an issue.<br> Variables: One categorical IV with<br>three or more categories; one<br>continuous DV.	
Two-Way ANOVA	Purpose: tests for differences in the<br>mean scores on a DV across three or<br>more groups.<br> Variables: One categorical IV with<br>three or more categories; one<br>continuous DV.<br>Note: Two-way means two independent variables (IV)	
Mixed Between-Within ANOVA	 Purpose: measures the outcome<br>between groups (males/females) and<br>within groups (repeated measures).<br> Variables: One categorical between<br>groups IV and one categorical within<br>groups IV; one continuous variable.<br>Note: Between = two or more different groups;<br>Within = one group measured two or more times.	
Researchers used an analysis of variance to evaluate the differences in blood pressure among five groups with different alcohol drinking habits. Each group has a sample of n = 10. The analysis produces SS within groups = 210, SS between groups = 340. What is the SS total?	550	
Researchers used an analysis of variance to evaluate the differences in blood pressure among five groups with different alcohol drinking habits. Each group has a sample of n =10. The analysis produces SS within groups = 210, SS between groups = 340. What is the MS within groups?	210 / 45	
Researchers used an analysis of variance to evaluate the differences in blood pressure among five groups with different alcohol drinking habits. Each group has a sample of n = 10. The analysis produces SS within groups = 210, SS between groups = 340. What is the F-value?	F(4, 45) = 18.21	
Researchers used an analysis of variance to evaluate the differences in blood pressure among five groups with different alcohol drinking habits. Each group has a sample of n = 10. The analysis produces SS within groups = 210, SS between groups = 340. What statistical conclusion can we reach if the corresponding p-value is < 0.05?	Reject H0 and conclude that not all group means are equal	
The one-way ANOVA is best used when the measurement scale of the characteristic of interest is Which measurement scale of the characteristic of interest makes the one-way ANOVA the best choice?	interval or ratio	
What does the one-way ANOVA compare to determine whether the means of the groups are different?	Within-group variance to the between-group variance	
When does the one-way ANOVA test tells you?	Whether the mean of one or more groups is different from the others	
When an ANOVA test is significant, what should the researcher do next?	Conduct a post-hoc test to determine which mean(s) are significantly different from the others	
When would an independent samples t-test be used instead of an ANOVA?	When there are only two categories in the grouping variable	
When should nonparametric tests such as the Kruskal-Wallis and the Mann-Whitney U-test should be used?	When the data do not meet the distribution requirements for a parametric test	
What does a calculated value of chi-square compare?	The frequencies of categories of items in a sample to the frequencies that are expected in the population	
The correlation between the variables A and B is .12 with a significance of p < .01. What is true about the relationship between the variables?	There is a small relationship between A and B.	
A researcher identifies a significant positive correlation (r = .42) between the number of children a person has and the person's life satisfaction. Which statement is inappropriate to conclude from this research?	That someone who has children is likely to be happier than someone who doesnot	
Why does practice-based evidence (PBE) require close partnering with informatics specialist? (Choose all that apply.)	To design screens and terms to capture interventions<br>To create and maintain the databases required for PBE studies	
How does practice-based evidence (PBE) differ from evidence-based practice (EBP)?	EBP determines best practices using best evidence such as results from RCTs.<br>PBE is prospective and, EBP is retrospective.<br>PBE attempts to capture the complexity and variability of actual clinical care..	
Which is not a common step in a practice-based evidence study?	Obtain patient consent	
Explain what regularization is and how it works.	Regularization is the process of adding a tuning parameter to a model to induce smoothness in order to prevent overfitting.<br><br>This is most often done by adding a constant multiple to an existing weight vector. This constant is often either the L1 (Lasso) or L2 (ridge), but can in actuality can be any norm. The model predictions should then minimize the mean of the loss function calculated on the regularized training set.	
You created a predictive model for a quantitative outcome variable using multiple regression. How would you validate this model?	Proposed methods for model validation: <br><br>1) If the values predicted by the model are far outside of the response variable range, this would immediately indicate poor estimation or model inaccuracy.<br><br>2) If the values seem to be reasonable, examine the parameters; any of the following would indicate poor estimation or multi-collinearity: opposite signs of expectations, unusually large or small values, or observed inconsistency when the model is fed new data.<br><br>3) Use the model for prediction by feeding it new data, and use the coefficient of determination (R squared) as a model validity measure.<br><br>4) Use data splitting to form a separate dataset for estimating model parameters, and another for validating predictions.<br><br>5) Use jackknife resampling if the dataset contains a small number of instances, and measure validity with R squared and mean squared error (MSE).	
What is Multiple Regression Analysis?	"Multiple regression is an extension of simple linear regression. It is used when we want to predict the value of a variable based on the value of two or more other variables. The variable we want to predict is called the dependent variable (or sometimes, the outcome, target or criterion variable). The variables we are using to predict the value of the dependent variable are called the independent variables (or sometimes, the predictor, explanatory or regressor variables).<br><br>For example, you could use multiple regression to understand whether exam performance can be predicted based on revision time, test anxiety, lecture attendance and gender. Alternately, you could use multiple regression to understand whether daily cigarette consumption can be predicted based on smoking duration, age when started smoking, smoker type, income and gender.<br><br>Multiple regression also allows you to determine the overall fit (variance explained) of the model and the relative contribution of each of the predictors to the total variance explained. For example, you might want to know how much of the variation in exam performance can be explained by revision time, test anxiety, lecture attendance and gender ""as a whole"", but also the ""relative contribution"" of each independent variable in explaining the variance."	
Explain what precision and recall are. How do they relate to the ROC curve?	RECALL (aka SENSITIVITY; aka TRUE POSITIVE RATE) = True positives / (True positives + False negatives)<br><br>PRECISION = True positives / (True positives + False positives)<br><br>FALSE POSITIVE RATE (FPR) = False Positives / (False Positives + True Negatives)<br><br>SPECIFICITY = True negatives/(true negatives + false positives) = 1 - FPR<br><br>ROC curve represents a relation between sensitivity (RECALL) and specificity (NOT PRECISION) and is commonly used to measure the performance of binary classifiers. However, when dealing with highly skewed datasets, Precision-Recall (PR) curves give a more representative picture of performance.	
What is the difference between Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves in the context of Machine Learning?	Receiver Operator Characteristic (ROC)<br>curves are commonly used to present results<br>for binary decision problems in machine<br>learning. However, when dealing<br>with highly skewed datasets, Precision-Recall<br>(PR) curves give a more informative picture<br>of an algorithm's performance.	
Explain type I and type II errors.	In statistics there are type I errors and type II errors. <br><br>Relative to true positive and false positive terminology, a type I error occurs when you reject the null hypothesis (as false) when it is actually true, which by convention corresponds to a false positive. <br><br>A type II error occurs when you accept the null hypothesis (as true) when it is actually false, which by convention corresponds to a false negative.	
Explain the difference between test sensitivity and test specificity in the context of a medical diagnosis.	In medical diagnosis, test sensitivity is the ability of a test to correctly identify those with the disease (true positive rate), whereas test specificity is the ability of the test to correctly identify those without the disease (true negative rate).	
What is root cause analysis?	Root cause analysis (RCA) is a method of problem solving used for identifying the root causes of faults or problems. A factor is considered a root cause if removal thereof from the problem-fault-sequence prevents the final undesirable event from recurring; whereas a causal factor is one that affects an event's outcome, but is not a root cause.	
What is statistical power?	Wikipedia defines Statistical power or sensitivity of a binary hypothesis test is the probability that the test correctly rejects the null hypothesis (H0) when the alternative hypothesis (H1) is true. <br><br>To put in another way, Statistical power is the likelihood that a study will detect an effect when the effect is present. The higher the statistical power, the less likely you are to make a Type II error (concluding there is no effect when, in fact, there is).	
What do you need to calculate statistical power?	Test Value (value to compare the sample average to), Sample Average (value measured from sample or expected from sample), Sample Size (size of sample or desired number of respondents), Standard Deviation for Sample, and Confidence Level (aka p-value or Alpha Error Level; Probability of incorrectly rejecting the null hypothesis that there is no difference in the average values). A p-value of 5% corresponds to a 95% Confidence Interval.	
Explain what resampling methods are and why they are useful. Also explain their limitations.	Classical statistical parametric tests compare observed statistics to theoretical sampling distributions. Resampling a data-driven, not theory-driven methodology which is based upon repeated sampling within the same sample. <br><br>Resampling refers to methods for doing one of these<br>Estimating the precision of sample statistics (medians, variances, percentiles) by using subsets of available data (jackknifing) or drawing randomly with replacement from a set of data points (bootstrapping)<br>Exchanging labels on data points when performing significance tests (permutation tests, also called exact tests, randomization tests, or re-randomization tests)<br>Validating models by using random subsets (bootstrapping, cross validation)	
Is it better to have too many false positives, or too many false negatives? Explain.	It depends on the question as well as on the domain for which we are trying to solve the question. <br><br>In medical testing, false negatives may provide a falsely reassuring message to patients and physicians that disease is absent, when it is actually present. This sometimes leads to inappropriate or inadequate treatment of both the patient and their disease. So, it is desired to have too many false positive. <br><br>For spam filtering, a false positive occurs when spam filtering or spam blocking techniques wrongly classify a legitimate email message as spam and, as a result, interferes with its delivery. While most anti-spam tactics can block or filter a high percentage of unwanted emails, doing so without creating significant false-positive results is a much more demanding task. So, we prefer too many false negatives over many false positives.	
What is selection bias, why is it important and how can you avoid it?	Selection bias, in general, is a problematic situation in which error is introduced due to a non-random population sample. For example, if a given sample of 100 test cases was made up of a 60/20/15/5 split of 4 classes which actually occurred in relatively equal numbers in the population, then a given model may make the false assumption that probability could be the determining predictive factor. Avoiding non-random samples is the best way to deal with bias; however, when this is impractical, techniques such as resampling, boosting, and weighting are strategies which can be introduced to help deal with the situation.	
Explain what is overfitting (aka high variance and low bias) and how would you control for it.	Your model is overfitting your training data when you see that the model performs well on the training data but does not perform well on the evaluation data. This is because the model is memorizing the data it has seen and is unable to generalize to unseen examples.<br><br>If your model is overfitting the training data, it makes sense to take actions that reduce model flexibility. To reduce model flexibility, try the following:<br><br>Feature selection: consider using fewer feature combinations, decrease n-grams size, and decrease the number of numeric attribute bins.<br>Increase the amount of regularization used.	
Explain what is underfitting (aka High Bias) and how would you control for it.	Your model is underfitting the training data when the model performs poorly on the training data. This is because the model is unable to capture the relationship between the input examples (often called X) and the target values (often called Y). <br><br>Poor performance on the training data could be because the model is too simple (the input features are not expressive enough) to describe the target well. Performance can be improved by increasing model flexibility. To increase model flexibility, try the following:<br><br>Add new domain-specific features and more feature Cartesian products, and change the types of feature processing used (e.g., increasing n-grams size)<br>Decrease the amount of regularization used.	
Give an example of how you would use experimental design to answer a question about user behavior.	Step 1: Formulate the Research Question: <br>What are the effects of page load times on user satisfaction ratings? <br><br>Step 2: Identify variables: <br>We identify the cause & effect. Independent variable -page load time, Dependent variable- user satisfaction rating <br><br>Step 3: Generate Hypothesis: <br>Lower page download time will have more effect on the user satisfaction rating for a web page. Here the factor we analyze is page load time. <br><br>Step 4: Determine Experimental Design. <br>We consider experimental complexity i.e vary one factor at a time or multiple factors at one time in which case we use factorial design (2^k design). A design is also selected based on the type of objective (Comparative, Screening, Response surface) & number of factors. <br><br>Here we also identify within-participants, between-participants, and mixed model.For e.g.: There are two versions of a page, one with Buy button (call to action) on left and the other version has this button on the right. <br><br>Within-participants design - both user groups see both versions. <br><br>Between-participants design - one group of users see version A & the other user group version B. <br><br>Step 5: Develop experimental task & procedure: <br>Detailed description of steps involved in the experiment, tools used to measure user behavior, goals and success metrics should be defined. Collect qualitative data about user engagement to allow statistical analysis. <br><br>Step 6: Determine Manipulation & Measurements <br><br>Manipulation: One level of factor will be controlled and the other will be manipulated. We also identify the behavioral measures:<br>Latency- time between a prompt and occurrence of behavior (how long it takes for a user to click buy after being presented with products).<br>Frequency- number of times a behavior occurs (number of times the user clicks on a given page within a time)<br>Duration-length of time a specific behavior lasts(time taken to add all products)<br>Intensity-force with which a behavior occurs ( how quickly the user purchased a product)<br><br>Step 7: Analyze results <br>Identify user behavior data and support the hypothesis or contradict according to the observations made for e.g. how majority of users satisfaction ratings compared with page load times.	
"What is the difference between ""long"" (""tall"") and ""wide"" format data?"	"In most data mining / data science applications there are many more records (rows) than features (columns) - such data is sometimes called ""tall"" (or ""long"") data. <br><br>In some applications like genomics or bioinformatics you may have only a small number of records (patients), eg 100, but perhaps 20,000 observations for each patient. The standard methods that work for ""tall"" data will lead to overfitting the data, so special approaches are needed. <br><br>The problem is not just reshaping the data, but avoiding false positives by reducing the number of features to find most relevant ones."	
How would you screen for outliers and what should you do if you find one?	"Inter Quartile Range <br><br>An outlier is a point of data that lies over 1.5 IQRs below the first quartile (Q1) or above third quartile (Q3) in a given data set.<br><br>High = (Q3) + 1.5 IQR<br>Low = (Q1) - 1.5 IQR<br><br>When you find outliers, you should not remove it without a qualitative assessment because that way you are altering the data and making it no longer pure. It is important to understand the context of analysis or importantly ""The Why question - Why an outlier is different from other data points?"" <br><br>This reason is critical. If outliers are attributed to error, you may throw it out but if they signify a new trend, pattern or reveal a valuable insight into the data you should retain it."	
What is a recommendation engine? How does it work?	They typically produce recommendations in one of two ways: using collaborative or content-based filtering. <br><br>Collaborative filtering methods build a model based on users past behavior (items previously purchased, movies viewed and rated, etc) and use decisions made by current and other users. This model is then used to predict items (or ratings for items) that the user may be interested in. <br><br>Content-based filtering methods use features of an item to recommend additional items with similar properties. These approaches are often combined in Hybrid Recommender Systems.	
"The data scientists at ""BigMart Inc"" have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product based on these attributes and store have been defined. The aim is to build a predictive model and find out the sales of each product at a particular store during a defined period.  Which learning problem does this belong to?  A) Supervised learning B) Unsupervised learning C) Reinforcement learning D) None"	Solution: A<br><br>Supervised learning is the machine learning task of inferring a function from labeled training data. Here historical sales data is our training data and it contains the labels / outcomes.	
What is RMSE?	The root-mean-square error (RMSE) is a measure of the differences between values predicted by a model or an estimator and the values actually observed.<br><br>RMSE is used to evaluate regression models. The lower the RMSE, the better the model.<br><br>The formula is :<br><br>rmse = (sqrt(sum(square(predicted_values - actual_values)) / number of observations))	
Which methodology does Decision Tree take to decide on first split?  A) Greedy approach B) Look-ahead approach C) Brute force approach D) None of these	Solution: A<br><br>The process of top-down induction of decision trees (TDIDT) is an example of a greedy algorithm, and it is by far the most common strategy for learning decision trees from data.	
There are 24 predictors in a dataset. You build 2 models on the dataset:  1. Bagged decision trees and 2. Random forest  Let the number of predictors used at a single split in bagged decision tree is A and Random Forest is B.  Which of the following statement is correct?  A) A >= B B) A < B C) A >> B D) Cannot be said since different iterations use different numbers of predictors	Solution: A <br><br>Random Forest uses a subset of predictors for model building, whereas bagged trees use all the features at once.	
Why do we prefer information gain over accuracy when splitting?  A) Decision Tree is prone to overfit and accuracy doesn't help to generalize B) Information gain is more stable as compared to accuracy C) Information gain chooses more impactful features closer to root D) All of these	Solution: D<br><br>All the above options are correct	
Random forests (While solving a regression problem) have the higher variance of predicted result in comparison to Boosted Trees (Assumption: both Random Forest and Boosted Tree are fully optimized).  A) True B) False C) Cannot be determined	Solution: C<br><br>It completely depends on the data, the assumption cannot be made without data.	
Assume everything else remains same, which of the following is the right statement about the predictions from decision tree in comparison with predictions from Random Forest?  A) Lower Variance, Lower Bias B) Lower Variance, Higher Bias C) Higher Variance, Higher Bias D) Lower Bias, Higher Variance	Solution: D<br><br>The predicted values in Decision Trees have low Bias but high Variance when compared to Random Forests. This is because random forest attempts to reduce variance by bootstrap aggregation.	
Which of the following tree based algorithm uses some parallel (full or partial) implementation?  A) Random Forest B) Gradient Boosted Trees C) XGBOOST D) Both A and C E) A, B and C	Solution: D<br><br>Only Random Forest and XGBoost have parallel implementations.<br><br>Random Forest is very easy to parallelize, where as XGBoost can have partially parallel implementation. In Random Forest, all trees grows parallel and finally ensemble the output of each tree .<br><br>Xgboost doesn't run multiple trees in parallel like Random Forest, you need predictions after each tree to update gradients. Rather it does the parallelization WITHIN a single tree to create branches independently.	
Which of the following is not possible in a boosting algorithm?  A) Increase in training error. B) Decrease in training error C) Increase in testing error D) Decrease in testing error E) Any of the above	Solution: A<br><br>Boosted algorithms minimize error in previously predicted values by last estimator. So it always decreases training error.	
Let's say we have m numbers of estimators (trees) in a boosted tree. Now, how many intermediate trees will work on modified version (OR weighted) of data set?  A) 1 B) m-1 C) m D) Can't say E) None of the above	Solution: B<br><br>The first tree in boosted trees works on the original data, whereas all the rest work on modified version of the data.	
What is Bias and Variance Tradeoff?	Conceptual Definition<br><br>Error due to Bias: The error due to bias is taken as the difference between the expected (or average) prediction of our model and the correct value which we are trying to predict. Of course you only have one model so talking about expected or average prediction values might seem a little strange. However, imagine you could repeat the whole model building process more than once: each time you gather new data and run a new analysis creating a new model. Due to randomness in the underlying data sets, the resulting models will have a range of predictions. Bias measures how far off in general these models' predictions are from the correct value.<br><br>Error due to Variance: The error due to variance is taken as the variability of a model prediction for a given data point. Again, imagine you can repeat the entire model building process multiple times. The variance is how much the predictions for a given point vary between different realizations of the model.	
Boosting is a general approach that can be applied to many statistical learning methods for regression or classification.   A) True B) False	Solution: A<br><br>Boosting is an ensemble technique and can be applied to various base algorithms.	
Generally, in terms of prediction performance from highest to lowest, which of the following arrangements are correct:  A) Bagging>Boosting>Random Forest>Single Tree B) Boosting>Random Forest>Single Tree>Bagging C) Boosting>Random Forest>Bagging>Single Tree D) Boosting >Bagging>Random Forest>Single Tree	Solution: C<br><br>Generally speaking, Boosting algorithms will perform better than bagging algorithms. In terms of bagging vs random forest, random forest works better in practice because random forest has less correlated trees compared to bagging. And it's always true that ensembles of algorithms are better than single models	
In which of the following application(s), a tree based algorithm can be applied successfully?  A) Recognizing moving hand gestures in real time B) Predicting next move in a chess game C) Predicting sales values of a company based on their past sales D) A and B E) A, B, and C	Solution: E<br><br>Option E is correct as we can apply tree based algorithm in all the 3 scenarios.	
Boosting is said to be a good classifier because:  A) It creates all ensemble members in parallel, so their diversity can be boosted. B) It attempts to minimize the margin distribution C) It attempts to maximize the margins on the training data D) None of these	Solution: B<br><br>A. Trees are sequential in boosting. They are not parallel<br><br>B. Boosting attempts to minimize residual error which reduces margin distribution<br><br>C. As we saw in B, margins are minimized and not maximized.<br><br>Therefore B is true	
What is cardinality in database?	"In the context of databases, cardinality refers to the uniqueness of data values contained in a column. High cardinality means that the column contains a large percentage of totally unique values. For example, high-cardinality column values are typically identification numbers, email addresses, or user names. <br><br>Low cardinality means that the column contains a lot of ""repeats"" in its data range."	
Which splitting algorithm is better with categorical variable having high cardinality?  A) Information Gain B) Gain Ratio C) Change in Variance D) None of these	Solution: B<br><br>When high cardinality problems, gain ratio is preferred over any other splitting technique.	
Suppose we have missing values in our data. Which of the following method(s) can help us to deal with missing values while building a decision tree?  A) Let it be. Decision Trees are not affected by missing values B) Fill dummy value in place of missing, such as -1 C) Impute missing value with mean/median D) All of these	Solution: D<br><br>All the options are correct.	
To reduce under fitting of a Random Forest model, which of the following method can be used?  A) Increase minimum sample leaf value B) increase depth of trees C) Increase the value of minimum samples to split D) None of these	Solution: B<br><br>Only option B is correct, because<br><br>A: increasing the number of samples for a leaf will reduce the depth of a tree, indirectly increasing underfitting<br><br>B: Increasing depth will definitely decrease help reduce underfitting<br><br>C: increasing the number of samples considered to split will have no effect, as the same information will be given to the model.	
While creating a Decision Tree, can we reuse a feature to split a node?  A) Yes B) No	Solution: A<br><br>Yes, decision tree recursively uses all the features at each node.	
Which of the following is a mandatory data pre-processing step(s) for XGBOOST?  A) Impute Missing Values B) Remove Outliers C) Convert data to numeric array / sparse matrix D) Input variable must have normal distribution E) Select the sample of records for each tree/ estimators	Solution: C<br><br>XGBoost is doesn't require most of the pre-processing steps, so only converting data to numeric is required among of the above listed steps	
Decision Trees are not affected by multicollinearity in features:  A) TRUE B) FALSE	Solution: A<br><br>The statement is true. For example, if there are two 90% correlated features, decision tree would consider only one of them for splitting.	
For parameter tuning in a boosting algorithm, which of the following search strategies may give best tuned model:  A) Random Search. B) Grid Search. C) A or B D) Can't say	Solution: C<br><br>For a a given search space,<br><br>Random search randomly picks out hyperparameters. In terms of time required, random search requires much less time to converge.<br>Grid search deterministically tries to find optimum hyperparameters. This is a brute force approach for solving a problem, and requires much time to give output.<br>Both random search or grid search may give best tuned model. It depends on how much time and resources can be allocated for search.	
Imagine a two variable predictor space having 10 data points. A decision tree is built over it with 5 leaf nodes. The number of distinct regions that will be formed in predictors space?  A) 25 B) 10 C) 2 D) 5	Solution: D<br><br>The predictor space will be divided into 5 regions. Therefore, option D is correct.	
In Random Forest, which of the following is randomly selected?  A) Number of decision trees B) Features to be taken into account when building a tree C) Samples to be given to train individual tree in a forest D) B and C E) A, B and C	Solution: D<br><br>Option A is False because the number of trees has to be decided when building a tree. It is not random.<br><br>Options B and C are true	
Which of the following are the disadvantage of Decision Tree algorithm?  A) Decision tree is not easy to interpret B) Decision tree is not a very stable algorithm C) Decision Tree will over fit the data easily if it perfectly memorizes it D) Both B and C	Solution: D<br><br>Option A is False, as decision tree are very easy to interpret<br><br>Option B is True, as decision tree are high unstable models<br><br>Option C is True, as decision tree also tries to memorize noise.	
"While tuning the parameters ""Number of estimators"" and ""Shrinkage Parameter""/""Learning Rate"" for boosting algorithm.Which of the following relationship should be kept in mind?  A) Number of estimators is directly proportional to shrinkage parameter B) Number of estimators is inversely proportional to shrinkage parameter C) Both have polynomial relationship"	Solution: B<br><br>It is generally seen that smaller learning rates require more trees to be added to the model and vice versa. So when tuning parameters of boosting algorithm, there is a trade-off between learning rate and number of estimators.	
Let's say we have m number of estimators (trees) in a XGBOOST model. Now, how many trees will work on bootstrapped data set?  A) 1 B) m-1 C) m D) Can't say E) None of the above	Solution: C<br><br>All the trees in XGBoost will work on bootstrapped data. Therefore, option C is true.	
Which of the following statements is correct about XGBOOST parameters (may be more than one):  A) Learning rate can go upto 10 B) Sub Sampling / Row Sampling percentage should lie between 0 to 1 C) Number of trees / estimators can be 1 D) Max depth can not be greater than 10	Solution: B and C<br><br>A and D are wrong statements, whereas B and C are correct.	
Predictions of individual trees of bagged decision trees have higher correlation in comparison to individual trees of random forest.  A) TRUE B) FALSE	Solution: B<br><br>This is False because random Forest has more randomly generated uncorrelated trees than bagged decision trees. Random Forest considers only a subset of total features. So individual trees that are generated by random forest may have different feature subsets. This is not true for bagged trees.	
Below is a list of parameters of Decision Tree. In which of the following cases higher is better?  A) Number of samples used for split B) Depth of tree C) Samples for leaf D) Can't Say	"Solution: D<br><br>For all three options A, B and C, it is not necessary that if you increase the value of parameter the performance may increase. For example, if we have a very high value of depth of tree, the resulting tree may overfit the data, and would not generalize well. On the other hand, if we have a very low value, the tree may underfit the data. So, we can't say for sure that ""higher is better""."	
When do we use the One Sample T-Test?	To examine the average difference between a sample and the known value<br>of the population mean.	
What are the assumptions of a One Sample T-Test?	- The population from which the sample is drawn is normally distributed.<br>- Sample observations are randomly drawn and independent.	
"What type of test do you use for ""You are told that the average height of a person in your building (ᶞ) is 68 inches; however, you think the average person is actually much taller."""	One sample T-test. For this scenario:<br>➢ Null Hypothesis (H0<br>): ᶞ = 68 inches<br>➢ Alternative Hypothesis (HA<br>): ᶞ > 68 inches	
When do we use the the Two sample T test?	To examine the average difference between two samples drawn from two<br>different populations.	
What are the assumptions of the two sample t-test?	➢ The populations from which the samples are drawn are normally dist.<br>➢ The standard deviations of the two populations are equal.<br>➢ Sample observations are randomly drawn and independent.	
"What test should you use for the following problem, ""Although the difficulty of the SAT should not vary across its different administrations, you believe that timing is everything; you suppose that there is a difference in the average score from tests taken in spring and fall."" ?"	Two Sample T-Test. For this scenario:<br>➢ Null Hypothesis (H0<br>): ᶞSpring = ᶞFall<br>➢ Alternative Hypothesis (HA<br>): ᶞSpring ≠ Fall	
When do we use the F-Test?	To assess whether the variances of two different populations are equal	
What are the assumption of the F-Test?	Assumptions:<br>➢ The populations from which the samples are drawn are normally dist.<br>➢ Sample observations are randomly drawn and independent.	
"What test should you apply to the following problem: ""When we tested the difficulty of SAT exams in the previous example using the Two Sample T-Test, we should have had equal variances; however, the variances were slightly different. Were they significantly different?"""	For this scenario:<br>Null Hypothesis<br>Spring SD =<br>Fall SD<br><br>Alternative Hypothesis (HA)<br>Spring SD ≠ Fall SD	
When do we use One-Way ANOVA?	To assess the equality of means of two or more groups. NB: When there are<br>exactly two groups, this is equivalent to a Two Sample T-Test	
What are the assumptions of a One-Way ANOVA?	➢The populations from which the samples are drawn are normally dist.<br>➢ The standard deviations of the populations are equal.<br>➢ Sample observations are randomly drawn and independent	
"What test should be applied to the following problem, ""You desire to test the efficacy of different types of diets on weight loss: low calorie, low carbohydrate, and low fat. You also have a control group for comparison purposes."""	One-Way ANOVA. Null Hypothesis (H0<br>): ᶞLow Calorie = ᶞLow Carbohydrate = ᶞLow Fat = ᶞControl<br>➢ Alternative Hypothesis (HA<br>): At least one of the average amounts of weight<br>loss differs from the others.	
When do we use the chi-square  Test of Independence?	To test whether two categorical variables are independent.	
What are the assumptions of a chi-square test?	Sample observations are randomly drawn and independent	
"What test should you apply to following problem? ""A review session was held before a quiz was administered to a class of students. You would like to determine whether a student's grade on the quiz is dependent on whether or not they attended the review session."""	For this scenario:<br>➢ Null Hypothesis (H0<br>): The two variables are independent of one another.<br>➢ Alternative Hypothesis (HA<br>): The two variables are dependent on each other	
What is machine learning?	"Machine learning developed from the combination of statistics and computer<br>science; it aims to implement algorithms that allow computers to ""learn"" about<br>the data it analyzes.<br><br>Traditional algorithms require computers to follow a strict set of program<br>instructions; machine learning algorithms instead assess the data at hand to<br>make informed decisions.<br><br>Machine learning algorithms have the ability to learn and adapt; traditional<br>algorithms do not."	
What is supervised learning?	"Your data includes the ""truth"" that you wish to predict.<br>➢ Use what you know about your observations to construct a model for future<br>decision making.<br>■ Regression<br>■ Classification"	
What is unsupervised learning?	"Your data does not include the ""truth"" that you wish to predict.<br>➢ Use your data to find underlying structure to inform intrinsic behavior that is<br>not already explicitly available.<br>■ Clustering<br>■ Dimension Reduction"	
What is missing data?	"Missingness occurs when at least some of an observation's values are not present<br>within the dataset. We say that the absent values are ""missing,"" and that the<br>observation itself is ""incomplete."""	
Why does missing data matter?	Many statistical methods and machine learning techniques have difficulty<br>incorporating incomplete observations in their algorithms; they simply don't<br>know what to do when there isn't any data to crunch!	
What's wrong with deleting missing values?	While the solution of complete-case analysis seems to be the quickest and<br>easiest on the surface, it can severely limit the amount of information<br>available for our tests.<br>➢ With fewer observations in our dataset we have a smaller sample size,<br>increasing the standard errors of any estimates we make.	
What are the three types of missing data?	There are three main types of missingness:<br>➢ Missing Completely at Random (MCAR)<br>➢ Missing at Random (MAR)<br>➢ Missing Not at Random (MNAR)	
What is missing completely at random?	"each piece of data in the overall<br>dataset has an equally likely chance of being absent.<br>➢ The reason for the missingness is neither related to the observed variables<br>nor related to the unobserved variables of interest; they are independent.<br><br>MCAR data is the best case scenario for missing data in general, because its<br>manifestation is truly ""completely at random""; unfortunately, data that is MCAR<br>is also often the rarest form of missing data.<br><br>❖ When data are MCAR, it is ok to ignore these observations; their deletion will not<br>end up biasing your results because there is no underlying pattern that they<br>reveal."	
What type of missing data are the following examples?   1) You write a survey with 99 questions and distribute it to everyone in your office. You randomly select a few people to answer an additional 100th question. 2) A piece of lab equipment is supposed to take a measurement on each specimen that it encounters. For one arbitrary specimen, the equipment malfunctions and the measurement is not recorded.	Missing completely at random	
What is missing at random data?	When data are missing at random, the chance that a piece of data is missing is<br>dependent on variables for which we have complete information within our<br>overall dataset.<br>➢ The probability a piece of data is missing depends on available information<br>that we have already collected; they are not independent.<br>❖ MAR is the next-best scenario for missing data after MCAR because, although<br>each observation has a different likelihood of missing, we theoretically can<br>estimate this likelihood.<br>❖ When data are MAR, it is acceptable to drop these observations from our analysis<br>if we control for the factors that are related to the missingness and adjust for<br>their effects, we can avoid bias in our model.	
What is the type of missing data in the following examples:  1) You write a survey and ask both men and women to submit responses. In the survey, there is a section that asks questions about various sports teams. The women you surveyed are more likely to not respond to the sports-related questions. 2) A photocopier takes a log of the amount of copies it is supposed to make, and the amount of ink it uses for each job. For particularly large amounts of copies, the machine has a higher chance of malfunctioning and thus not recording the amount of ink it used for the job.	missing at random data	
What is missing not at random data?	When data are missing not at random, the chance that a piece of data is missing<br>is dependent on the actual value of the observation itself.<br>➢ The value of the missing piece of data is directly related to the reason why it<br>is missing in the first place.<br>❖ MNAR is the worst-case scenario for missing data because it is non-ignorable. We<br>cannot theoretically accurately estimate the missing values because the reason<br>they are missing is not captured within our dataset.<br>❖ When data are MNAR, it is not appropriate to drop these observations from our<br>analysis; doing so would leave us with a biased dataset, and thus our analyses<br>would return biased models.	
What do the following examples of data match?  1) You write a survey and ask individuals to report their weight. Individuals who are particularly overweight tend to not answer this question 2) A scale is supposed to measure the weight of various items, but is not sensitive enough to detect weights that are less than 5 pounds, and thus does not record weights for such items.	Missing not at random data	
What is mean value imputation?	Mean value imputation procedure:<br>➢ Compute the average of the observed values for a variable that has<br>missingness.<br>➢ Impute the average for each of the missing values.<br>❖ Advantages:<br>➢ One of the simplest ways of dealing with missing data because of its<br>relatively straightforward approach.<br>❖ Disadvantages:<br>➢ Can distort the distribution of the variable and underestimate the standard<br>deviation.<br>➢ Can distort relationships between variables by dragging correlation<br>estimates towards 0	
What is simple random imputation?	Simple random imputation procedure:<br>➢ For each missing value in a variable, randomly select a complete value of the<br>same variable; impute this randomly selected value.<br>➢ Repeat the process until all values are complete.<br>❖ Advantages:<br>➢ Uses true, observed values to fill in missingness.<br>❖ Disadvantages:<br>➢ Can amplify outlier observation values by having them repeat in the dataset.<br>➢ Can induce bias into the dataset	
What is regression imputation?	❖ Regression prediction procedure:<br>➢ Assume an underlying, linear structure exists in the data.<br>➢ Give weights to a subset of the complete variables.<br>➢ Use a relationship between the complete variables and the complete<br>observations to impute missing observations.<br>❖ Advantages:<br>➢ Uses true, observed values to fill in missingness.<br>➢ Uses the relationships among multiple variables to fill in missingness.<br>❖ Disadvantages:<br>➢ Must make assumptions about the structure of the data.<br>➢ Can inappropriately extrapolate beyond the scope of available information<br>in our dataset.	
Common error types	1. TypeError<br>2. NameError<br>3. ValueError	
Key Error	Error for when something can't be found in a dictionary	
Name Error	Error for problems related to variable names	
Type Error	Error for problems related to data types	
Levels of logging (5)	1. Debug<br>2. Info<br>3. Warning<br>4. Error<br>5. Critical	
Debug (logging)	Notes for you, while working on code	
Info (logging)	Notes that everything is going OK	
Warning (logging)	Something seems wrong but not urgent	
Error (logging)	Something did not work	
Critical (logging)	Entire program stopped running	
Benefits of making errors (2)	1. Makes debugging easier<br>2. Can be dealt with programatically	
Complexity	- Provides information on the how quickly your code will run<br>- Defined by the number of nested for loops	
Cross-validation	Model validation technique for assessing how the results of a statistical analysis will generalize to an independent data set	
Common types of cross-validation	- Leave one out<br>- Train test split<br>- K-fold	
import this (15)	1. Beautiful is better than ugly.<br>2. Explicit is better than implicit.<br>3. Simple is better than complex.<br>4. Complex is better than complicated.<br>5. Flat is better than nested.<br>6. Sparse is better than dense.<br>7. Readability counts.<br>8. Special cases aren't special enough to break the rules.<br>9. Practicality beats purity.<br>10. Errors should never pass silently. Unless explicitly silenced.<br>11. In the face of ambiguity, refuse the temptation to guess.<br>12. There should be one-- and preferably only one --obvious way to do it.<br>13. If the implementation is hard to explain, it's a bad idea.<br>14. If the implementation is easy to explain, it may be a good idea.<br>15. Namespaces are one honking great idea -- let's do more of those!	
Pandas Data Structures (3)	1. Series<br>2. DataFrame<br>3. Panel	
Series	1D array	
DataFrame	2D labeled data structure	
Panel	3D labeled data structure	
Type I Error	- False positive<br>- Reject null even though it's true	
Power	Probability of not making a type II error	
Type II Error	- Fail to reject the null even though it's false	
Machine Learning	Branch of AI concerned with the construction and study of systems that can learn from data	
Facets of machine learning (2)	1. Representation<br>2. Generalization	
Representation (ML)	Extracting structure from data	
Generalization (ML)	Making predictions from data	
Types of learning (2)	1. Supervised<br>2. Unsupervised	
Supervised learning	Learning from labeled data; aimed at generalizing/predicting	
Types of supervised learning techniques		
Unsupervised learning	Learning from unlabeled data; aimed at extracting structure	
Types of unsupervised learning techniques (2)	1. Clustering<br>2. Natural Language Processing	
Supervised/Continuous	Regression	
Supervised/Categorical	Classification	
Unsupervised/Continuous	Dimension Reduction	
Unsupervised/Categorical	Clustering	
Vector space	Feature space that data live	
Record	A single point in a vector space	
Other names for model inputs (6)	1. Features<br>2. Attributes<br>3. Predictors<br>4. Inputs<br>5. IVs<br>6. Dimensions	
Other names for model outputs (5)	1. Target<br>2. Response<br>3. Output<br>4. DV<br>5. Labels	
Other names for a row of data (4)	1. Observation<br>2. Datapoint<br>3. Record<br>4. Row	
Labels	Values on target values in supervised learning	
Feature engineering	The art of using your inputs in unique ways	
Linear model (equation)	yi = B0 + B1X + Ei	
Parameters (linear regression)		
Cost function (equation)		
Cost function	Minimize the distance between what your line predicted for each point and what was actually observed	
Goal of linear regression	Minimize the cost function to find the best fitting model	
Errors v. model complexity graph		
Convergence graph (cross-validation)		
Types of probability (2)	1. Discrete<br>2. Continuous	
Probability	The study of theoretical possibilities and their likelihood of occurring	
Bayes theorem	P(B) = P(B|A)P(A) - P(B|~A)P(~A); related to conditional probabilities of two events	
Random variable	Function mapping between all real numbers and the numbers between 0 and 1	
Expected value	The weighted average of the numerical outcomes of a probability experiment	
Discrete random variable	When there are only finitely many values obtained by your variable	
Law of large numbers	The average value of a large number of independent samples of a random variable X get arbitration close to its expected value	
Continuous random variable	Random variable that attains a continuum of values	
Properties of a gaussian distribution	1. Normally distributed<br>2. Centered around mean	
Properties of log gaussian distribution		
Properties of exponential distribution		
Properties of poisson distribution		
Central limit theorem	If we have a lot of small independent things happening with no bias, then their cumulative effect will be given by something very close to a normal distribution	
AIC (equation)	2k - 2ln(L)	
Regularization	Used to prevent under/overfitting; penalizes model complexity while awarding for goodness of fit	
Ridge regularization (equation)	Lambda SUM of B^2	
Ridge regularization (L2)	Decreases model complexity by penalizing the cost function by forcing down the importance of each of the variables	
Lasso regularization (L1)	Decreases model complexity by penalizing the cost function by essentially elimination (forcing to near-zero) the unimportant variables	
Elastic net regularization	Combination of L1 & L2	
Lasso regularization (equation)	Lambda SUM of |B|	
Lambda (underfitting)	High	
Lambda (overfitting)	Low	
R squared equation		
SSE	Randomness left in the model	
SST	Variation in the data	
R squared	Portion of variation explained by the model	
Null hypothesis	Modeled by setting all Bs to zero; linear relationship found is purely due to chance	
P-value	Probability of finding the observed value results when the null hypothesis is true	
Log likelihood	Cost function	
Bias-variance tradeoff	- A way of thinking about overfitting<br>- Both are measures of what would happen if you retrained your model many times on different sets of training data<br>- Holding model complexity constant, the more data you have the harder it is to overfit	
High bias	- Makes a lot of mistakes for pretty much any training set<br>- Add more features	
Improving high variance	- Remove features<br>- Obtain more data	
High bias/low variance	Underfitting	
Low bias/high variance	Overfitting	
Ways to improve confidence (3)	1. Decrease confidence<br>2. Be biased<br>3. Increase sample size	
Student t-distribution		
Linear Regression Assumptions (5)	1. Regression is linear in parameters and correctly specified<br>2. Errors are normally distributed<br>3. Errors have constant variance (no heteroskedasticity)<br>4. Errors are uncorrelated<br>5. No multi-collinearity	
Auto-regressive models	Regression where one or more previously observed target values is used as a feature	
AR-1	One previous point is among the features	
AR-2	Two previous points as features	
KNN	Classification technique that uses k nearest neighbors to predict what the new point will be	
Decision Boundaries		
KNN Assumptions (2)	1. Notion of distance<br>2. Assumption that points that are close to one another are similar	
Curse of dimensionality	High dimensional spaces are vast, thus points in these spaces tend not to be close to one another making classification difficult	
KNN Benefits	1. Fits fast<br>2. Low complexity	
KNN Pitfalls	1. Lazy<br>2. Predicts slow<br>3. Requires a lot of memory	
Models that require scaling	1. KNN<br>2. SVM	
Logistic regression (equation)		
Logistic regression (graph)		
Odds (equation)		
Log Odds (equation)		
Logistic Function (equation)		
Classification methods using 1 v all	1. Logistic Regression	
Classification metrics (5)	1. Accuracy<br>2. Precision<br>3. Recall (Sensitivity)<br>4. F1 Score<br>5. Specificity	
Recall (Sensitivity) (equation)	TP / (TP + FN)	
Precision (equation)	TP / (TP + FP)	
Specificity (equation)	TN / (TN + FP)	
Accuracy (equation)	(TP + TN) / (TP + TN + FP + FN)	
Precision	Out of all the cases predicted positive, how many times was I right?	
Recall	Out of all the positive cases, how many did I find?	
F1 score	Harmonic mean of precision and recall	
F1 score (equation)	(2 X Precision X recall) / (Precision + recall)	
Receiver Operating Characteristic (lower threshold)	- Better at catching positives<br>- Higher recall / less precision<br>- Higher true positive rate<br>- Higher false positive rate	
Receiver Operating Characteristic (higher threshold)	- More sure about positives<br>- Lower recall / more precision<br>- Lower true positive rate<br>- Lower false positive rate	
AUC	Evaluation of classification algorithms	
Types of classifiers ()	1. KNN<br>2. Logistic Regression<br>3. SVM<br>4. Decision Trees<br>5. Random Forests	
Support Vector Machines (3)	1. Linear classifier<br>2. Geometrically motivated<br>3. Originally proposed for binary classes but has been extended to multi-class	
SVM Decision Boundary (equation)	wTx + b = 0	
How do SVMs work?	Find optimal separating hyperplane that has the maximum margin	
Margin (SVM)	Distance between the closest points to the separator; no points inside margin	
Support vectors	Subset of your data closest to decision boundary; they define the hyperplane; rest of points are essentially irrelevant	
SVM mathematically ***	Maximize d= 2/||w||; minimize wTw	
Slack variables	Can be added to SVM if training set is not linearly separable; allow for misclassification of difficult or noisy samples with a resulting soft margin	
Soft margin (equation)	wTw + slack variable	
Non-linear SVMs	Useful for classifying when the data is in higher-dimensional space or is not linear	
Kernel trick	Function that, given two vectors, implicitly computes the dot product between them in a higher dimensional space without explicitly transforming them	
Kernel function	Function that is equivalent to an inner product in some feature space; can efficiently learn nonlinear decision boundaries by replacing all dot products in SVM computation with kerbnels	
How to choose a kernel? (3)	1. Choosing correct kernel is non-trivial and may depend on specific task/dataset at hand<br>2. Kernels still need to be tuned to get good performance from classifier<br>3. Popular tuning technique: K-Fold Cross Validation	
How did you choose parameters for RBF kernel?	- C<br>- Gamma	
What model for: a lot of features and small data	- Simple model<br>- Linear Regression<br>- LinearSVC	
What model for: few features, decent data	- Gaussian Kernel SVC	
What model for: few features, lots of data	- Linear Regression<br>- Linear SVC<br>- Gaussian kernel SVC too slow	
Decision Trees	- Uses a tree structure to represent a number of possible decision paths and an outcome for each path<br>- Each inner node is a decision based on a feature<br>- Each leaf node is a predicted value	
Decision Tree advantages (3)	1. Easy to understand and interpret<br>2. Both numerical and categorical features can be used naturally<br>2. Natural multiclass classifier	
Decision Tree Disadvantages (4)	1. Can overfit to training data with complex trees<br>2. Small changes in input data can result in completely different trees<br>3. Can make mistakes with unbalanced classes<br>4. No confidence intervals	
Decision tree steps (2)	1. Build tree split by split<br>2. Find best split you can at each step (entropy)	
Entropy	Uncertainty associated with data	
When is entropy small?	- When every p is close to 0 or 1 - Most of data in single class	
When is entropy large?	When many of the p's are not close to 0 <br>- Data spread across multiple classes	
Entropy (equation)	H(S) = -p1 log2 p1 - ... pn log2 pn	
Entropy (drawing)		
Prune (decision trees)		
Ensemble methods (decision trees)		
Bagging	- Bootstrap aggregating<br>- Fits a model to each random set of data<br>- Each model has one vote, choose max vote	
Random forests	- Introduce randomness when building each tree<br>- Don't take best feature split<br>- Randomly choose sqrt(n_feat) features<br>- Choose best split among those	
Prior	Initial belief	
Naive Bayes assumption	Assume each feature is independent	
Types of Naive Bayes ()	1. Multinomial<br>2. Binomial<br>3. Gaussian<br>4. Bernoulli	
Gradient descent	Start with cost function and take steps in opposite direction of gradient vector towards minimum	
Gradient descent - problems with local minima	May run into the issue that you reach a local minimum and get stuck	
Gradient descent - problems with step size too high	May get stuck and can't actually find global minimum	
Types of gradient descent (3)	1. Traditional<br>2. Stochastic<br>3. Batch	
Benefits of SGD (3)	1. Faster - only take derivative of a single point at each step<br>2. Online training - only need to keep single point in memory<br>3. Covers many algorithms	
SVM	hinge loss	
What is batch gradient descent typically used for?	Neural nets	
Perceptron	Simplest neural net approximating a single neuron with n binary inputs	
Feed forward neural network	- Entails an input layer which receives inputs and feeds them forward unchanged	
Hidden layers	- Each consists of neurons that take the outputs of the previous layer, performs a calculation, and passes the result to the next layer, and an output layer	
Neuron	Part of neural network with weight attached to each input and a bias	
Bias (NN)	- Added to ends of weights<br>- Input always equals 1	
Feed forward neural net		
Backpropagation steps (5)	1. Run feed forward net on an input vector to produce the outputs of all the neurons in the network<br>2. This results in an error for each output neuron -- the difference between its output and target<br>3. Compute the gradient of this error as a function of the neuron's weights, and adjust its weights in the direction that most decreases the error<br>4. Propagate these output errors backward to infer error for the hidden layer<br>5. Compute the gradients of these errors and adjust the hidden layer's weights in the same manner	
Likelihood	Function of a parameter for a fixed outcome after data is available	
Likelihood (equation)	L (B|y) p (y|B)	
Likelihood cost function (equation)	L (B|y) = PIp(yi|B)	
Maximum Likelihood (equation)		
MLE steps (3)	1. Write down likelihood<br>2. Take natural log and simplify<br>3. Maximize	
Information gain ***		
Maximum likelihood***		
Model:	A simplified representation of reality created to serve a purpose	
Predictive Model:	A formula for estimating the unknown value of interest: the target - <br>The formula can be mathematical, logical statement (e.g., rule), etc	
Prediction:	Estimate an unknown value (i.e. the target)	
Instance / example:	Represents a fact or a data point<br>Described by a set of attributes (fields, columns, variables, or features)	
Model induction:	The creation of models from data	
Training data:	The input data for the induction algorithm<br>aka: in-sample data	
Test data:	Used ONCE to test the results of the training and assess suitability for use. (Also useful for robustness checking - aka: out-of-sample data)	
Model Feature Type - Numeric:	Anything that has some order	
Model Feature Type - Categorical	Stuff that does not have an order	
Dimensionality of a dataset	Sum of the dimensions of the features	
Common Data Mining Task - Classification and Class probability estimation	How likely is this consumer to respond to our campaign?	
Common Data Mining Task - Regression	How much will she use the service?	
Common Data Mining Task - Similarity Matching	Can we find consumers similar to my best customers?	
Common Data Mining Task - Clustering	Do my customers form natural groups?	
Common Data Mining Task - Co-occurrence Grouping	Also known as frequent itemset mining, association rule discovery, and market-basket analysis<br>What items are commonly purchased together?	
Common Data Mining Task - Profiling (behaviour description)	"What does ""normal behavior"" look like? (for example, as baseline to detect fraud)"	
Common Data Mining Task - Data Reduction	Which latent dimensions describe the consumer taste preferences?	
Common Data Mining Task - Link Prediction	Since John and Jane share 2 friends, should John become Jane's friend?	
Common Data Mining Task - Causal Modeling	Why are my customers leaving :( ?	
Supervised Methods	Classification, Regression, Causal Modeling, Similarity Matching, Link Prediction, Data Reductuin	
UnSupervised Methods	Profiling, Co-occurence Grouping, Clustering, Data Reduction, Link Prediction, Similarity Matching	
Data Scientist:	= Part Hacker + Part Technologist + Part Detective + Part Scientist + Part Business Analyst + Part Visual Artist	
Statistical Inference	Methods for drawing conclusions about a population from sample data	
Information Gain	The Measure of change in entropy due to any amount of new infromation being added	
Entropy	The Measure of Impurity in the data, lower to 0 the better	
Data Format: CSV	Comma Delimited Files	
Data Format: JSON	JavaScript Object Notation	
Data Format: XMl	eXtensible Markup Language	
Data Format: HTML	Hyper Text Markup Language	
API:	Application Programming Interface	
Sources of Error in Data	Data entry errors (e.g., telephone call centers)<br>Measurement errors (e.g., improper sampling)<br>Distillation errors (e.g., smoothing due to noise)<br>Data integration errors (e.g., multiple databases)	
Data Semantics:	The real-world meaning e.g., company name, day of the month, person height, etc.	
Data Type:	Interpretation in terms of scales of measurements e.g., quantity or category, sensible mathematical operations, data structure, etc.	
Data Types: Nominal (Catergorical) (N)	Are Equal or Not Equal to other Values, Apples, Oranges, Bananas,...	
Data Types: Ordinal (O)	Obey a <(greater than) relationship, from Small, Medium, Large	
Data Types: Quantitative (Q)	Can do arithmetic on them, 10cm, 23cm, etc.	
Data Types: Quantitative (Q) : Interval (Location of Zero is arbitary)	Dates. Cant be compared directly, only the differences (intervals can be compared	
Data Types: Quantitative (Q) : Ratio (Zero is fixed	Measurements: Lengths, Mass, Temp. Origin is meaningful, can measure ratios and proportions.	
A Database map is also called	ERD - Entity Relationship Diagram	
The only way to access a database is via a	Data Base Management System	
Nulls can also represent	"An unknown attribute value<br>A known, but missing, attribute value<br>A ""not applicable"" condition"	
Types of Key's - Foreign Key (FK)	An attribute whose values match primary key values in the related table or must be null	
Types of Key's - Foreign Key (FK) Referential Integrity	FK contains a value that refers to an existing valid tuple (row) in another relation	
Types of Key's - Secondary Key	Key used strictly for data retrieval purposes	
Types of Key's - Superkey	An Attribute or combination of attributes that uniquely identifies each row in a table	
Types of Key's - Candidate Key	A minimal superkey; a superkey that does not contain a subset of attributes that is itself a superkey	
Types of Key's - Primary Key	A candidate key selected to uniquely identify all other attribute values in any given row; cannot contain null entries	
Which of the following objects are raw data? (As opposed to processed data.)  Answers: A Web page downloaded using urllib.request.urlopen() or saved from a Web browser.  A table that contains the frequencies of each unique word in Moby Dick.  A TIFF image file obtained by scanning a book page.  The text of Moby Dick extracted from a scanned image using optical character recognition (OCR).	A Web page downloaded using urllib.request.urlopen() or saved from a Web browser.<br><br>A TIFF image file obtained by scanning a book page.	
Which data analysis technique is a machine learning technique?  Answers:  Information retrieval.  Linear regressions.  Decision trees.  Signal processing.	Decision trees.	
Is it a good idea to use interactive GUI tools for reproducible data analysis (as opposed to command-line programmed tools), and why?  Answers: No, it is not. Interactive GUI tools do not record the history of operations, which makes the analysis not reproducible.  No, it is not. Interactive GUI tools are usually oversimplified, stripped down versions of powerful programmable data processing environments.  Yes, it is. Interactive GUI tools simplify data analysis and make it more accessible.  Yes, it is. Interactive GUI tools, as a rule, provide more powerful data analysis techniques.	No, it is not. Interactive GUI tools do not record the history of operations, which makes the analysis not reproducible.	
Alice noticed that the scatter plot of variable Y vs variable X that she plotted as a part of the exploratory data analysis, looks almost like a straight diagonal line. What statement is Alice entitled to make, based on this observation?  Answers:  A change in X causes a change in Y.  X and Y are correlated.  A change in Y causes a change in X.  A change in X causes a change in Y and a change in Y causes a change in X.	X and Y are correlated.	
s is a Python string. What does the function s.upper() return?  Answers:  A copy of s with each alphabetic character converted to the upper case.  A reference to s where each alphabetic character has been converted to the upper case and all other characters removed.  A copy of s with each alphabetic character converted to the upper case and all other characters removed.  A reference to s where each alphabetic character has been converted to the upper case.	A copy of s with each alphabetic character converted to the upper case.	
"Which statement converts a string s into a list of unique vowels?  Answer: list(set(c for c in s if c in ""aouieAOUIE""))  [c for c in s if c in ""aouieAOUIE""]  set(c for c in s if c.isvowel())  list([c for c in s if c in ""aouieAOUIE""])"	"list(set(c for c in s if c in ""aouieAOUIE""))"	
infile is an open file of an unknown size. Which functions can be safely used to read from this file? (Check all that apply.)  Answers: infile.read(100)   infile.readline()  infile.readlines()  infile.read()	infile.read(100)<br> <br>infile.readline()	
"Bob attempts to download a data file using the follolwing statement:  data = urllib.request.urlopen (""http://foo.bar/foobar.tgz"")  However, the URL http://foo.bar/foobar.tgz is no longer valid. What will be the value of the variable data after the execution of the statement?  Answers: The statement raises an exception. The variable data does not exist.  The value of data is None.  The value of data is unknown.  The value of data is an empty string."	The statement raises an exception. The variable data does not exist.	
Which regular expression(s) correctly describe(s) North American ZIP codes? (Check all that apply.)  Answers: r'[0-5]{9}'  r'[0-9]+'  r'[0-9]{5}'  r'\d{5}'	r'[0-9]{5}'<br> <br>r'\d{5}'	
Which symbol shall be inserted instead of the # sign in the following regular expression so that it correctly matches a human name with an optional generational title? (Such as Jr or Sr).  r'[a-zA-Z]+\s[a-zA-Z]+(\s+(Jr\.|Sr\.|II|III))#'  Answers: +  ?  $  *	?	
What is the best external storage format for each of the following Python objects?  Rich text with emphasized words, sections, paragraphs, etc., intended for human users.  A two-dimensional list of unordered floating point numbers, intended for human users.  A set of dictionaries, intended for another Python program.  All Answer Choices A. HTML  B. Pickle  C. CSV	A. HTML<br><br>C. CSV<br><br>B. Pickle	
"Alice uses BeautifulSoup to process an HTML document. She expects that the tag <div>, that defines a certain division of the document (<div>...</div>), has an attribute class, and would like to extract the class name. The division tag is in the variable fragment. Which expression correctly obtains the class name and stores it in the variable c?  Answers: c=fragment.get(""class"")  c=div[""class""]  if fragment.has_attr(""class""): c=fragment[""class""]  fragment.find(div=""class"")"	"if fragment.has_attr(""class""): c=fragment[""class""]"	
"Bob uses BeautifulSoup to process a well-formed HTML document. The soup is stored in the variable doc. Which Python expression calculates the first top-level header of the document, represented as a human-readable string?   Note: Incidentally, this question has two correct answers. Select any correct answer to get full credit.  Answers: doc.body.h1()  doc.body.h1  doc.find_all(""h1"")  doc.h1"	doc.body.h1	
What is the way to read a CSV file without the header row using the standard CSV reader?  Answers:   Read the first line from the file using readline() and then construct a CSV reader that reads from the file.  Pass the option nrows=1 to the reader.  Pass the option header=False to the reader.  Read the whole file as a list of strings, remove the first string, and construct a CSV reader that reads from the list of the remaining strings.	Read the first line from the file using readline() and then construct a CSV reader that reads from the file.	
What symbols can be used as delimiters in a CSV file?  Answers: Any ASCII symbol, as long as it is not used in any dataitem stored in the file.  Only commas.  Any ASCII character.  Commas, tabs, colons, and vertical bars	Any ASCII character.	
What is data serialization?  Answers: The process of assigning a serial number to an object.  The process of converting an object into a stream of bytes in order to store the object to a file.  The process of reading a stream of bytes from a file in order to convert them into an object.  The process of storing a stream of bytes to a file.	The process of converting an object into a stream of bytes in order to store the object to a file.	
"The following HTML fragment has been converted into a BeautifulSoup and stored in the variable soup:  <a href='http://moon.ss' > Take me to the moon! </a>  Match the Python expressions related to the soup and their values.   All Answer Choices  A. ""http://moon.ss""  B. "" Take me to the moon! ""  C. ""Take me to the moon!""  D. ""a"""	"D. ""a""<br><br>B. "" Take me to the moon! ""<br><br>A. ""http://moon.ss""<br><br>C. ""Take me to the moon!"""	
"At least what level of data analysis is needed to make the following statement: ""Based on the observation of 20 students taking CMPSC-310, we conclude that 20% of the world population are female.""  Answers: Descriptive.  Inferential.  Predictive.  Exploratory."	Inferential.	
Which Python operator is used to find the words which are in one set but not in another?  Answers: -  &   ^  |	^	
Why is it necessary to eliminate stopwords from a text before analyzing it?  Answers: Stopwords considerably slow down text analysis tasks.  Stopwords make certain text processing functions crash.  Stopwords make texts look more similar that they actually are.  Stopwords are different in different languages.	Stopwords make texts look more similar that they actually are.	
What is the motivation for precompiling regular expressions?  Answers: Precompiled regular expressions match faster.  There are no advantages, it's a purely aesthetic choice.  Precompiled regular expressions are more accurate.	Precompiled regular expressions match faster.	
How many English names listed in the names corpus are also common English words listed in the words corpus? Hint: Treat the corpora as sets of words.  Answers: ~6000  ~400  ~800   ~1800	~1800	
What is the difference between the Porter and Lancaster stemmers?  Answers:   The Lancaster stemmer is more aggressive than the Porter stemmer. (In produces shorter stems.)  Both stemmers are very similar, there are no major differences.  The Porter stemmer, unlike the Lancaster stemmer, removes prefixes as well as endings.  The Porter stemmer, unlike the Lancaster stemmer, looks up stems on Wordnet.	The Lancaster stemmer is more aggressive than the Porter stemmer. (In produces shorter stems.)	
"How many characters does the following string have?  r""\\\n""  Answers: Answers:  5  4  3  2"	4	
Which regular expression matches any positive decimal integer number?   Answers:  \d*[1-9]\d*  [0-9]+  \d+  \d*	\d*[1-9]\d*	
Let corpus be a custom-made word corpus. What does the method corpus.raw() return?  Answers:  A string consisting of all the words in the corpus separated by white spaces.  A non-human-readable (binary) representation of all the words in the corpus.  A list of all the words in the corpus.  A string consisting of all the words in the corpus separated by line breaks.	A string consisting of all the words in the corpus separated by line breaks.	
What is the second most frequent part of speech, as reported by the NLTK POS tagger, among the first 10,000 common English words from the words corpus? Hint: Use a Counter!   Answers:  Proper noun.  Adverb.  Common noun.   Adjective.	Adjective	
Which of the following words is probably an entity?   Answers:  vandalize  actually  strongly  Philadelphia	Philadelphia	
Volume, Velocity, Variety	3 V's for datascience	
Data Driven, Expert Driven, Data + Expert Driven, Descriptive	4 Knowledge levels	
Expert Driven	Computationally encode expert opinions and assumptions.	
Deterministically summarize data	Descripitive	
Data Driven	Induce new rules or formulas from data.	
Data + Expert Driven	Combine deductive and inductive reasoning to determine causes from measured effects	
Data Mining	integrates theory and heuristics	
Data Mining	focus on the entire process of knowledge discovery, including data cleaning, learning, and integration and visualization of results	
Machine learning	focused on improving performance of a learning agent	
Machine learning	also looks at real-time learning and robotics - areas not part of data mining	
Statistics	more theory-based and more focused on testing hypotheses	
Phase, Generic task, Specialized task , Process instance	Life Cycle Industry Standard Process for Data Mining Phases	
Phase	Each phase consists of several second-level generic tasks.	
Generic task	Tasks are intended to be as complete and stable as possible.	
Specialized task	Tasks describe how actions in the generic tasks should be carried out in certain specific situations.	
Process instance	A record of the actions, decisions, and results of an actual data mining engagement.	
Associations, Classification, Clustering, Deviation Detection, Estimation, Link Analysis, Summarization, Visualization	Major Data Mining Tasks	
Associations	A & B & C occur frequently (i.e. market basket analysis)	
Classification	predicting an item class	
Clustering	finding clusters in data	
Deviation Detection	finding changes	
Estimation	predicting a continuous value	
Link Analysis	finding relationships	
Summarization	describing a group	
Visualization	to facilitate human discovery	
Big Data More Real time Traditonal data not suited well for newer apps Big Data comes from web Traditon comes from things on paper or phone calls	Traditional Data vs Big Data	
Data Islands	Spreadsheets and low volume DB's for recordkeeping	
Data Warehouse	Supports BI and reporting, but restricts robust analysis	
Analytic Sandbox	Enables high performance analytics using in-db processing.	
Unstructured, Quasi-Structured, Semi-Structured, Structured	Big data characteristics: Data structures	
Structured	tabular data can be stored in SQL databases in rows and columns	
Semi-structured	Self describing due to existence of markers<br>and Schema is not explicit, must be explored or known beforehand	
Unstructured	comes from information not organized or easily interpreted by traditional databases	
Big Data	is data whose scale, diversity, and complexity require new architecture, new tools, techniques, algorithms, and analytics to manage it and extract value and hidden knowledge from it	
Real time,	Value of Big Data	
architecture, algorithms, techniques, and experts are needed	Challenges of Big Data	
Simple Random Sampling, Stratified Sampling, Cluster Sampling,	Sampling Methods we learned	
Cluster Sampling,	Divide the population into groups amd sample those groups	
Stratified Sampling	Population gets partitioned into groups based on a factor that may influence the variable that is being measured.	
Random Sampling	A sample selected in such a way that every element in the population has a equal probability of being chosen.	
Non-probability Sampling	Convenience (accidental) - selected on the basis of availability	
Volume	size of big data and it increasing exponentially	
Variety	Various formats, types, and changing data structures<br>Text, numerical, images, audio, video, sequences, time series, social media data, multi-dim arrays, etc	
Velocity	Data is begin generated fast and need to be processed fast<br>Data flow is continuous and massive, batch<br>Processing does not work<br>Online Data Analytics	
Veracity	Uncertainty due to data inconsitencys	
VARIABILITY	5TH v	
VARIABILITY	refers to data whose meaning is constantly changing.	
OLTP	Online Transaction Processing (DBMSs)	
OLAP	Online Analytical Processing (Data Warehousing)	
RTAP	Real-Time Analytics Processing (Big Data Architecture & technology)	
Kernel trick	"Using the kernel trick to find separating hyperplanes in higher dimensional space<br>To solve a nonlinear problem using an SVM, we transform the training data onto a higher dimensional feature space via a mapping function Using the kernel trick to find separating hyperplanes in higher dimensional space and train a linear SVM model to classify the data in this new feature space. Then we can use the same mapping function Using the kernel trick to find separating hyperplanes in higher dimensional space to transform new, unseen data to classify it using the linear SVM model.<br><br>However, one problem with this mapping approach is that the construction of the new features is computationally very expensive, especially if we are dealing with high-dimensional data. This is where the so-called kernel trick comes into play. Although we didn't go into much detail about how to solve the quadratic programming task to train an SVM, in practice all we need is to replace the dot product Using the kernel trick to find separating hyperplanes in higher dimensional space by Using the kernel trick to find separating hyperplanes in higher dimensional space. In order to save the expensive step of calculating this dot product between two points explicitly, we define a so-called kernel function: Using the kernel trick to find separating hyperplanes in higher dimensional space.<br><br>One of the most widely used kernels is the Radial Basis Function kernel (RBF kernel) or Gaussian kernel:<br>The trick is to choose a transformation so that the kernel can be computed without actually computing the transformation.<br>replacing the dot-product function with a new function that returns what the dot product would have been if the data had first been transformed to a higher dimensional space. Usually done using the radial-basis function         <div><img src=""quizlet-Ku7IYly5HzEkrPJVa8cnyQ_m.png"" /></div>         "	
Radial Basis Function kernel (RBF kernel)	Used for Kernel Trick in SVMs	
Gaussian Kernel	Used for Kernel Trick in SVMs	
Types of Kernels for Kernel Trick	Fisher kernel<br>Graph kernels<br>Kernel smoother<br>Polynomial kernel<br>RBF kernel<br>String kernels	
What are kernels?	A kernel is a similarity function. It is a function that you, as the domain expert, provide to a machine learning algorithm. It takes two inputs and spits out how similar they are. <br><br>Kernels offer an alternative. Instead of defining a slew of features, you define a single kernel function to compute similarity between images. You provide this kernel, together with the images and labels to the learning algorithm, and out comes a classifier.	
SVM - Strengths and Weeknesses	...	
Decision tree classifiers - Strength and Weeknesses	Strength:<br>1) feature scaling is not a requirement for decision tree algorithms<br>2) Can visualize the DT (using GraphViz)<br><br>Weakness:<br>1) we have to be careful since the deeper the decision tree, the more complex the decision boundary becomes, which can easily result in overfitting<br><br>Note:<br>Using Random Forest allows combining weak learners with strong learners	
Information gain (IG)	Information gain is simply the difference between the impurity of the parent node and the sum of the child node impurities—the lower the impurity of the child nodes, the larger the information gain	
Gini index	...	
Entropy	...	
Classification error	This is a useful criterion for pruning but not recommended for growing a decision tree, since it is less sensitive to changes in the class probabilities of the nodes.	
z	,,,	
Parametric versus nonparametric models	Machine learning algorithms can be grouped into parametric and nonparametric models. Using parametric models, we estimate parameters from the training dataset to learn a function that can classify new data points without requiring the original training dataset anymore. Typical examples of parametric models are the perceptron, logistic regression, and the linear SVM. In contrast, nonparametric models can't be characterized by a fixed set of parameters, and the number of parameters grows with the training data. Two examples of nonparametric models that we have seen so far are the decision tree classifier/random forest and the kernel SVM.<br><br>KNN belongs to a subcategory of nonparametric models that is described as instance-based learning. Models based on instance-based learning are characterized by memorizing the training dataset, and lazy learning is a special case of instance-based learning that is associated with no (zero) cost during the learning process.	
Nonparametric	Nonparametric models can't be characterized by a fixed set of parameters, and the number of parameters grows with the training data. <br><br>Two examples of nonparametric models that we have seen so far are the decision tree classifier/random forest and the kernel SVM.	
Parametric	Using parametric models, we estimate parameters from the training dataset to learn a function that can classify new data points without requiring the original training dataset anymore. <br><br>Typical examples of parametric models are the perceptron, logistic regression, and the linear SVM.	
Free parameter	...	
Slack variable	...	
Soft-margin classification	...	
OvR technique	...	
L2 regularization	L2 regularization (sometimes also called L2 shrinkage or weight decay)	
Collinearity	collinearity (high correlation among features), filter out noise from data, and eventually prevent overfitting	
Partial derivative of the log-likelihood function	...	
Optimization algorithm	Optimization algorithm such as gradient ascent	
Log-likelihood	...	
Likelihood	...	
Sigmoid	...	
TBD: Cost function becomes differentiable	...	
z	...	
Quantizer	...	
The mean of each feature is centered at value 0 and the feature column has a standard deviation of 1	...	
Standardization	...	
Feature scaling	Feature scaling such as standardization	
impute missing dat	...	
Grouping and grading	...	
geometric	probabilistic, and logical , ...	
z	...	
subgroup discovery	...	
Scatterplot matrix	...	
Exploratory Data Analysis (EDA)	...	
If we stop at this point and feed the array to our classifier	we will make one of the most common mistakes in dealing with categorical data. Can you spot the problem? Although the color values don't come in any particular order, a learning algorithm will now assume that green is larger than blue, and red is larger than green , ...	
IDF	Inverse document frequency	
term frequency	...	
term frequency-inverse document frequency	...	
term frequency-inverse document frequency	...	
Raw term frequencies	...	
TBD: Convert categorical data	such as text or words, into a numerical form , ...	
Building feature vectors from text	...	
test set is not to be used for model selection; its only purpose is to report an unbiased estimate of the generalization performance of a classifier system	...	
MajorityVotingClassifier	...	
Machine learning projects can be divided into five distinct activities	shown as follows:Defining the object and specificationPreparing and exploring the dataModel buildingImplementationTestingDeployment , ...	
Addressing overfitting and underfitting with validation curves	...	
Validation curves	...	
Diagnosing bias and variance problems with learning curves	When a model has both low training and cross-validation accuracy, which indicates that it underfits the training data. <br><br>Common ways to address this issue are to <br>1) increase the number of parameters of the model, for example, by collecting or constructing additional features, or <br>2) by decreasing the degree of regularization, for example, in SVM or logistic regression classifiers. <br><br>When a model suffers from high variance, which is indicated by the large gap between the training and cross-validation accuracy. <br><br>To address this problem of overfitting, <br>1) we can collect more training data or reduce the complexity of the model, for example, by increasing the regularization parameter; <br>2) for unregularized models, it can also help to decrease the number of features via feature selection or feature extraction (Compressing Data via Dimensionality Reduction). <br>3) Collecting more training data decreases the chance of overfitting. However, it may not always help, for example, when the training data is extremely noisy or the model is already very close to optimal.	
increasing the regularization parameter; for unregularized models	...	
High variance	which is indicated by the large gap between the training and cross-validation accuracy , ...	
decreasing the degree of regularization	...	
increase the number of parameters	...	
validation curves	...	
Learning curves	...	
stratified k-fold cross-validation	...	
Leave-one-out (LOO) cross-validation	...	
Evaluate predictive models	...	
Fine-tune machine learning models	...	
Diagnose the common problems	...	
unbiased estimates of a model's performance	...	
zTBD: disadvantage of the holdout method is that the performance estimate is sensitive to how we partition the training set into the training and validation subsets	...	
k-fold cross-validation	...	
Holdout cross-validation	...	
TBD: Pipeline	Combining transformers and estimators in a pipeline	
Preprocessing techniques	...	
variance measures	...	
Node impuritie	...	
PCA	PCA attempts to find the orthogonal component axes of maximum variance in a dataset. Kernel principal component analysis	
Linear Discriminant Analysis	...	
Recursive backward elimination	...	
Sequential Backward Selection (SBS)	...	
Feature selection	...	
Feature extraction	...	
Sequential feature selection	...	
One-vs-Rest (OvR)	...	
Regularization	Collect more training dataIntroduce a penalty for complexity via regularizationChoose a simpler model with fewer parametersReduce the dimensionality of the data<br><br>L1 regularization can be understood as a technique for feature selection.	
Normalization	...	
Feature scaling	...	
Dummy features	...	
Categorical features	...	
One-hot encoding	...	
LabelEncoder	...	
Encoding class labels	...	
Numerical feature	...	
Nominal features	...	
Ordinal features	...	
Categorical data	...	
Estimator API	...	
imputing categorical feature values	...	
Median or most_frequent	...	
Mean imputation	...	
Accuracy	Execution time, memory usage, throughput, tuning, and adaptability	
TBD: Crossover or breeding	...	
Mutation	...	
Generation	...	
Elitism	...	
Local minimum	...	
Global minimum	...	
Random-restart hill climbing	...	
Cost function	Cost function is the key to solving any problem using optimization	
Jaccard coefficient or Manhattan		
.		
"value means more similar."""	...	
Collaborative filtering	The term collaborative filtering was first used by David Goldberg at Xerox PARC in 1992 in a paper called 'Using collaborative filtering to weave an information tapestry.' He designed a system called Tapestry that allowed people to annotate documents as either interesting or uninteresting and used this information to filter documents for other people.There are now hundreds of web sites that employ some sort of collaborative filtering algorithm for movies, music, books, dating, shopping, other web sites, podcasts, articles, and even jokes.	
"used by David Goldberg at Xerox PARC in 1992 in a paper called """"Using"		
this information to filter documents for other people.There are now hundreds of web sites that employ some sort of		
Three Classes Of Metrics: Centrality	Volatility, Bumpiness. , ...	
Correlograms	trends, change point, normalization and periodicity , ...	
Six Sigma	approximate solutions, the 80/20 rule, cross-validation, design of experiments, modern pattern recognition, lift metrics, third-party data, Monte Carlo simulations, or the life cycle of data science projects , ...	
R	Python (or Perl), Excel, SQL, graphics (visualization), FTP, basic UNIX commands (sort, grep, head, tail, the pipe and redirect operators, cat, cron jobs, and so on) , ...	
Random variables	probability, mean, variance, percentiles, experimental design, cross-validation, goodness of fit, and robust statistics , ...	
The RM4Es (Research Methods Four Elements) is a good framework to summarize Machine Learning components and processes. The RM4Es include:Equation: Equations are used to represent the models for our researchEstimation: Estimation is the link between equations (models) and the data used for our researchEvaluation: Evaluation needs to be performed to assess the fit between models and the dataExplanation: Explanation is the link between equations (models) and our research purposes. How we explain our research results often depends on our research purposes and also on the subject we are studying	...	
Load data	with packages like RODBC or RMySQLManipulate data, with packages like stringr or lubridateVisualize data, with packages like ggplot2 or leafletModel data, with packages like Random Forest or survivalReport results, with packages like shiny or markdown , ...	
Adaptable Systems	...	
Interactive Systems	...	
Distributed Systems.	...	
From Mud to Structure.	...	
Layers	Pipes and Filters, Blackboard, Broker, Model-View-Controller, Presentation-Abstraction-Control, Microkernel, and Reflection , ...	
Convolutional net	...	
structured SVMs	...	
structured perceptron	...	
CRF (conditional random fields)	...	
structure prediction	...	
ICLR	which stands for the International Conference on Learning Representation , ...	
AI or machine learning	"the main conferences are NIPS and ICML, and also conferences like AI Stats, UAI, and KDD, which is more data scienceâ€""oriented , ..."	
Stochastic gradient descent	...	
Algorithm	A series of repeatable steps for carrying out a certain type of task with data	
Angular JS	An open-source javascript library maintained by google and the community. Lets you create single web page applications to display results	
Artificial intelligence	The ability to have machines act with apparent intelligence. Can be through symbolic logic or statistical analysis	
Backpropagation	An algorithm for iteratively adjusting the weights used in a neural network system. Often used to implement gradient descent.	
Bayes' Theorem	An equation for calculating the probability that something is true if something potentially related is true. P(A|B) = P(B|A) * P(A) / P(B)	
Good for situations where you need to know the amount of false positives (diseases)		
Bayesian network	Graphs that compactly represent the relationship between random variables for a given problem	
Bias	In machine learning when a learner consistently learns the same thing wrong	
Big data	Working with large datasets that usually require distributed storage	
Binomial distribution	A distribution of independent events with two mutually exclusive possible outcomes a fixed number of trials and a constant probability of success. Discrete probability distribution. Graphed using histograms.	
Centroid	Center of a cluster	
Chi-square test	Statistical test of whether two categorical variables are independent	
Classification	The identification of two or more discrete categories for items classic machine learning task. Spam or ham. Movie genres. Supervised learning.	
Clustering	Unsupervised learning technique for dividing data into groups based on an algorithm	
Coefficient	A number or algebraic symbol prefixed as a multiplier to a variable or unknown quantity (slope in line equation)	
Computational linguistics	Also called natural language processing (NLP) converting text of spoken languages into structured data to extract valuable information	
Confidence interval	A range specified around an estimate to indicate margin of error combined with a probability that a value will fall in that range	
Continuous variable	A variable whose value can be any of infinite values	
Correlation coefficient	Measure of how closely two variables correlate. Ranges from -1 to 1	
Correlation	The degree of relative correspondence between two variables	
Covariance	A measure of the relationship between two variables whose values are observed at the same time	
Cross-validation	Set of techniques that divide up data into training sets and test sets usually 80-20. Training sets are given the correct categorization and an algorithm is created	
CSV	Comma separated values common data file type	
D3	Data Driven Documents a JavaScript library that eases the creation of interactive visualizations embedded in web pages	
Data engineer	A specialist in data wrangling they build infrastructure for real tangible analysis. Run ETL	
Data Mining	The use of computers to analyze large data sets to look for patterns that let people make business decisions	
Data science	The ability to extract knowledge and insights from large and complex data sets	
Data structure	A particular arrangement of units of data such as an array or a tree	
Data wrangling	AKA data munging the conversion of data using scripting languages to make it easy to work with	
DataFrame.boxplot()	Make a boxplot using matplotlib	
DataFrame.groupby()	Splits data into different groups depending on the variable you choose	
DataFrame.head(n = 5)	Returns first n rows of a dataframe	
DataFrame.hist()	Make a histogram using matplotlib	
DataFrame['A'].count()	Counts the number of values in column A gets the number of rows	
DataFrame['A'].max()	Returns largest value in column A	
DataFrame['A'].mean()	Returns average of values in column A	
DataFrame['A'].sum()	Adds up all values in column A	
Decision trees	Uses a tree structure to represent a number of possible decision paths and an outcome for each path	
Deep learning	A multi-level algorithm that gradually identifies things at higher levels of abstraction	
Dependent variable	The value depends on the value of the independent variable	
Dimension reduction	Using PCA or a similar method to find the smallest subset of dimensions that captures the most variation	
Discrete variable	A variable whose potential value must be one of a specific number of values	
Econometrics	The use of mathematical and statistical methods in the field of economics to verify and develop economic theories	
ETL	Extract Transform	
Feature engineering	Using feature to come up with a good model through iteration	
Feature	A machine learning expression for a piece of measurable information	
GATE	General Architecture for Text Engineering; open source java-based framework for natural language processing tasks	
Gaussian distribution	A probability distribution that when graphed is a symmetrical bell curve with the mean at the center	
Gradient boosting	Machine learning technique for regression and classification. Produces a prediction model in the form of an ensemble of weak prediction models typically decision trees; stage-wise	
Gradient descent	Optimization algorithm for finding the input to a function that produces the optimal value; iterative	
Histogram	A graphical representation of the distribution of a set of numeric data usually a vertical bar graph	
Hyperplane	Sub space of one dimension less than its ambient space for 3-D space	
Import matplotlib.pyplot as plt	Python module useful for graphing data	
K means clustering	Data mining algorithm to cluster classify	
K-nearest neighbors	Machine learning algorithm that classifies things based on their similarity to nearby neighbors. Pick the number of neighbors K	
Latent variable	Variables that are not directly observed but inferred from other variables that are observed	
Least squares	Smallest sum of the squared distances to the data from the line	
Lift	Compares the frequency of an observed pattern with how often you'd expect to see that pattern by chance near 1 is chance	
Linear algebra	Math that deals with vector spaces and operations on them such as addition and subtraction	
Linear regression	Technique that looks for a linear relationship between two variables using the line with the least squares	
Logarithm	A quantity representing the power to which a fixed number base	
Logistic regression	Model where the dependent variable is categorical. Estimates the probability of a relationship between a categorical variable and one or more independent variables	
Machine learning	The use of data-driven algorithms that perform better as they have more data to work with; generally uses cross-validation	
Matrix	Two dimensional array of values arranged in rows and columns	
Mean Absolute Error	The average error of all predicted values when compared with observed values	
Mean Squared Error	The average of the squares of all the errors when comparing predicted values with observed values	
Monte Carlo method	The use of randomly generated numbers as part of an algorithm	
Moving average	The mean of time series data from several consecutive periods; continually updated	
N-gram	The analysis of sequences of N items; usually words in natural language	
Naive Bayes classifier	A family of algorithms that consider every feature as independent of any other feature	
Neural network	A robust function that takes an arbitrary set of inputs and fits it to an arbitrary set of outputs that are binary; unique because of hidden layer of weighted functions	
Objective function	Used to find the optimal result of an objective; used to solve an optimization problem	
Overfitting	A model that is too tied to a training set and will not perform well on test data	
P-value	The probability under the assumption of no difference (bill hypothesis)	
PageRank	An algorithm that determines the importance of something typically to rank it in a list of search results	
Pandas	A python library for data manipulation	
Perceptron	"The simplest neural network approximates a single neuron with N binary inputs. It computes a weighted sum of the inputs and ""fires"" if that weighted sum is zero or greater"	
Perl	An older scripting language with roots in pre-unix systems. Popular for text processing like data cleanup and enhancement	
Pivot table	Quickly summarizes long lists of data without requiring the writing of formulas or copying cells. Can be arranged dynamically or pivoted	
Poisson distribution	A distribution of independent events used to predict the probability of an event occurring in a set time or place	
Predictive analytics	The analysis of data to predict future events usually to aid in business planning	
Predictive modeling	The development of drastically models to predict future events	
PCA Principal Component Analysis	Statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values linearly uncorrelated variables called principal components	
Prior distribution	Models the many plausible values of the unknown quantity to be estimated in Bayes interference	
Probability distribution	Listing of all possible distinct outcomes and their probabilities of occurring sum is equal to 1	
Python	Programming language that is used in data science. Easy to use and powerful for advanced users by using specialized libraries	
Quartile	Data set divided into 4 groups 25% of data in each	
R	An open-source programming language and environment for statistical computing and graph generation	
Random forest	"An algorithm used for regression or classification that uses a collection of tree data structures trees ""vote"" on the best model"	
Regression	Fitting a model to data	
Reinforcement learning	A class of machine learning algorithms which do not have specific goals but is continuously monitoring if it's doing well or not	
Root Mean Square Error (RMSE)	Square root of mean squared error. More popular because it gives a number that is easier to understand in the units of the original observations	
Ruby	A scripting language that can be used for data science not as popular as Python	
S curve	A pattern in which something is adopted slowly gains popularity quickly	
SAS	A commercial drastically software suite that includes a programming language	
Scalar	Quantity that has magnitude but No direction in space such as volume or temperature	
Serial correlation	A pattern where values in a series are correlated can shift time series by an interval called a lag and then compute the correlation of the shifted and original series	
Spatiotemporal data	Time series data that also includes geographic identifiers such as latitude-longitude pairs	
z	The ISO standard query language for relational databases	
Standard deviation	The square root of the variance common way to indicate how different a particular measurement is from the mean	
Standard normal distribution	A normal distribution with a mean of 0 and a standard deviation of 1	
Standardized score	Transformed raw score into units of standard deviation above or below the mean	
Stratified sampling	Population is divided into homogeneous groups called strata	
Supervised learning	A type of machine learning algorithm in which a system is taught to classify input into specific known classes	
Support vector machine	Supervised learning classification tool that seeks a dividing hyperplane for any number of dimensions can be used for regression or classification	
T-distribution	Variation of normal distribution that accounts for the fact that you're only using a sample of values not all of them	
Three V's	Volume Velocity	
What make big datasets impractical	...	
Time series data	A sequence of measurements of some quantity taken at different times often at equally spaced intervals	
Unstructured Information Management Architecture (UIMA)	Framework developed at IBM to analyze unstructured information especially natural language	
Unsupervised learning	Class of machine learning algorithms designed to identify groupings of data without knowing in advance what the groups will be	
Variance	How much a list of numbers vary from the average the average of the squared difference of each number from the mean	
Vector space	...	
Vector	...	
Instance-based learning	KNN belongs to a subcategory of nonparametric models that is described as instance-based learning. Models based on instance-based learning are characterized by memorizing the training dataset, and lazy learning is a special case of instance-based learning that is associated with no (zero) cost during the learning process.	
Specificity	"The propensity of a test/experiment to reduce false positives (reject type 1 errors)<br><br>The p in ""specificity"" cues rejecting false positives"	
Sensitivity	"Reduces false negatives<br><br>The n in ""sensitivity"" cues rejecting false negatives"	
Precision	The propensity of test outcomes to lie near/close to each other: to have low variance<br><br>Precision means consistency	
Accuracy	The propensity of test outcomes to lie near/close to the target: to have low variance from the target<br><br>Accuracy means being on-target	
Type 1 error	Synonym for false positive.<br><br>Reduced by test sPecificity	
Type 2 error	Synonym for false negative<br><br>Reduced by test seNsitivity	
alpha level	Synonym for significance level<br><br>The acceptable chance of false positives	
p value	The probability of the null-hypothesis - usually the probability that a statistic value results by chance.	
confidence level		
Decreases bias	Accuracy	
Is independent of bias	Precision	
Low variance	High precision	
alpha significance	Synonym for significance level<br><br>The acceptable chance of false positives	
Histogram	Plots the relative frequency of an interval	
Box Plot	Plots the center, quartiles, and outliers of a variable.	
Bar Chart	Plots a scalar numeric value	
Interval variable		
Ordinal variable	Takes values that can be ordered	
Ratio variable	Takes values having a fixed-zero point that allows meaningful division	
Categorical variable		
Nominal variable		
Numeric variable		
Spearman's Rho		
Cramer's V		
Chi Squared		
Association test between ordinal variables		
Pearson's r test	A Statistic that measures correlation between two properties of a set of samples:<br> r -> 1 implies correlation<br> r -> 0 implies no correlation<br> r-> -1 implies anti-correlation	
Contingency table		
Bivariate analysis		
Outlier	a point which falls more than 1.5 times the interquartile range above the third quartile or below the first quartile.	
Multinomial Distribution		
Beta Distribution		
Bernoulli Distribution		
Dirichlet Distribution		
Histogram Distribution		
Survival		
Odds	P(y) / P(-y) <br><br>P(y|x) / P(-y|x)	
Likelihood	P(y | x) / P(y | -x)	
Probability	P(y) represents the percent of population Y in which y occurs	
mean	A Statistic that measures ..	
median	A Statistic that measures ..	
mode	A Statistic that measures ..	
standard deviation	A Statistic that measures dispersion	
variance	A Statistic that measures ..	
moment	A Statistic that measures ..	
PDF versus probability		
Parametric Distributions	A family of distributions the exact member of which is determined by	
Uniform Distribution versus Discrete Uniform Distribution	unbiased samples from an Interval, e.g. [2..7] <br>versus<br>unbiased samples from a Categorical, e.g. {2,3,4,5,6,7}	
Maximum Likelihood Estimation	(see EstimatedDistribution)	
Goodness of fit	(see DistributionFitTest)	
Regression		
Regression model versus Distribution model		
Quantile		
Covariance		
Correlation	...<br><br>see Pearson's Rho	
Entropy	A Statistic that measures ..	
Modern versus classic Machine Learning	(see paclet: guide/ScientificDataAnalysis)	
Data set	Terminology that refers to a sample along with some statistic values.	
Tableua		
classification versus regression		
significance level	The cut-off value for a p-value below which the null-hypothesis is rejected and the p-value's statistic is accepted.	
Contrast p-value and alpha-value	Both are probabilities. <br>The p-value is the probability the chosen statistic occurs by chance.<br>The alpha value is the decision point below which we accept the statistic and tolerate chance.<br>( http://bit.ly/1qnC7TW )	
sampling distribution	The distribution of a statistic that approximates a population parameter. <br><br>e.g. the distribution of averages of samples	
statistic	Either<br><br>a) A statistical function that computes some measure of a sample of a population (mean, entropy), or<br><br>b) The value of such a function on a particular sample<br> (e.g. mean age of 1000 US citizens is 32)	
parameter	A synonym for statistical parameter and population parameter.<br><br>The (usually unknown) result of applying a statistical function (see statistic) to the entire population.<br>(e.g. mean age of (all) US citizens is 41)<br><br>( http://bit.ly/1qnE7vB )	
statistical inference	distribution over observed counts of each possible category in a set of categorically distributed observation	
two branches of statistics	parameter estimation<br>hypothesis testing	
interquartile range	Q3 - Q1 and contains 50% of the probability mass	
quartile	A set of values representing 25% of the probability mass.	
Q1	contains 25% of the probability mass	
Q3	contains 75% of the probability mass	
Statistical Model	"A statistical model is a class of mathematical model, which embodies a set of assumptions concerning the generation of some sample data, and similar data from a larger population. A statistical model represents, often in considerably idealized form, the data-generating process.<br><br>The assumptions embodied by a statistical model describe a set of probability distributions, some of which are assumed to adequately approximate the distribution from which a particular data set is sampled. The probability distributions inherent in statistical models are what distinguishes statistical models from other, non-statistical, mathematical models.<br><br>A statistical model is usually specified by mathematical equations that relate one or more random variables and possibly other non-random variables. As such, ""a model is a formal representation of a theory"".<br><br>All statistical hypothesis tests and all statistical estimators are derived from statistical models. More generally, statistical models are part of the foundation of statistical inference."	
Data Science	Data science is an interdisciplinary field about processes and systems to extract knowledge or insights from data in various forms, either structured or unstructured,[1][2] which is a continuation of some of the data analysis fields such as statistics, machine learning, data mining, and predictive analytics,[3] similar to Knowledge Discovery in Databases (KDD).<br><br>Data science employs techniques and theories drawn from many fields within the broad areas of mathematics, statistics, operations research,[4] information science, and computer science, including signal processing, probability models, machine learning, statistical learning, data mining, database, data engineering, pattern recognition and learning, visualization, predictive analytics, uncertainty modeling, data warehousing, data compression, computer programming, artificial intelligence, and high performance computing. Methods that scale to big data are of particular interest in data science, although the discipline is not generally considered to be restricted to such big data, and big data technologies are often focused on organizing and preprocessing the data instead of analysis. The development of machine learning has enhanced the growth and importance of data science.<br><br>Data science affects academic and applied research in many domains, including machine translation, speech recognition, robotics, search engines, digital economy, but also the biological sciences, medical informatics, health care, social sciences and the humanities. It heavily influences economics, business and finance. From the business perspective, data science is an integral part of competitive intelligence, a newly emerging field that encompasses a number of activities, such as data mining and data analysis.[5]	
Data Scientist	Data scientists use their data and analytical ability to find and interpret rich data sources; manage large amounts of data despite hardware, software, and bandwidth constraints; merge data sources; ensure consistency of datasets; create visualizations to aid in understanding data; build mathematical models using the data; and present and communicate the data insights/findings. They are often expected to produce answers in days rather than months, work by exploratory analysis and rapid iteration, and to produce and present results with dashboards (displays of current values) rather than papers/reports, as statisticians normally do.[6]	
Data Vizualization	"Data visualization or data visualisation is viewed by many disciplines as a modern equivalent of visual communication. It involves the creation and study of the visual representation of data, meaning ""information that has been abstracted in some schematic form, including attributes or variables for the units of information"".[1]<br><br>A primary goal of data visualization is to communicate information clearly and efficiently via statistical graphics, plots and information graphics. Numerical data may be encoded using dots, lines, or bars, to visually communicate a quantitative message.[2] Effective visualization helps users analyze and reason about data and evidence. It makes complex data more accessible, understandable and usable. Users may have particular analytical tasks, such as making comparisons or understanding causality, and the design principle of the graphic (i.e., showing comparisons or showing causality) follows the task. Tables are generally used where users will look up a specific measurement, while charts of various types are used to show patterns or relationships in the data for one or more variables.<br><br>Data visualization is both an art and a science. It is viewed as a branch of descriptive statistics by some, but also as a grounded theory development tool by others. The rate at which data is generated has increased. Data created by internet activity and an expanding number of sensors in the environment, such as satellites, are referred to as ""Big Data"". Processing, analyzing and communicating this data present a variety of ethical and analytical challenges for data visualization. The field of data science and practitioners called data scientists have emerged to help address this challenge.[3]"	
Exploratory Data Analysis	In statistics, exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task. Exploratory data analysis was promoted by John Tukey to encourage statisticians to explore the data, and possibly formulate hypotheses that could lead to new data collection and experiments. EDA is different from initial data analysis (IDA),[1] which focuses more narrowly on checking assumptions required for model fitting and hypothesis testing, and handling missing values and making transformations of variables as needed. EDA encompasses IDA.	
Big Data	"Big data is a term for data sets that are so large or complex that traditional data processing applications are inadequate. Challenges include analysis, capture, data curation, search, sharing, storage, transfer, visualization, querying, updating and information privacy. The term often refers simply to the use of predictive analytics, user behavior analytics, or certain other advanced data analytics methods that extract value from data, and seldom to a particular size of data set.[2] Accuracy in big data may lead to more confident decision making, and better decisions can result in greater operational efficiency, cost reduction and reduced risk.<br><br>Analysis of data sets can find new correlations to ""spot business trends, prevent diseases, combat crime and so on.""[3] Scientists, business executives, practitioners of medicine, advertising and governments alike regularly meet difficulties with large data sets in areas including Internet search, finance, urban informatics, and business informatics. Scientists encounter limitations in e-Science work, including meteorology, genomics,[4] connectomics, complex physics simulations, biology and environmental research.[5]"	
Data Mining	"Data mining is an interdisciplinary subfield of computer science.[1][2][3] It is the computational process of discovering patterns in large data sets involving methods at the intersection of artificial intelligence, machine learning, statistics, and database systems.[1] The overall goal of the data mining process is to extract information from a data set and transform it into an understandable structure for further use.[1] Aside from the raw analysis step, it involves database and data management aspects, data pre-processing, model and inference considerations, interestingness metrics, complexity considerations, post-processing of discovered structures, visualization, and online updating.[1] Data mining is the analysis step of the ""knowledge discovery in databases"" process, or KDD.[4]<br><br>The term is a misnomer, because the goal is the extraction of patterns and knowledge from large amounts of data, not the extraction (mining) of data itself.[5] It also is a buzzword[6] and is frequently applied to any form of large-scale data or information processing (collection, extraction, warehousing, analysis, and statistics) as well as any application of computer decision support system, including artificial intelligence, machine learning, and business intelligence. The book Data mining: Practical machine learning tools and techniques with Java[7] (which covers mostly machine learning material) was originally to be named just Practical machine learning, and the term data mining was only added for marketing reasons.[8] Often the more general terms (large scale) data analysis and analytics - or, when referring to actual methods, artificial intelligence and machine learning - are more appropriate.<br><br>The actual data mining task is the automatic or semi-automatic analysis of large quantities of data to extract previously unknown, interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection), and dependencies (association rule mining). This usually involves using database techniques such as spatial indices. These patterns can then be seen as a kind of summary of the input data, and may be used in further analysis or, for example, in machine learning and predictive analytics. For example, the data mining step might identify multiple groups in the data, which can then be used to obtain more accurate prediction results by a decision support system. Neither the data collection, data preparation, nor result interpretation and reporting is part of the data mining step, but do belong to the overall KDD process as additional steps.<br><br>The related terms data dredging, data fishing, and data snooping refer to the use of data mining methods to sample parts of a larger population data set that are (or may be) too small for reliable statistical inferences to be made about the validity of any patterns discovered. These methods can, however, be used in creating new hypotheses to test against the larger data populations."	
Analytics	Analytics is the discovery, interpretation, and communication of meaningful patterns in data. Especially valuable in areas rich with recorded information, analytics relies on the simultaneous application of statistics, computer programming and operations research to quantify performance. Analytics often favors data visualization to communicate insight.<br><br>Organizations may apply analytics to business data to describe, predict, and improve business performance. Specifically, areas within analytics include predictive analytics, prescriptive analytics, enterprise decision management, retail analytics, store assortment and stock-keeping unit optimization, marketing optimization and marketing mix modeling, web analytics, sales force sizing and optimization, price and promotion modeling, predictive science, credit risk analysis, and fraud analytics. Since analytics can require extensive computation (see big data), the algorithms and software used for analytics harness the most current methods in computer science, statistics, and mathematics.[1]<br><br>Analytics is multidisciplinary. There is extensive use of mathematics and statistics, the use of descriptive techniques and predictive models to gain valuable knowledge from data—data analysis. The insights from data are used to recommend action or to guide decision making rooted in business context. Thus, analytics is not so much concerned with individual analyses or analysis steps, but with the entire methodology. There is a pronounced tendency to use the term analytics in business settings e.g. text analytics vs. the more generic text mining to emphasize this broader perspective.[citation needed]. There is an increasing use of the term advanced analytics,[citation needed] typically used to describe the technical aspects of analytics, especially in the emerging fields such as the use of machine learning techniques like neural networks to do predictive modeling.	
Information Extraction	"Information extraction (IE) is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents. In most of the cases this activity concerns processing human language texts by means of natural language processing (NLP). Recent activities in multimedia document processing like automatic annotation and content extraction out of images/audio/video could be seen as information extraction.<br><br>Due to the difficulty of the problem, current approaches to IE focus on narrowly restricted domains. An example is the extraction from news wire reports of corporate mergers, such as denoted by the formal relation:<br><br>A broad goal of IE is to allow computation to be done on the previously unstructured data. A more specific goal is to allow logical reasoning to draw inferences based on the logical content of the input data. Structured data is semantically well-defined data from a chosen target domain, interpreted with respect to category and context.<br><br>Information Extraction is the part of a greater puzzle which deals with the problem of devising automatic methods for text management, beyond its transmission, storage and display. The discipline of information retrieval (IR)[1] has developed automatic methods, typically of a statistical flavor, for indexing large document collections and classifying documents. Another complementary approach is that of natural language processing (NLP) which has solved the problem of modelling human language processing with considerable success when taking into account the magnitude of the task. In terms of both difficulty and emphasis, IE deals with tasks in between both IR and NLP. In terms of input, IE assumes the existence of a set of documents in which each document follows a template, i.e. describes one or more entities or events in a manner that is similar to those in other documents but differing in the details. An example, consider a group of newswire articles on Latin American terrorism with each article is presumed to be based upon one or more terroristic acts. We also define for any given IE task a template, which is a(or a set of) case frame(s) to hold the information contained in a single document. For the terrorism example, a template would have slots corresponding to the perpetrator, victim, and weapon of the terroristic act, and the date on which the event happened. An IE system for this problem is required to ""understand"" an attack article only enough to find data corresponding to the slots in this template."	
MECE principal	The MECE principle, pronounced 'me see', is a grouping principle for separating a set of items into subsets that are mutually exclusive and collectively exhaustive.[1]<br><br>The MECE principle is useful in the business mapping process where the optimum arrangement of information is exhaustive and does not double count at any level of the hierarchy.<br><br>Examples of MECE arrangements include categorizing people by year of birth (assuming all years are known). A non-MECE example would be categorization by nationality, because nationalities are neither mutually exclusive (some people have dual nationality) nor collectively exhaustive (some people have none).	
Techniques for analyzing quantitative data	"Author Jonathan Koomey has recommended a series of best practices for understanding quantitative data. These include:<br><br>Check raw data for anomalies prior to performing your analysis;<br>Re-perform important calculations, such as verifying columns of data that are formula driven;<br>Confirm main totals are the sum of subtotals;<br>Check relationships between numbers that should be related in a predictable way, such as ratios over time;<br>Normalize numbers to make comparisons easier, such as analyzing amounts per person or relative to GDP or as an index value relative to a base year;<br>Break problems into component parts by analyzing factors that led to the results, such as DuPont analysis of return on equity.[6]<br>For the variables under examination, analysts typically obtain descriptive statistics for them, such as the mean (average), median, and standard deviation. They may also analyze the distribution of the key variables to see how the individual values cluster around the mean.<br><br><br>An illustration of the MECE principle used for data analysis.<br>The consultants at McKinsey and Company named a technique for breaking a quantitative problem down into its component parts called the MECE principle. Each layer can be broken down into its components; each of the sub-components must be mutually exclusive of each other and collectively add up to the layer above them. The relationship is referred to as ""Mutually Exclusive and Collectively Exhaustive"" or MECE. For example, profit by definition can be broken down into total revenue and total cost. In turn, total revenue can be analyzed by its components, such as revenue of divisions A, B, and C (which are mutually exclusive of each other) and should add to the total revenue (collectively exhaustive).<br><br>Analysts may use robust statistical measurements to solve certain analytical problems. Hypothesis testing is used when a particular hypothesis about the true state of affairs is made by the analyst and data is gathered to determine whether that state of affairs is true or false. For example, the hypothesis might be that ""Unemployment has no effect on inflation"", which relates to an economics concept called the Phillips Curve. Hypothesis testing involves considering the likelihood of Type I and type II errors, which relate to whether the data supports accepting or rejecting the hypothesis.<br><br>Regression analysis may be used when the analyst is trying to determine the extent to which independent variable X affects dependent variable Y (e.g., ""To what extent do changes in the unemployment rate (X) affect the inflation rate (Y)?""). This is an attempt to model or fit an equation line or curve to the data, such that Y is a function of X.<br><br>Necessary condition analysis (NCA) may be used when the analyst is trying to determine the extent to which independent variable X allows variable Y (e.g., ""To what extent is a certain unemployment rate (X) necessary for a certain inflation rate (Y)?""). Whereas (multiple) regression analysis uses additive logic where each X-variable can produce the outcome and the X's can compensate for each other (they are sufficient but not necessary), necessary condition analysis (NCA) uses necessity logic, where one or more X-variables allow the outcome to exist, but may not produce it (they are necessary but not sufficient). Each single necessary condition must be present and compensation is not possible."	
Knowledge Representation and Reasoning	Knowledge representation and reasoning (KR) is the field of artificial intelligence (AI) dedicated to representing information about the world in a form that a computer system can utilize to solve complex tasks such as diagnosing a medical condition or having a dialog in a natural language. Knowledge representation incorporates findings from psychology[citation needed] about how humans solve problems and represent knowledge in order to design formalisms that will make complex systems easier to design and build. Knowledge representation and reasoning also incorporates findings from logic to automate various kinds of reasoning, such as the application of rules or the relations of sets and subsets.<br><br>Examples of knowledge representation formalisms include semantic nets, systems architecture, Frames, Rules, and ontologies. Examples of automated reasoning engines include inference engines, theorem provers, and classifiers.	
Code	In communications and information processing, code is a system of rules to convert information—such as a letter, word, sound, image, or gesture—into another form or representation, sometimes shortened or secret, for communication through a channel or storage in a medium. An early example is the invention of language, which enabled a person, through speech, to communicate what he or she saw, heard, felt, or thought to others. But speech limits the range of communication to the distance a voice can carry, and limits the audience to those present when the speech is uttered. The invention of writing, which converted spoken language into visual symbols, extended the range of communication across space and time<br><br>The process of encoding converts information from a source into symbols for communication or storage. Decoding is the reverse process, converting code symbols back into a form that the recipient of that understands time.	
Data Processing	"Data processing is, generally, ""the collection and manipulation of items of data to produce meaningful information.""[1] In this sense it can be considered a subset of information processing, ""the change (processing) of information in any manner detectable by an observer."" [note 1]<br><br>The term Data processing (DP) has also been used previously to refer to a department within an organization responsible for the operation of data processing applications.[2]<br><br>Data processing may involve various processes, including:<br><br>Validation - Ensuring that supplied data is correct and relevant.<br>Sorting - ""arranging items in some sequence and/or in different sets.""<br>Summarization - reducing detail data to its main points.<br>Aggregation - combining multiple pieces of data.<br>Analysis - the ""collection, organization, analysis, interpretation and presentation of data."".<br>Reporting - list detail or summary data or computed information.<br>Classification - separates data into various categories."	
Data set	A data set (or dataset) is a collection of data.<br><br>Most commonly a data set corresponds to the contents of a single database table, or a single statistical data matrix, where every column of the table represents a particular variable, and each row corresponds to a given member of the data set in question. The data set lists values for each of the variables, such as height and weight of an object, for each member of the data set. Each value is known as a datum. The data set may comprise data for one or more members, corresponding to the number of rows.<br><br>The term data set may also be used more loosely, to refer to the data in a collection of closely related tables, corresponding to a particular experiment or event. An example of this type is the data sets collected by space agencies performing experiments with instruments aboard space probes.	
Raw Data	"Raw data, also known as primary data, is data (e.g., numbers, instrument readings, figures, etc.) collected from a source. If a scientist sets up a computerized thermometer which records the temperature of a chemical mixture in a test tube every minute, the list of temperature readings for every minute, as printed out on a spreadsheet or viewed on a computer screen is ""raw data"". Raw data has not been subjected to processing, ""cleaning"" by researchers to remove outliers, obvious instrument reading errors or data entry errors, or any analysis (e.g., determining central tendency aspects such as the average or median result). As well, raw data has not been subject to any other manipulation by a software program or a human researcher, analyst or technician. It is also referred to as primary data. Raw data is a relative term (see data), because even once raw data has been ""cleaned"" and processed by one team of researchers, another team may consider this processed data to be ""raw data"" for another stage of research. Raw data can be inputted to a computer program or used in manual procedures such as analyzing statistics from a survey. The term ""raw data"" can refer to the binary data on electronic storage devices, such as hard disk drives (also referred to as ""low-level data"")."	
Field Research	Field research or fieldwork is the collection of information outside a laboratory, library or workplace setting. The approaches and methods used in field research vary across disciplines. For example, biologists who conduct field research may simply observe animals interacting with their environments, whereas social scientists conducting field research may interview or observe people in their natural environments to learn their languages, folklore, and social structures.<br><br>Field research involves a range of well-defined, although variable, methods: informal interviews, direct observation, participation in the life of the group, collective discussions, analyses of personal documents produced within the group, self-analysis, results from activities undertaken off- or on-line, and life-histories. Although the method generally is characterized as qualitative research, it may (and often does) include quantitative dimensions.	
Experimental Data	Experimental data in science are data produced by a measurement, test method, experimental design or quasi-experimental design. In clinical research any data produced are the result of a clinical trial. Experimental data may be qualitative or quantitative, each being appropriate for different investigations.<br><br>Generally speaking, qualitative data are considered more descriptive and can be subjective in comparison to having a continuous measurement scale that produces numbers. Whereas quantitative data are gathered in a manner that is normally experimentally repeatable, qualitative information is usually more closely related to phenomenal meaning and is, therefore, subject to interpretation by individual observers.<br><br>Experimental data can be reproduced by a variety of different investigators and mathematical analysis may be performed on these data.	
Knowledge	"Knowledge is a familiarity, awareness or understanding of someone or something, such as facts, information, descriptions, or skills, which is acquired through experience or education by perceiving, discovering, or learning.<br><br>Knowledge can refer to a theoretical or practical understanding of a subject. It can be implicit (as with practical skill or expertise) or explicit (as with the theoretical understanding of a subject); it can be more or less formal or systematic.[1] In philosophy, the study of knowledge is called epistemology; the philosopher Plato famously defined knowledge as ""justified true belief"", though this definition is now agreed by most analytic philosophers to be problematic because of the Gettier problems. However, several definitions of knowledge and theories to explain it exist.<br><br>Knowledge acquisition involves complex cognitive processes: perception, communication, and reasoning;[2] while knowledge is also said to be related to the capacity of acknowledgment in human beings.[3]"	
Philosophy of Information	The philosophy of information (PI) is the area of research that studies conceptual issues arising at the intersection of computer science, information science, information technology, and philosophy.<br><br>It includes:<br><br>the critical investigation of the conceptual nature and basic principles of information, including its dynamics, utilisation and sciences<br>the elaboration and application of information-theoretic and computational methodologies to philosophical problems.[1]	
Accuracy vs. Precision	"Precision is a description of random errors, a measure of statistical variability.<br><br>Accuracy has two definitions:<br><br>more commonly, it is a description of systematic errors, a measure of statistical bias;<br>alternatively, ISO defines accuracy as describing both types of observational error above (preferring the term trueness for the common definition of accuracy).<br><br>In the fields of science, engineering and statistics, the accuracy of a measurement system is the degree of closeness of measurements of a quantity to that quantity's true value.[1] The precision of a measurement system, related to reproducibility and repeatability, is the degree to which repeated measurements under unchanged conditions show the same results.[1][2] Although the two words precision and accuracy can be synonymous in colloquial use, they are deliberately contrasted in the context of the scientific method.<br><br>A measurement system can be accurate but not precise, precise but not accurate, neither, or both. For example, if an experiment contains a systematic error, then increasing the sample size generally increases precision but does not improve accuracy. The result would be a consistent yet inaccurate string of results from the flawed experiment. Eliminating the systematic error improves accuracy but does not change precision.<br><br>A measurement system is considered valid if it is both accurate and precise. Related terms include bias (non-random or directed effects caused by a factor or factors unrelated to the independent variable) and error (random variability).<br><br>The terminology is also applied to indirect measurements—that is, values obtained by a computational procedure from observed data.<br><br>In addition to accuracy and precision, measurements may also have a measurement resolution, which is the smallest change in the underlying physical quantity that produces a response in the measurement.<br><br>In numerical analysis, accuracy is also the nearness of a calculation to the true value; while precision is the resolution of the representation, typically defined by the number of decimal or binary digits.<br><br>Statistical literature prefers to use the terms bias and variability instead of accuracy and precision: bias is the amount of inaccuracy and variability is the amount of imprecision. In military terms, accuracy refers primarily to the accuracy of fire (or ""justesse de tir""), the precision of fire expressed by the closeness of a grouping of shots at and around the centre of the target.[3]"	
Accuracy vs. Measurement	In industrial instrumentation, accuracy is the measurement tolerance, or transmission of the instrument and defines the limits of the errors made when the instrument is used in normal operating conditions.[4]<br><br>Ideally a measurement device is both accurate and precise, with measurements all close to and tightly clustered around the true value. The accuracy and precision of a measurement process is usually established by repeatedly measuring some traceable reference standard. Such standards are defined in the International System of Units (abbreviated SI from French: Système international d'unités) and maintained by national standards organizations such as the National Institute of Standards and Technology in the United States.<br><br>This also applies when measurements are repeated and averaged. In that case, the term standard error is properly applied: the precision of the average is equal to the known standard deviation of the process divided by the square root of the number of measurements averaged. Further, the central limit theorem shows that the probability distribution of the averaged measurements will be closer to a normal distribution than that of individual measurements.<br><br>With regard to accuracy we can distinguish:<br><br>the difference between the mean of the measurements and the reference value, the bias. Establishing and correcting for bias is necessary for calibration.<br>the combined effect of that and precision.<br>A common convention in science and engineering is to express accuracy and/or precision implicitly by means of significant figures. Here, when not explicitly stated, the margin of error is understood to be one-half the value of the last significant place.	
Quantification	In mathematics and empirical science, quantification (or quantitation) is the act of counting and measuring that maps human sense observations and experiences into members of some set of numbers. Quantification in this sense is fundamental to the scientific method.	
Scientific Method	"The scientific method is a body of techniques for investigating phenomena, acquiring new knowledge, or correcting and integrating previous knowledge.[2] To be termed scientific, a method of inquiry is commonly based on empirical or measurable evidence subject to specific principles of reasoning.[3] The Oxford Dictionaries Online define the scientific method as ""a method or procedure that has characterized natural science since the 17th century, consisting in systematic observation, measurement, and experiment, and the formulation, testing, and modification of hypotheses"".[4]<br><br>The scientific method is an ongoing process, which usually begins with observations about the natural world. Human beings are naturally inquisitive, so they often come up with questions about things they see or hear and often develop ideas (hypotheses) about why things are the way they are. The best hypotheses lead to predictions that can be tested in various ways, including making further observations about nature. In general, the strongest tests of hypotheses come from carefully controlled and replicated experiments that gather empirical data. Depending on how well the tests match the predictions, the original hypothesis may require refinement, alteration, expansion or even rejection. If a particular hypothesis becomes very well supported a general theory may be developed.[1]<br><br>Although procedures vary from one field of inquiry to another, identifiable features are frequently shared in common between them. The overall process of the scientific method involves making conjectures (hypotheses), deriving predictions from them as logical consequences, and then carrying out experiments based on those predictions.[5][6] A hypothesis is a conjecture, based on knowledge obtained while formulating the question. The hypothesis might be very specific or it might be broad. Scientists then test hypotheses by conducting experiments. Under modern interpretations, a scientific hypothesis must be falsifiable, implying that it is possible to identify a possible outcome of an experiment that conflicts with predictions deduced from the hypothesis; otherwise, the hypothesis cannot be meaningfully tested.[7]<br><br>The purpose of an experiment is to determine whether observations agree with or conflict with the predictions derived from a hypothesis.[8] Experiments can take place in a college lab, on a kitchen table, at CERN's Large Hadron Collider, at the bottom of an ocean, on Mars, and so on. There are difficulties in a formulaic statement of method, however. Though the scientific method is often presented as a fixed sequence of steps, it represents rather a set of general principles.[9] Not all steps take place in every scientific inquiry (or to the same degree), and are not always in the same order.[10] Some philosophers and scientists have argued that there is no scientific method. For example, Lee Smolin[11] and Paul Feyerabend (in his Against Method). Nola and Sankey remark that ""For some, the whole idea of a theory of scientific method is yester-year's debate"".[12]"	
False Precision	"False precision (also called overprecision, fake precision, misplaced precision and spurious accuracy) occurs when numerical data are presented in a manner that implies better precision than is actually the case; since precision is a limit to accuracy, this often leads to overconfidence in the accuracy as well.[1]<br><br>Madsen Pirie defines the term ""false precision"" in a more general way: when exact numbers are used for notions that cannot be expressed in exact terms. For example, ""I am 90% sure he is wrong"". Often false precision is abused to produce an unwarranted confidence in the claim: ""our mouthwash is twice as good as our competitor's"". [2]<br><br>In science and engineering, convention dictates that unless a margin of error is explicitly stated, the number of significant figures used in the presentation of data should be limited to what is warranted by the precision of those data. For example, if an instrument can be read to tenths of a unit of measurement, results of calculations using data obtained from that instrument can only be confidently stated to the tenths place, regardless of what the raw calculation returns or whether other data used in the calculation are more accurate. Even outside these disciplines, there is a tendency to assume that all the non-zero digits of a number are meaningful; thus, providing excessive figures may lead the viewer to expect better precision than actually exists.<br><br>However, in contrast, it is good practice to retain more significant figures than this in the intermediate stages of a calculation, in order to avoid accumulated rounding errors.<br><br>False precision commonly arises when high-precision and low-precision data are combined, and in conversion of units."	
Problem Solving	Problem solving consists of using generic or ad hoc methods, in an orderly manner, for finding solutions to problems. Some of the problem-solving techniques developed and used in artificial intelligence, computer science, engineering, mathematics, or medicine are related to mental problem-solving techniques studied in psychology.<br><br>The term problem-solving is used in many disciplines, sometimes with different perspectives, and often with different terminologies. For instance, it is a mental process in psychology and a computerized process in computer science. Problems can also be classified into two different types (ill-defined and well-defined) from which appropriate solutions are to be made. Ill-defined problems are those that do not have clear goals, solution paths, or expected solution. Well-defined problems have specific goals, clearly defined solution paths, and clear expected solutions. These problems also allow for more initial planning than ill-defined problems.[1] Being able to solve problems sometimes involves dealing with pragmatics (logic) and semantics (interpretation of the problem). The ability to understand what the goal of the problem is and what rules could be applied represent the key to solving the problem. Sometimes the problem requires some abstract thinking and coming up with a creative solution.	
Empiricism	"Empiricism is a theory that states that knowledge comes only or primarily from sensory experience.[1] One of several views of epistemology, the study of human knowledge, along with rationalism and skepticism, empiricism emphasizes the role of empirical evidence in the formation of ideas, over the notion of innate ideas or traditions;[2] empiricists may argue however that traditions (or customs) arise due to relations of previous sense experiences.[3]<br><br>Empiricism in the philosophy of science emphasizes evidence, especially as discovered in experiments. It is a fundamental part of the scientific method that all hypotheses and theories must be tested against observations of the natural world rather than resting solely on a priori reasoning, intuition, or revelation.<br><br>Empiricism, often used by natural scientists, says that ""knowledge is based on experience"" and that ""knowledge is tentative and probabilistic, subject to continued revision and falsification.""[4] One of the epistemological tenets is that sensory experience creates knowledge. The scientific method, including experiments and validated measurement tools, guides empirical research."	
Predictions	D	
Forecasts	D	
Data (computing)	"Data (/ˈdeɪtə/ day-tə, or /ˈdɑːtə/ dah-tə;[1] treated as singular, plural, or as a mass noun) is any sequence of one (1) or more symbols given meaning by specific act(s) of interpretation.<br><br>Data (or datum - a single unit of data) is not information. Data requires interpretation to become information. To translate data to information, there must be several known factors considered. The factors involved are determined by the creator of the data and the desired information. The term metadata is used to reference the data about the data. Metadata may be implied, specified or given. Data relating to physical events or processes will also have a temporal component. In almost all cases this temporal component is implied. This is the case when a device such as a temperature logger received data from a temperature sensor. When the temperature is received it is assumed that the data has a temporal references of ""now"". So the device records the date, time and temperature together. When the data logger communicates temperatures, it must also report the date and time (metadata) for each temperature.<br><br>Digital data is data that is represented using the binary number system of ones (1) and zeros (0). As opposed to analog representation. In modern (post 1960) computer systems, all data is digital. Data within a computer, in most cases, moves as parallel data. Data moving to or from a computer, in most cases, moves as serial data. See Parallel communication and Serial communication. Data sourced from an analog device, such as a temperature sensor, must pass through an ""analog to digital converter"" or ""ADC"" (see Analog-to-digital converter) to convert the analog data to digital data.<br><br>Data representing quantities, characters, or symbols on which operations are performed by a computer, stored and recorded on magnetic, optical, or mechanical recording media, and transmitted in the form of digital electrical signals.[2]<br><br>A program is a set of data that consists of a series of coded software instructions to control the operation of a computer or other machine.[3] Physical computer memory elements consist of an address and a byte/word of data storage. Digital data are often stored in relational databases, like tables or SQL databases, and can generally be represented as abstract key/value pairs.<br><br>Data can be organized in many different types of data structures, including arrays, graphs, and objects. Data structures can store data of many different types, including numbers, strings and even other data structures. Data pass in and out of computers via peripheral devices."	
Data	"Data (/ˈdeɪtə/ day-tə, /ˈdætə/ da-tə, or /ˈdɑːtə/ dah-tə)[1] is a set of values of qualitative or quantitative variables. An example of qualitative data would be an anthropologist's handwritten notes about her interviews with people of an Indigenous tribe. Pieces of data are individual pieces of information. While the concept of data is commonly associated with scientific research, data is collected by a huge range of organizations and institutions, ranging from businesses (e.g., sales data, revenue, profits, stock price), governments (e.g., crime rates, unemployment rates, literacy rates) and non-governmental organizations (e.g., censuses of the number of homeless people by non-profit organizations).<br><br>Data is measured, collected and reported, and analyzed, whereupon it can be visualized using graphs, images or other analysis tools. Data as a general concept refers to the fact that some existing information or knowledge is represented or coded in some form suitable for better usage or processing. Raw data (""unprocessed data"") is a collection of numbers or characters before it has been ""cleaned"" and corrected by researchers. Raw data needs to be corrected to remove outliers or obvious instrument or data entry errors (e.g., a thermometer reading from an outdoor Arctic location recording a tropical temperature). Data processing commonly occurs by stages, and the ""processed data"" from one stage may be considered the ""raw data"" of the next stage. Field data is raw data that is collected in an uncontrolled ""in situ"" environment. Experimental data is data that is generated within the context of a scientific investigation by observation and recording."	
Information	"Information (shortened as info) is that which informs. In other words, it is the answer to a question of some kind. It is also that from which data and knowledge can be derived, as data represents values attributed to parameters, and knowledge signifies understanding of real things or abstract concepts.[1] As it regards data, the information's existence is not necessarily coupled to an observer (it exists beyond an event horizon, for example), while in the case of knowledge, the information requires a cognitive observer.<br><br>At its most fundamental, information is any propagation of cause and effect within a system. Information is conveyed either as the content of a message or through direct or indirect observation of some thing. That which is perceived can be construed as a message in its own right, and in that sense, information is always conveyed as the content of a message.<br><br>Information can be encoded into various forms for transmission and interpretation (for example, information may be encoded into a sequence of signs, or transmitted via a sequence of signals). It can also be encrypted for safe storage and communication.<br><br>Information resolves uncertainty. The uncertainty of an event is measured by its probability of occurrence and is inversely proportional to that. The more uncertain an event, the more information is required to resolve uncertainty of that event. The bit is a typical unit of information, but other units such as the nat may be used. Example: information in one ""fair"" coin ﬂip: log2(2/1) = 1 bit, and in two fair coin flips is log2(4/1) = 2 bits.<br><br>The concept that information is the message has different meanings in different contexts.[2] Thus the concept of information becomes closely related to notions of constraint, communication, control, data, form, education, knowledge, meaning, understanding, mental stimuli, pattern, perception, representation, and entropy."	
Measurement (Data)	Measurement is the assignment of a number to a characteristic of an object or event, which can be compared with other objects or events.[1][2] The scope and application of a measurement is dependent on the context and discipline. In the natural sciences and engineering, measurements do not apply to nominal properties of objects or events, which is consistent with the guidelines of the International vocabulary of metrology published by the International Bureau of Weights and Measures.[2] However, in other fields such as statistics as well as the social and behavioral sciences, measurements can have multiple levels, which would include nominal, ordinal, interval, and ratio scales.[1][3]<br><br>Measurement is a cornerstone of trade, science, technology, and quantitative research in many disciplines. Historically, many measurement systems existed for the varied fields of human existence to facilitate comparisons in these fields. Often these were achieved by local agreements between trading partners or collaborators. Since the 18th century, developments progressed towards unifying, widely accepted standards that resulted in the modern International System of Units (SI). This system reduces all physical measurements to a mathematical combination of seven base units. The science of measurement is pursued in the field of metrology.	
Data reporting	Data reporting is the process of collecting and submitting data to authorities entrusted with compiling statistics. Accurate data reporting gives rise to accurate analyses of the facts on the ground; inaccurate data reporting can lead to vastly uninformed decisions based on erroneous evidence. When data is not reported, the problem is known as underreporting; the opposite problem leads to false positives.<br><br>Data reporting can be an incredibly difficult endeavor. Census bureaus may hire even hundreds of thousands of workers to achieve the task of counting all of the residents of a country.[1][2] Teachers use data from student assessments to determine grades; cellphone manufacturers rely on sales data from retailers to point the way to which models to increase production of. The effective management of nearly any company relies on accurate data.	
Data Analysis	Analysis of data is a process of inspecting, cleaning, transforming, and modeling data with the goal of discovering useful information, suggesting conclusions, and supporting decision-making. Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, in different business, science, and social science domains.<br><br>Data mining is a particular data analysis technique that focuses on modeling and knowledge discovery for predictive rather than purely descriptive purposes. Business intelligence covers data analysis that relies heavily on aggregation, focusing on business information. In statistical applications, some people divide data analysis into descriptive statistics, exploratory data analysis (EDA), and confirmatory data analysis (CDA). EDA focuses on discovering new features in the data and CDA on confirming or falsifying existing hypotheses. Predictive analytics focuses on application of statistical models for predictive forecasting or classification, while text analytics applies statistical, linguistic, and structural techniques to extract and classify information from textual sources, a species of unstructured data. All are varieties of data analysis.<br><br>Data integration is a precursor to data analysis, and data analysis is closely linked to data visualization and data dissemination. The term data analysis is sometimes used as a synonym for data modeling.	
Data processing		
Data organizing		
Concept Learning	process of learning which helps form new concepts	
Continuous-Valued Attribute	numeric EX cars houses	
Discrete-Valued Attribute	nominal EX jobtype, address	
Inductive learning	guessing knowledge that is statistically supported; training data includes desired outputs	
Version Space	boundary groups <br>Group S: Most specific matching concept(s)<empty cases><br>Group G: Most General Matching concept(s)	
Bias	learner predicts outputs given inputs that it has not encountered. <br>High bias can cause an algorithm to miss the relavant relations between features;<br>underfitting;	
Variance	error from sensitivity to small fluctuations in training set. High variance can cause over fitting modeling the random noise rather then intended values	
Bayes optimal error	the proportion of error that cannot be eliminated	
N-Fold Cross Validation	Some data removed before training. Then data removed is used to test the training. Divided into N subsets	
Leave One Out Cross Validation	proportion data into different groups. Train group 2-10;Test group 1; ect;	
Confusion Matrix	Used to analyze source of error	
ROC Curve	fro comparing algorithms illustrates performance of binary classifier system by thresholds	
Precision	TP / (FP + TP)	
Recall	TP / #Positives	
False Positive	Incorrectly indicate that attribute is present	
False Negative	Incorrectly indicate that attribute is absent	
Decision Tree	Each internal Node Test attribute, each branch corresponds to attribute, each leaf node assigns classifier	
Entropy	E = (-p+log(p)+-plog(-p))<br><br>Measure of Randomness<br><br>The higher entropy the harder it is to draw conclusions	
Information gain	expected reduction in entropy due to sorting on A	
Gain ratio	gain(S,A)/Split info(S,A)	
Overfitting	paying to close attention to each data points	
Noise	Random Variance error	
Artificial Neural Network	Learning System set up like the biology of the brain where each node is an activation node in the neural network	
hidden unit	transform input into something the output can use	
linearUnit	A(netinput) = netinput	
LinearThreshold Unit	a(netinput) = {1 netinput > 0 ; 0 otherwise}	
Sigmoid Unit	a(netinput) = 1/1+e^(-netinput)	
Perceptron	an algorithm for learning binary classifier that maps its input to a single binary out value <br>-models a neuron	
MultiLayer Perceptron	Artificial network model that maps set of inputs data onto a set of appropriate ouputs	
Gradient Descent	search determines a weight vector that mnimizes E by starting with an arbitrary initial weight vector; then modify in small steps; continued until the global minimum is reached	
batch-mode Gradient Descent	calculate error for all examples then take a step ; linear unit training rule uses gradient descent;	
Incremental(stochastic) Gradient Descent	calculate error for a static chosen point can approximate batch gradient if n is small enough	
Convolution Neural Network	Feed forward neural network in which the connectivity pattern between neurons is inspired by the organization of animal cortex;<br>edge detection;<br>convolutionMatrix - run kernel over array of pixels ;	
Encoder-Decorder Network	feed forward neural network rep original data. <br>- multilayer PCA with non-linearities	
long short term memory	uses no activation function	
recurrent Neural Network	can use internal unit to maintain information	
Bagging	For # classifiers to generate <br>- select a bag sample of data <br>- generate classifier	
Ada-Boost	"adaptive boosting <br>- the output of other ""weak"" learners is combined into weighted sum that represents output"	
Stacking	training a learning algorithm to combine the predictions of others.	
Apriori	used for mining and association learning. <br>- highlight trends in database<br> finding association rules<br>by efficiently finding sets of items (itemsets) that<br>meet a minimal support criterion	
Random Forest	ensemble learning method for classification that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes or mean prediction	
Market Basket	list of products that are purchased by customers	
Apriori Properties	For some support threshold S<br>- If any itemset I meets the threshold S, then any nonempty<br>subset of I also meets the threshold<br>- If any itemset I does not meet the threshold S, any<br>superset (including 0	
Nearest Neighbor	In a cluster classification model data is plotted within the classification and the new points are then judged and voted by their nearest neighbor	
kd-tree	This is a type of classification that graphs the training data into groups and then puts the groups into a decision tree <br>-construct lookup tree	
Curse of dimensionality	-Nearest neighbor is misled when high dimensional space<br>-Arises when analyzing data in high dimensional space <br>-hard to find distribution and measure distances	
First order Logic	Use Inductive rules to generate concept	
Covering Algorithm	Each classification method uses an algorhithm to generate rules from sample data	
Single point Crossover	Single point is selected All data beyond that point is swapped between parents	
Two point crossover	Two points are selected; Everything between points is swapped	
Uniform Crossover	used fixed mixing ratio between parents ; gene level contribution	
Unsupervised Learning	used to draw inferences from data sets without label outputs <br>- most common method is clustering	
Clustering Algorithm	Evaluated based on the data that was clustered <br>- high score that produces high similarity within cluster and low between clusters	
Dendrogram	Tree diagram used to illustrate the aragement of clusters	
Delayed Reward	RL the agents actions determine not only its immediate reward but also the next state of the enviroment <br>- must consider future actions	
Discounted Future Reward	A reward in the future is less the reward right now <br>Increase exponentially	
Markov Decision Process	Set of States; Actions;Transition;Rewards;Transition Function;	
Linear Programming	Form: f(x1,x2,..,xn) to be maximized subject to set of constraints of form g(x1,x2,..,xn)<br>Solve math problems where constraint functions maximized use linear combo	
Slack Variable	"Dealing with nonseperable data <br>-0 if ansnwer is correct <br>-y ""distance"" we need to move example to make correct"	
Margin	maximizing this distance between both points on both sides for better accuracy	
support vector		
What's the trade-off between bias and variance?	Bias is error due to erroneous or overly simplistic assumptions in the learning algorithm you're using. This can lead to the model underfitting. <br><br>Variance is error due to too much complexity in the learning algorithm you're using. This leads to the algorithm being highly sensitive to high degrees of variation in your training data, which can lead your model to overfit the data.	
How is KNN different from k-means clustering?	K-Nearest Neighbors is a supervised classification algorithm, while k-means clustering is an unsupervised clustering algorithm. While the mechanisms may seem similar at first, what this really means is that in order for K-Nearest Neighbors to work, you need labeled data you want to classify an unlabeled point into (thus the nearest neighbor part). K-means clustering requires only a set of unlabeled points and a threshold: the algorithm will take unlabeled points and gradually learn how to cluster them into groups by computing the mean of the distance between different points.<br>The critical difference here is that KNN needs labeled points and is thus supervised learning, while k-means doesn't — and is thus unsupervised learning.	
Explain how a ROC curve works	"The ROC curve is a graphical representation of the contrast between true positive rates and the false positive rate at various thresholds. It's often used as a proxy for the trade-off between the sensitivity of the model (true positives) vs the fall-out or the probability it will trigger a false alarm (false positives).         <div><img src=""quizlet-oXuNtjEB8IxRQiXOxeLLtA_m.jpg"" /></div>         "	
Define precision and recall	Recall is also known as the true positive rate: the amount of positives your model claims compared to the actual number of positives there are throughout the data.<br><br>Precision is also known as the positive predictive value, and it is a measure of the amount of accurate positives your model claims compared to the number of positives it actually claims. <br><br>It can be easier to think of recall and precision in the context of a case where you've predicted that there were 10 apples and 5 oranges in a case of 10 apples. You'd have perfect recall.	
"Why is ""Naive"" Bayes naive?"	"Despite its practical applications, especially in text mining, Naive Bayes is considered ""Naive"" because it makes an assumption that is virtually impossible to see in real-life data: the conditional probability is calculated as the pure product of the individual probabilities of components. This implies the absolute independence of features — a condition probably never met in real life.<br>As a Quora commenter put it whimsically, a Naive Bayes classifier that figured out that you liked pickles and ice cream would probably naively recommend you a pickle ice cream."	
Explain the difference between L1 and L2 regularization.	L2 regularization tends to spread error among all the terms, while L1 is more binary/sparse, with many variables either being assigned a 1 or 0 in weighting. L1 corresponds to setting a Laplacean prior on the terms, while L2 corresponds to a Gaussian prior. L2 regularization tends to spread error among all the terms, while L1 is more binary/sparse, with many variables either being assigned a 1 or 0 in weighting. L1 corresponds to setting a Laplacean prior on the terms, while L2 corresponds to a Gaussian prior.	
What's the difference between Type I and Type II error?	Type I error is a false positive, while Type II error is a false negative. Briefly stated, Type I error means claiming something has happened when it hasn't, while Type II error means that you claim nothing is happening when in fact something is.<br>A clever way to think about this is to think of Type I error as telling a man he is pregnant, while Type II error means you tell a pregnant woman she isn't carrying a baby.	
What's a Fourier transform?	A Fourier transform is a generic method to decompose generic functions into a superposition of symmetric functions. A Fourier transform converts a signal from time to frequency domain — it's a very common way to extract features from audio signals or other time series such as sensor data.	
What is deep learning, and how does it contrast with other machine learning algorithms?	Deep learning is a subset of machine learning that is concerned with neural networks: how to use backpropagation and certain principles from neuroscience to more accurately model large sets of unlabelled or semi-structured data. In that sense, deep learning represents an unsupervised learning algorithm that learns representations of data through the use of neural nets.	
What cross-validation technique would you use on a time series dataset?	Instead of using standard k-folds cross-validation, you have to pay attention to the fact that a time series is not randomly distributed data — it is inherently ordered by chronological order. If a pattern emerges in later time periods for example, your model may still pick up on it even if that effect doesn't hold in earlier years!<br>You'll want to do something like forward chaining where you'll be able to model on past data then look at forward-facing data.<br>• fold 1 : training [1], test [2]<br>• fold 2 : training [1 2], test [3]<br>• fold 3 : training [1 2 3], test [4]<br>• fold 4 : training [1 2 3 4], test [5]<br>• fold 5 : training [1 2 3 4 5], test [6]	
Which is more important to you- model accuracy, or model performance?	This question tests your grasp of the nuances of machine learning model performance! Machine learning interview questions often look towards the details. There are models with higher accuracy that can perform worse in predictive power — how does that make sense?<br>Well, it has everything to do with how model accuracy is only a subset of model performance, and at that, a sometimes misleading one. For example, if you wanted to detect fraud in a massive dataset with a sample of millions, a more accurate model would most likely predict no fraud at all if only a vast minority of cases were fraud. However, this would be useless for a predictive model — a model designed to find fraud that asserted there was no fraud at all! Questions like this help you demonstrate that you understand model accuracy isn't the be-all and end-all of model performance.	
What's the F1 score? How would you use it?	The F1 score is a measure of a model's performance. It is a weighted average of the precision and recall of a model, with results tending to 1 being the best, and those tending to 0 being the worst. You would use it in classification tests where true negatives don't matter much	
How would you handle an imbalanced dataset?	An imbalanced dataset is when you have, for example, a classification test and 90% of the data is in one class. That leads to problems: an accuracy of 90% can be skewed if you have no predictive power on the other category of data! Here are a few tactics to get over the hump:<br>1- Collect more data to even the imbalances in the dataset.<br>2- Resample the dataset to correct for imbalances.<br>3- Try a different algorithm altogether on your dataset.<br>What's important here is that you have a keen sense for what damage an unbalanced dataset can cause, and how to balance that.	
When should you use classification over regression?	Classification produces discrete values and dataset to strict categories, while regression gives you continuous results that allow you to better distinguish differences between individual points. You would use classification over regression if you wanted your results to reflect the belongingness of data points in your dataset to certain explicit categories (ex: If you wanted to know whether a name was male or female rather than just how correlated they were with male and female names.)	
Name an example where ensemble techniques might be useful.	"Ensemble techniques use a combination of learning algorithms to optimize better predictive performance. They typically reduce overfitting in models and make the model more robust (unlikely to be influenced by small changes in the training data). <br>You could list some examples of ensemble methods, from bagging to boosting to a ""bucket of models"" method and demonstrate how they could increase predictive power."	
How do you ensure you're not overfitting with a model?	This is a simple restatement of a fundamental problem in machine learning: the possibility of overfitting training data and carrying the noise of that data through to the test set, thereby providing inaccurate generalizations.<br>There are three main methods to avoid overfitting:<br>1- Keep the model simpler: reduce variance by taking into account fewer variables and parameters, thereby removing some of the noise in the training data.<br>2- Use cross-validation techniques such as k-folds cross-validation.<br>3- Use regularization techniques such as LASSO that penalize certain model parameters if they're likely to cause overfitting.	
"What's the ""kernel trick"" and how is it useful?"	The Kernel trick involves kernel functions that can enable in higher-dimension spaces without explicitly calculating the coordinates of points within that dimension: instead, kernel functions compute the inner products between the images of all pairs of data in a feature space. This allows them the very useful attribute of calculating the coordinates of higher dimensions while being computationally cheaper than the explicit calculation of said coordinates. Many algorithms can be expressed in terms of inner products. Using the kernel trick enables us effectively run algorithms in a high-dimensional space with lower-dimensional data	
Pick an algorithm. Write the psuedo-code for a parallel implementation.	This kind of question demonstrates your ability to think in parallelism and how you could handle concurrency in programming implementations dealing with big data. Take a look at pseudocode frameworks such as Peril-L and visualization tools such as Web Sequence Diagrams to help you demonstrate your ability to write code that reflects parallelism.	
Which data visualization libraries do you use? What are your thoughts on the best data visualization tools?	What's important here is to define your views on how to properly visualize data and your personal preferences when it comes to tools. Popular tools include R's ggplot, Python's seaborn and matplotlib, and tools such as Plot.ly and Tableau.	
How would you implement a recommendation system for our company's users?	A lot of machine learning interview questions of this type will involve implementation of machine learning models to a company's problems. You'll have to research the company and its industry in-depth, especially the revenue drivers the company has, and the types of users the company takes on in the context of the industry it's in.<br>(Store a set of keywords alongside each product, which should essentially be everything in the title besides a set of stop words. When a title is displayed, you find any other products which share keywords in common (with those with one or more in common given priority).<br>You could further enhance this by assigning a score to each keyword based on its scarcity (with more scarce words being given a higher score, as a match on 'PHP', for instance, is going to be more relevant than a match on 'programming'), or by tracking the number of times a user navigates manually between a set of products.<br>Regardless you'd best start off by making it simple, and then enhance it as you go on. Depending on the size of your database more advanced techniques may not be all that fruitful	
When does KNN struggle?	The KNN does particularly bad where the datasets have more features as 0. In other words, if the data is sparse.	
What is the difference between Cluster and Systematic Sampling?	Cluster sampling is a technique used when it becomes difficult to study the target population spread across a wide area and simple random sampling cannot be applied. Cluster Sample is a probability sample where each sampling unit is a collection, or cluster of elements. Systematic sampling is a statistical technique where elements are selected from an ordered sampling frame. In systematic sampling, the list is progressed in a circular manner so once you reach the end of the list,it is progressed from the top again. The best example for systematic sampling is equal probability method.	
What does P-value signify about the statistical data?	P-value is used to determine the significance of results after a hypothesis test in statistics. P-value helps the readers to draw conclusions and is always between 0 and 1.<br>• P- Value > 0.05 denotes weak evidence against the null hypothesis which means the null hypothesis cannot be rejected.<br>• P-value <= 0.05 denotes strong evidence against the null hypothesis which means the null hypothesis can be rejected.<br>• P-value=0.05is the marginal value indicating it is possible to go either way	
What is the goal of A/B Testing?	It is a statistical hypothesis testing for randomized experiment with two variables A and B. The goal of A/B Testing is to identify any changes to the web page to maximize or increase the outcome of an interest. An example for this could be identifying the click through rate for a banner ad.	
Explain about the box cox transformation in regression models.	For some reason or the other, the response variable for a regression analysis might not satisfy one or more assumptions of an ordinary least squares regression. The residuals could either curve as the prediction increases or follow skewed distribution. In such scenarios, it is necessary to transform the response variable so that the data meets the required assumptions. A Box cox transformation is a statistical technique to transform non-mornla dependent variables into a normal shape. If the given data is not normal then most of the statistical techniques assume normality. Applying a box cox transformation means that you can run a broader number of tests.	
What is the difference between Bayesian Estimate and Maximum Likelihood Estimation (MLE)?	In bayesian estimate we have some knowledge about the data/problem (prior) .There may be several values of the parameters which explain data and hence we can look for multiple parameters like 5 gammas and 5 lambdas that do this. As a result of Bayesian Estimate, we get multiple models for making multiple predcitions i.e. one for each pair of parameters but with the same prior. So, if a new example need to be predicted than computing the weighted sum of these predictions serves the purpose.<br>Maximum likelihood does not take prior into consideration (ignores the prior) so it is like being a Bayesian while using some kind of a flat prior.	
Can you cite some examples where a false negative important than a false positive?	Assume there is an airport 'A' which has received high security threats and based on certain characteristics they identify whether a particular passenger can be a threat or not. Due to shortage of staff they decided to scan passenger being predicted as risk positives by their predictive model.<br>What will happen if a true threat customer is being flagged as non-threat by airport model?<br> Another example can be judicial system. What if Jury or judge decide to make a criminal go free?<br> What if you rejected to marry a very good person based on your predictive model and you happen to meet him/her after few years and realize that you had a false negative?	
Can you cite some examples where both false positive and false negatives are equally important?	In the banking industry giving loans is the primary source of making money but at the same time if your repayment rate is not good you will not make any profit, rather you will risk huge losses.<br>Banks don't want to lose good customers and at the same point of time they don't want to acquire bad customers. In this scenario both the false positives and false negatives become very important to measure.<br>These days we hear many cases of players using steroids during sport competitions Every player has to go through a steroid test before the game starts. A false positive can ruin the career of a Great sportsman and a false negative can make the game unfair	
A/B testing	A statistical way of comparing two (or more) techniques, typically an incumbent against a new rival. A/B testing aims to determine not only which technique performs better but also to understand whether the difference is statistically significant. A/B testing usually considers only two techniques using one measurement, but it can be applied to any finite number of techniques and measures.	
Accuracy	The fraction of predictions that a classification model got right. In multi-class classification, accuracy is defined as follows:<br><br>Accuracy=Correct PredictionsTotal Number Of Examples<br>In binary classification, accuracy has the following definition:<br><br>Accuracy=(True Positives+True Negatives)/Total Number Of Examples<br>See true positive and true negative.	
Activation Function	A function (for example, ReLU or sigmoid) that takes in the weighted sum of all of the inputs from the previous layer and then generates and passes an output value (typically nonlinear) to the next layer.	
AdaGrad	A sophisticated gradient descent algorithm that rescales the gradients of each parameter, effectively giving each parameter an independent learning rate. For a full explanation, see this paper.	
AUC (Area under the ROC Curve)	An evaluation metric that considers all possible classification thresholds.<br><br>The Area Under the ROC curve is the probability that a classifier will be more confident that a randomly chosen positive example is actually positive than that a randomly chosen negative example is positive.	
Backpropagation	The primary algorithm for performing gradient descent on neural networks. First, the output values of each node are calculated (and cached) in a forward pass. Then, the partial derivative of the error with respect to each parameter is calculated in a backward pass through the graph.	
Baseline	A simple model or heuristic used as reference point for comparing how well a model is performing. A baseline helps model developers quantify the minimal, expected performance on a particular problem.	
Batch	The set of examples used in one iteration (that is, one gradient update) of model training.<br><br>See also batch size.	
Batch Size	The number of examples in a batch. For example, the batch size of SGD is 1, while the batch size of a mini-batch is usually between 10 and 1000. Batch size is usually fixed during training and inference; however, TensorFlow does permit dynamic batch sizes.	
Bias	An intercept or offset from an origin. Bias (also known as the bias term) is referred to as b or w0 in machine learning models. For example, bias is the b in the following formula:<br><br>y′=b+w1x1+w2x2+...wnxn<br>Not to be confused with prediction bias.	
Binary Classification	"A type of classification task that outputs one of two mutually exclusive classes. For example, a machine learning model that evaluates email messages and outputs either ""spam"" or ""not spam"" is a binary classifier."	
Binning	See bucketing.	
Bucketing	Converting a (usually continuous) feature into multiple binary features called buckets or bins, typically based on value range. For example, instead of representing temperature as a single continuous floating-point feature, you could chop ranges of temperatures into discrete bins. Given temperature data sensitive to a tenth of a degree, all temperatures between 0.0 and 15.0 degrees could be put into one bin, 15.1 to 30.0 degrees could be a second bin, and 30.1 to 50.0 degrees could be a third bin.	
Calibration Layer	A post-prediction adjustment, typically to account for prediction bias. The adjusted predictions and probabilities should match the distribution of an observed set of labels.	
Candidate Sampling	A training-time optimization in which a probability is calculated for all the positive labels, using, for example, softmax, but only for a random sample of negative labels. For example, if we have an example labeled beagle and dog candidate sampling computes the predicted probabilities and corresponding loss terms for the beagle and dog class outputs in addition to a random subset of the remaining classes (cat, lollipop, fence). The idea is that the negative classes can learn from less frequent negative reinforcement as long as positive classes always get proper positive reinforcement, and this is indeed observed empirically. The motivation for candidate sampling is a computational efficiency win from not computing predictions for all negatives.	
Categorical Data	Features having a discrete set of possible values. For example, consider a categorical feature named house style, which has a discrete set of three possible values: Tudor, ranch, colonial. By representing house style as categorical data, the model can learn the separate impacts of Tudor, ranch, and colonial on house price.<br><br>Sometimes, values in the discrete set are mutually exclusive, and only one value can be applied to a given example. For example, a car maker categorical feature would probably permit only a single value (Toyota) per example. Other times, more than one value may be applicable. A single car could be painted more than one different color, so a car color categorical feature would likely permit a single example to have multiple values (for example, red and white).<br><br>Categorical features are sometimes called discrete features.<br><br>Contrast with numerical data.	
Checkpoint	Data that captures the state of the variables of a model at a particular time. Checkpoints enable exporting model weights, as well as performing training across multiple sessions. Checkpoints also enable training to continue past errors (for example, job preemption). Note that the graph itself is not included in a checkpoint.	
Class	One of a set of enumerated target values for a label. For example, in a binary classification model that detects spam, the two classes are spam and not spam. In a multi-class classification model that identifies dog breeds, the classes would be poodle, beagle, pug, and so on.	
Class-Imbalanced Data Set	A binary classification problem in which the labels for the two classes have significantly different frequencies. For example, a disease data set in which 0.0001 of examples have positive labels and 0.9999 have negative labels is a class-imbalanced problem, but a football game predictor in which 0.51 of examples label one team winning and 0.49 label the other team winning is not a class-imbalanced problem.	
Classification Model	A type of machine learning model for distinguishing among two or more discrete classes. For example, a natural language processing classification model could determine whether an input sentence was in French, Spanish, or Italian. Compare with regression model.	
Classification Threshold	A scalar-value criterion that is applied to a model's predicted score in order to separate the positive class from the negative class. Used when mapping logistic regression results to binary classification. For example, consider a logistic regression model that determines the probability of a given email message being spam. If the classification threshold is 0.9, then logistic regression values above 0.9 are classified as spam and those below 0.9 are classified as not spam.	
Collaborative Filtering	Making predictions about the interests of one user based on the interests of many other users. Collaborative filtering is often used in recommendation systems.	
Confusion Matrix	An NxN table that summarizes how successful a classification model's predictions were; that is, the correlation between the label and the model's classification. One axis of a confusion matrix is the label that the model predicted, and the other axis is the actual label. N represents the number of classes. In a binary classification problem, N=2. For example, here is a sample confusion matrix for a binary classification problem:<br><br>Tumor (predicted) Non-Tumor (predicted)<br>Tumor (actual) 18 1<br>Non-Tumor (actual) 6 452<br>The preceding confusion matrix shows that of the 19 samples that actually had tumors, the model correctly classified 18 as having tumors (18 true positives), and incorrectly classified 1 as not having a tumor (1 false negative). Similarly, of 458 samples that actually did not have tumors, 452 were correctly classified (452 true negatives) and 6 were incorrectly classified (6 false positives).<br><br>The confusion matrix for a multi-class classification problem can help you determine mistake patterns. For example, a confusion matrix could reveal that a model trained to recognize handwritten digits tends to mistakenly predict 9 instead of 4, or 1 instead of 7.<br><br>Confusion matrices contain sufficient information to calculate a variety of performance metrics, including precision and recall.	
Continuous Feature	A floating-point feature with an infinite range of possible values. Contrast with discrete feature.	
Convergence	Informally, often refers to a state reached during training in which training loss and validation loss change very little or not at all with each iteration after a certain number of iterations. In other words, a model reaches convergence when additional training on the current data will not improve the model. In deep learning, loss values sometimes stay constant or nearly so for many iterations before finally descending, temporarily producing a false sense of convergence.<br><br>See also early stopping.<br><br>See also Boyd and Vandenberghe, Convex Optimization.	
Convex Function	A function in which the region above the graph of the function is a convex set. The prototypical convex function is shaped something like the letter U. For example, the following are all convex functions:<br><br>A typical convex function is shaped like the letter 'U'.<br><br>By contrast, the following function is not convex. Notice how the region above the graph is not a convex set:<br><br>local<br>minimum<br>local<br>minimum<br>global<br>minimum<br><br>A strictly convex function has exactly one local minimum point, which is also the global minimum point. The classic U-shaped functions are strictly convex functions. However, some convex functions (for example, straight lines) are not.<br><br>A lot of the common loss functions, including the following, are convex functions:<br><br>L2 loss<br>Log Loss<br>L1 regularization<br>L2 regularization<br>Many variations of gradient descent are guaranteed to find a point close to the minimum of a strictly convex function. Similarly, many variations of stochastic gradient descent have a high probability (though, not a guarantee) of finding a point close to the minimum of a strictly convex function.<br><br>The sum of two convex functions (for example, L2 loss + L1 regularization) is a convex function.<br><br>Deep models are never convex functions. Remarkably, algorithms designed for convex optimization tend to find reasonably good solutions on deep networks anyway, even though those solutions are not guaranteed to be a global minimum.	
Convex Optimization	The process of using mathematical techniques such as gradient descent to find the minimum of a convex function. A great deal of research in machine learning has focused on formulating various problems as convex optimization problems and in solving those problems more efficiently.<br><br>For complete details, see Boyd and Vandenberghe, Convex Optimization.	
Convex Set	A subset of Euclidean space such that a line drawn between any two points in the subset remains completely within the subset. For instance, the following two shapes are convex sets:<br><br>A rectangle<br>and a semi-ellipse are both convex sets.<br><br>By contrast, the following two shapes are not convex sets:<br><br>A pie-chart<br>with a missing slice and a firework are both nonconvex sets.	
Cost	Synonym for loss.	
Cross-Entropy	A generalization of Log Loss to multi-class classification problems. Cross-entropy quantifies the difference between two probability distributions. See also perplexity.	
Custom Estimator	An Estimator that you write yourself by following these directions.<br><br>Contrast with pre-made Estimators.	
Data Set	A collection of examples.	
Data Set API	A high-level TensorFlow API for reading data and transforming it into a form that a machine learning algorithm requires. A tf.data.Dataset object represents a sequence of elements, in which each element contains one or more Tensors. A tf.data.Iterator object provides access to the elements of a Dataset.<br><br>For details about the Dataset API, see Importing Data in the TensorFlow Programmer's Guide.	
Decision Boundary	The separator between classes learned by a model in a binary class or multi-class classification problems. For example, in the following image representing a binary classification problem, the decision boundary is the frontier between the orange class and the blue class:	
Dense Layer	Synonym for fully connected layer.	
Deep Model	A type of neural network containing multiple hidden layers. Deep models rely on trainable nonlinearities.<br><br>Contrast with wide model.	
Dense Feature	A feature in which most values are non-zero, typically a Tensor of floating-point values. Contrast with sparse feature.	
Derived Feature	Synonym for synthetic feature.	
Discrete Feature	A feature with a finite set of possible values. For example, a feature whose values may only be animal, vegetable, or mineral is a discrete (or categorical) feature. Contrast with continuous feature.	
Dropout Regularization	A form of regularization useful in training neural networks. Dropout regularization works by removing a random selection of a fixed number of the units in a network layer for a single gradient step. The more units dropped out, the stronger the regularization. This is analogous to training the network to emulate an exponentially large ensemble of smaller networks. For full details, see Dropout: A Simple Way to Prevent Neural Networks from Overfitting.	
Dynamic Model	A model that is trained online in a continuously updating fashion. That is, data is continuously entering the model.	
Early Stopping	A method for regularization that involves ending model training before training loss finishes decreasing. In early stopping, you end model training when the loss on a validation data set starts to increase, that is, when generalization performance worsens.	
Embeddings	A categorical feature represented as a continuous-valued feature. Typically, an embedding is a translation of a high-dimensional vector into a low-dimensional space. For example, you can represent the words in an English sentence in either of the following two ways:<br><br>As a million-element (high-dimensional) sparse vector in which all elements are integers. Each cell in the vector represents a separate English word; the value in a cell represents the number of times that word appears in a sentence. Since a single English sentence is unlikely to contain more than 50 words, nearly every cell in the vector will contain a 0. The few cells that aren't 0 will contain a low integer (usually 1) representing the number of times that word appeared in the sentence.<br>As a several-hundred-element (low-dimensional) dense vector in which each element holds a floating-point value between 0 and 1. This is an embedding.<br>In TensorFlow, embeddings are trained by backpropagating loss just like any other parameter in a neural network.	
Empirical Risk Minimization (ERM)	Choosing the model function that minimizes loss on the training set. Contrast with structural risk minimization.	
Ensemble	A merger of the predictions of multiple models. You can create an ensemble via one or more of the following:<br><br>different initializations<br>different hyperparameters<br>different overall structure<br>Deep and wide models are a kind of ensemble.	
Epoch	A full training pass over the entire data set such that each example has been seen once. Thus, an epoch represents N/batch size training iterations, where N is the total number of examples.	
Estimator	An instance of the tf.Estimator class, which encapsulates logic that builds a TensorFlow graph and runs a TensorFlow session. You may create your own custom Estimators (as described here) or instantiate pre-made Estimators created by others.	
Example	One row of a data set. An example contains one or more features and possibly a label. See also labeled example and unlabeled example.	
False Negative (FN)	An example in which the model mistakenly predicted the negative class. For example, the model inferred that a particular email message was not spam (the negative class), but that email message actually was spam.	
False Positive (FP)	An example in which the model mistakenly predicted the positive class. For example, the model inferred that a particular email message was spam (the positive class), but that email message was actually not spam.	
False Positive Rate (FP rate)	The x-axis in an ROC curve. The FP rate is defined as follows:<br><br>False Positive Rate=False Positives/(False Positives+True Negatives)	
Feature	An input variable used in making predictions.	
Feature Columns	"A set of related features, such as the set of all possible countries in which users might live. An example may have one or more features present in a feature column.<br><br>Feature columns in TensorFlow also encapsulate metadata such as:<br><br>the feature's data type<br>whether a feature is fixed length or should be converted to an embedding<br>A feature column can contain a single feature.<br><br>""Feature column"" is Google-specific terminology. A feature column is referred to as a ""namespace"" in the VW system (at Yahoo/Microsoft), or a field."	
Feature Cross	A synthetic feature formed by crossing (multiplying or taking a Cartesian product of) individual features. Feature crosses help represent nonlinear relationships.	
Feature Engineering	The process of determining which features might be useful in training a model, and then converting raw data from log files and other sources into said features. In TensorFlow, feature engineering often means converting raw log file entries to tf.Example protocol buffers. See also tf.Transform.<br><br>Feature engineering is sometimes called feature extraction.	
Feature Set	The group of features your machine learning model trains on. For example, postal code, property size, and property condition might comprise a simple feature set for a model that predicts housing prices.	
Feature Spec	Describes the information required to extract features data from the tf.Example protocol buffer. Because the tf.Example protocol buffer is just a container for data, you must specify the following:<br><br>the data to extract (that is, the keys for the features)<br>the data type (for example, float or int)<br>The length (fixed or variable)<br>The Estimator API provides facilities for producing a feature spec from a list of FeatureColumns.	
Full Softmax	See softmax. Contrast with candidate sampling.	
Fully Connected Layer	A hidden layer in which each node is connected to every node in the subsequent hidden layer.<br><br>A fully connected layer is also known as a dense layer.	
Generalization	Refers to your model's ability to make correct predictions on new, previously unseen data as opposed to the data used to train the model.	
Generalized Linear Model	"A generalization of least squares regression models, which are based on Gaussian noise, to other types of models based on other types of noise, such as Poisson noise or categorical noise. Examples of generalized linear models include:<br><br>logistic regression<br>multi-class regression<br>least squares regression<br>The parameters of a generalized linear model can be found through convex optimization.<br><br>Generalized linear models exhibit the following properties:<br><br>The average prediction of the optimal least squares regression model is equal to the average label on the training data.<br>The average probability predicted by the optimal logistic regression model is equal to the average label on the training data.<br>The power of a generalized linear model is limited by its features. Unlike a deep model, a generalized linear model cannot ""learn new features."""	
Gradient	The vector of partial derivatives with respect to all of the independent variables. In machine learning, the gradient is the the vector of partial derivatives of the model function. The gradient points in the direction of steepest ascent.	
Gradient Clipping	Capping gradient values before applying them. Gradient clipping helps ensure numerical stability and prevents exploding gradients.	
Gradient Descent	A technique to minimize loss by computing the gradients of loss with respect to the model's parameters, conditioned on training data. Informally, gradient descent iteratively adjusts parameters, gradually finding the best combination of weights and bias to minimize loss.	
Graph	In TensorFlow, a computation specification. Nodes in the graph represent operations. Edges are directed and represent passing the result of an operation (a Tensor) as an operand to another operation. Use TensorBoard to visualize a graph.	
heuristic	A practical and nonoptimal solution to a problem, which is sufficient for making progress or for learning from.	
hidden layer	A synthetic layer in a neural network between the input layer (that is, the features) and the output layer (the prediction). A neural network contains one or more hidden layers.	
hinge loss	A family of loss functions for classification designed to find the decision boundary as distant as possible from each training example, thus maximizing the margin between examples and the boundary. KSVMs use hinge loss (or a related function, such as squared hinge loss). For binary classification, the hinge loss function is defined as follows:<br><br>loss=max(0,1−(y′∗y))<br>where y' is the raw output of the classifier model:<br><br>y′=b+w1x1+w2x2+...wnxn<br>and y is the true label, either -1 or +1.<br><br>Consequently, a plot of hinge loss vs. (y * y') looks as follows:	
holdout data	"Examples intentionally not used (""held out"") during training. The validation data set and test data set are examples of holdout data. Holdout data helps evaluate your model's ability to generalize to data other than the data it was trained on. The loss on the holdout set provides a better estimate of the loss on an unseen data set than does the loss on the training set."	
hyperparameter	"The ""knobs"" that you tweak during successive runs of training a model. For example, learning rate is a hyperparameter.<br><br>Contrast with parameter."	
hyperplane	A boundary that separates a space into two subspaces. For example, a line is a hyperplane in two dimensions and a plane is a hyperplane in three dimensions. More typically in machine learning, a hyperplane is the boundary separating a high-dimensional space. Kernel Support Vector Machines use hyperplanes to separate positive classes from negative classes, often in a very high-dimensional space.	
independently and identically distributed (IID)	Data drawn from a distribution that doesn't change, and where each value drawn doesn't depend on values that have been drawn previously. An i.i.d. is the ideal gas of machine learning—a useful mathematical construct but almost never exactly found in the real world. For example, the distribution of visitors to a web page may be i.i.d. over a brief window of time; that is, the distribution doesn't change during that brief window and one person's visit is generally independent of another's visit. However, if you expand that window of time, seasonal differences in the web page's visitors may appear.	
Inference	In machine learning, often refers to the process of making predictions by applying the trained model to unlabeled examples. In statistics, inference refers to the process of fitting the parameters of a distribution conditioned on some observed data. (See the Wikipedia article on statistical inference.)	
Input Function	In TensorFlow, a function that returns input data to the training, evaluation, or prediction method of an Estimator. For example, the training input function returns a batch of features and labels from the training set.	
Input Layer	The first layer (the one that receives the input data) in a neural network.	
Instance	Synonym for example.	
Interpretability	The degree to which a model's predictions can be readily explained. Deep models are often non-interpretable; that is, a deep model's different layers can be hard to decipher. By contrast, linear regression models and wide models are typically far more interpretable.	
Inter-Rater Agreement	A measurement of how often human raters agree when doing a task. If raters disagree, the task instructions may need to be improved. Also sometimes called inter-annotator agreement or inter-rater reliability. See also Cohen's kappa, which is one of the most popular inter-rater agreement measurements.	
Iteration	A single update of a model's weights during training. An iteration consists of computing the gradients of the parameters with respect to the loss on a single batch of data.	
Keras	A popular Python machine learning API. Keras runs on several deep learning frameworks, including TensorFlow, where it is made available as tf.keras.	
Kernel Support Vector Machines (KSVMS)	A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input data set consists of a hundred features. In order to maximize the margin between positive and negative classes, KSVMs could internally map those features into a million-dimension space. KSVMs uses a loss function called hinge loss.	
L1 Loss	Loss function based on the absolute value of the difference between the values that a model is predicting and the actual values of the labels. L1 loss is less sensitive to outliers than L2 loss.	
L1 Regularization	A type of regularization that penalizes weights in proportion to the sum of the absolute values of the weights. In models relying on sparse features, L1 regularization helps drive the weights of irrelevant or barely relevant features to exactly 0, which removes those features from the model. Contrast with L2 regularization.	
L2 Loss	See squared loss.	
L2 Regularization	A type of regularization that penalizes weights in proportion to the sum of the squares of the weights. L2 regularization helps drive outlier weights (those with high positive or low negative values) closer to 0 but not quite to 0. (Contrast with L1 regularization.) L2 regularization always improves generalization in linear models.	
Label	"In supervised learning, the ""answer"" or ""result"" portion of an example. Each example in a labeled data set consists of one or more features and a label. For instance, in a housing data set, the features might include the number of bedrooms, the number of bathrooms, and the age of the house, while the label might be the house's price. in a spam detection dataset, the features might include the subject line, the sender, and the email message itself, while the label would probably be either ""spam"" or ""not spam."""	
Lambda	Synonym for regularization rate.<br><br>(This is an overloaded term. Here we're focusing on the term's definition within regularization.)	
Layer	A set of neurons in a neural network that process a set of input features, or the output of those neurons.<br><br>Also, an abstraction in TensorFlow. Layers are Python functions that take Tensors and configuration options as input and produce other tensors as output. Once the necessary Tensors have been composed, the user can convert the result into an Estimator via a model function.	
Layers API	A TensorFlow API for constructing a deep neural network as a composition of layers. The Layers API enables you to build different types of layers, such as:<br><br>tf.layers.Dense for a fully-connected layer.<br>tf.layers.Conv2D for a convolutional layer.<br>When writing a custom Estimator, you compose Layers objects to define the characteristics of all the hidden layers.<br><br>The Layers API follows the [Keras](#Keras] layers API conventions. That is, aside from a different prefix, all functions in the Layers API have the same names and signatures as their counterparts in the Keras layers API.	
Learning Rate	A scalar used to train a model via gradient descent. During each iteration, the gradient descent algorithm multiplies the learning rate by the gradient. The resulting product is called the gradient step.<br><br>Learning rate is a key hyperparameter.	
Least Squares Regression	A linear regression model trained by minimizing L2 Loss.	
Linear Regression	A type of regression model that outputs a continuous value from a linear combination of input features.	
Logistic Regression	A model that generates a probability for each possible discrete label value in classification problems by applying a sigmoid function to a linear prediction. Although logistic regression is often used in binary classification problems, it can also be used in multi-class classification problems (where it becomes called multi-class logistic regression or multinomial regression).	
Log Loss	The loss function used in binary logistic regression.	
Loss	A measure of how far a model's predictions are from its label. Or, to phrase it more pessimistically, a measure of how bad the model is. To determine this value, a model must define a loss function. For example, linear regression models typically use mean squared error for a loss function, while logistic regression models use Log Loss.	
Machine Learning	A program or system that builds (trains) a predictive model from input data. The system uses the learned model to make useful predictions from new (never-before-seen) data drawn from the same distribution as the one used to train the model. Machine learning also refers to the field of study concerned with these programs or systems.	
Mean Squared Error (MSE)	"The average squared loss per example. MSE is calculated by dividing the squared loss by the number of examples. The values that TensorFlow Playground displays for ""Training loss"" and ""Test loss"" are MSE."	
Metric	A number that you care about. May or may not be directly optimized in a machine-learning system. A metric that your system tries to optimize is called an objective.	
Metrics API	A TensorFlow API for evaluating models. For example, tf.metrics.accuracy determines how often a model's predictions match labels. When writing a custom Estimator, you invoke Metrics API functions to specify how your model should be evaluated.	
Mini-Batch	A small, randomly selected subset of the entire batch of examples run together in a single iteration of training or inference. The batch size of a mini-batch is usually between 10 and 1,000. It is much more efficient to calculate the loss on a mini-batch than on the full training data.	
Mini-Batch Stochastic Gradient Descent (SGD)	A gradient descent algorithm that uses mini-batches. In other words, mini-batch SGD estimates the gradient based on a small subset of the training data. Vanilla SGD uses a mini-batch of size 1.	
Model	The representation of what an ML system has learned from the training data. This is an overloaded term, which can have either of the following two related meanings:<br><br>The TensorFlow graph that expresses the structure of how a prediction will be computed.<br>The particular weights and biases of that TensorFlow graph, which are determined by training.	
Model Training	The process of determining the best model.	
Momentum	A sophisticated gradient descent algorithm in which a learning step depends not only on the derivative in the current step, but also on the derivatives of the step(s) that immediately preceded it. Momentum involves computing an exponentially weighted moving average of the gradients over time, analogous to momentum in physics. Momentum sometimes prevents learning from getting stuck in local minima.	
Multi-Class Classification	Classification problems that distinguish among more than two classes. For example, there are approximately 128 species of maple trees, so a model that categorized maple tree species would be multi-class. Conversely, a model that divided emails into only two categories (spam and not spam) would be a binary classification model.	
Multinomial Classification	Synonym for multi-class classification.	
NaN Trap	"When one number in your model becomes a NaN during training, which causes many or all other numbers in your model to eventually become a NaN.<br><br>NaN is an abbreviation for ""Not a Number."""	
Negative Class	"In binary classification, one class is termed positive and the other is termed negative. The positive class is the thing we're looking for and the negative class is the other possibility. For example, the negative class in a medical test might be ""not tumor."" The negative class in an email classifier might be ""not spam."" See also positive class."	
Neural Network	A model that, taking inspiration from the brain, is composed of layers (at least one of which is hidden) consisting of simple connected units or neurons followed by nonlinearities.	
Neuron	A node in a neural network, typically taking in multiple input values and generating one output value. The neuron calculates the output value by applying an activation function (nonlinear transformation) to a weighted sum of input values.	
Node	An overloaded term that means either of the following:<br><br>A neuron in a hidden layer.<br>An operation in a TensorFlow graph.	
Normalization	The process of converting an actual range of values into a standard range of values, typically -1 to +1 or 0 to 1. For example, suppose the natural range of a certain feature is 800 to 6,000. Through subtraction and division, you can normalize those values into the range -1 to +1.<br><br>See also scaling.	
Numerical Data	Features represented as integers or real-valued numbers. For example, in a real estate model, you would probably represent the size of a house (in square feet or square meters) as numerical data. Representing a feature as numerical data indicates that the feature's values have a mathematical relationship to each other and possibly to the label. For example, representing the size of a house as numerical data indicates that a 200 square-meter house is twice as large as a 100 square-meter house. Furthermore, the number of square meters in a house probably has some mathematical relationship to the price of the house.<br><br>Not all integer data should be represented as numerical data. For example, postal codes in some parts of the world are integers; however, integer postal codes should not be represented as numerical data in models. That's because a postal code of 20000 is not twice (or half) as potent as a postal code of 10000. Furthermore, although different postal codes do correlate to different real estate values, we can't assume that real estate values at postal code 20000 are twice as valuable as real estate values at postal code 10000. Postal codes should be represented as categorical data instead.<br><br>Numerical features are sometimes called continuous features.	
Numpy	An open-source math library that provides efficient array operations in Python. pandas is built on numpy.	
Objective	A metric that your algorithm is trying to optimize.	
Offline Inference	Generating a group of predictions, storing those predictions, and then retrieving those predictions on demand. Contrast with online inference.	
One-hot Encoding	A sparse vector in which:<br><br>One element is set to 1.<br>All other elements are set to 0.<br>One-hot encoding is commonly used to represent strings or identifiers that have a finite set of possible values. For example, suppose a given botany data set chronicles 15,000 different species, each denoted with a unique string identifier. As part of feature engineering, you'll probably encode those string identifiers as one-hot vectors in which the vector has a size of 15,000.	
One vs. All	Given a classification problem with N possible solutions, a one-vs.-all solution consists of N separate binary classifiers—one binary classifier for each possible outcome. For example, given a model that classifies examples as animal, vegetable, or mineral, a one-vs.-all solution would provide the following three separate binary classifiers:<br><br>animal vs. not animal<br>vegetable vs. not vegetable<br>mineral vs. not mineral	
Online Inference	Generating predictions on demand. Contrast with offline inference.	
Operation (op)	A node in the TensorFlow graph. In TensorFlow, any procedure that creates, manipulates, or destroys a Tensor is an operation. For example, a matrix multiply is an operation that takes two Tensors as input and generates one Tensor as output.	
Optimizer	A specific implementation of the gradient descent algorithm. TensorFlow's base class for optimizers is tf.train.Optimizer. Different optimizers may leverage one or more of the following concepts to enhance the effectiveness of gradient descent on a given training set:<br><br>momentum (Momentum)<br>update frequency (AdaGrad = ADAptive GRADient descent; Adam = ADAptive with Momentum; RMSProp)<br>sparsity/regularization (Ftrl)<br>more complex math (Proximal, and others)<br>You might even imagine an NN-driven optimizer.	
Outliers	Values distant from most other values. In machine learning, any of the following are outliers:<br><br>Weights with high absolute values.<br>Predicted values relatively far away from the actual values.<br>Input data whose values are more than roughly 3 standard deviations from the mean.<br>Outliers often cause problems in model training.	
Output Layer	"The ""final"" layer of a neural network. The layer containing the answer(s)."	
Overfitting	Creating a model that matches the training data so closely that the model fails to make correct predictions on new data.	
Pandas	A column-oriented data analysis API. Many ML frameworks, including TensorFlow, support pandas data structures as input. See pandas documentation.	
Parameter	A variable of a model that the ML system trains on its own. For example, weights are parameters whose values the ML system gradually learns through successive training iterations. Contrast with hyperparameter.	
Parameter Server (PS)	A job that keeps track of a model's parameters in a distributed setting.	
Parameter Update	The operation of adjusting a model's parameters during training, typically within a single iteration of gradient descent.	
Partial Derivative	A derivative in which all but one of the variables is considered a constant. For example, the partial derivative of f(x, y) with respect to x is the derivative of f considered as a function of x alone (that is, keeping y constant). The partial derivative of f with respect to x focuses only on how x is changing and ignores all other variables in the equation.	
Partitioning Strategy	The algorithm by which variables are divided across parameter servers.	
Performance	Overloaded term with the following meanings:<br><br>The traditional meaning within software engineering. Namely: How fast (or efficiently) does this piece of software run?<br>The meaning within ML. Here, performance answers the following question: How correct is this model? That is, how good are the model's predictions?	
Perplexity	One measure of how well a model is accomplishing its task. For example, suppose your task is to read the first few letters of a word a user is typing on a smartphone keyboard, and to offer a list of possible completion words. Perplexity, P, for this task is approximately the number of guesses you need to offer in order for your list to contain the actual word the user is trying to type.<br><br>Perplexity is related to cross-entropy as follows:	
Pipeline	The infrastructure surrounding a machine learning algorithm. A pipeline includes gathering the data, putting the data into training data files, training one or more models, and exporting the models to production.	
Positive Class	"In binary classification, the two possible classes are labeled as positive and negative. The positive outcome is the thing we're testing for. (Admittedly, we're simultaneously testing for both outcomes, but play along.) For example, the positive class in a medical test might be ""tumor."" The positive class in an email classifier might be ""spam.""<br><br>Contrast with negative class."	
Precision	A metric for classification models. Precision identifies the frequency with which a model was correct when predicting the positive class. That is:<br><br>Precision=True Positives/(True Positives+False Positives)	
Prediction	A model's output when provided with an input example.	
Prediction Bias	A value indicating how far apart the average of predictions is from the average of labels in the data set.	
Pre-Made Estimator	An Estimator that someone has already built. TensorFlow provides several pre-made Estimators, including DNNClassifier, DNNRegressor, and LinearClassifier. You may build your own pre-made Estimators by following these instructions.	
Pre-Trained Model	Models or model components (such as embeddings) that have been already been trained. Sometimes, you'll feed pre-trained embeddings into a neural network. Other times, your model will train the embeddings itself rather than rely on the pre-trained embeddings.	
Prior Belief	What you believe about the data before you begin training on it. For example, L2 regularization relies on a prior belief that weights should be small and normally distributed around zero.	
Queue	A TensorFlow Operation that implements a queue data structure. Typically used in I/O.	
Rank	Overloaded term in ML that can mean either of the following:<br><br>The number of dimensions in a Tensor. For instance, a scalar has rank 0, a vector has rank 1, and a matrix has rank 2.<br>The ordinal position of a class in an ML problem that categorizes classes from highest to lowest. For example, a behavior ranking system could rank a dog's rewards from highest (a steak) to lowest (wilted kale).	
Rater	"A human who provides labels in examples. Sometimes called an ""annotator."""	
Recall	A metric for classification models that answers the following question: Out of all the possible positive labels, how many did the model correctly identify? That is:<br><br>Recall=True Positives/(True Positives+False Negatives)	
Rectified Linear Unit (ReLU)	An activation function with the following rules:<br><br>If input is negative or zero, output is 0.<br>If input is positive, output is equal to input.	
Regression Model	"A type of model that outputs continuous (typically, floating-point) values. Compare with classification models, which output discrete values, such as ""day lily"" or ""tiger lily."""	
Regularization	The penalty on a model's complexity. Regularization helps prevent overfitting. Different kinds of regularization include:<br><br>L1 regularization<br>L2 regularization<br>dropout regularization<br>early stopping (this is not a formal regularization method, but can effectively limit overfitting)	
Regularization Rate	A scalar value, represented as lambda, specifying the relative importance of the regularization function. The following simplified loss equation shows the regularization rate's influence:<br><br>minimize(loss function + λ(regularization function))<br>Raising the regularization rate reduces overfitting but may make the model less accurate.	
Representation	The process of mapping data to useful features.	
ROC (Receiver Operating Characteristic) Curve	A curve of true positive rate vs. false positive rate at different classification thresholds. See also AUC.	
Root Directory	The directory you specify for hosting subdirectories of the TensorFlow checkpoint and events files of multiple models.	
Root Mean Squared Error (RMSE)	The square root of the Mean Squared Error.	
SavedModel	The recommended format for saving and recovering TensorFlow models. SavedModel is a language-neutral, recoverable serialization format, which enables higher-level systems and tools to produce, consume, and transform TensorFlow models.<br><br>See Saving and Restoring in the TensorFlow Programmer's Guide for complete details.	
Saver	A TensorFlow object responsible for saving model checkpoints.	
Scaling	A commonly used practice in feature engineering to tame a feature's range of values to match the range of other features in the data set. For example, suppose that you want all floating-point features in the data set to have a range of 0 to 1. Given a particular feature's range of 0 to 500, you could scale that feature by dividing each value by 500.<br><br>See also normalization.	
Scikit-Learn	A popular open-source ML platform. See www.scikit-learn.org.	
Semi-Supervised Learning	Training a model on data where some of the training examples have labels but others don't. One technique for semi-supervised learning is to infer labels for the unlabeled examples, and then to train on the inferred labels to create a new model. Semi-supervised learning can be useful if labels are expensive to obtain but unlabeled examples are plentiful.	
Sequence Model	A model whose inputs have a sequential dependence. For example, predicting the next video watched from a sequence of previously watched videos.	
Session	Maintains state (for example, variables) within a TensorFlow program.	
Sigmoid Function	A function that maps logistic or multinomial regression output (log odds) to probabilities, returning a value between 0 and 1. The sigmoid function has the following formula:<br><br>y=11+e−σ<br>where σ in logistic regression problems is simply:<br><br>σ=b+w1x1+w2x2+...wnxn<br>In other words, the sigmoid function converts σ into a probability between 0 and 1.<br><br>In some neural networks, the sigmoid function acts as the activation function.	
Softmax	A function that provides probabilities for each possible class in a multi-class classification model. The probabilities add up to exactly 1.0. For example, softmax might determine that the probability of a particular image being a dog at 0.9, a cat at 0.08, and a horse at 0.02. (Also called full softmax.)<br><br>Contrast with candidate sampling.	
Sparse Feature	Feature vector whose values are predominately zero or empty. For example, a vector containing a single 1 value and a million 0 values is sparse. As another example, words in a search query could also be a sparse feature—there are many possible words in a given language, but only a few of them occur in a given query.<br><br>Contrast with dense feature.	
Squared Hinge Loss	The square of the hinge loss. Squared hinge loss penalizes outliers more harshly than regular hinge loss.	
Squared Loss	The loss function used in linear regression. (Also known as L2 Loss.) This function calculates the squares of the difference between a model's predicted value for a labeled example and the actual value of the label. Due to squaring, this loss function amplifies the influence of bad predictions. That is, squared loss reacts more strongly to outliers than L1 loss.	
Static Model	A model that is trained offline.	
Stationarity	A property of data in a data set, in which the data distribution stays constant across one or more dimensions. Most commonly, that dimension is time, meaning that data exhibiting stationarity doesn't change over time. For example, data that exhibits stationarity doesn't change from September to December.	
Step	A forward and backward evaluation of one batch.	
Step Size	Synonym for learning rate.	
Stochastic Gradient Descent (SGD)	A gradient descent algorithm in which the batch size is one. In other words, SGD relies on a single example chosen uniformly at random from a data set to calculate an estimate of the gradient at each step.	
Structural Risk Minimization (SRM)	An algorithm that balances two goals:<br><br>The desire to build the most predictive model (for example, lowest loss).<br>The desire to keep the model as simple as possible (for example, strong regularization).<br>For example, a model function that minimizes loss+regularization on the training set is a structural risk minimization algorithm.<br><br>For more information, see http://www.svms.org/srm/.<br><br>Contrast with empirical risk minimization.	
Summary	In TensorFlow, a value or set of values calculated at a particular step, usually used for tracking model metrics during training.	
Supervised Machine Learning	Training a model from input data and its corresponding labels. Supervised machine learning is analogous to a student learning a subject by studying a set of questions and their corresponding answers. After mastering the mapping between questions and answers, the student can then provide answers to new (never-before-seen) questions on the same topic. Compare with unsupervised machine learning.	
Synthetic Feature	A feature that is not present among the input features, but is derived from one or more of them. Kinds of synthetic features include the following:<br><br>Multiplying one feature by itself or by other feature(s). (These are termed feature crosses.)<br>Dividing one feature by a second feature.<br>Bucketing a continuous feature into range bins.<br>Features created by normalizing or scaling alone are not considered synthetic features.	
Target	Synonym for label.	
Temporal Data	Data recorded at different points in time. For example, winter coat sales recorded for each day of the year would be temporal data.	
Tensor	The primary data structure in TensorFlow programs. Tensors are N-dimensional (where N could be very large) data structures, most commonly scalars, vectors, or matrices. The elements of a Tensor can hold integer, floating-point, or string values.	
Tensor Processing Unit (TPU)	An ASIC (application-specific integrated circuit) that optimizes the performance of TensorFlow programs.	
Tensor Rank	See rank.	
Tensor Shape	The number of elements a Tensor contains in various dimensions. For example, a [5, 10] Tensor has a shape of 5 in one dimension and 10 in another.	
Tensor Size	The total number of scalars a Tensor contains. For example, a [5, 10] Tensor has a size of 50.	
TensorBoard	The dashboard that displays the summaries saved during the execution of one or more TensorFlow programs.	
TensorFlow	A large-scale, distributed, machine learning platform. The term also refers to the base API layer in the TensorFlow stack, which supports general computation on dataflow graphs.<br><br>Although TensorFlow is primarily used for machine learning, you may also use TensorFlow for non-ML tasks that require numerical computation using dataflow graphs.	
TensorFlow Playground	A program that visualizes how different hyperparameters influence model (primarily neural network) training. Go to http://playground.tensorflow.org to experiment with TensorFlow Playground.	
TensorFlow Serving	A platform to deploy trained models in production.	
Test Set	The subset of the data set that you use to test your model after the model has gone through initial vetting by the validation set.<br><br>Contrast with training set and validation set.	
tf. Example	A standard protocol buffer for describing input data for machine learning model training or inference.	
Time Series Analysis	A subfield of machine learning and statistics that analyzes temporal data. Many types of machine learning problems require time series analysis, including classification, clustering, forecasting, and anomaly detection. For example, you could use time series analysis to forecast the future sales of winter coats by month based on historical sales data.	
Training	The process of determining the ideal parameters comprising a model.	
Training Set	The subset of the data set used to train a model.<br><br>Contrast with validation set and test set.	
Transfer Learning	Transferring information from one machine learning task to another. For example, in multi-task learning, a single model solves multiple tasks, such as a deep model that has different output nodes for different tasks. Transfer learning might involve transferring knowledge from the solution of a simpler task to a more complex one, or involve transferring knowledge from a task where there is more data to one where there is less data.<br><br>Most machine learning systems solve a single task. Transfer learning is a baby step towards artificial intelligence in which a single program can solve multiple tasks.	
True Negative (TN)	An example in which the model correctly predicted the negative class. For example, the model inferred that a particular email message was not spam, and that email message really was not spam.	
True Positive (TP)	An example in which the model correctly predicted the positive class. For example, the model inferred that a particular email message was spam, and that email message really was spam.	
True Positive Rate (TP Rate)	Synonym for recall. That is:<br><br>True Positive Rate=True Positives/(True Positives+False Negatives)<br>True positive rate is the y-axis in an ROC curve.	
Unlabeled Example	An example that contains features but no label. Unlabeled examples are the input to inference. In semi-supervised and unsupervised learning, unlabeled examples are used during training.	
Unsupervised Machine Learning	Training a model to find patterns in a data set, typically an unlabeled data set.<br><br>The most common use of unsupervised machine learning is to cluster data into groups of similar examples. For example, an unsupervised machine learning algorithm can cluster songs together based on various properties of the music. The resulting clusters can become an input to other machine learning algorithms (for example, to a music recommendation service). Clustering can be helpful in domains where true labels are hard to obtain. For example, in domains such as anti-abuse and fraud, clusters can help humans better understand the data.<br><br>Another example of unsupervised machine learning is principal component analysis (PCA). For example, applying PCA on a data set containing the contents of millions of shopping carts might reveal that shopping carts containing lemons frequently also contain antacids.<br><br>Compare with supervised machine learning.	
Validation Set	A subset of the data set—disjunct from the training set—that you use to adjust hyperparameters.<br><br>Contrast with training set and test set.	
Weight	A coefficient for a feature in a linear model, or an edge in a deep network. The goal of training a linear model is to determine the ideal weight for each feature. If a weight is 0, then its corresponding feature does not contribute to the model.	
wide model	"A linear model that typically has many sparse input features. We refer to it as ""wide"" since such a model is a special type of neural network with a large number of inputs that connect directly to the output node. Wide models are often easier to debug and inspect than deep models. Although wide models cannot express nonlinearities through hidden layers, they can use transformations such as feature crossing and bucketization to model nonlinearities in different ways.<br><br>Contrast with deep model."	
Supervised Learning	ML technique where you have the answer for a sub-set of data which is used to learn from large set of data	
Unsupervised Learning	ML technique where you do not have an answer and are relying on her ML algorithm to identify STRUCTURE(patterns or clusters)	
Regression Analysis	predict the value Y for a give n set of X variables	
INTERPOLATION	Prediction of values within your data set	
EXTRAPOLATION	Prediction of values outside your data set	
CATEGORIZATION problem	a problem where there are a FINITE number of answer(YES, NO), (dog, cat, snake)	
REGRESSION Problem	"a problem where there are an infinite amount of answers: ""how much is my house worth?"""	
How do you handle INFINITE attributes in a LEARNING ALGORITHM?	Support Vector Machine	
COST FUNCTION	- function that measures the distance(cost) between the HYPOTHESIS FX and TRAINING SET<br>- a minimization problem	
HYPOTHESIS	- A function we hope represents the actual data set	
HYPOTHESIS FUNCTION	"         <div><img src=""quizlet-5EIHEs8XypZjOxjmaWN5tQ_m.png"" /></div>         "	
GRADIENT DESCENT	"- iterative optimization algorithm<br>- finds local MINIMUM by repeatedly taking steps in the direction of the steepest descent(slope)<br>- the size of the steps is called the ""learning weight"""	
GRADIENT DESCENT EQUATION	"         <div><img src=""quizlet-C2f9wkANIuFwORsoY4dKhQ_m.png"" /></div>         "	
GRADIENT DESCENT STEP SIZE/SLOP	- when alpha (step size, slope) is too small more calculations will be made on the way to the local minimum<br>- when alpha (step size, slope)is too large it may fail to converge or even diverge<br>- as we approach the local minimum the slope gets steeper, eventually reaching 0	
SLOP OBSERVATIONS	- rise/run<br>- larger the slope the steeper<br>- smaller the slope the more gradual<br>- slope of 0 is horizontal line	
tangent line	a straight line is said to be a tangent of a curve y=f(x) at a point x=c on the curve if the line passes through the point (c, f(c)) on the curve and has slope f '(c) where f ' is the derivative of f.	
m x n MATRIX	- m rows<br>- n columns	
MATRIX ADDITION	- must be same dimension	
MATRIX MULTIPLICATION		
MATRIX TRANSPOSE		
MATRIX IDENTITY		
MATRIX SOLVE FIRST POLYNOMIAL		
GRADIENT DESCENT & MATRIX MULTIPLICATION		
Perceptron	A device that makes decisions by weighing up evidence. Takes binary inputs, x1, x2...and produces a single binary output. To compute the output, you weight the importance of inputs to the output. The output, 0 or 1, is determined by whether the sum is less than or greater than a threshold value. <br><br>output={0 if ∑jwjxj≤ threshold<br> 1 if ∑jwjxj > threshold }	
Bias	A measure of how easy it is to get the perceptron to output a 1. Or how easy it is to get the perceptron to fire. If the bias is very negative, it will be diffiult to output a 1.	
Input layer	Inputs like x1 and x2 drawn as a layer of perceptrons, Think of them as units simply defined to output desired values x1, x2....	
Learning Algorithms	can automatically tune the weights and biases of a network of artificial neurons	
Sigmoid Neurons	Sigmoid neurons are similar to perceptrons, but modified so that small changes in their weights and bias cause only a small change in their output. while sigmoid neurons have much of the same qualitative behaviour as perceptrons, they make it much easier to figure out how changing the weights and biases will change the output.	
Sigmoid Function	By using the actual σσ function we get, as already implied above, a smoothed out perceptron. Indeed, it's the smoothness of the σσ function that is the crucial fact	
Cost Function	"We can measure the accuracy of our hypothesis function by using a cost function. This takes an average difference (actually a fancier version of an average) of all the results of the hypothesis with inputs from x's and the actual output y's.<br><br>J(θ0,θ1)=12m∑i=1m(y^i−yi)2=12m∑i=1m(hθ(xi)−yi)2<br>To break it apart, it is 12 x¯ where x¯ is the mean of the squares of hθ(xi)−yi , or the difference between the predicted value and the actual value.<br><br>This function is otherwise called the ""Squared error function"", or ""Mean squared error"". The mean is halved (12) as a convenience for the computation of the gradient descent, as the derivative term of the square function will cancel out the 12 term. The following image summarizes what the cost function does:         <div><img src=""quizlet-N8wW5zNu-MUIPTSpXAp0XQ_m.png"" /></div>         "	
Classification	"To attempt classification, one method is to use linear regression and map all predictions greater than 0.5 as a 1 and all less than 0.5 as a 0. However, this method doesn't work well because classification is not actually a linear function.<br><br>The classification problem is just like the regression problem, except that the values we now want to predict take on only a small number of discrete values. For now, we will focus on the binary classification problem in which y can take on only two values, 0 and 1. (Most of what we say here will also generalize to the multiple-class case.) For instance, if we are trying to build a spam classifier for email, then x(i) may be some features of a piece of email, and y may be 1 if it is a piece of spam mail, and 0 otherwise. Hence, y∈{0,1}. 0 is also called the negative class, and 1 the positive class, and they are sometimes also denoted by the symbols ""-"" and ""+."" Given x(i), the corresponding y(i) is also called the label for the training example."	
Sigmoid Function	"also called the ""Logistic Function""         <div><img src=""quizlet-btBYz9Iw.shWqTqMYig0Fw_m.png"" /></div>         "	
hθ(x)=g(θTx)z=θTxg(z)=11+e−z	The function g(z), shown here, maps any real number to the (0, 1) interval, making it useful for transforming an arbitrary-valued function into a function better suited for classification.<br><br>hθ(x) will give us the probability that our output is 1. For example, hθ(x)=0.7 gives us a probability of 70% that our output is 1. Our probability that our prediction is 0 is just the complement of our probability that it is 1 (e.g. if probability that it is 1 is 70%, then the probability that it is 0 is 30%).<br><br>hθ(x)=P(y=1|x;θ)=1−P(y=0|x;θ)P(y=0|x;θ)+P(y=1|x;θ)=1	
decision boundary	The line that separates the area where y = 0 and where y = 1. It is created by our hypothesis function.	
Logistic Regression Cost Function	We cannot use the same function that we use for linear regression because the Logistic Function will cause the output to be wavy, causing many local optima. In other words, it will not be a convex function.	
Convex optimizationfunction	there can be only one optimal solution, which is globally optimal or you might prove that there is no feasible solution to the problem, while in b) ------- may have multiple locally optimal points and it can take a lot of time to identify whether the problem has no solution or if the solution is global. Hence, the efficiency in time of the ---- --- problem is much better. From my experience a ----- problem usually is much more easier to deal with in comparison to a non ---- problem which takes a lot of time and it might lead you to a dead end.	
Optimization algorithms	Gradient descent; Conjugate gradient; BFGS; L-BFGS	
The advantages of other optimization algorithms over Gradient Descent	- No need to manually pick the alpha - Faster	
The disadvantages of other optimization algorithms over Gradient Descent	more complex	
sigmoid function	"         <div><img src=""quizlet-btBYz9Iw.shWqTqMYig0Fw_m.png"" /></div>         "	
Precision	(true positives) / (# predicted positive)	
Recall	(true positives) / (# actual positive)	
F score	"1/2 * (Precision * Recall) / (Precision + Recall)         <div><img src=""quizlet-TFHdPeF.9SjsCXnCbXH6gA_m.jpg"" /></div>         "	
Large-margin classifier		
Support-vector machine		
Decision boundery		
Kernel	A 'similarity' function	
Gaussian kernel	Defined by a mean and variance. Or in multi-dimentional case, a mean vector and covariance matrix.	
"""Linear kernel"""		
Clustering		
IID	Identically distributed and independently drawn	
Density estimation	Estimating the probability density function from which IID data has been drawn.	
Blind signal separation	The problem of separating mixed data from two sources into the two seperate signals. For example, seperating audio of two people speaking over eachother into the seperate voice signals.	
Factor analysis		
Expectation maximisation	Generalization of k-means clustering, where the correspondence is based on a kernel similarity function, rather than being a hard 0 or 1 based on the closest cluster center.	
Dimensionality reduction	Linear and non-linear.	
Linear Dimensionality Reduction	1) Fit a gaussian distribution.<br>2) Calculate the Gaussian's covariance matrix's eigenvectors.<br>3) Pick eigenvector which maximizes eigenvalues.<br>4) This defines the principal dimension of the data. Project data onto this vector.	
Spectral clustering	Clusters by 'affinity' or closeness of points. Uses <br>principal component analysis.	
Principal component analysis	Find the eigenvectors of the data. The ones with large eigenvalues correspond to the 'principal components' or dimensions of the data.	
What is feature scaling?	method of applying weights to features	
What range is used for feature scaling	0-1	
What is the formula for feature scaling?	(x-xmin)/(xmax-xmin)	
What two algorithms does features scaling help with?	K-means and SVM RBF Kernal	
What two algorithms does features scaling NOT help with?	Linear regression and decision trees	
What are two ways to select features?	SelectPercentile and SelectKBest	
What is SelectPercentile?	Selects the X% of features that are most powerful (where X is a parameter)	
What is SelectKBest?	Selects the K features that are most powerful (where K is a parameter)	
What are two issues with overfitting and underfitting?	High bias and high variance	
What is high bias?	1. Pays little attention to the data<br>2. Oversimplified <br>3. High error on training set	
What is high variance?	1. Pays too much attention to the data<br>2. Much higher error rate on test data<br>3. Considered overfitting	
What is the ideal feature selection?	1. Fit data but with minimum number of features<br>2. Large r2 (proximity of data to to fitted regression line)<br>3. low SSE (sum of squared errors), or the data is close to regression line	
What is regularization?	Finds the ideal number of features to maximize model quality	
What does Lasso Regression do?	Penalizes overfitting	
What is principle component analysis (PCA)?	Repositions the 0 point to the middle of the dataset and redraws the x & y axis<br><br>Loses information by collapsing data into one line	
What are measurable vs latent features?	Latent features are grouping of measurable features<br><br>e.g. given features of a house, what is its price?<br>Measurable - square footage, no of rooms<br>Latent - size, neighborhood	
What are composite features?	Some instances a larger number of smaller features might denote an underlying trend	
What problems are great for unsupervised learning?	Data that isn't cleaned or flagged, e.g. clustering	
What is a good clustering algorithm?	K-means	
What are the two steps to K-means clustering?	1. Assign clusters<br>2. Optimize clusters	
How does K-means optimize itself?	Finds the best centroid by assigning many centroids	
What are some challenges with K-means clustering?	1. Hill climbing algorithm<br>2. Very dependent on where you initially put your centroids<br>3. Cluster changes with a fixed dataset<br>4. Very important to assign clusters initially	
What are the three sets in classifier training?	1. Training<br>2. Validation<br>3. Test	
What two sets are used to train the classifier	1. Training<br>2. Validation	
Why is the test set kept separate?	To avoid overtraining the classifier to the validation and training set	
What is a decision tree?	Tiered set of decision to group and classify a dataset and predict outcomes. e.g.:<br><br>get out of bed (-> make breakfast or exercise) or go back to bed (-> sleep or look at phone) <br>SO, if I get out of bed, I'm not going to look on my phone or sleep	
What is naive bayes?	"Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. e.g.:<br><br>if 90% of spam emails contain ""cheap"" (a feature) then we can estimate that most inbox emails that contain ""cheap"" are spam"	
What is gradient descent?	Method of reducing the error rate in an algorithm by reducing the error on linear regression lines.<br><br>e.g.:<br>Stepping down to the bottom (solution) a mountain (problem) to avoid any cliffs. Make one step, decide the next best step, and so on.	
What is least squares in linear regression?	Square the line to data error and add them up	
What is logistic regression?	Classifies data on a scatter plot and separates that data in the best way possible<br><br>e.g.<br>boys and girls at a high school dance (girls on one side and boys on the other). Draw a line between them and you have logistic regression	
What is the log loss function?	Penalizes errors in gradient descent<br><br>e.g. <br>all kids in high school are hormonal (minor penalty) but the kids that should be in class but skipping are penalized more. Add up all of the errors and you have the quality of students. If you put all the kids skipping class in their own school and all the kids attending in a different school then your error rate would be best optimized to get the best school.	
What is a support vector machine?	Maximize the minimum distance of all errors.<br><br>e.g.<br>The dish is good by itself but to enhance the dish, you put the most amount of salt in a dish without it tasting too salty	
What is a neural network?	Takes an input layer -> hidden layer of logistic regression -> outputs of the hidden layer are binary that go to the output layer<br><br>e.g.<br>is that a house cat? input layer is whiskers, fur, paws, large. Hidden layer finds that cats are small (so the output of the hidden layer is 1, 1, 1 ,0). Because not all features (outputs) from the hidden layers are true, it's not a house cat.	
What is the kernal method?	When you can't use logistical regression because there isn't a clear delineation between the two groups, you need to draw a curved line. Multiply x & y to separate groups on a 3d plane.<br><br>e.g. <br>monkey in the middle. If there are two people on either side of the person in the middle, how do you draw a straight line to separate the two groups (e.g. logistical regression)? You can't. You have to draw a curved line.	
What is k-means clustering?	Finding the centroid of separate groups<br><br>e.g.<br>how do you find out where to draw your service lines in you're a pizza parlor? Find population densities for each pizza location and put your pizza parlor there.	
Machine Learning	A computer program is said to learn from from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.	
Supervised Learning	"we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.<br>Categorized into ""regression"" and ""classification"" problems."	
Regression	We are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function.	
Classification	We are trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories.	
Unsupervised Learning	Allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables.	
Clustering	Derive a structure by grouping the data based on relatiship among the variables	
Linear regression	Trying to fit a linear continuous function to the data. Univariate or Multivariate.	
Hypothesis function	Function to start with - improves with iterations - relies on theta	
Cost Function	"Takes an average (actually a fancier version of an average) of all the results of the hypothesis with inputs from x's compared to the actual output y's. We're using the ""Squared error function""."	
Gradient Descent	is an algorithm to improve a hypothesis function in respect to some cost function.	
convex	Curved Evenly, resembling a segment of the outer edge of a sphere	
Feature Scaling	Mean normalization of data to speed up gradient descend	
Debugging gradient descent	Make a plot with number of iterations on the x-axis. Now plot the cost function, J(θ) over the number of iterations of gradient descent. If J(θ) ever increases, then you probably need to decrease α.	
Automatic convergence test	Declare convergence if J(θ) decreases by less than E in one iteration, where E is some small value such as 10^-3	
Normal Equation	Version of finding the optimum without iteration. No feature scaling!	
Gradient Descent vs Normal Equation	Need to choose alpha No need to choose alpha<br>Needs many iterations No need to iterate<br>Works well when n is large Slow if n is very large	
negative class	Negative means not having the symptoms<br>absense of something - 0	
positive class	presence of something we are looking for - 1	
multiclass classification problem	more classes than the classical 2	
Logistic regression	A kind of regression analysis often used when the dependent variable is dichotomous and scored 0 or 1. It is usually used for predicting whether something will happen or not, such as graduation, business failure, or heart attack-anything that can be expressed as event/non-event. Independent variables may be categorical or continuous in logistic regression analysis.	
sigmoid function	an S-shaped mathamatical curve is often used to describe the activation function of a neuron over time	
Decision boundary	A hypersurface that partitions the underlying vector space into two sets, one for each class.	
One-vs-all classification	Multiclass classification<br>reducing a classification problem with multiple features that have to be predicted to a simple classification problem by looking at one feature at a time. Then to determin the final prediction we take the max of all the predicted values.	
underfitting	"-Coefficients are generally biased (as well as inconsistent) <br>""high bias""<br>Fitting a line to a curve"	
overfitting	"When the model describes an error or noise instead of the actual model. A problem that occurs when data-mining is used to create overly complex models that are not suited to making accurate predictions.<br>""High variance""<br>If we have too many features the learned hypothesis may fit the training set very well, but fails to generalzie to new examples(predict prices on new examples)"	
model selection algorithm	algorithm that automatically selects a good model function for a dataset.	
regularization	penalizing the higher-order parameters to avoid overfitting and getting a simpler hypothesis.	
regularization parameter	lambda - controlls the trade-off between fitting the data well & keeping the parameters small.	
"The ""one learning algorithm"" hypothesis"	Hypothesis that there aren't n different expert systems in the brain but instead all regions of the brain are theoretically capable of doing every path.	
bias unit	x_0 = 1	
weights of the model	parameters of the model in neuronal networks	
hidden layer	The second layer of a three-layer network where the input layer sends its signals, performs intermediary processing	
neural network	Interconnected neural cells. With experience, networks can learn, as feedback strengthens or inhibits connections that produce certain results. Computer simulations of neural networks show analogous learning.	
Forward propagation	In neuronal networks the process of calculating the subsequent layers of the network. Each layer depends on the calculations done on the layer before it.	
architecture	The connectivity pattern of the layers of a neuronal network is also called its :	
Random initialization	Symmetry breaking for neural networks is achieved by:	
autonomous driving	A car driving by itself without human interaction	
Misclassification error	Define Test error as summed error for classification (false prediction)	
Machine learning diagnostic	A test that you can run to gain insight what is/isn't working with a learning algorithm, and gain guidance as to how best improve its performance.	
True positive	Hypotheses correctly predicts positive output.	
True negative	Hypotheses correctly predicts negative output.	
Precision	Of all predicted positives, how many are positive?	
Recall	Of all positives how many were predicted as positive?	
Large data rationale	Assume data available is sufficiently complex to theoretically be able to predict outcome. How big should the data-set be? Use a learning algorithm with many features - low bias - and a large data set - low variance.	
Support vector machine	can extrapolate information from one dimensional data (input space) and some information about weights & correlative relationships to another dimension (feature space)	
gaussian kernel	similarity function with exp(x) - landmark distances	
Memorization	Memorizing, given facts, is an obvious task in learning. This can be done by storing the input samples explicitly, or by identifying the concept behind the input data, and memorizing their general rules.	
Generalization	The ability to identify the rules, to generalize, allows the system to make predictions on unknown data.	
Inductive bias / Learning bias	The set of assumptions that the learner uses to predict outputs given inputs that it has not encountered. E.g. Maximum margin bias (SVM), nearest neighbors bias (knn), etc.	
Loss function	"Tells us how 'bad' a system's prediction is in comparison to the truth. E.g. can be seen as a measure of error.         <div><img src=""quizlet-wTq3yjRzY51WwfbJwPs8jw_m.png"" /></div>         "	
Data generating distribution	Now that we have defined our loss function, we need to consider where the data (training and test) comes from. The model that we will use is the probabilistic model of learning. Namely, there is a probability distribution D over input/output pairs. This is often called the data generating distribution. A useful way to think about D is that it gives high probability to reasonable (x, y) pairs, and low probability to unreasonable (x, y) pairs.	
Expected Loss	"The loss l (loss function) we expect given a data generating distribution D.         <div><img src=""quizlet-bOeLS1EWcKLqcTN5aK7F2Q_m.png"" /></div>         "	
Training error	"The training error is simply our average error over the training<br>data.         <div><img src=""quizlet-iIIcBeLZF4ggESnIpDZtzQ_m.png"" /></div>         "	
Formal definition of induction machine learning	Given (i) a loss function l and (ii) a sample D from some unknown distribution D, you must compute a function f that has low expected error e over D with respect to l.	
Regularization	"Helps avoid overfitting by reducing the magnitude of a certain feature.         <div><img src=""quizlet-rncKT7O03UuD5RQfSIBmMA_m.png"" /></div>         "	
Greedy algorythm	Greedy Algorithm works by making the decision that seems most promising at any moment; it never reconsiders this decision, whatever situation may arise later. They are shortsighted in their approach in the sense that they take decisions on the basis of information at hand without worrying about the effect these decisions may have in the future.	
"""Divide & Conquer"" algorithm"	"A divide and conquer algorithm works by recursively breaking down a problem into two or more sub-problems of the same (or related) type (divide), until these become simple enough to be solved directly (conquer).         <div><img src=""quizlet-4n2zQCBEktVX1m3g5g7brA_m.png"" /></div>         "	
Shallow decision tree	We limit the depth of the decision tree?	
Reasons for failure in ML	*Noise* in the training data: 1) at feature level (e.g. incorrect values such as typos) or 2) at label level (e.g. the wrong label is assigned to a set of features).<br>*Insufficient features*: There are not enough features / data available for a learning algorithm to work.<br>*More than one correct answer*: There might exist more than one correct answer.<br>*Inductive bias* is too far away from the concept that is being learned.	
Hyperparameter	A parameter that controls other parameters in the model. Cannot naively adjusted using the training data but need a validation set or development data because if we do it on the train data we risk overfitting whereas if we do it on the test data we break the rule that test data has always have to be unseen.	
Convergence	Read this: https://www.researchgate.net/post/How_to_proof_the_convergence_properties_of_a_metaheuristic_algorithm	
Hyperspheres	a geometrical figure in four or more dimensions which is analogous to a cube in three dimensions.	
Hypercube	a geometrical figure in four or more dimensions which is analogous to a cube in three dimensions.	
knn scaling	You should normalize when the scale of a feature is irrelevant or misleading, and not normalize when the scale is meaningful.<br>K-means considers Euclidean distance to be meaningful. If a feature has a big scale compared to another, but the first feature truly represents greater diversity, then clustering in that dimension should be penalized.	
How do we measure the *accuracy* of a hypothesis function?	By using a *cost function*, usually denoted by J.	
What is the definition of a *cost function* of a supervised learning problem?	"Takes an average difference of all the results of the hypothesis with inputs from x's and the actual output y's.         <div><img src=""quizlet-DCXY9UhBLk1Z5R23oczyMw_m.png"" /></div>         "	
What are alternative terms of a Cost Function? #2	• *Squared error function*.<br><br>• *Mean squared error*.	
State the algorithm for *gradient descent*.	"Repeat until convergence, where j=0,1 represents the feature index number.         <div><img src=""quizlet-Dxl.Wg.Ewo-R2MW361E8IA_m.png"" /></div>         "	
How does gradient descent converge with a *fixed* step size alpha? #2	"• As we approach a local minimum, gradient descent will take smaller steps. <br><br>• Thus no need to decrease alpha over time.         <div><img src=""quizlet-Ivr7PgBaPgZxEF7jIUPhXg_m.png"" /></div>         "	
What is the algorithm for implementing gradient descent for *linear regression*? #2	"• We can substitute our actual cost function and our actual hypothesis function.<br><br>• m is the size of the training set, theta 0 a constant that will be changing simultaneously with theta 1 and x, y are values of the given training set (data).         <div><img src=""quizlet-Q4kKhskheT39YQHm8lwY2w_m.png"" /></div>         "	
Give a derivation of for a single example in batch gradient descent! (Gradient Descent For Linear Regression)	"Derivation of a single variable in gradient descent.         <div><img src=""quizlet-dsXwf88mfqQc9v3JWuoeLg_m.png"" /></div>         "	
What is *batch gradient descent*? #2 (Gradient Descent For Linear Regression)	• Gradient descent on the original cost function J.<br><br>•This method looks at every example in the entire training set on every step.	
How does batch gradient descent differ from gradient descent? (Gradient Descent For Linear Regression)	While gradient descent can be susceptible to local minima in general, batch gradient descent has only one global, and no other local, optima.	
Depict an example of gradient descent as it is run to minimize a quadratic function. #2	"• shown is the trajectory taken by gradient descent, which was initialized at 48,30.<br><br>• The x's in the figure (joined by straight lines) mark the successive values of theta that gradient descent went through as it converged to its minimum.         <div><img src=""quizlet-lvEgIfClajJAybRPPLBSfg_m.png"" /></div>         "	
What is *multivariate linear regression*?	Linear regression with multiple variables.	
What is the notation for equations where we can have any number of input variables? (Multivariate Linear Regression)	"Notation.         <div><img src=""quizlet-uuplXpvcSC1fCKdWgyjWlQ_m.png"" /></div>         "	
What is the multivariate form of a hypothesis function?	"Multivariate form of the hypothesis function.         <div><img src=""quizlet-uXMsPHFaTcMwoAXEhHeuXw_m.png"" /></div>         "	
What is the intuition of the multivariable form of a hypothesis function in the example of estimating housing prices? #2	"• We can think about theta 0 as the basic price of a house, theta 1 as the price per square meter, theta 2 as the price per floor, etc. <br><br>• x1 will be the number of square meters in the house, x2 the number of floors, etc.         <div><img src=""quizlet-9Wb8EeTJQqLixiAh39OUeQ_m.png"" /></div>         "	
Give the *vectorization* of the multivariable form of a hypothesis function.	"Using the definition of matrix multiplication, our multivariable hypothesis function can be concisely represented as:         <div><img src=""quizlet-9Wb8EeTJQqLixiAh39OUeQ_m.png"" /></div>         "	
Why do we assume that x0=1 in multivariate linear regression?	"Convention.         <div><img src=""quizlet-HAYErl60qjMOXngbxWQzIg_m.png"" /></div>         "	
What is the Gradient Descent for Multiple Variables? #2	"• The gradient descent equation itself is generally the same form.<br><br>• we just have to repeat it for our 'n' features.         <div><img src=""quizlet-DRKXVJIBg8XYVg6kq.5srQ_m.png"" /></div>         "	
How can we *speed up* gradient descent?	We can speed up gradient descent by having each of our input values in roughly the same range.	
Why does *feature scaling* speed up gradient descent? #2	• This is because theta will descend quickly on small ranges and slowly on large ranges.<br><br>• Thus it will oscillate inefficiently down to the optimum when the variables are very uneven.	
What are the ideal ranges of our input variables in gradient descent? #2	• For example a range between minus 1 and 1.<br><br>• These aren't exact requirements; we are only trying to speed things up.	
What is *feature scaling*? #2	• Involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable.<br><br>• Results in a new range of just 1.	
What is *mean normalization*? #2	• Involves subtracting the average value for an input variable from the values for that input variable.<br><br>• Results in a new average value for the input variable of just zero.	
How do you implement both feature scaling and mean normalization? #2	"Feature Scaling and Mean Normalization.         <div><img src=""quizlet-Tsrlr7.JYf1BCbfIdtoG4g_m.png"" /></div>         "	
How can you *debug* gradient descent? #3	• Make a plot with number of iterations on the x-axis. <br><br>• Now plot the cost function J of theta over the number of iterations of gradient descent. <br><br>• If J of theta ever increases, then you probably need to decrease alpha.	
How can the step parameter alpha in gradient descent cause bugs? #2	"• If alpha is too small: slow convergence.<br><br>• If alpha is too large: may not decrease on every iteration and thus may not converge.         <div><img src=""quizlet-LlJydBfuZdEw.SskfJ3DQw_m.png"" /></div>         "	
What is the *Automatic convergence test* in gradient descent? #2	"• Declare convergence if J of theta decreases by less than E in one iteration, where E is some small value such as 0.001.<br><br>• However in practice it's difficult to choose this threshold value.         <div><img src=""quizlet-kG9j.7xfb41Jg9icXtzYYg_m.png"" /></div>         "	
How can we improve our features? (Multivariate Linear Regression) #2	• We can *combine* multiple features into one. <br><br>• For example, we can combine x1 and x2 into a new feature x3 by taking x1 times x2.	
How can we *improve* the form of our hypothesis function? (Multivariate Linear Regression)	"By making it a *quadratic*, cubic or square root function (or any other form).         <div><img src=""quizlet-reFj0aYGX7BdYnIs7yVS1w_m.png"" /></div>         "	
What important thing should one keep in mind if one changes the form of a hypothesis function? (Multivariate Linear Regression) #2	• If you create new features when doing polynomial regression then *feature scaling* becomes very important.<br><br>• For example, if x has range 1 - 1000 then range of x^2 becomes 1 - 1000000.	
State the *normal equation formula*!	"Normal Equation Formula.         <div><img src=""quizlet-1iSzZQMTJODqG4RLGpP71g_m.png"" /></div>         "	
Compare gradient descent and the normal equation!	"The following is a comparison of gradient descent and the normal equation:         <div><img src=""quizlet-X6V-JWkvSIE78buQu1LkSg_m.png"" /></div>         "	
Does feature scaling speed up the implementation of the normal equation?	There is *no need* to do feature scaling with the normal equation.	
What is the complexity of computing the inversion with the normal equation?	With the normal equation, computing the inversion has complexity of n cubed.	
When might it be a good time to go from a normal solution to an iterative process?	When the number of examples exceeds *10,000* due to the complexity of the normal equation.	
Which function do we want to use in octave when implementing the normal equation? #2	• Use the 'pinv' function rather than 'inv'.<br><br>• The 'pinv' function will give you a value of theta even if X Transpose X is not invertible.	
What are common causes for X Transpose X to be *noninvertible*? #2	"• Redundant features, where two features are very closely related (i.e. they are linearly dependent).<br><br>• Too many features (e.g. m ≤ n). In this case, delete some features or use ""regularization""."	
How do we change the form of our binary hypothesis function to be continuous in the range between 0 and 1?	"By using the *Sigmoid Function*, also called the *Logistic Function*.         <div><img src=""quizlet-yVl2KU8l5tCFdQJVcIIhYw_m.png"" /></div>         "	
How can we interpret the output of our logistic function?	"h of theta of a given input variable give us the probability that our output is 1.         <div><img src=""quizlet-MkFAR6DCdjwZlnUDjPcgpw_m.png"" /></div>         "	
How can we get our discrete 0 or 1 classification from a logistic function?	"We can translate the output of the hypothesis function as follows:         <div><img src=""quizlet-G.VqUTsV60tXFRvZm.WO3g_m.png"" /></div>         "	
What is the *decision boundary* given a logistic function? #2	"• The decision boundary is the line that separates the area where y = 0 and where y = 1. <br><br>• It is created by our hypothesis function.         <div><img src=""quizlet-1ZRpg1AWJTPXPsRhNbddnA_m.png"" /></div>         "	
How does the *cost function* for a logistic regression look like? #2	"• We cannot use the same cost function that we use for linear regression because the Logistic Function will cause the output to be wavy, causing many local optima. <br><br>• In other words, it will not be a convex function.         <div><img src=""quizlet-labBi2nFliNonX54lH9WBg_m.png"" /></div>         "	
Plot the cost function J, if the correct answer for y is 1.	"• If our correct answer 'y' is 1, then the cost function will be 0 if our hypothesis function outputs 1. <br><br>• If our hypothesis approaches 0, then the cost function will approach infinity.         <div><img src=""quizlet-ltqqIJdsbPMLT8INUY1K7w_m.png"" /></div>         "	
Plot the cost function, if the correct answer for y is 0. #2	"• If our correct answer 'y' is 0, then the cost function will be 0 if our hypothesis function also outputs 0.<br><br>• If our hypothesis approaches 1, then the cost function will approach infinity.         <div><img src=""quizlet-jgsywUrcFPnihr6ef5jU-A_m.png"" /></div>         "	
How can we *simplify* our cost function? (Logistic Regression Model)	"We can compress our cost function's two conditional cases into one case.         <div><img src=""quizlet-rB4zNZtWE83Eg8CLF7nxWg_m.png"" /></div>         "	
Give the vectorized implementation of our simplified cost function! (Logistic Regression Model)	"A vectorized implementation is:         <div><img src=""quizlet-BWHZY4IYh3rEqRi-lF3VfQ_m.png"" /></div>         "	
Give the vectorized implementation for Gradient Descent! (Logistic Regression Model)	"A vectorized implementation is:         <div><img src=""quizlet-LnlClZI6P-R62SO.xT73Lg_m.png"" /></div>         "	
What is *gradient descent* for our simplified cost function? (Logistic Regression Model) #2	"• Notice that this algorithm is identical to the one we used in linear regression. <br><br>• We still have to simultaneously update all values in theta.         <div><img src=""quizlet-vSVjH2GcbL9yqsb0L015sA_m.png"" /></div>         "	
Depict an example of *One-versus-all* to classify 3 classes! (Multiclass Classification)	"The following image shows how one could classify 3 classes:         <div><img src=""quizlet--hlNrfj9.ITWEkcHGyGPbg_m.png"" /></div>         "	
What is the implementation of *One-versus-all* in Multiclass Classification? #2	"• Train a logistic regression classifier h of theta for each class to predict the probability that y = i .<br><br>• To make a prediction on a new x, pick the class that maximizes h of theta.         <div><img src=""quizlet-WdFaSA5JOkx7o001DAW1cQ_m.png"" /></div>         "	
What is *underfitting*?	"Underfitting, or high bias, is when the form of our hypothesis function h maps poorly to the trend of the data.         <div><img src=""quizlet-jLxtxiKTg3oU7LCqQDUGkQ_m.png"" /></div>         "	
What usually *causes* underfitting?	It is usually caused by a function that is too simple or uses too few features.	
What is *overfitting*?	"Overfitting, or *high variance*, is caused by a hypothesis function that fits the available data but does not generalize well to predict new data.         <div><img src=""quizlet-BDIF2TdOXUd6md1XKY6Iaw_m.png"" /></div>         "	
What usually *causes* overfitting?	It is usually caused by a complicated function that creates a lot of unnecessary curves and angles unrelated to the data.	
What are the two *main options* to address the issue of overfitting? #4	*Reduce the number of features*:<br>• Manually select which features to keep.<br>• Use a model selection algorithm.<br><br>*Regularization*:<br>• Keep all the features, but reduce the magnitude of parameters theta j.<br>• Regularization works well when we have a lot of slightly useful features.	
In a basic sense, what are *neurons*?	"Neurons are basically computational units that take inputs, called *dendrites*, as electrical inputs, called ""spikes"", that are channeled to outputs , called *axons*."	
What are the *dendrites* in the model of neural networks?	In our model, our dendrites are like the input features.	
What are the *axons* in the model of neural networks?	In our model, the axons are the results of our hypothesis function.	
What is the *bias unit* of a neural network? #2	"• The input node x0 is sometimes called the ""bias unit."" <br><br>• It is always equal to 1."	
What are the *weights* of a neural network?	"Using the logistic function, our ""theta"" parameters are sometimes called ""weights""."	
What is the *activation* function of a neural network?	The logistic function (as in classification) is also called a *sigmoid (logistic) activation function*.	
How do we label the hidden layers of a neural network? #2	"• We label these intermediate or hidden layer nodes.<br><br>• The nodes are also called *activation units*.         <div><img src=""quizlet-LhoVOiOeI7yv3dmeD4i9kw_m.png"" /></div>         "	
How do we determine the dimension of the matrices of weights? (Neural Network) #2	"• The +1 comes from the addition of the ""bias nodes.<br><br>• In other words the output nodes will not include the bias nodes while the inputs will.         <div><img src=""quizlet-i4OUI7CQJfpW7DJUmoDiFQ_m.png"" /></div>         "	
How do we obtain the values for each of the activation nodes, given a single-layer neural network with 3 activation nodes and a 4-dimensional input? #2	"• We apply each row of the parameters to our inputs to obtain the value for one activation node.<br><br>• Our hypothesis output is the logistic function applied to the sum of the values of our activation nodes, which have been multiplied by the parameter matrix theta 2.         <div><img src=""quizlet-j3Oe.kS4ZooRyFgkoR2A8Q_m.png"" /></div>         "	
Give an example of the implementation of the *OR-function* as a neural network!	"The following is an example of the logical operator 'OR', meaning either x1 is true or x2 is true, or both:         <div><img src=""quizlet-CH6UzELNcU-jvwgM7TAKhg_m.png"" /></div>         "	
Give an example of the implementation of the *AND-function* as a neural network!	"The following is an example of the logical operator AND, meaning it s only true if both x1 and x2 are 1.         <div><img src=""quizlet-YbHRrvsT6vjCkscdGPsdFg_m.png"" /></div>         "	
What are the theta-matrices for implementing the logical functions 'AND', 'NOR', and 'OR' as a neural network?	"Theta Matrices for Neural Network implementation.         <div><img src=""quizlet-iMNUuNheDeXgGH5lDNp3nQ_m.png"" /></div>         "	
How can we implement the 'XNOR' operator with a neural network?	"We can implement the 'XNOR' operator by using two hidden layers.         <div><img src=""quizlet-1UTY89D3GSnznCvGx3vezQ_m.png"" /></div>         "	
Give an example of a neural network which classifies data into one of four categories!	"The inner layers, each provide us with some new information which leads to our final hypothesis function.         <div><img src=""quizlet-xRmODWe9MT18dOBGW2AWAA_m.png"" /></div>         "	
State the *cost function* for neural networks. #3	"• the double sum simply adds up the logistic regression costs calculated for each cell in the output layer.<br><br>• the triple sum simply adds up the squares of all the individual theta s in the entire network.<br><br>• the i in the triple sum does not refer to training example i.         <div><img src=""quizlet-VIr6aALLegw3H8E4ElHAvQ_m.png"" /></div>         "	
How are the variables L, s of l and K in the cost function of a neural network defined? #3	• L = total number of layers in the network.<br><br>• s of l = number of units (not counting bias unit) in layer l.<br><br>• K = number of output units.	
Define *Backpropagation* for neural networks.	*Backpropagation* is neural-network terminology for *minimizing* our cost function.	
What does the matrix Delta in the Back propagation algorithm do?	"The capital-delta matrix D is used as an ""accumulator"" to add up our values as we go along and eventually compute our partial derivative.         <div><img src=""quizlet-HyjbPd.wbWuJmoysx4FyPQ_m.png"" /></div>         "	
State the *Backpropagation algorithm*.	"Backpropagation algorithm.         <div><img src=""quizlet-4chnvX1uZZuC2DITySIJHA_m.png"" /></div>         "	
Which method randomly initializes our weights for our Theta matrices of a neural network?	"We initialize each Theta l,i,j to a random value between minus epsilon and epsilon.         <div><img src=""quizlet-h9sXbyqj3xnAdie7Yj6O4w_m.png"" /></div>         "	
Give the setup of using a neural network. #4	• Pick a network *architecture*.<br><br>• choose the *layout* of your neural network.<br><br>• Number of input units; dimension of features x i.<br><br>• Number of output units; number of classes.<br><br>• Number of hidden units per layer; usually more the better.	
How does one *train* a neural network? #6	"1. Randomly initialize the weights.<br><br>2. Implement forward propagation.<br><br>3. Implement the cost function.<br><br>4. Implement backpropagation.<br><br>5. Use gradient checking to confirm that your backpropagation works. <br><br>6. Use gradient descent to minimize the cost function with the weights in theta.         <div><img src=""quizlet-nAwEVFvbW.kPmWyYRZ4.GQ_m.png"" /></div>         "	
What code is implemented if we perform forward *and* back propagation?	"When we perform forward and back propagation, we loop on every training example.         <div><img src=""quizlet-CBB8T8ok8y6ZHN5e19Yicw_m.png"" /></div>         "	
How can we break down our decision process *deciding what to do next*? #6	• *Getting more training examples*: Fixes high variance.<br><br>• *Trying smaller sets of features*: Fixes high variance.<br><br>• *Adding features*: Fixes high bias.<br><br>• *Adding polynomial features*: Fixes high bias.<br><br>• *Decreasing lambda*: Fixes high bias.<br><br>• *Increasing lambda*: Fixes high variance.	
What issue poses a neural network with fewer parameters?	A neural network with fewer parameters is *prone to underfitting*.	
What issue poses a neural network with more parameters?	A large neural network with more parameters is *prone to overfitting*.	
How can you address the overfitting of a large neural network?	In this case you can use regularization (increase λ) to address the overfitting.	
What bias-variance tradeoff do lower-order polynomials (low model complexity) have?	Lower-order polynomials (low model complexity) have *high bias* and *low variance*.	
What is the issue with higher-oder polynomials in regard to fitting the training data and test data?	Higher-order polynomials (high model complexity) fit the *training data* extremely well and the *test data* extremely poorly.	
What bias-variance tradeoff do higher-order polynomials (high model complexity) have?	Higher-order polynomials (high model complexity) have low bias on the training data, but very high variance.	
Why does training an algorithm on a very few number of data points easily have 0 errors?	Because we can always find a quadratic curve that touches exactly those number of points.	
How does one experience *high bias* with a low training set size?	"*Low training set size*: causes J train of theta to be low and J CV of theta to be high.         <div><img src=""quizlet-jHLfdurJG41U2LsGApIwfA_m.png"" /></div>         "	
How does one experience *high bias* with a large training set size?	"*Large training set size*: causes both J train of theta and J CV of theta to be high with J train approximately equal to J CV.         <div><img src=""quizlet-jHLfdurJG41U2LsGApIwfA_m.png"" /></div>         "	
What approach will not generally help much by itself, when a learning algorithm is suffering from high bias?	If a learning algorithm is suffering from high bias, *getting more training data* will not (by itself) help much.	
How does one experience *high variance* with a low training set size?	"*Low training set size*: J train of theta will be low and J CV of theta will be high.         <div><img src=""quizlet-nIm4ZxTMlI4f2WtVLkIfNw_m.png"" /></div>         "	
How does one experience *high variance* with a large training set size?	"*Large training set size*: J train of theta increases with training set size and J CV of theta continues to decrease without leveling off.         <div><img src=""quizlet-nIm4ZxTMlI4f2WtVLkIfNw_m.png"" /></div>         "	
Under which circumstances will *getting more training data* help a learning algorithm to perform better?	If a learning algorithm is suffering from high variance, *getting more training data* is likely to help.	
What is the relationship between the degree of the polynomial d and the underfitting or overfitting of our hypothesis? #2	"• *High bias (underfitting)*: both J train(Θ) and J CV(Θ) will be high. Also, J CV(Θ) is approximately equal to J train(Θ).<br><br>• *High variance (overfitting)*: J train(Θ) will be low and J CV(Θ) will be much greater than J train(Θ).         <div><img src=""quizlet-VAp4DMEctpwT2sCLlzk33w_m.png"" /></div>         "	
Which 3 separate error values can we calculate, if we break down our dataset as such: • Training set: 60%. • Cross validation set: 20%. • Test set: 20%.	1. Optimize the parameters in Theta (Θ) using the training set for each polynomial degree.<br><br>2. Find the polynomial degree d with the least error using the cross validation set.<br><br>3. Estimate the generalization error using the test set with J test, using d = theta from polynomial with lower error.	
Which function returns the values for jVal and gradient in a single turn?	"function [jVal, gradient] = costFunction(theta)<br> jVal = [...code to compute J(theta)...];<br> gradient = [...code to compute derivative of J(theta)...];<br>end         <div><img src=""quizlet-CBPUi8hLkKToVkscbfqxNA_m.png"" /></div>         "	
Given costFunction(), what do we have to do to implement fminunc()?	"we can use octave's ""fminunc()"" optimization algorithm along with the ""optimset()"" function that creates an object containing the options we want to send to ""fminunc()""         <div><img src=""quizlet-9fFyyVJO-rPptY9NzjhSDg_m.png"" /></div>         "	
How can we approach regularization using the alternate method of the non-iterative normal equation?	"To add in regularization, the equation is the same as our original, except that we add another term inside the parentheses:         <div><img src=""quizlet-N3wLpGg0kCXGVFmMHk9p4A_m.png"" /></div>         "	
Given a training set and a test set, what is the new procedure for evaluating a hypothesis?	The new procedure using these two sets is then:<br><br>1. Learn Θ and minimize Jtrain(Θ) using the training set<br>2. Compute the test set error Jtest(Θ)	
What is the test set error for linear regression?	"For linear regression         <div><img src=""quizlet-NsPHMytGuZeCrlO7QM4INg_m.png"" /></div>         "	
What is the test set error for linear classification?	"For classification ~ Misclassification error (aka 0/1 misclassification error):         <div><img src=""quizlet-8CKXEAy2SnlCSw8PapVUlQ_m.png"" /></div>         "	
What is the average test error for the test set?	"The average test error for the test set is.<br><br>This gives us the proportion of the test data that was misclassified.         <div><img src=""quizlet-sY-kgf3p4tYdu0C9W99l.w_m.png"" /></div>         "	
Just because a learning algorithm fits a training set well, that does not mean [...]	Just because a learning algorithm fits a training set well, that does not mean it is a good hypothesis.	
The error of your hypothesis as measured on the data set with which you trained the parameters will be [...]	The error of your hypothesis as measured on the data set with which you trained the parameters will be lower than any other data set.	
Model Selection without the validation set?	1. Optimize the parameters in Θ using the training set for each polynomial degree.<br><br>2. Find the polynomial degree d with the least error using the test set.<br><br>3. Estimate the generalization error also using the test set with Jtest(Θ(d)), (d = theta from polynomial with lower error);	
What is the consequence of selecting a model without the validation set?	In this case, we have trained one variable, d, or the degree of the polynomial, using the test set. This will cause our error value to be greater for any other set of data.	
How can we solve the problem of selecting a model with only the training set?	To solve this, we can introduce a third set, the Cross Validation Set, to serve as an intermediate set that we can train d with. <br><br>Then our test set will give us an accurate, non-optimistic error.	
Model Selection with the validation set?	1. Optimize the parameters in Θ using the training set for each polynomial degree.<br><br>2. Find the polynomial degree d with the least error using the cross validation set.<br><br>3. Estimate the generalization error using the test set with Jtest(Θ(d)), (d = theta from polynomial with lower error);	
What are the benefits of selecting a model with the validation set?	This way, the degree of the polynomial d has not been trained using the test set.<br><br>note: be aware that using the CV set to select 'd' means that we cannot also use it for the validation curve process of setting the lambda value	
High bias (underfitting):	"both Jtrain(Θ) and JCV(Θ) will be high. Also, JCV(Θ)≈Jtrain(Θ)         <div><img src=""quizlet-Tr5xo2HzmXi.GESjl-rgzg_m.png"" /></div>         "	
High variance (overfitting):	"Jtrain(Θ) will be low and JCV(Θ) will be much greater thanJtrain(Θ).         <div><img src=""quizlet-Tr5xo2HzmXi.GESjl-rgzg_m.png"" /></div>         "	
A large lambda [...], which [...].	A large lambda heavily penalizes all the Θ parameters, which greatly simplifies the line of our resulting function, so causes underfitting.	
The relationship of λ to the training set and the variance set is as follows:  Low λ:	"Jtrain(Θ) is low and JCV(Θ) is high (high variance/overfitting).         <div><img src=""quizlet-6lcU-Kqq72MBdKBRB6wJ9w_m.png"" /></div>         "	
The relationship of λ to the training set and the variance set is as follows:  Intermediate λ:	"Jtrain(Θ) and JCV(Θ) are somewhat low and Jtrain(Θ)≈JCV(Θ).         <div><img src=""quizlet-6lcU-Kqq72MBdKBRB6wJ9w_m.png"" /></div>         "	
The relationship of λ to the training set and the variance set is as follows:  Large λ	"both Jtrain(Θ) and JCV(Θ) will be high (underfitting /high bias)         <div><img src=""quizlet-6lcU-Kqq72MBdKBRB6wJ9w_m.png"" /></div>         "	
What do we need in order to choose the model and the regularization λ?	1. Create a list of lambdas (i.e. λ∈{0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24});<br>2. Create a set of models with different degrees or any other variants.<br><br>3. Iterate through the λs and for each λ go through all the models to learn some Θ.<br><br>4. Compute the cross validation error using the learned Θ (computed with λ) on the JCV(Θ) without regularization or λ = 0.<br><br>5. Select the best combo that produces the lowest error on the cross validation set.<br><br>6. Using the best combo Θ and λ, apply it on Jtest(Θ) to see if it has a good generalization of the problem.	
As the training set gets larger, the error [...] increases.	As the training set gets larger, the error for a quadratic function increases.	
The error value will [...] after a certain m, or training set size.	The error value will plateau out after a certain m, or training set size.	
With high bias  Low training set size: [...]	Low training set size: causes Jtrain(Θ) to be low and JCV(Θ) to be high.	
With high bias  Large training set size: [...]	Large training set size: causes both Jtrain(Θ) and JCV(Θ) to be high with Jtrain(Θ)≈JCV(Θ).	
With high variance  Low training set size: [...]	Low training set size: Jtrain(Θ) will be low and JCV(Θ) will be high.	
With high variance  Large training set size:	Large training set size: Jtrain(Θ) increases with training set size and JCV(Θ) continues to decrease without leveling off. <br>lso, Jtrain(Θ)<JCV(Θ) but the difference between them remains significant.	
"How can we tell which parameters Θ to leave in the model (known as ""model selection"")?"	There are several ways to solve this problem:<br><br>- Get more data (very difficult).<br>- Choose the model which best fits the data without overfitting (very difficult).<br>- Reduce the opportunity for overfitting through regularization.	
Bias: approximation error (Difference between expected value and optimal value)	- High Bias = UnderFitting (BU)<br>- Jtrain(Θ) and JCV(Θ) both will be high and Jtrain(Θ) ≈ JCV(Θ)	
Variance: estimation error due to finite data	- High Variance = OverFitting (VO)<br>- Jtrain(Θ) is low and JCV(Θ) ≫Jtrain(Θ)	
Intuition for the bias-variance trade-off:  Complex model => [...]	Complex model => sensitive to data => much affected by changes in X => high variance, low bias.	
Intuition for the bias-variance trade-off:  Simple model => [...]	Simple model => more rigid => does not change as much with changes in X => low variance, high bias.	
Regularization Effects?	- Small values of λ allow model to become finely tuned to noise leading to large variance => overfitting.<br><br>- Large values of λ pull weight parameters to zero leading to large bias => underfitting	
Model Complexity Effects?	Lower-order polynomials (low model complexity) have high bias and low variance. In this case, the model fits poorly consistently.<br><br>Higher-order polynomials (high model complexity) fit the training data extremely well and the test data extremely poorly. These have low bias on the training data, but very high variance.<br><br>In reality, we would want to choose a model somewhere in between, that can generalize well but also fits the data reasonably well.	
A typical rule of thumb when running diagnostics is?	More training examples fixes high variance but not high bias.<br><br>Fewer features fixes high variance but not high bias.<br><br>Additional features fixes high bias but not high variance.<br><br>The addition of polynomial and interaction features fixes high bias but not high variance.<br><br>When using gradient descent, decreasing lambda can fix high bias and increasing lambda can fix high variance (lambda is the regularization parameter).<br><br>When using neural networks, small neural networks are more prone to under-fitting and big neural networks are prone to over-fitting. Cross-validation of network size is a way to choose alternatives.	
Different ways we can approach a machine learning problem?	"Collect lots of data (for example ""honeypot"" project but doesn't always work)<br><br>Develop sophisticated features (for example: using email header data in spam emails)<br><br>Develop algorithms to process your input in different ways (recognizing misspellings in spam)."	
The recommended approach to solving machine learning problems is?	Start with a simple algorithm, implement it quickly, and test it early.<br><br>Plot learning curves to decide if more data, more features, etc. will help<br><br>Error analysis: manually examine the errors on examples in the cross validation set and try to spot a trend.	
It's important to get error results as [...]. Otherwise it is difficult to [...]	It's important to get error results as a single, numerical value. Otherwise it is difficult to assess your algorithm's performance	
It is sometimes difficult to tell whether a reduction in error is actually an improvement of the algorithm. When does this usually happen?	This usually happens with skewed classes; that is, when our class is very rare in the entire data set.<br><br>Or to say it another way, when we have lot more examples from one class than from the other clas	
Predicted: 1, Actual: 1	Predicted: 1, Actual: 1 --- True positive	
Predicted: 0, Actual: 0	Predicted: 0, Actual: 0 --- True negative	
Predicted: 0, Actual, 1	Predicted: 0, Actual, 1 --- False negative	
Predicted: 1, Actual: 0	Predicted: 1, Actual: 0 --- False positive	
Precision: of all patients we predicted where y=1, [...]	"Precision: of all patients we predicted where y=1, what fraction actually has cancer?         <div><img src=""quizlet-dKDeQxMTZqgvzZagc2yl.A_m.png"" /></div>         "	
Recall: Of all the patients that actually have cancer, what [...]	"Recall: Of all the patients that actually have cancer, what fraction did we correctly detect as having cancer?         <div><img src=""quizlet-xWA2r4fz5jDMzakLms.NQA_m.png"" /></div>         "	
When is the F1 score not defined?	if an algorithm predicts only negatives like it does in one of exercises, the precision is not defined, it is impossible to divide by 0.	
We might want a confident prediction of two classes using logistic regression. One way is to [...]	"We might want a confident prediction of two classes using logistic regression. One way is to increase our threshold.<br><br>This way, we only predict cancer if the patient has a 70% chance.         <div><img src=""quizlet-EvEDZb9ydw2eLYxYpcSlXA_m.png"" /></div>         "	
What tradeoff will we have if we want a more confident prediction of two classes using logistic regression?	Doing this, we will have higher precision but lower recall (refer to the definitions in the previous section).	
What is the result if we want to get a very safe prediction?	"This will cause higher recall but lower precision.         <div><img src=""quizlet-o-mg90tznGbckO6aneQrzA_m.png"" /></div>         "	
Trading Off Precision and Recal  The greater the threshold, the [...]	The greater the threshold, the greater the precision and the lower the recall.	
Trading Off Precision and Recal  The lower the threshold, the [...]	The lower the threshold, the greater the recall and the lower the precisio	
Trading Off Precision and Recal  In order to turn these two metrics into one single number, we can [...]	"In order to turn these two metrics into one single number, we can take the F value.         <div><img src=""quizlet-.NnyIp-eXsdb38rNHfxblA_m.png"" /></div>         "	
In order for the F Score to be large, [...]	In order for the F Score to be large, both precision and recall must be large.	
We want to train precision and recall on the [...]	We want to train precision and recall on the cross validation set so as not to bias our test set	
"In certain cases, an ""inferior algorithm,"" if given [...], can [...]"	"In certain cases, an ""inferior algorithm,"" if given enough data, can outperform a superior algorithm with less data."	
We must choose our features to have [...].  A useful test is: [...]	We must choose our features to have enough information. <br><br>A useful test is: Given input x, would a human expert be able to confidently predict y?	
"What is the ""Rationale for large data""?"	Rationale for large data: if we have a low bias algorithm (many features or hidden units making a very complex function), then the larger the training set we use, the less we will have overfitting (and the more accurate the algorithm will be on the test set).	
The Support Vector Machine (SVM) is yet another type of supervised machine learning algorithm. It is sometimes [...]	The Support Vector Machine (SVM) is yet another type of supervised machine learning algorithm. It is sometimes cleaner and more powerful.	
To make a support vector machine, we will modify the first term of the cost function so that [...]	"To make a support vector machine, we will modify the first term of the cost function so that when θTx (from now on, we shall refer to this as z) is greater than 1, it outputs 0.         <div><img src=""quizlet-eA3bmBK9sbmkF81qNYGQWA_m.png"" /></div>         "	
Similarly (to make a support vector machine), we modify the second term of the cost function so that [...]	"Similarly (to make a support vector machine), we modify the second term of the cost function so that when z is less than -1, it outputs 0.         <div><img src=""quizlet-19ZS5TKWlFrOZmpv-YXVdg_m.png"" /></div>         "	
How are the terms We shall cost1(z) and cost0(z) in a SVM defined?	"cost1(z) is the cost for classifying when y=1, and cost0(z) is the cost for classifying when y=0         <div><img src=""quizlet-di-WI3E-pZb2YvWF-yjmwQ_m.png"" /></div>         "	
How do we transform the cost function from (regularized) logistic regression for SVMs?	"We may transform this into the cost function for support vector machines by substituting cost0(z) and cost1(z):         <div><img src=""quizlet-BcvU3P4He54ST-j-e0aDRg_m.png"" /></div>         "	
What is the convention when using regularization in SVMs?	"onvention dictates that we regularize using a factor C, instead of λ, like so:<br><br>This is equivalent to multiplying the equation by C=1/λ.         <div><img src=""quizlet-suR0kX5Kk-XTm.XrSrdRcQ_m.png"" /></div>         "	
Finally, note that the hypothesis of the Support Vector Machine is not interpreted as [...] (as it is for the hypothesis of logistic regression). Instead, it [...]	"Finally, note that the hypothesis of the Support Vector Machine is not interpreted as the probability of y being 1 or 0 (as it is for the hypothesis of logistic regression). Instead, it outputs either 1 or 0.         <div><img src=""quizlet-Ra49cinXYPH2eifGSoiUJQ_m.png"" /></div>         "	
A useful way to think about Support Vector Machines is to think of them as [...]	"A useful way to think about Support Vector Machines is to think of them as Large Margin Classifiers         <div><img src=""quizlet-TaIajxOxrrV.EDSRfVwnIQ_m.png"" /></div>         "	
Large Margin Intuition  If C is very large, we must choose Θ parameters such that [...]	"If C is very large, we must choose Θ parameters such that:         <div><img src=""quizlet-3qjaSjJOyRXuE-xts0tqHQ_m.png"" /></div>         "	
In SVMs, the decision boundary has the special property that it is [...]	In SVMs, the decision boundary has the special property that it is as far away as possible from both the positive and the negative examples.	
The [...] is called the margin.	The distance of the decision boundary to the nearest example is called the margin.	
Since SVMs maximize this margin, it is often called a [...]	Since SVMs maximize this margin, it is often called a Large Margin Classifier.	
The SVM will separate the negative and positive examples by a large margin.  This large margin is only achieved when [...]	This large margin is only achieved when C is very large.	
Data is linearly separable when [...]	Data is linearly separable when a straight line can separate the positive and negative examples.	
If we have [...], then we can reduce C.	If we have outlier examples that we don't want to affect the decision boundary, then we can reduce C.	
Increasing and decreasing C is similar to [...], and can [...]	Increasing and decreasing C is similar to respectively decreasing and increasing λ, and can simplify our decision boundary.	
Kernels allow us to [...]	Kernels allow us to make complex, non-linear classifiers using Support Vector Machines.	
"Ho do we find the ""similarity"" of x and some landmark l(i)?"	"the ""similarity"" of x and some landmark l(i):         <div><img src=""quizlet-z8t7MnB4zYWP1NoyzQtVuA_m.png"" /></div>         "	
What are the properties of the similarity function?	"There are a couple properties of the similarity function:         <div><img src=""quizlet-UzXWD-z37vwgO3MJHCK4LQ_m.png"" /></div>         "	
In other words, if x and the landmark are close, then [...], and if x and the landmark are far away from each other, the [...]	In other words, if x and the landmark are close, then the similarity will be close to 1, and if x and the landmark are far away from each other, the similarity will be close to 0.	
Each landmark gives us [...]	"Each landmark gives us the features in our hypothesis:         <div><img src=""quizlet-aXq7l1QhyNNnWivpFy8jZg_m.png"" /></div>         "	
One way to get the landmarks is to [...]	One way to get the landmarks is to put them in the exact same locations as all the training examples.	
If C is large, then we get [...]	If C is large, then we get higher variance/lower bias	
If C is small, then we get [...]	If C is small, then we get lower variance/higher bias	
With a large σ2, the features fi [...]	With a large σ2, the features fi vary more smoothly, causing higher bias and lower variance.	
With a small σ2, the features fi [...]	With a small σ2, the features fi vary less smoothly, causing lower bias and higher variance	
There are lots of good SVM libraries already written. A. Ng often uses [...]	There are lots of good SVM libraries already written. A. Ng often uses 'liblinear' and 'libsvm'.	
Using An SVM  In practical application, the choices you do need to make are: [...]	"Choice of parameter C<br><br>Choice of kernel (similarity function)<br><br>No kernel (""linear"" kernel) -- gives standard linear classifier<br><br>Choose when n is large and when m is small<br><br>Gaussian Kernel (above) -- need to choose σ2<br><br>Choose when n is small and m is large"	
Note: do perform [...] before using the Gaussian Kernel.	Note: do perform feature scaling before using the Gaussian Kernel.	
Note: not all similarity functions are valid kernels. They must satisfy [...] which guarantees that the SVM package's optimizations [...]	"Note: not all similarity functions are valid kernels. They must satisfy ""Mercer's Theorem"" which guarantees that the SVM package's optimizations run correctly and do not diverge."	
Logistic Regression vs. SVMs  If n is large (relative to m), then [...]	"If n is large (relative to m), then use logistic regression, or SVM without a kernel (the ""linear kernel"")<br><br>In the second example, we have enough examples that we may need a complex non-linear hypothesis"	
Logistic Regression vs. SVMs  If n is small and m is intermediate, then [...]	If n is small and m is intermediate, then use SVM with a Gaussian Kernel<br><br>In the second example, we have enough examples that we may need a complex non-linear hypothesis	
Logistic Regression vs. SVMs  If n is small and m is large, then [...]	If n is small and m is large, then manually create/add more features, then use logistic regression or SVM without a kernel.<br><br> In the last case, we want to increase our features so that logistic regression becomes applicable.	
Unsupervised learning is contrasted from supervised learning because it [...]	Unsupervised learning is contrasted from supervised learning because it uses an unlabeled training set rather than a labeled one.	
Clustering is good for [...]	Market segmentation<br><br>Social network analysis<br><br>Organizing computer clusters<br><br>Astronomical data analysis	
The K-Means Algorithm is the most popular and widely used algorithm for [...]	The K-Means Algorithm is the most popular and widely used algorithm for automatically grouping data into coherent subsets.	
K-Means Algorithm	Randomly initialize two points in the dataset called the cluster centroids.<br><br>Cluster assignment: assign all examples into one of two groups based on which cluster centroid the example is closest to.<br><br>Move centroid: compute the averages for all the points inside each of the two cluster centroid groups, then move the cluster centroid points to those averages.<br><br>Re-run (2) and (3) until we have found our clusters.	
K-Means Algorithm  Our main variables are [...]	K (number of clusters)<br><br>Training set x(1),x(2),...,x(m)<br><br>Where x(i)∈Rn<br><br>Note that we will not use the x0=1 convention.	
what is the implementation for K-Means Algorithm?	"The first for-loop is the 'Cluster Assignment' step<br><br>The second for-loop is the 'Move Centroid' step where we move each centroid to the average of its group.         <div><img src=""quizlet-Nz6CmDYBh-hemd8pOoo8KA_m.png"" /></div>         "	
Recall some of the parameters we used in our K-means algorithm!	c(i) = index of cluster (1,2,...,K) to which example x(i) is currently assigned<br><br>μk= cluster centroid k (μk∈ℝn)<br><br>μc(i) = cluster centroid of cluster to which example x(i) has been assigned	
What is the cost function for k-means?	"Using these variables we can define our cost function:         <div><img src=""quizlet-beKtIZetDqSOn5EWH0mrcQ_m.png"" /></div>         "	
In the cluster assignment step, our goal is to: [...]	Minimize J(...) with c(1),...,c(m) (holding μ1,...,μK fixed)	
In the move centroid step, our goal is to: [...]	Minimize J(...) with μ1,...,μK	
With k-means, it is not possible [...]	With k-means, it is not possible for the cost function to sometimes increase. It should always descend.	
What is our optimization objective in k-means?	"Our optimization objective is to minimize all our parameters using the above cost function:         <div><img src=""quizlet-Rd0E3rAMKNvHi2Mrs1eTeQ_m.png"" /></div>         "	
In cases where [...] it is strongly recommended to run a loop of random initializations.	In cases where K<10 it is strongly recommended to run a loop of random initializations.	
K-means can get stuck [...].   To decrease the chance of this happening, you can [...]	"K-means can get stuck in local optima. <br><br>To decrease the chance of this happening, you can run the algorithm on many different random initializations.         <div><img src=""quizlet-rEGXyX4.4dNpDDvngPTXsw_m.png"" /></div>         "	
Choosing the Number of Clusters  The elbow method [...]	The elbow method: plot the cost J and the number of clusters K. <br><br>The cost function should reduce as we increase the number of clusters, and then flatten out. <br><br>Choose K at the point where the cost function starts to flatten out.<br><br>However, fairly often, the curve is very gradual, so there's no clear elbow.	
Note: J will always decrease as K is increased. The one exception is if k-means [...]	Note: J will always decrease as K is increased. The one exception is if k-means gets stuck at a bad local optimum.	
Another way to choose K is to observe how well k-means performs on a downstream purpose. In other words [...]	In other words, you choose K that proves to be most useful for some goal you're trying to achieve from using these clusters.	
We may want to reduce the dimension of our features if [...]	We may want to reduce the dimension of our features if we have a lot of redundant data.	
Doing dimensionality reduction will [...]	Doing dimensionality reduction will reduce the total data we have to store in computer memory and will speed up our learning algorithm.	
Note: in dimensionality reduction, we are reducing our features rather than [...].	Note: in dimensionality reduction, we are reducing our features rather than our number of examples.	
Motivations for Dimensionality Reduction?	Motivation I: Data Compression<br><br>Motivation II: Visualization	
The most popular dimensionality reduction algorithm is [...]	The most popular dimensionality reduction algorithm is Principal Component Analysis (PCA)	
PCA Problem formulation	Given two features, x1 and x2, we want to find a single line that effectively describes both features at once. We then map our old features onto this new line to get a new single feature.	
The goal of PCA is to [...]	The goal of PCA is to reduce the average of all the distances of every feature to the projection line.<br><br>This is the projection error.	
PCA is not linear regression!	In linear regression, we are minimizing the squared error from every point to our predictor line. These are vertical distances.<br><br>In PCA, we are minimizing the shortest distance, or shortest orthogonal distances, to our data points.	
In PCA, we are taking a number of features x1,x2,...,xn, and finding a [...]. We aren't trying to [...] and we aren't [...]	In PCA, we are taking a number of features x1,x2,...,xn, and finding a closest common dataset among them. We aren't trying to predict any result and we aren't applying any theta weights to the features.	
Before we can apply PCA, there is a [...]	Before we can apply PCA, there is a data pre-processing step we must perform	
Data preprocessing in PCA?	"Given training set: x(1),x(2),...,x(m)<br><br>Preprocess (feature scaling/mean normalization):<br><br>Replace each x(i)j with x(i)j−μj<br><br>If different features on different scales (e.g., x1 = size of house, x2 = number of bedrooms), scale features to have comparable range of values         <div><img src=""quizlet-KAWDrOL7pyOvgHdS1doc5w_m.png"" /></div>         "	
So, PCA has two tasks: [...]	So, PCA has two tasks: figure out u(1),...,u(k) and also to find z1,z2,...,zm.	
1. Step in PCA?	"1. Compute ""covariance matrix""<br><br>This can be vectorized in Octave as: Sigma = (1/m) * X' * X;         <div><img src=""quizlet-u6N.mZoG5blg4TuFjnIoCw_m.png"" /></div>         "	
2. Step in PCA?	"2. Compute ""eigenvectors"" of covariance matrix Σ<br><br>This can be vectorized in Octave as: [U,S,V] = svd(Sigma);"	
3. Step in PCA?	"3. Take the first k columns of the U matrix and compute z         <div><img src=""quizlet-stetbzng5YwPs8MTkVb1hg_m.png"" /></div>         "	
Summarize the whole PCA algorithm in octave is roughly:	"         <div><img src=""quizlet-uX88tdZMalCQCsfS7tNXYQ_m.png"" /></div>         "	
If we use PCA to compress our data, how can we uncompress our data, or go back to our original number of features?	We can do this with the equation: x(1)approx=Ureduce⋅z(1)	
Choosing the Number of Principal Components?	"In other words, the squared projection error divided by the total variation should be less than one percent, so that 99% of the variance is retained.         <div><img src=""quizlet-dfqBYOHu-hR87wdSnDnwOA_m.png"" /></div>         "	
Algorithm for choosing k in PCA?	"Try PCA with k=1,2,...<br><br>Compute Ureduce,z,x<br><br>Check the formula given above that 99% of the variance is retained. If not, go to step one and increase k.         <div><img src=""quizlet-8ZyZA3LtiHkQJtPJnXVytw_m.png"" /></div>         "	
The most common use of PCA is to [...]	The most common use of PCA is to speed up supervised learning.	
Bad use of PCA?	trying to prevent overfitting. <br><br>We might think that reducing the features with PCA would be an effective way to address overfitting. <br><br>It might work, but is not recommended because it does not consider the values of our results y. <br><br>Using just regularization will be at least as effective.	
Stochastic gradient cost function?	"Stochastic gradient descent is written out in a different but similar way:         <div><img src=""quizlet-ajrdvnNM-LC9GmpT9cKCMw_m.png"" /></div>         "	
Stochastic gradient descnet algorithm?	"1. Randomly 'shuffle' the dataset<br><br>2. For i=1...m<br><br>Θj:=Θj−α(hΘ(x(i))−y(i))⋅x(i)j         <div><img src=""quizlet-qaZIflZ0yab3r7NI1Nwseg_m.png"" /></div>         "	
Stochastic gradient descent will be unlikely to [...] and will instead [...], but usually yields a result that is close enough	Stochastic gradient descent will be unlikely to converge at the global minimum and will instead wander around it randomly, but usually yields a result that is close enough	
Stochastic gradient descent will usually take [...] passes through your data set to get near the global minimum.	Stochastic gradient descent will usually take 1-10 passes through your data set to get near the global minimum.	
Mini-Batch Gradient Descent	Instead of using all m examples as in batch gradient descent, and instead of using only 1 example as in stochastic gradient descent, we will use some in-between number of examples b	
Typical values for b in mini-batch gradient descent?	Typical values for b range from 2-100 or so.	
Why is it possible that you may get a slightly better solution with stochastic gradient descent with a smaller learning rate?	That is because stochastic gradient descent will oscillate and jump around the global minimum, and it will make smaller random jumps with a smaller learning rate.	
How do we choose the learning rate α for stochastic gradient descent?	One strategy is to plot the average cost of the hypothesis applied to every 1000 or so training examples.<br><br>If you increase the number of examples you average over to plot the performance of your algorithm, the plot's line will become smoother. <br><br>With a very small number of examples for the average, the line will be too noisy and it will be difficult to find the trend.	
With a continuous stream of users to a website, we can [...], where we collect [...] for the features in x to predict some behavior y.	With a continuous stream of users to a website, we can run an endless loop that gets (x,y), where we collect some user actions for the features in x to predict some behavior y.	
Map Reduce and Data Parallelism	We can divide up batch gradient descent and dispatch the cost function for a subset of the data to many different machines so that we can train our algorithm in parallel.	
Your learning algorithm is MapReduceable if [...]	Your learning algorithm is MapReduceable if it can be expressed as computing sums of functions over the training set	
Which algorithms are easily parallelizable?	Linear regression and logistic regression are easily parallelizable.	
Map Reduce and Data Parallelism for Neural Networks?	For neural networks, you can compute forward propagation and back propagation on subsets of your data on many machines.<br> <br>Those machines can report their derivatives back to a 'master' server that will combine them.	
"What will MapReduce to with the ""dispatched jobs""?"	"MapReduce will take all these dispatched (or 'mapped') jobs and 'reduce' them by calculating:         <div><img src=""quizlet-fuCJezYl7QwEZi9m7keOgA_m.png"" /></div>         "	
A very common application of anomaly detection is [...]	"A very common application of anomaly detection is detecting fraud:         <div><img src=""quizlet-gHY3EJ1keXYrMozW.-lKzQ_m.png"" /></div>         "	
If our anomaly detector is flagging too many anomalous examples, then we need to [...]	If our anomaly detector is flagging too many anomalous examples, then we need to decrease our threshold ϵ	
What is the function of the Gaussian distribution?	"The full function is as follows:         <div><img src=""quizlet-7bzubK2PQdoMrzfuSwZKIA_m.png"" /></div>         "	
Algorithm for anomaly detection with gaussian distribution?	"Choose features xi that you think might be indicative of anomalous examples.<br><br>Fit parameters μ1,...,μn,σ21,...,σ2n<br><br>Calculate μj<br><br>Calculate σ2j<br><br>Given a new example x, compute p(x)<br><br>Anomaly if p(x)<ϵ         <div><img src=""quizlet-sqi85TKaCqNmeeAQ.W.CYA_m.png"" /></div>         "	
What are possible evaluation metrics for anomaly detection?	True positive, false positive, false negative, true negative.<br><br>Precision/recall<br><br>F1 score	
Use anomaly detection when...	"We have a very small number of positive examples (y=1 ... 0-20 examples is common) and a large number of negative (y=0) examples.<br><br>We have many different ""types"" of anomalies and it is hard for any algorithm to learn from positive examples what the anomalies look like; future anomalies may look nothing like any of the anomalous examples we've seen so far."	
Use supervised learning when...	We have a large number of both positive and negative examples. In other words, the training set is more evenly divided into classes.<br><br>We have enough positive examples for the algorithm to get a sense of what new positives examples look like. The future positive examples are likely similar to the ones in the training set.	
How can we check if our features are gaussian?	We can check that our features are gaussian by plotting a histogram of our data and checking for the bell-shaped curve.	
Say we are trying to recommend movies to customers. We can use the following definitions [...]	"We can use the following definitions         <div><img src=""quizlet-3ZCKtveb3AhSHADUv3OuRw_m.png"" /></div>         "	
%% Change Octave prompt	PS1('>> ');	
% Displaying them:	a = pi	
disp(a)		
disp(sprintf('2 decimals: %0.2f', a))		
disp(sprintf('6 decimals: %0.6f', a))		
format long		
a		
format short		
a		
% from 1 to 2, with stepsize of 0.1. Useful for plot axes	v = 1:0.1:2	
% from 1 to 6, assumes stepsize of 1 (row vector)	v = 1:6	
% same as C = [2 2 2; 2 2 2]	C = 2*ones(2,3)	
% 1x3 vector of ones	w = ones(1,3)	
% drawn from a uniform distribution	w = rand(1,3)	
% drawn from a normal distribution (mean=0, var=1)	w = randn(1,3)	
% (mean = -6, var = 10) - note: add the semicolon	w = -6 + sqrt(10)*(randn(1,10000));	
% plot histogram using 10 bins (default)	hist(w)	
% plot histogram using 50 bins	hist(w,50)	
% note: if hist() crashes, try [...]	"% note: if hist() crashes, try ""graphics_toolkit('gnu_plot')"""	
% 4x4 identity matrix	I = eye(4)	
% 1x2 matrix: [(number of rows) (number of columns)]	sz = size(A)	
% number of rows	size(A,1)	
% number of cols	size(A,2)	
% size of longest dimension	length(v)	
%% loading data	load q1y.dat % alternatively, load('q1y.dat')	
% list variables in workspace	who	
% list variables in workspace (detailed view)	whos	
% clear command without any args clears all vars	clear q1y	
% first 10 elements of q1x (counts down the columns)	v = q1x(1:10);	
% save variable v into file hello.mat	save hello.mat v;	
% save as ascii	save hello.txt v -ascii;	
% indexing is (row,col)	A(3,2)	
% get the 2nd row.	A(2,:)	
% get the 2nd col	A(:,2)	
% print all the elements of rows 1 and 3	A([1 3],:)	
% change second column	A(:,2) = [10; 11; 12]	
% append column vec	A = [A, [100; 101; 102]];	
% Select all elements as a column vector.	A(:)	
% concatenating A and B matrices side by side	C = [A B]	
C = [A, B]		
% Concatenating A and B top and bottom	C = [A; B]	
% element-wise multiplication	A .* B	
% element-wise square of each element in A	A .^ 2	
% element-wise reciprocal	1./v	
% functions like this operate element-wise on vecs or matrices	log(v)	
exp(v)		
abs(v)		
% v + 1 % same	v + ones(length(v), 1)	
% matrix transpose	A'	
% val - maximum element of the vector a and index - index value where maximum occur	[val,ind] = max(a)	
% if A is matrix, returns max from each column	val = max(A)	
% checks which values in a are less than 3	a < 3	
% gives location of elements less than 3	find(a < 3)	
% generates a magic matrix - not much used in ML algorithms	A = magic(3)	
% row, column indices for values matching comparison	[r,c] = find(A>=7)	
% maximum along columns(defaults to columns - max(A,[]))	max(A,[],1)	
% maximum along rows	max(A,[],2)	
% Matrix inverse (pseudo-inverse)	pinv(A)	
inv(A'*A)*A'		
"% ""hold off"" to turn off"	hold on;	
% Divide plot into 1x2 grid, access 1st element	subplot(1,2,1);	
% Divide plot into 1x2 grid, access 2nd element	subplot(1,2,2);	
% change axis scale	axis([0.5 1 -1 1]);	
% comma-chaining function calls.	a=1,b=2,c=3	
a=1;b=2;c=3;		
%% plotting	t = [0:0.01:0.98];	
y1 = sin(2*pi*4*t);		
plot(t,y1);		
y2 = cos(2*pi*4*t);		
hold on;		
xlabel('time');		
ylabel('value');		
legend('sin','cos');		
title('my plot');		
print -dpng 'myPlot.png'		
% To add the path for the current session of Octave:	addpath('/path/to/function/')	
% To remember the path for future sessions of Octave, after executing addpath above, also do:	savepath	
Octave's functions can return more than one value	function [y1, y2] = squareandCubeThisNo(x)	
y1 = x^2		
y2 = x^3		
Difference star/snowflake scheme	*Star scheme:* consists of single fact table and a single table for each dimension. Each tuple in fact table consists of a pointer to each of the dimensions providing it multidimensional coordinates and stores numeric measures for those coordinates.<br>*Snow flake schemas*: refinement of star schemes where dimensional hierarchy is explicitly represented by normalizing the dimensional tables.<br>Star is purely denormalized, whereas snowflake can be normalized.	
Data warehouse  (Definition and goal)	- *s*ubject-oriented, *i*ntegrated, *n*on-volatile, *t*ime-varying collection of data <br>- collection of decision support technologies<br>- aimed at enabling the knowledge worker to make better & faster organizational decisions.	
OLAP	= *o*n*l*ine *a*nalytical *p*rocessing. <br>- relatively low volume of transactions. <br>- Queries are often very complex and involve aggregations. <br>- response time is an effectiveness measure.<br>- widely used by Data Mining techniques.<br>- aggregated, historical data, stored in multi-dimensional schemas (usually star schema).	
OLTP	= *o*n*l*ine *t*ransaction *p*rocessing. <br>- large number of short on-line transactions (INSERT, UPDATE, DELETE). <br>- very fast query processing, maintaining data integrity in multi-access environments <br>- effectiveness measured by number of transactions/sec. <br>- detailed and current data, and schema used to store transactional databases is the entity model	
Difference OLAP / OLTP	OLAP contains data from *several OLTP databases* over potentially *longer time periods*, combined with data from *external sources*. <br><br>Therefore an OLAP database is typically larger than an OLTP database.	
Data mart	Building a *data warehouse is a long and complex process* which may take many years to develop. <br><br>Data mart: *departmental subset* focussed on selected subjects (e.g. a marketing data mart may include only customer, product and sales information)	
Applications of SQL	1. *Data definition language (DDL)*; instructions to build and maintain data (CREATE TABLE) <br>-> used by database developers<br>2. *Data control language (DCL)*; instructions for maintaining the data base (GRANT)<br>-> used by database admin<br>3. *Data manipulation language (DML)*; instructions to manipulate the data (SELECT)<br>-> used by end user	
3 Vs in big data model	1. *Volume*: currently increasing at a high speed due to devices/interactions nowadays, makes big data different from earlier days.<br>2. *Velocity*: time period when data is refreshed. Earlier: weekly/monthly (also reports). Nowadays velocity increased rapidly because of real time contact, contributing to the volume of data.<br>3. *Variety*: Earlier: only certain external datasets (e.g. from crm systems). Nowadays more data sources available such as social media and open source data.	
Benefits/problems/challenges for big data	*Benefits*: <br>-fine-tuning of marketing, <br>-client based segmentation, <br>-automated decision making.<br>*Problems*: <br>-lacking knowledge (inexpert), <br>-lack of staff, <br>-lack of current database software, <br>-data load slow in current database software.<br>*Challenges*: <br>-data growth, <br>-data infrastructure, <br>-data integration, <br>-data velocity. data variety, data visualization.	
How to improve the marketing performance?	Step 1: Set up *KPI framework* & *collect data*<br>Step 2: *Merging* data to get a holistic marketing view on performance<br>Step 3/4: *Transpose insights* into *challenges and opportunities*<br>Step 5: *Creating initiatives*	
3 challenges for organizations  (big data)	*Technical*: scattered and fragmented datasets due to different aggregation levels of data sources but also different storages (e.g. MRX agency). First one solved by e.g. powerful pc, the second by physical integration.<br>*Analytical*: lack of similar and synchronized customer perspective and consistent segmentation; explaining past instead of future and data at different aggregation levels<br>*Business*: no link with metrics of the P&L for assignment and acceptance from financial department. Need to define KPI metrics within and across data sources.	
Main characteristics of unstructured data (or semi-structured data)	- Unstructured data is *not directly suited* for analyses, require *structuring before they can be stored in table or spreadsheet* for analyses. <br>- It is not always clear *what you can do* with unstructured data.<br>- Unstructured data are *often not completely without structure* (e.g. email log)	
Difference between structured and unstructured data	- Structured data comes in *fixed format*, based on a *detailed record* and *variable structure*. Good *labeling of values* in the database and high-quality data. <br>- Unstructured data needs a lot *more processing and handling* before it becomes useful. It is also *not always obvious what you can do* with it.<br>- Unstructured data *grows much faster*<br>- Structured data can often be stored efficiently (Rich data requires much more data storage!)	
4 issues of unstructured data	- *Filtering:* Need computer algorithms for filtering relevant content. <br>- *Structuring* (involving classification or grading), need to group data, relate to categories and those that are not related to categories<br>- *Need to be matched to data from other sources:* easy if you can identify a unique key for a unique customer, however in many cases not available e.g. social media -> need to do based on e.g. zipcodes and age<br>- *Companies lack skills to generate insights from unstructured data:* Appropriate hard-/ software is not always available and analysts have not always required IT-skills.	
Problems in data quality	- *Accuracy*, e.g. measurement error. People don't correct typos or to fill in right numbers. Or how volatile? Download new twitter data or download new fresh sample when analysing the data?<br>- *Consistency*, check on the ranges.<br>- *Completeness*, missing observations or variables?	
What is data cleansing? (data scrubbing)	-*Act of detecting and correcting (or removing) corrupt or inaccurate records* from a record set, table or database.<br>- *Goal*: not just cleaning up but also bringing *consistency* to different sets of data that have been merged from separate data sources e.g. correction of typos and spelling errors or properly labeling mislabeled data.	
5 Steps for cleansing technically correct data ('fix' step)	1) *P*arsing <br>2) *c*orrecting<br>3) *s*tandardizing<br>4) *m*atching<br>5) *c*onsolidating	
Tidy data according to Wickham (2014)	Tidy data is a *standard way* of mapping the meaning of a dataset to its *structure*. It facilitates analysis. <br>1. Each *variable forms a column*<br>2. Each *observation forms a row*<br>3. Each type of *observational unit forms a table*	
Machine Learning & Predictive Statistics	- Share common methodologies (e.g. logistic regression)<br>- Fields arose from different sources:<br>- Statistics = social sciences, economics <br>- Machine Learning = computer sciences<br>- Statistics = low dimensional problems emphasizing formal statistical inferences<br>- Machine Learning = outcome-oriented focusing on accurate prediction making<br>- less restrictive and formal than classic statistics	
Machine Learning	Using *pre-classified training data* to teach a machine through an algorithm an *inferred function* with which it is able to *classify unseen new data*.<br>- Very close to forecasting or predictive modeling in MRX.<br>- Training in Machine Learning = parameter estimation in MRX<br>- By assigning weights to the input factors	
Supervised Learning	"- Aims to determine a rule that maps attributes of an observation (inputs of the rule) to a label or category (output of prediction rule). <br>- Algorithm is trained with data containing both the inputs (e.g., words & word combinations), as well as the desired output (i.e., ""spam""/""ham""). <br>- E.g. SVM, Decision Trees (CRT), Naïve Bayes, Neural Networks.<br>- face recognition, sentiment analysis, language detection, fraud detection"	
Unsupervised Learning	"- No desired output in the training data.<br>- Consequently, the algorithm involved cannot ""learn"" how to classify or predict new<br>data points. <br>- Aims at identifying a structure within the data (usually used in data mining where interest is more in finding patterns or phenomena than assigning labels)<br>- pattern recognition, cluster identification,<br>opinion mining, referrals and collaborative filtering"	
Nearest Neighbors & Entropy	- Neighboring helps assigning people into groups or predicting peoples' behavior given previous observations from similar people<br>- Neighboring approaches are good in assessing total similarity.<br>- Entropy allows determining which factors or features help best to make good predictions.<br>- Entropy refers to the degree of heterogeneity within a group. <br>- High entropy = all group members share many different features<br>- Low entropy score = high degree of common features amongst group members.	
Support Vector Machines	- SVMs try to identify a function that uses a number of features from a training set to split<br>observations into two separate classes. <br>- For any new observation —out of the<br>training sample— the function can then determine with the help of the features to<br>which class the new object belongs.<br>- Aim: plane that maximizes the margin between the two different classes.	
Non-linearly separable data & SVMs	"- *Soft margin machines*: relax the rules for the margin and allow few ""misclassified"" observations to be within the margin.<br>- *Kernel based SVMs*: split up data in a more dimensional space to find a plane that then helps to separate data into groups.<br>- Usually generalize quite well, while being robust to over-fitting issues. However, non-linear<br>Kernels usually require more testing efforts and longer training times."	
Decision trees	Idea: start out with the complete training set, and determine a series of splits to create more homogenous sub-groups, create a classification that is as good as possible, with a minimum number of splits. <br>- At each split, a variable is selected (based on entropy and information gain) that forms the basis for a decision rule that drives the split.	
Ensemble methods	- Combining *different tree models* together aggregating decision rules across different<br>tree models to obtain *better predictive performance*.<br>- *Reduce variance* by taking *repeated random samples* with replacement and *average resulting predictions*<br>- *Bagging, Random Forest, Boosting*	
Neural Networks	- Inspired by how the human brain works. <br>- Just as the neurons in a human brain, a neural network consists of a number of interconnected elements that transform inputs to outputs. <br>- Their weighted sum is processed by some activation function, and this results in a binary outcome.<br>- Such an artificial neuron is called a perceptron.<br>- Organized in input/hidden/output layer	
Overfitting	The more specific model is to training data, the less it will be able to generalize to new data points. By enforcing a near-perfect fit (include maximum number of variables into models to maximize degree of explained variance) of<br>our training data set, we sacrifice generalizability.	
Natural Language Processing (NLP)	-Goal: determine text sentiments.<br>- With the help of pre-labeled texts (i.e., positive and negative) the machine learns to understand how the occurrence of certain words<br>or word combinations determines the favorability of a text. <br>- Documents for each labeled category get stripped into a Term Document Matrix (TDM)<br>- Each column = any word that occurs <br>- Each rows = different documents.<br>- Incoming new, unlabeled text can then been assigned to the two categories	
4 fundamental verbes of data manipulation (Wickham, 2014)	• *Filtering:* removing or subsetting observations based on some condition.<br>• *Transform:* adding or modifying variables.<br>• *Aggregate:* collapsing multiple values into a single value e.g. by summing or taking means <br>• *Sort:* change the order of observations	
Data cleaning approach according to Rahm & Do (2000)	1) Detect and remove all major errors and inconsistencies both on dividual data sources and when integrating multiple data sources.<br>2) Don't perform in isolation but together with schema-related data transformation based on comprehensive metadata.<br>3) workflow infrastructure should be supported to execute all data transformation steps for multiple sources & large data sets in reliable and efficient way.	
Single source problems according to Rahm & Do (2000)	- Can be divided into schema and instance levels. <br>- Schema-related data quality problems occur because of lack of appropriate model: specific or application-specific integrity constraints (e.g. due to data model limitations or poor schema design)<br>- Or because only few integrity constraints were defined to limit overhead for integrity control. <br>- Instance-problems relate to errors and inconsistencies that can't be prevented at schema level (e.g. misspellings).	
Multiple source problems (Rahm & Do, 2000)	Multiple source problems can be divided into schema and instance levels.<br>- At schema level, data model and schema design differences are to be addressed by the steps of schema translation and schema integration respectively.	
Two approaches for data analysis (Rahm & Do, 2000)	Data profiling & data mining. <br>- Data profiling focusses on the instance analysis of individual attributes, derives information such as data type, length, value range, discrete values and their frequency etc. <br>- Data minings helps discover specific data patterns in large data sets e.g. relationships between several attributes.	
Consequences of missing data	- *Inaccurate predictions* & *biased/inefficient estimates*<br>- Predictions will be not accurate and the descriptive coefficients that you are getting are not as good as they could be. <br>- Either value is not precise (biased) or procedures become less efficient (larger uncertainty hence inefficient) when estimating those problems.	
How to detect outliers	- descriptives and graphical summaries. <br>- If x is less then q1 - 1,5 x iqr (inter quartile range = q3 - q1) or more than q3 + 1,5 x iqr. <br>- Potential solution for this is trimming; throw away the most extreme x% on both sides<br>- Remove outliers by default: may throw away interesting part. Always investigate outliers and what causes them.	
Machine learning	- concerned with computer programs that automatically improve their performance through experience<br>- Basic concept is using training data to teach a machine through an algorithm a function with which the machine is able to classify new unseen data.	
Advantages of machine learning	• Develop systems that can *automatically adapt and customize* themselves to individual users <br>• Discover *new knowledge* from large databases (data mining)<br>• Able to *mimic human and replace certain tasks* which require some intelligence <br>• Develop *systems that are too difficult/ expensive* to construct manually (specific detailed skills or knowledge tuned to a specific task)	
Disadvantages of machine learning	- Takes *long to train*<br>- *many subjectives*<br>- *stopping criteria* matters<br>- effects are *not interpretable*	
Aims of KDD process	Knowledge discovery in database:<br>Identifying implicit, valid, novel, potentially useful and understandable patterns in data	
Steps in the KDD process	1. *Data cleaning and integration*, missing values/merging from multiple sources<br>2. *Data selection and transformation*, select relevant data/choose aggregation level<br>3. *Data mining*, apply methods to find patterns<br>4. *Evaluation and presentation*, confirm hypothesis/ find new patterns. use visualization techniques to present, sould conclude in new knowledge.	
Assessing quality of a classification	- *% correctly classified:* percentage that is correctly classified <br>- *Top decile lift:* predicts the top 10%. <br>- *Lift curve:* cumulative percentage of customer at x axis and cumulative percentage of e.g. churn at y axis<br>- *Gini (Area under the curve):* focuses on the overall performance of the model.	
Advantages of neural networks	• *Prediction accuracy* is generally high,<br>• It is *robust*, also when training set contains errors of noisy data<br>• *Output may be discrete, real-valued or a vector* of several discrete or real-valued attributes<br>• *Fast evaluation* of the learned target function	
Disadvantages of neural networks	• Takes *long training time*<br>• *Difficult to understand* the learned function (Weights)<br>• *Not easy to incorporate domain knowledge*	
4 dimensions according to Berinato (2016)	*Idea illustration* (declarative / conceptual)<br>*Idea generation* (exploratory / conceptual)<br>*Everyday dataviz* (declarative / data-driven)<br>*Visual discovery* (exploratory / data-driven)	
Eelementary tasks ordered from most to least accurate	1. Position along common scale<br>2. Position along nonaligned scale<br>3. Length, direction and angle<br>4. Area<br>5. Volume, curvature<br>6. Shading, color saturation	
4 categories of preattentive attributes	Color, form, position, animation.	
Types of dashboard	- *Strategic;* high level managers and executives see information and trends <br>- *Analytical:* technical for business users, information actually searches themselves, dive in data.<br>- *Operational:* what is happening now, able to make my decision real time	
Data quality	Distinguishing characteristic describing fitness of a dataset/record for a particular use that one may have in mind for the data.	
Statistical analysis value chain (De Jonge & van der Loo)	1) Raw data<br>2) Technically correct data<br>3) Consistent data<br>4) Statistical results<br>5) Formatted output	
Data Mining	- 3rd step in KDD process<br>- Extraction of implicit, previously unknown and potentially useful information from data<br>- Exploration & analysis, by automatic or semiautomatic means, of large quantities of data in order to discover meaningful patterns (decription and prediction)	
Difference boosting & bagging/rf	- Boosting is *sequential*, bagging and rf based on independent *resampling* (bootstrapping)<br>- In boosting *each following tree is weighted* according to the wrongly classified observations of previous tree. <br>- New (test) observations have to go through the<br>*entire sequence of trees* until the final outcome becomes clear.<br>- For bagging and RF the trees are built on independent samples of the data, *then aggregated*<br>- either *majority vote* (discrete outcomes) or *simple averaging* (continuous outcomes)	
Applications of tiday data	- *Manipulation* (Filter, transform, aggregate, sort)<br>- *Visualization*: Tools need to be input-tidy<br>- *Modeling*: most modeling tools work best with tidy datasets	
5 most common problems with messy data	1) *column headers are values* not variable names<br>2) multiple variables are *stored in one column*<br>3) variables are *stored in both rows and columns*<br>4) *multiple types of observational units* in same tbl<br>5) a single *observational unit is stored in multiple tables*	
Imputation of missing values	Missing data for a subject is imputed by a value that is predicted using the subject's other known characteristics.<br>- MCAR = you can use simple techniques without bias<br>- MNAR = depends on value itself<br>- MAR = depends on other, observed variables<br>Single imputation<br>Multiple imputation (using various estimates)	
Supervised learning	"Supervised learning is a type of machine learning algorithm that uses a known dataset (called the training dataset) to make predictions. The training dataset includes input data and response values. From it, the supervised learning algorithm seeks to build a model that can make predictions of the response values for a new dataset. A test dataset is often used to validate the model. Using larger training datasets often yield models with higher predictive power that can generalize well for new datasets.<br><br>Called Supervised learning BECAUSE the data is labeled with the ""correct"" responses."	
Regression vs Classification?	"Regression: the output variable takes continuous values. - Price of house given a size. <br><br>Classification: the output variable takes class labels, or discrete value output - Breast cancer, malignant or benign?<br><br>Almost like quantitative vs categorical         <div><img src=""quizlet-PtwyfZgqCnk-sB34Ew23Qw_m.png"" /></div>         "	
Clustering	a method of unsupervised learning - a good way of discovering unknown relationships in datasets.<br><br>Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). It is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, bioinformatics, data compression, and computer graphics.<br><br>Cluster analysis itself is not one specific algorithm, but the general task to be solved. It can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them. Popular notions of clusters include groups with small distances among the cluster members, dense areas of the data space, intervals or particular statistical distributions. Clustering can therefore be formulated as a multi-objective optimization problem. The appropriate clustering algorithm and parameter settings (including values such as the distance function to use, a density threshold or the number of expected clusters) depend on the individual data set and intended use of the results. Cluster analysis as such is not an automatic task, but an iterative process of knowledge discovery or interactive multi-objective optimization that involves trial and failure. It is often necessary to modify data preprocessing and model parameters until the result achieves the desired properties.	
Unsupervised learning	Unsupervised learning is the machine learning task of inferring a function to describe hidden structure from unlabeled data. Since the examples given to the learner are unlabeled, there is no error or reward signal to evaluate a potential solution. This distinguishes unsupervised learning from supervised learning and reinforcement learning.<br><br>Unsupervised learning is closely related to the problem of density estimation in statistics.[1] However unsupervised learning also encompasses many other techniques that seek to summarize and explain key features of the data.	
Cocktail party effect/problem	The cocktail party effect is the phenomenon of being able to focus one's auditory attention on a particular stimulus while filtering out a range of other stimuli, much the same way that a partygoer can focus on a single conversation in a noisy room.<br><br>Example of source separation.	
Synonym for Input variable?	Features	
Synonym for output variable?	Targets	
"What is ""hypothesis"" in machine learning?"	Hypothesis: A hypothesis is a certain function that we believe (or hope) is similar to the true function, the target function that we want to model. In context of email spam classification, it would be the rule we came up with that allows us to separate spam from non-spam emails.	
Training sample definition?	Training sample: A training sample is a data point x in an available training set that we use for tackling a predictive modeling task. For example, if we are interested in classifying emails, one email in our dataset would be one training sample. Sometimes, people also use the synonymous terms training instance or training example.	
Target Function definition?	Target function: In predictive modeling, we are typically interested in modeling a particular process; we want to learn or approximate a particular function that, for example, let's us distinguish spam from non-spam email. The target function f(x) = y is the true function f that we want to model.<br><br>The target function is the (unknown) function which the learning problem attempts to approximate.	
Model definition?	"Model: In machine learning field, the terms hypothesis and model are often used interchangeably. In other sciences, they can have different meanings, i.e., the hypothesis would be the ""educated guess"" by the scientist, and the model would be the manifestation of this guess that can be used to test the hypothesis."	
Learning algorithm?	Learning algorithm: Again, our goal is to find or approximate the target function, and the learning algorithm is a set of instructions that tries to model the target function using our training dataset. A learning algorithm comes with a hypothesis space, the set of possible hypotheses it can come up with in order to model the unknown target function by formulating the final hypothesis	
Classifier?	Classifier: A classifier is a special case of a hypothesis (nowadays, often learned by a machine learning algorithm). A classifier is a hypothesis or discrete-valued function that is used to assign (categorical) class labels to particular data points. In the email classification example, this classifier could be a hypothesis for labeling emails as spam or non-spam. However, a hypothesis must not necessarily be synonymous to a classifier. In a different application, our hypothesis could be a function for mapping study time and educational backgrounds of students to their future SAT scores.	
What does this hypothesis represent?  h_theta(x) = theta_0 + theta_1 x	univariate linear regression model	
Cost function vs Gradient Descent?	A cost function is something you want to minimize. For example, your cost function might be the sum of squared errors over your training set. Gradient descent is a method for finding the minimum of a function of multiple variables. So you can use gradient descent to minimize your cost function. If your cost is a function of K variables, then the gradient is the length-K vector that defines the direction in which the cost is increasing most rapidly. So in gradient descent, you follow the negative of the gradient to the point where the cost is a minimum. If someone is talking about gradient descent in a machine learning context, the cost function is probably implied (it is the function to which you are applying the gradient descent algorithm).	
What is SSE?	The sum of squared error	
Derive SSE	Given a linear regression model, the difference at each predicted point with the correct point is given by diff = y_i - (mx + b)	
Why do we square instead of using the absolute value when calculating variance and standard deviation?	"First I'll answer the mathematical question asked in the question details, which I'm going to restate because I think it is stated wrong:<br><br>The short answer is ""Because of Jensen's inequality."" See http://en.wikipedia.org/wiki/Jen... and the rest of the article for context.<br><br>It says in particular that for a concave function <br><br>What about the more general question, ""Why variance?""<br><br>I don't believe there is any compelling conceptual reason to use variance as a measure of spread. If forced to choose, my guess is that most people would say more robust measures like interquartile range or MAD better capture the concept of ""spread"" in most cases.<br><br>But variance (and more generally ""sum of squares"") has some attractive properties, many of which flow from the Pythagorean theorem one way or another. Here some of them, without much math:<br>We can decompose sums of squares into meaningful components like ""between group variance"" and ""within-group variance.""<br>To generalize the above point, when a random variable <br>Y<br>Y is partly explained by another random variable <br>X<br>X there is a useful decomposition of the variance of <br>Y<br>Y into the part explained by <br>X<br>X and the unexplained part. (See http://en.wikipedia.org/wiki/Law...).<br>If we think more broadly about mean squared error, this too can be decomposed into the sum of variance and squared bias. It is easy to interpret this total error as the sum of ""systematic error"" and ""noise.""<br>Often we want to minimize our error. When the error is a sum of squares, we are minimizing something quadratic. This is easily accomplished by solving linear equations.<br>So yes, variance and mean squared error are conveniences rather than conceptual necessities. But they are convenient conveniences."	
3D Surface Plot - how can it be used to plot the cost function?	"Theta 0 and Theta 1 in a univariate linear regression can be plotted on the x and y axes. the Z axis will indicate the actual cost         <div><img src=""quizlet-FmM44wO0aCtQqw1X2bxqmg_m.png"" /></div>         "	
What are contour plots?	"A contour plot is a graphical technique for representing a #D surface by plotting constant z slices, called contours onto a 2Dimensional format. That is, given a value for z, lines are drawn for connecting the x,y, coordinates twhere that z value occurs. The circles in a contour plot are called level sets - the function J is equal here.The center of the contour plot is the minimum of the cost function typically in ML.         <div><img src=""quizlet-yOVdgm3T9-GnjaJKnqsgEw_m.png"" /></div>         "	
What letter is typically used to depict a cost function?	Function J	
Gradient Descent algorithm	Image result for gradient descent<br>Gradient descent is a first-order optimization algorithm. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or of the approximate gradient) of the function at the current point.<br><br>used with simultaneous updates of the parameters of success<br><br>Susceptible to falling into local optimum depending on initialization.	
What are first order methods in numerical analysis?	In numerical analysis, methods that have at most linear local error are called first order methods. They are frequently based on finite differences, a local linear approximation.	
What does the derivative of a function tell us?	"The derivative of a function of a real variable measures the sensitivity to change of a quantity (a function value or dependent variable) which is determined by another quantity (the independent variable). Derivatives are a fundamental tool of calculus. For example, the derivative of the position of a moving object with respect to time is the object's velocity: this measures how quickly the position of the object changes when time is advanced.<br><br>The derivative of a function of a single variable at a chosen input value, when it exists, is the slope of the tangent line to the graph of the function at that point. The tangent line is the best linear approximation of the function near that input value. For this reason, the derivative is often described as the ""instantaneous rate of change"", the ratio of the instantaneous change in the dependent variable to that of the independent variable."	
What is the downside of using an alpha (learning rate) that is too small?	Gradient descent can be way too slow.	
What is the downside of using an alpha (learning rate) that is too big?	Gradient descent can overshoot the minimum and it may fail to converge or even diverge.	
What happens if you initialize a parameter at a local minimum and attempt to use gradient descent on it?	The derivative turns out to be zero because the tangent is a flat line meaning that regardless of alpha it is multiplied by zero, indicating no change.	
Why is it unnecessary to change alpha over time to ensure that the gradient descent converges to a local minimum?	As we approach a local minimum, the gradient descent will take smaller steps because of the change of the derivative or the steepness of the cost function J. Don't need to worry about divergence.	
Convex functions?	In mathematics, a real-valued function defined on an interval is called convex (or convex downward or concave upward) if the line segment between any two points on the graph of the function lies above or on the graph, in a Euclidean space (or more generally a vector space) of at least two dimensions. Equivalently, a function is convex if its epigraph (the set of points on or above the graph of the function) is a convex set. Well-known examples of convex functions include the quadratic function {\displaystyle x^{2}} x^{2} and the exponential function {\displaystyle e^{x}} e^{x} for any real number x.<br><br>Convex functions play an important role in many areas of mathematics. They are especially important in the study of optimization problems where they are distinguished by a number of convenient properties. For instance, a (strictly) convex function on an open set has no more than one minimum.	
"""Batch"" Gradient Descent (BGD or GD)"	Each step of gradient descent uses all the training examples. batch GD - This is different from (SGD - stochastic gradient descent or MB-GD - mini batch gradient descent)<br><br><br>In GD optimization, we compute the cost gradient based on the complete training set; hence, we sometimes also call it batch GD. In case of very large datasets, using GD can be quite costly since we are only taking a single step for one pass over the training set -- thus, the larger the training set, the slower our algorithm updates the weights and the longer it may take until it converges to the global cost minimum (note that the SSE cost function is convex).	
Gradient Descent for linear regression?	"(Review again)         <div><img src=""quizlet-yk7qnbEgOpLp-II9Bgi91Q_m.png"" /></div>         "	
What is overfitting?	"In statistics and machine learning, one of the most common tasks is to fit a ""model"" to a set of training data, so as to be able to make reliable predictions on general untrained data. In overfitting, a statistical model describes random error or noise instead of the underlying relationship. Overfitting occurs when a model is excessively complex, such as having too many parameters relative to the number of observations. A model that has been overfit has poor predictive performance, as it overreacts to minor fluctuations in the training data.<br><br>how to avoid overfitting? cross-validation, regularization, early stopping, pruning, Bayesian priors on parameters or model comparison and more!"	
What is cross-validation?	"Cross-validation, sometimes called rotation estimation,[1][2][3] is a model validation technique for assessing how the results of a statistical analysis will generalize to an independent data set. It is mainly used in settings where the goal is prediction, and one wants to estimate how accurately a predictive model will perform in practice. In a prediction problem, a model is usually given a dataset of known data on which training is run (training dataset), and a dataset of unknown data (or first seen data) against which the model is tested (testing dataset).[4] The goal of cross validation is to define a dataset to ""test"" the model in the training phase (i.e., the validation dataset), in order to limit problems like overfitting, give an insight on how the model will generalize to an independent dataset (i.e., an unknown dataset, for instance from a real problem), etc."	
K-Fold?	In k-fold cross-validation, the original sample is randomly partitioned into k equal sized subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k − 1 subsamples are used as training data. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data. The k results from the folds can then be averaged to produce a single estimation. The advantage of this method over repeated random sub-sampling (see below) is that all observations are used for both training and validation, and each observation is used for validation exactly once. 10-fold cross-validation is commonly used,[7] but in general k remains an unfixed parameter.<br><br>When k=n (the number of observations), the k-fold cross-validation is exactly the leave-one-out cross-validation.<br><br>In stratified k-fold cross-validation, the folds are selected so that the mean response value is approximately equal in all the folds. In the case of a dichotomous classification, this means that each fold contains roughly the same proportions of the two types of class labels.<br><br>Ultimately this helps fix the problem that we want to maximize both the training and test sets in cross-validation.	
What is a simple linear regression?	In statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. In other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.<br><br>minimize squared error	
What does theta typically represent in stat/ML?	quite often θ stands for the set of parameters of a distribution.	
Linear regression formula?		
SSE formula?	"observation - mean for each observation squared.         <div><img src=""quizlet-4jttVc0778Mpj.RtiDyGfg_m.jpg"" /></div>         "	
x^i_j notation in ML means?	an index into a training set for the ITH training example and JTH feature (input variable)	
hypothesis model	"remember that the HYPOTHESIS MODEL or SET is what is depicted with h(theta)         <div><img src=""quizlet-f8ik3dSSiO1mEZWwmYFmxg_m.png"" /></div>         "	
multivariate linear regression	"ask: why is the notation shorter and what does that convenience notation indicate?         <div><img src=""quizlet-C6ysK3lYipH96VLwGpmxSg_m.png"" /></div>         "	
why use features that are on a similar scale?	"contour plots with differently scaled features will be extremely thin or extremely fat resulting in a very slow gradient descent (convergence is slower)<br><br>get them to a -1 <= x <= 1 scale. poorly scaled is too large -100 to 100 or -0.00001 or 0.00001         <div><img src=""quizlet-dTDvdSlRxaR4uDs2EieGpQ_m.png"" /></div>         "	
What does it mean for an algorithm to converge?	"An iterative algorithm is said to converge when as the iterations proceed the output gets closer and closer to a specific value. In some circumstances, an algorithm will diverge; its output will undergo larger and larger oscillations, never approaching a useful result.<br><br>The ""converge to a global optimum"" phrase in your first sentence is a reference to algorithms which may converge, but not to the ""optimal"" value (e.g. a hill-climbing algorithm which, depending on initial conditions, may converge to a local maximum, never reaching the global maximum)."	
What is normalization?	"In statistics and applications of statistics, normalization can have a range of meanings.[1] In the simplest cases, normalization of ratings means adjusting values measured on different scales to a notionally common scale, often prior to averaging. In more complicated cases, normalization may refer to more sophisticated adjustments where the intention is to bring the entire probability distributions of adjusted values into alignment. In the case of normalization of scores in educational assessment, there may be an intention to align distributions to a normal distribution. A different approach to normalization of probability distributions is quantile normalization, where the quantiles of the different measures are brought into alignment.         <div><img src=""quizlet-IiGOI7sRoPBe8ZHdsbenDg_m.png"" /></div>         "	
What is feature scaling?	"Feature scaling is a method used to standardize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step.<br><br>The range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization[citation needed]. For example, the majority of classifiers calculate the distance between two points by the Euclidean distance[citation needed]. If one of the features has a broad range of values, the distance will be governed by this particular feature[citation needed]. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance[citation needed].<br><br>Another reason why feature scaling is applied is that gradient descent converges much faster with feature scaling than without it[citation needed].<br><br><br>Some methods are rescaling, standardization, scaling to unit length.         <div><img src=""quizlet-yQhDd-lNm33cueWC8T5OkA_m.png"" /></div>         "	
Higher derivatives?	Let f be a differentiable function, and let f ′(x) be its derivative. The derivative of f ′(x) (if it has one) is written f ′′(x) and is called the second derivative of f. Similarly, the derivative of a second derivative, if it exists, is written f ′′′(x) and is called the third derivative of f. Continuing this process, one can define, if it exists, the nth derivative as the derivative of the (n-1)th derivative. These repeated derivatives are called higher-order derivatives. The nth derivative is also called the derivative of order n.	
Standardization vs normalization	"Normalization rescales the values from to a range of [0,1]. This might useful in some cases where all parameters need to have the same positive scale, but outliers from data set are lost.<br><br>Xchanged = (X - Xmin)/(Xmax-Xmin)<br><br>Standardization rescales data to have a mean of 0 and standard deviation of 1 (unit variance).<br><br>Xchanged = (x-mean)/sd<br><br>For most applications standardization is recommended.<br><br><br>In the business world, ""normalization"" typically means that the range of values are ""normalized to be from 0.0 to 1.0"". ""Standardization"" typically means that the range of values are ""standardized"" to measure how many standard deviations the value is from its mean. However, not everyone would agree with that. It's best to explain your definitions before you use them.<br><br>In any case, your transformation needs to provide something useful."	
Definition of stochastic?	randomly determined; having a random probability distribution or pattern that may be analyzed statistically but may not be predicted precisely.	
How to make sure gradient descent is working properly?	"create an automatic convergence test - declare convergence based on amount of decrease of J(Theta)<br><br>plot on graph, y axis being J and axis being number of iterations.         <div><img src=""quizlet-Ged.hmYHRX39yQhWYl6nFQ_m.png"" /></div>         "	
What does J(Theta) increasing tell you about ur gradient descent?	it's not working lol. use a bigger alpha. on the other end if you use too big of an alpha you'll end up with a bowl shaped curve and you might be moving farther away from convergence.	
What to do when J(Theta) is moving up and down in waves ?	Use a smaller Alpha!!	
For a sufficiently small alpha...	J(Theta) should decrease EVERY iteration	
Cubic functions...	"         <div><img src=""quizlet-wqNi21mI9X76QPPSGyizlw_m.png"" /></div>         "	
Inflection points	Inflection points are where the function changes concavity. Since concave up corresponds to a positive second derivative and concave down corresponds to a negative second derivative, then when the function changes from concave up to concave down (or vise versa) the second derivative must equal zero at that point. So the second derivative must equal zero to be an inflection point. But don't get excited yet. You have to make sure that the concavity actually changes at that point.	
What is the formula for theta in a normal equation?	"         <div><img src=""quizlet-J2jkStbQLVv2nvFkeppF6Q_m.png"" /></div>         "	
Machine Learning	Field of study that<br>gives computers the ability to learn without being explicitly<br>programmed.	
Well-posed Learning Problem	A computer program is said to learn from experience E with<br>respect to some task T and some performance measure P, if its<br>performance on T, as measured by P, improves with experience E.	
ABSTRACT ESSENCE OF ML	Representation + Evaluation + Optimisation	
Machine Learning	Learning from experience. It's also called<br>supervised learning, were E is the supervision.	
Pattern Recognition	finding patterns without experience. It's<br>also called unsupervised learning.	
Classification	ML task where T has a discrete set of<br>outcomes<br>• Often classification is binary<br>• Examples:<br>• face detection<br>• smile detection<br>• spam classification<br>• hot/cold	
Regression	ML task where T has a real-valued<br>outcome on some continuous sub-space<br>Examples:<br>• age estimation<br>• stock value prediction<br>• temperature prediction<br>• energy consumption prediction	
Labels	the values that h aims to predict<br>Example:<br>•Facial expressions of pain<br>•Impact of diet on astronauts in space<br>•Predictions of house prices	
Features/Attributes	measurable values of variables that<br>correlate with the label y<br>Examples:<br>• Sender domain in spam detection<br>• Mouth corner location in smile detection<br>• Temperature in forest fire prediction<br>• Pixel value in face detection	
TRAINING ALGORITHM	Given a model h with solution space S and a training set {X,Y}, a learning algorithm finds the solution that minimises the cost function J(S)	
Well-posed Learning Problem	A computer program is said to learn from experience E with<br>respect to some task T and some performance measure P, if its<br>performance on T, as measured by P, improves with experience<br>E.	
Machine Learning broad definition	Field of study that<br>gives computers the ability to learn without being explicitly<br>programmed	
COST FUNCTION	Squared error cost function	
Local minima	is the smallest value of the function. but it might not be the only one.	
Local maxima	The real smallest value of the function.	
LINEAR BASIS FUNCTIONS		
General classification problem	If classes are disjoint, i.e. each pattern belongs to one and<br>only one class then input space is divided into decision<br>regions separated by decision boundaries or surfaces	
Decision surfaces are	• linear functions of x<br>• defined by (D-1)-dimensional hyperplanes in the Ddimensional<br>input space	
LINEAR SEPARABILITY	Linearly separable data:<br>• datasets whose classes can be separated by linear<br>decision surfaces<br>• implies no class-overlap<br>• classes can be divided by e.g. lines for 2D data or planes<br>in 3D data	
ORTHOGONALITY	Two vectors and are orthogonal<br>if they're perpendicular<br><br>In this case, their inner product is 0:<br>a · b = 0	
TRAINING LDA objective:	Find (i.e. learn) that minimises<br>some error function on the training set.<br><br>Significant approaches:<br>• Least squares<br>• Fisher<br>• Perceptron	
LEAST SQUARED LDA	Benefits:<br>Exact closed form solution<br>Disatvantages:<br>• Not probabilistic<br>• Sensitive to outliers<br>• Problems with multiple classes and/<br>or unbalanced data	
Insight: LDA is a form of dimensionality reduction.	y = wT x<br>High-dimensional input is mapped by w onto a single dimension y	
FISHER LDA	Fisher's idea is to adjust/constrain so that class<br>separation in 1D is maximised	
ARTIFICIAL NEURAL NETS	Feed-forward neural network/Multilayer Perceptron one of<br>many ANNs<br>We focus on the Multilayer Perceptron<br>Really multiple layers of logistic regression<br>models	
The simplest ANNs consist of	•A layer of D input nodes<br>•A layer of hidden nodes<br>•A layer of output nodes<br>•Fully connected between layers	
Curse of Dimensionality	When D becomes large, learning problems can become very<br>difficult. For example:<br>when dividing a space (e R^d) into regular cells, the number of<br>cells grows exponentially with D. <br>in linear regression a polynomial model of order M has D^m coefficients<br>a sphere in high dimension has most of it's volume in an<br>infinitesimally thin slice near the surface	
EXTREME Dimensionality Case	In an extreme, degenerate case, if D > n, each example can be<br>uniquely described by a set of feature values.	
Hidden layer(s) can	have arbitrary number of nodes/units<br>have arbitrary number of links from input nodes and to<br>output nodes (or to next hidden layer)<br>there can be multiple hidden layers<br>(Default is a fully interconnected graph, i.e. every input node is linked<br>to every hidden node, and every hidden node to every output node)	
HIDDEN UNIT ACTIVATION	Common functions for are the sigmoid or h(·) tanh:	
RELU	Rectified Linear Unit <br>New trend, responsible for great deal of Deep Learning success:<br>• No 'vanishing gradient' problem<br>• Can model any positive real value<br>• Can stimulate sparseness	
Output layer can be:	single node for binary classification<br>single node for regression<br>n nodes for multi-class classification<br>(One network can also cover multiple output variables, thus<br>increasing the number of nodes.)	
NETWORK TOPOLOGY	Variations include:<br>Arbitrary number of layers<br>Fewer hidden units than input units (causes in effect<br>dimensionality reduction, equivalent to PCA)<br>Skip-layer connections (see below)<br>Fully/sparsely interconnected networks	
TRAINING A NETWORK	Choice of depends on the output variables:<br>*unity for regression<br>*logistic sigmoid for (multiple independent) binary classification<br>*softmax for exclusive (1-of-K) multiclass classification<br>(Training a network involves finding the that minimise some<br>error function)	
NN ERROR FUNCTIONS	*Regression:<br>*Binary classification<br>*Multiple independent binary classification:<br>*Multi-class classification<br>(mutually exclusive):	
Gradient point in the direction of:	Steepest Ascent	
In order to optimise the performance of ANN	an error function on the training set must be minimised<br>This is done by adjusting:<br>*weights connecting nodes<br>*parameters of non-linear functions h(a)	
EIGENVALUES	Given an invertible matrix , an eigenvalue equation can be foundin terms of a set of orthogonal vectors , and scalars such that:<br>M	
JACOBIAN, First-order partial derivative of functions :	Can be used to determine if a point is a (local) extreme.	
HESSIAN, Second-order partial derivative of functions : y = f(x)	Can be used to determine if a stationary point is a (local)<br>minimum or maximum.	
Gradient descent is a poor algorithm itself. Better variants exist:	Conjugate gradients<br>Quasi Newton<br>Online gradient descent	
ONLINE GRADIENT DESCENT	On-line gradient descent updates weight vector one<br>data point at a time<br>Maximum Likelihood-based error functions use a sum<br>of terms for independent data points:<br>*Handles redundancy better<br>*Can deal with new data better<br>*Good chance of escaping local minima	
BACKPROPAGATION	Used to calculate derivatives of error<br>function efficiently<br>Errors propagate backwards layer by<br>layer	
Backprop is for:	Arbitrary feed-forward topology<br>Differentiable nonlinear activation functions<br>Broad class of error function	
ERROR BACKPROPAGATION	1. Apply input vector to network and propagate<br>forward<br>2. Evaluate d(k) for al output units<br>3. Backpropagate d's to obtain d(j) for all hidden units<br>4. Evaluate error derivatives as:	
REGULARIZATION	Maximum likelihood generalisation error<br>(i.e. cross-validation)<br>Regularised error (penalise large weights)<br>Early stopping	
DEEP LEARNING	Basically a Neural Network<br>Many hidden layers<br>Major breakthrough in pre-training<br>Treat each layer first as an unsupervised<br>restricted Boltzmann machine to initialise weights<br>Then do standard supervised backpropagation<br>Can be used for unsupervised learning and<br>dimensionality reduction	
REGULARIZATION	Regularization is a technique used in an attempt to solve the overfitting problem in statistical models.*	
What is Deep Learning?	Definition:<br>• Hierarchical organisation with more than one (non-linear)<br>hidden layer in-between the input and the output<br>variables<br>• Output of one layer is the input of the next layer	
Deep learning methods	(Deep) Neural Networks<br>• Convolutional Neural Networks<br>• Restricted Boltzmann Machines/Deep Belief Networks<br>• Recurrent Neural Networks	
Convolu+onal Neural Networks	is a type of feed-forward artificial neural network in which the connectivity pattern between its neurons is inspired by the organization of the animal visual cortex, whose individual neurons are arranged in such a way that they respond to overlapping regions tiling the visual field.[1]	
How is deep neural network optimised?	Optimised through gradient descent! (Forward-Backward algorithm)<br><br>Penalise complex solutions<br>to avoid overfitting	
cost function - L2 norm		
cost function - Euclidean distance		
cost function - L1 norm		
cost function - Manhattan		
cost function - City block distance		
BASIC DECISION TREES	Decision trees apply a series of linear decisions, that often<br>depend on only a single variable at a time. Such trees partition<br>the input space into cuboid regions, gradually refining the level<br>of detail of a decision until a leaf node has been reached,<br>which provides the final predicted label.	
Tree components	Root node, branch, node, leaf node.	
Branching Factor	Branching factor of node at level L is equal to the<br>number of branches it has to nodes at level L + 1	
CART	Classification And Regression Trees	
Six general questions to decide on decision tree algorithm:	1. How many splits per node (properties binary or multi<br>valued)?<br>2. Which property to test at each node?<br>3. When to declare a node to be leaf?<br>4. How to prune a tree that has become too large (and when<br>is a tree too large)?<br>5. If a leaf node is impure, how to assign a category label?<br>6. How to deal with missing data?	
Tree variaties	Trees are called monothetic if one property/variable is<br>considered at each node, polythetic otherwise	
What trees are preferable?	We prefer simple, compact trees, following Occam's Razor	
How to make trees compact?	To do so, we will seek to minimise impurity of data reaching<br>descendent nodes	
Occam's Razor	All things being equal - the simplest explanation is the best	
The Principle of Plurality	Plurality should not be posited<br>without necessity	
The Principle of Parsimony	It is pointless to do with more<br>what is done with less	
Misclassification Impurity	is the minimum probability that training<br>example will be misclassified at node N	
Bayes' Error	The Bayes Error rate is the theoretical lowest possible error rate<br>for a given classifier and a given problem (dataset).<br>For real data, it is not possible to calculate the Bayes Error rate,<br>although upper bounds can be given when certain assumptions on<br>the data are made.<br>The Bayes Error functions mostly as a theoretical device in<br>Machine Learning and Pattern Recognition research.	
Generalisation	Generalisation is the desired property of a classifier to be able to<br>predict the labels of unseen examples correctly. A hypothesis<br>generalises well if it can predict an example coming from the<br>same distribution as the training examples well.	
Overfitting	A hypothesis is said to be overfit if its prediction performance on<br>the training data is overoptimistic compared to that on unseen<br>data.<br>It presents itself in complicated decision boundaries that depend<br>strongly on individual training examples.	
STOPPING CRITERIA	Reaching a node with a pure sample is always possible but<br>usually not desirable as it usually causes over-fitting.	
Three common ways to decide when to stop splitting decision tree:	Validation set<br>Cross-validation<br>Hypothesis testing (chi-squared statistic)	
EVALUATION PROCEDURES	• For large datasets, a single split is usually sufficient.<br>• For smaller datasets, rely on cross validation	
VALIDATION SET CRITERION	Split training data in a training set and a validation set (e.g.<br>66% training data and 34% validation data)<br>Keep splitting nodes, using only the training data to learn<br>decisions, until the error on the validation set stops going<br>down.	
Cross-validation	In n-fold cross-validation, a dataset is split into n roughly equally<br>sized partitions, such that each example is assigned to one and only<br>one fold. At each iteration a hypothesis is learned using n-1 folds as<br>the training set and predictions are made on the n'th fold. This is<br>repeated until a prediction is made for all n examples, and an error<br>rate for the entire dataset is obtained.<br>Cross-validation maximises the amount of data available to train<br>and test on, at cost of increased time to perform the evaluation.<br>• Training Data segments between different folds should never overlap!<br>• Training and test data in the same fold should never overlap!<br>Error estimation can either be done per fold separately (as<br>shown above), or delayed by collating all predictions per fold.	
CROSS-VALIDATION CRITERION	Split training data in a number of folds<br>For each fold, train on all other folds and make predictions<br>on the held-out test fold<br>Combine all predictions and calculate error<br>If error has gone down, continue splitting nodes, otherwise,<br>stop	
PRUNING	First fully train a tree, without stopping criterion<br>After training, prune tree by eliminating pairs of leaf nodes<br>for which the impurity penalty is small	
MULTIVARIATE TREES I	Instead of monothetic decisions at each node, we can learn<br>polythetic decisions.<br>This can be done using many linear classifiers, but keep it simple!	
MISSING ATTRIBUTES	It is common to have examples in your dataset with missing<br>attributes/variables.<br>One way of training a tree in the presence of missing<br>attributes is removing all data points with any missing attributes.<br>A better method is to only remove data points that miss a required attribute when considering the test for a given node<br>for a given attribute.<br>This is a great benefit of trees (and in general of combined<br>models, see later slide)	
ID3	Interactive dichotomiser version 3<br>Used for nominal, unordered, input data only.<br>Every split has branching factor , where is the number<br>of values a variable can take (e.g. bins of discretised<br>variable)<br>Has as many levels as input variables	
C4.5	Successor of ID3<br>Multiway splits are used<br>Statistical significant split pruning	
REGRESSION TREES	Trained in a very similar way<br>Leaf nodes are now continuous values - the value at a leaf<br>node is that assigned to a test example if it reaches it<br>Leaf node label assignment is e.g. mean value of its data<br>sample<br>Problem: nodes make hard decisions, which is particularly<br>undesired in a regression problem, where a smooth function is<br>sought.	
MODEL COMBINATION VIEW	• Decision Trees combine a set of models (the nodes)<br>• In any given point in space, only one model (node) is responsible<br>for making predictions<br>• Process of selecting which model to apply can be described as a<br>sequential decision making process corresponding to the traversal of a binary tree	
RANDOM FORESTS	Very good performance (speed, accuracy) when abundant data is available<br>Use bootstrapping/bagging to initialise each tree with<br>different data<br>Use only a subset of variables at each node<br>Use a random optimisation criterion at each node<br>Project features on a random different manifold at each node	
Measures of classification accuracy	Classification Error Rate<br>Cross Validation<br>Recall, Precision, Confusion Matrix<br>Receiver Operator Curves, two-alternative forced choice	
Estimating hypothesis accuracy	Sample Error vs. True Error<br>Confidence Intervals	
Sampling Theory Basics	Binomial and Normal Distributions<br>Mean and Variance	
Comparing Hypotheses	t-test<br>Analysis of Variance (ANOVA) test	
CLASSIFICATION MEASURES - ERROR RATE	Common performance measure for classification problems<br>Success: instance's class is predicted correctly (True Positives (TP) /<br>Negatives (TN))<br>Error: instance's class is predicted incorrectly (False Positives (FP) /<br>Negatives (FN))<br>False positives - Type I error. False Negative - Type II error<br>Classification error rate: proportion of instances misclassified over the<br>whole set of instances	
SIMPLE DATA SPLITS	Fixed train, development and test sets: <br>Bootstrapping:<br>Cross-validation	
Fixed train, development and test sets:	Randomly split data into training, development, and test sets.<br>Does not make use of all data to train or test<br>Good for large datasets	
Bootstrapping:	Randomly select a subset to be training set<br>Randomly select a subset to be test set<br>Can be repeated many times<br>Has theoretical problems of statistical significance when<br>repeated	
Cross-validation	Randomly split data into n folds and iteratively use one as<br>test set<br>All data used to test, and almost all to train<br>Good for small sets	
EVALUATION PROCEDURE	For large datasets, a single split is usually sufficient.<br>For smaller datasets, rely on cross validation	
Overfitting can occur when:	Learning is performed for too long (e.g. in Neural Networks)<br>The examples in the training set are not representative of all<br>possible situations (is usually the case! )<br>Model parameters are adjusted to uninformative features in<br>the training set that have no causal relation to the true<br>underlying target function!	
F-MEASURE	Comparing different approaches is difficult when using<br>multiple evaluation measures (e.g. Recall and Precision)<br>F-measure combines recall and precision into a single<br>measure:	
ROC CURVES	Receiver Operator Characteristic (ROC) curves plot<br>TP vs FP rates	
CONFUSION MATRIX	Easy to see if the system is commonly mislabelling one class as another	
HYPOTHESIS QUALITY	We want to know how well a machine learner, which<br>learned the hypothesis as the approximation of the target<br>function , performs in terms of correctly classifying novel,<br>unseen examples<br>We want to assess the confidence that we can have in this<br>classification measure	
The true error of hypothesis h	is the probability that it will<br>misclassify a randomly drawn example from distribution : D<br>However, we cannot measure the true error. We can only estimate it by observing the sample error eS	
SAMPLE ERROR	In statistics, sampling error is incurred when the statistical characteristics of a population are estimated from a subset, or sample, of that population.	
A Bernoulli trial	is a trial with a binary outcome, for which the<br>probability that the outcome is 1 equals p (think of a coin toss of an<br>old warped coin with the probability of throwing heads being p).<br>A Bernoulli experiment is a number of Bernoulli trials performed after<br>each other. These trials are i.i.d. by definition.	
BINOMIAL DISTRIBUTION	In probability theory and statistics, the binomial distribution with parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent yes/no experiments, each of which yields success with probability p.	
NORMAL DISTRIBUTION	The Normal distribution has many useful properties. It<br>is fully described by it's mean and variance and is easy<br>to use in calculations.<br>The good thing: given enough experiments, a Binomial<br>distribution converges to a Normal distribution.	
T-TEST	Assesses whether the means of two distributions are<br>statistically different from each other	
SIGNIFICANCE LEVEL	Significance level α%: α times out of 100 you would find a<br>statistically significant difference between the distributions even if<br>there was none. It essentially defines our tolerance level.<br>If the calculated t value is above the threshold chosen for statistical<br>significance then the null hypothesis that the two groups do not differ is<br>rejected in favour of the alternative hypothesis: the groups do differ.	
Tests for comparing distributions	T-TEST compares two distributions<br>ANOVA compares multiple distributions<br>If NULL-hypothesis is refuted, there are at least two distributions<br>with significantly different means<br>Does NOT tell you which they are!	
LATENT VARIABLES	Latent variables are variables that are 'hidden' in the data. They<br>are not directly observed, but must be inferred.<br>Clustering is one way of finding discrete latent variables in data.	
Discrete latent variables	are hidden variables that can take only<br>a limited number of discrete values (e.g. gender or basic<br>emotion).	
CLUSTERING APPLICATIONS	Market segmentation<br>Social Network Analysis<br>Vector quantisation<br>Facial Point detection	
K-MEANS CLUSTERING	Informally, goal is to find groups of points that are close to each other but far from points in other groups<br>• Each cluster is defined entirely and only by its centre, or mean value µk	
K-MEANS ALGORITHM I	1. Initialise uk randomly<br>2. Minimise J with respect to rnk , keeping uk fixed<br>3. Minimise J with respect uk to , keeping rnk fixed<br>4. Repeat until convergence<br><br>Step 2 is called Expectation step, step 3 the<br>Maximisation step	
K-MEANS ISSUES	Convergence is guaranteed but not necessarily optimal - local<br>minima likely to occur<br>• Depends largely on initial values of uk<br>• Hard to define optimal number K<br>• K-means algorithm is expensive: requires Euclidean<br>distance computations per iteration<br>• Each instance is discretely assigned to one cluster<br>• Euclidian distance is sensitive to outliers	
ROBBINS-MONRO	•Addresses the slow update speed of the M-step in K-means<br>•Uses linear regression (see lecture 1)	
K-MEDOIDS CLUSTERING	Addresses issue with quadratic error function (L2-norm,<br>Euclidean norm)<br>Replace L2 norm with any other dissimilarity measure (V...)	
RANDOM INITIALISATION	Randomly Initialise K-Means clusters using actual instances as<br>cluster centres<br>Run K-Means and store centres and final Cost function<br>Pick clusters of iteration with lowest Cost function as optimal<br>solution<br>Most useful if K < 10	
CHOOSING K	Elbow method<br>• Visual inspection<br>• 'Downstream' Analysis	
PROBABILITY THEORY RECAP	p(x) = marginal distribution<br>p(x,y) = joint distribution<br>p(x|y) = conditional distribution	
MIXTURE OF GAUSSIANS	• Simple formulation: density model with richer representation<br>than single Gaussian	
IID	Independent and identically distributed random variables	
EM Algorythm ISSUES	• Takes a long time<br>• Often initialised using k-Means	
Data Mining	is the quest to extract knowledge and/<br>or unknown interesting patterns from apparently<br>unstructured data<br>AKA Knowledge Discovery from Data (KDD)<br>• Data mining bit of a misnomer - information/<br>knowledge is mined, not data.	
KNOWLEDGE DISCOVERY PROCESS	1. Data cleaning - remove noise and inconsistencies<br>2. Data integration - combine data sources<br>3. Data selection - retrieve relevant data from db<br>4. Data transformation - aggregation etc. (cf. feature extraction)<br>5. Data mining - machine learning<br>6. Pattern Evaluation - identify truly interesting patterns<br>7. Knowledge representation - visualise and transfer new<br>knowledge	
ARFF	Attribute-Relation File Format	
HDF5	Much more complex file format designed<br>for scientific data handling<br> It can store heterogeneous and<br>hierarchical organised data<br>• It has been designed for efficiency	
DM TYPES OF DATA	• Relational databases<br>• Data warehouses<br>• Transactional databases<br>• Object-relational databases<br>• Temporal/sequence/time-series databases<br>• Spatial and Spatio-temporal databases<br>• Text & Multimedia databases<br>• Heterogeneous & Legacy databases<br>• Data streams	
DM FUNCTIONALITIES	Concept/Class description<br>• Characterisation<br>• Discrimination<br>• Frequent patterns/Associations/Correlations<br>• Classification and Regression (Prediction)<br>• Cluster analysis<br>• Outlier analysis<br>• Evolution analysis	
The goal of data mining is to	find interesting patterns!<br>An interesting pattern is:<br>1. Easily understood<br>2. Valid on new data with some degree of<br>certainty<br>3. Potentially useful<br>4. Novel	
DM OBJECTIVE INTEREST	Support: P(X u Y )<br>Percentage of transactions that a rule satisfies<br><br>Confidence: P(Y | X)<br>Degree of certainty of a detected association, i.e.<br>the probability that a transaction containing X also contains Y	
DM SUBJECTIVE INTEREST	Subjective measures require a human with domain<br>knowledge to provide measures:<br>•Unexpected results contradicting a priori beliefs<br>•Actionable<br>•Expected results confirming hypothesis	
DM systems can be divided into types based on a number of variables:	•Kinds of databases<br>•Kinds of knowledge<br>•Kinds of techniques<br>•Target applications	
DM TASK PRIMITIVES	DM task primitives forms the basis for DM queries.<br>DM primitives specify:<br>•Set of task-relevant data to be mined<br>•Kind of knowledge to be mined<br>•Background knowledge to be used<br>•Interestingness measures and thresholds for<br>pattern evaluation<br>•Representation for visualising discovered patterns	
DM QUERY LANGUAGES	DM query language incorporates primitives<br>Allows flexible interaction with DM systems<br>Provides foundation for building user-friendly GUIs<br>Example: DMQL	
DM INTEGRATION WITH DBS/ DATA WAREHOUSES•Tight coupling	•No coupling - DMS will not utilise any DB/DW<br>system functionalit<br>•Loose coupling - uses some DB/DW<br>functionality, in particular data fetching/storing,<br>•Semi-tight coupling - in addition to loose<br>coupling use sorting, indexing, aggregation,<br>histogram analysis, multiway join, and statistics<br>primitives available in DB/DW systems<br>•Tight coupling	
DIRTY DATA	incomplete:<br>noisy:<br>inconsistent:	
•Causes of incomplete data:	"•""Not applicable"" data value when collected<br>•Different considerations between the time when the data<br>was collected and when it is analysed.<br>•Human/hardware/software problems"	
•Causes of noisy data (incorrect values):	•Faulty data collection instruments<br>•Human or computer error at data entry<br>•Errors in data transmission	
•Causes of inconsistent data:	•Different data sources<br>•Functional dependency violation (e.g., modify linked data)	
IMPORTANCE OF CLEANING	• If you have good data, the rest will follow	
DATA QUALITY MEASURES	Multi-Dimensional Measure of Data Quality<br>• A well-accepted multidimensional view:<br>• Accuracy<br>• Completeness<br>• Consistency<br>• Timeliness<br>• Believability<br>• Value added<br>• Interpretability<br>• Accessibility<br>• Broad categories:<br>• Intrinsic, contextual, representational, and accessibility	
MAJOR DM PREP TASKS	*Data cleaning<br>• Fill in missing values, smooth noisy data, identify or remove outliers,<br>and resolve inconsistencies<br>*Data integration<br>• Integration of multiple databases, data cubes, or files<br>*Data transformation<br>• Normalisation and aggregation<br>* Data reduction<br>• Obtains reduced representation in volume but produces the same<br>or similar analytical results<br> *Data discretisation<br>• Part of data reduction but with particular importance, especially for<br>numerical data	
NOISY DATA	Noise is a random error or variance in a measured variable	
Techniques for cancelling out noise:	1. Binning - first sort data, then distribute over local bins<br>2. Regression - fit a parametric function to the data (e.g.<br>linear or quadratic function)<br>3. Clustering	
NOISY DATA - BINNING	Cancelling noise by binning:<br>1. Sort data<br>2. Create local groups of data<br>3. Replace original values by:<br>3.1. The bin mean<br>3.2. The closest min/max value<br>of the bin	
NOISY DATA - REGRESSION	Cancelling noise by regression:<br>1. Fit a parametric function to<br>the data using minimisation of<br>e.g. least squares error<br>2. Replace original values by the<br>parametric function value	
NOISY DATA - clustering:	Cancelling noise by clustering:<br>1. Cluster data into N groups<br>2. Replace original values by<br>means of clusters<br>3. OR: use to detect outlierst	
DATA INTEGRATION	• Entity identification problem<br>• Redundancy detection<br>• correlation analysis<br>• Detection and resolution of data value conflicts<br>• e.g. weight units, in/exclusion of taxes	
DATA TRANSFORMATION	Data transformation alters original data to make it more<br>suitable for data mining.<br>• Smoothing (noise cancellation)<br>• Aggregation<br>• Generalisation<br>• Normalisation<br>• Attribute/feature construction	
ITEMSETS	simply a set of items (cf set theory)	
MINING FREQUENT PATTERNS	• One approach to data mining is to find sets of<br>items that appear together frequently: frequent<br>itemsets<br>• To be frequent some minimum threshold of<br>occurrence must be exceeded<br>• Other frequent patterns of interest:<br>• frequent sequential patterns<br>• frequent structured patterns	
ASSOCIATION RULES	reflect items that are frequently<br>found (purchased) together, i.e. they are frequent<br>itemsets<br>• Information that customers who buy beer also buy<br>crisps is e.g. encoded as:<br>beer ) crisps[support = 2%, conf idence = 75%]	
SUPPORT AND CONFIDENCE	are measures of pattern<br>interestingness	
Rule support:	support(A -> B) = P(A u B)	
• Rule confidence	confidence(A -> B) = P (B|A)	
FREQUENT ITEMSET	• Absolute support of an itemset is its frequency count<br>• Relative support is the frequency count of the itemset<br>divided by the total size of the dataset	
Min-max normalisation:	• Enables cost-function minimisation techniques to<br>function properly, taking all attributes into equal<br>account<br>• Transforms all attributes to lie on the range [0, 1]<br>or [-1, 1]<br>• Linear transformation of all data	
z-score normalisation	Better terminology is zero-mean normalisation<br>• min-max normalisation cannot cope with<br>outliers, z-score normalisation can<br>• Transforms all attributes to have zero mean and<br>unit standard deviation<br>• Outliers are in the heavy-tail of the Gaussian<br>• Still a linear transformation of all data:	
DATA REDUCTION	Should remove what's unnecessary, yet otherwise<br>maintain the distribution and properties of the<br>original data<br>• Data cube aggregation<br>• Attribute subset selection (feature selection)<br>• Dimensionality reduction (manifold projection)<br>• Numerosity reduction<br>• Discretisation	
ATTRIBUTE SUBSET SELECTION	Attribute subset selection = feature selection<br>Feature selection is a form of dimensionality reduction<br>in ML, hence the DM term 'dimensionality reduction'<br>for manifold projection is problematic.<br>Approaches:<br>• Exact solution infeasible<br>• Greedy forward selection<br>• Backward elimination<br>• Forward-backward<br>• Decision tree induction	
NUMEROSITY REDUCTION	Reduces the number of instances rather than attributes.<br>Much more dangerous, as it risks changing the data<br>distribution properties!<br>• Parametrisation<br>• Discretisation<br>• Sampling	
DATA DISCRETISATION	Grouping a possibly infinite space to a discrete set of possible values<br>For categorical data:<br>• Super-categories<br>For real numbers:<br>• Binning<br>• Histogram analysis<br>• Clustering	
INSTANCE REDUCTION	Reduces the number of instances rather than attributes.<br>Much more dangerous, as it risks changing the data<br>distribution properties!<br>• Duplicate removal<br>• Random sampling<br>• Cluster sample<br>• Stratified sampling	
COMPLEX ITEM SETS	The general rule procedure for finding frequent<br>item sets would be:<br>1. Find all frequent itemsets<br>2. Generate strong association rules<br>However, this is terribly costly, with the total<br>number of item sets to be checked for 100 items<br>being:	
SIMPLER METHOD for complex item sets	Closed frequent itemset: X is closed if there exists<br>no super-set Y such that Y has the same support<br>count as X<br>• Maximal frequent itemset: X is frequent, and there<br>exist no supersets Y of X that are also frequent	
APRIORI ALGORITHM	Apriori algorithm is a fast way of finding<br>frequent itemsets	
RULE BASED LEARNING	Equivalent in expression power to traditional<br>(mono-thetic) decision trees, but with more<br>flexibility<br>• They produce rule sets as solutions, in the form of a<br>set of IF... THEN rules	
PREDICATES	A logic statement, generally as boolean logic	
RULE SETS	• Single rules are not the solution of the problem, they<br>are members of rule sets<br>• Rules in a rule set cooperate to solve the problem.<br>Together they should cover the whole search space	
EVALUATING RULES	• A good rule should not make mistakes and should<br>cover as many examples as possible<br> Complexity: Favour rules with simple predicates<br>(Occam's Razor)	
EVALUATING RULE SETS	A complete rule set should be good at classifying all the<br>training examples<br>• Complexity: Favour rule sets with the minimal number<br>of rules	
LEARNING RULE SETS	Learning rules sequentially, one at a time<br>• Also known as separate-and-conquer<br>Learning all rules together<br>• Direct rule learning<br>• Deriving rules from decision trees	
There are three reasons to reduce the dimensionality of a feature set:	1. Remove features that have no<br>correlation with the target distribution<br>2. Remove/combine features that have<br>redundant correlation with target<br>distribution<br>3. Extract new features with a more<br>direct correlation with target<br>distribution	
Degrees of freedom of variability:	Number of ways data can change/number of separate<br>transformations possible	
Intrinsic dimensionality	Subspace of data space that captures degrees of variability<br>only, and is thus the most compact possible representation	
FEATURE SELECTION	Feature Selection returns a subset of original feature set.<br>It does not extract new features.<br>Benefits:<br>Features retain original meaning<br>After determining selected features, selection process is fast<br>Disadvantages:<br>Cannot extract new features which have stronger<br>correlation with target variable	
SEARCH METHODS	Exhaustive<br>Greedy forward selection<br>Greedy backward elimination<br>Forward-backward approach	
FILTER SCORES	Correlation<br>Mutual information<br>Entropy<br>Classification rate<br>Regression score	
MUTUAL INFORMATION	gives a measure of how 'close' two components<br>of a joint distribution are to being independent:	
FORWARD SELECTION	1.Start with empty SF set and candidate<br>set being all original features<br>2. Find feature with highest filter score<br>3.Remove feature from candidate set<br>4.Add feature to SF set<br>5.Repeat steps 2-4 until convergence	
BACKWARD ELIMINATION	1.Start with complete SF set (contains all<br>original features)<br>2. Find feature that, when removed, reduces<br>the filter score least<br>3.Remove feature from SF set<br>4.Repeat steps 2-3 until convergence	
Forward-backward algorithm	first applies Forward<br>selection and then filters redundant elements using<br>backward elimination	
CFS	Correlation based feature selection (CFS) selects features in a<br>forward-selection manner.<br>Looks at each step at both correlation with target variable and<br>already selected features.	
PCA	Manifold projection<br>Assumes Gaussian latent variables and Gaussian observed<br>variable distribution<br>Linear-Gaussian dependence of the observed variables on<br>the latent variables<br>Also known as Karhunen-Loève transform	
PCA requires calculation of:	mean of observed variables<br>covariance of observed variables<br>eigenvalue/eigenvector computation of covariance matrix	
ANN FEATURE SELECTION	Artificial Neural Networks can implicitly perform feature<br>selection<br>A multi-layer neural network where the first hidden layer<br>has fewer units (nodes) than the input layer<br>Called 'Auto-associative' networks	
Parametric methods:	Many methods learn parameters of prediction<br>function (e.g. linear regression, ANNs)<br>After training, training set is discarded.<br>Prediction purely based on learned parameters and new data	
Memory-based methods:	Uses all training data in every prediction (e.g. kNN)<br>Becomes a kernel method if using a non-linear example<br>comparison/metric:	
• Kernel methods	map a non-linearly separable input<br>space to another space which hopefully is linearly<br>separable<br>• This space is usually higher-dimensional, possibly<br>infinitely<br>The key element is that they do<br>not actually map features to this space, instead they<br>return the distance between elements in this space<br>• This implicit mapping is called the (Definition) Trick	
SPARSE KERNEL METHODS	Must be evaluated on all training examples during testing<br>Must be evaluated on all pairs of patterns during training<br>*Training takes a long time<br>*Testing too<br>*Memory intensive (both disk/RAM)<br>Solution: sparse methods	
Three ways of constructing new kernels:	Direct from feature space mappings<br>Proposing kernels directly<br>Combination of existing (valid) kernels<br>* multiplication by a constant<br>* exponential of a kerne<br>* sum of two kernels<br>* product of two kernels<br>*left/right multiplication by<br>any function of x/x'	
Commonly used kernels	Linear kernel:<br>Polynomial kernel<br>Gaussian kernel<br>(Gaussian kernel is probably the most frequently used kernel out there - Gaussian kernel maps to infinite feature space)	
Kernel	is a shortcut that helps us do certain calculation faster which otherwise would involve computations in higher dimensional space.	
Kernel methods	Kernel methods map a non-linearly separable input<br>space to another space which hopefully is linearly<br>separable<br>• This space is usually higher-dimensional, possibly<br>infinitely<br>• Even the 'non-linear' kernel methods essentially solve a linear<br>optimisation problem!!!!	
Kernel trick	The key element of kernel methods is that they do not actually map features to this space, instead they<br>return the distance between elements in this space This implicit mapping is called the (definition)	
Sparse kernel methods	Must be evaluated on all training examples during testing<br>Must be evaluated on all pairs of patterns during training<br>Training takes a long time<br>Testing too<br>Memory intensive (both disk/RAM)<br>Solution: sparse methods	
Maximum margin classifier	is a classifier which is able to give an associated distance from the decision boundary for each example.	
linearly-separable SVM	Satisfising solution (e.g. perceptron algorithm): finds a<br>solution, not necessarily the 'best'<br>Best is that solution that promises maximum generalisibility	
Slack variable	Slack variables introduced to solve optimisation problem<br>by allowing some training data to be misclassified<br>Slack variables en >= 0 give a linear penalty to examples<br>lying on the wrong side of the d.b.: <br>point on correct side of db<br>|tn ! y(xn)|, otherwise	
Relevance Vector Machines	model the typical points of a data set, rather than atypical( a la density estimation)<br>while remaining a (very) sparse (like heat map)<br>representation<br>Returns a true posterior<br>Naturally extends to multi-classification<br>Fewer parameters to tune	
SVMs seek a decision boundary	that maximises the margin	
SVM Margin is defined as	the minimum distance between<br>decision boundary and any sample of a class	
MAXIMUM MARGIN CLASSIFIERS	This turns out to be a solution where decision boundary is<br>determined by nearest points only<br>Minimal set of points spanning decision boundary sought<br>These points are called Support Vectors	
Small set of SVs means that	our solution is now sparse	
NON-LINEARLY SEPARABLE PROBLEMS	Usually problems aren't linearly separable (not even in<br>feature space)<br>'Perfect' separation of training data classes would cause<br>poor generalisation due to massive overfitting	
SOFT MARGIN	We have effectively replaced the hard margin with a soft<br>margin<br>New optimisation goal is maximising the margin while<br>penalising points on the wrong side of d.b.:	
MULTICLASS SVM	SVM is an inherently binary classifier<br>Two strategies to use SVMs for multiclass classification:<br>One-vs-all<br>One-vs-one<br>Problems:<br>Ambiguities (both strategies)<br>Imbalanced training sets (one-vs-all)	
ONE-CLASS SVM	Unsupervised learning problem<br>Similar to probability density estimation<br>Instead of a pdf, goal is to find smooth boundary enclosing a<br>region of high density of a class	
PRIOR PROBABILITY	is the probability of encountering a class without observing any evidence<br>Can be generalised for the state of any random variable<br>Easily obtained from training data (i.e. counting)	
JOINT PROBABILITY	Joint probability is the probability of encountering a particular<br>class while simultaneously observing the value of one or more<br>other random variables<br>Can be generalised for the state of any combination of random<br>variables	
BAYES' THEOREM	posterior =(likelihood x prior)/evidence	
MINIMUM ERROR RATE	Goal is to minimise error rate	
NORMAL DENSITY	By far the most (ab)used<br>density function is the<br>Normal or Gaussian<br>density	
All probability theory can be expressed in terms of two rules	Product rule<br>Sum rule	
Directed PGN:	edges have direction (Bayesian Network)	
Undirected PGN	no edge direction (Markov Random Field)	
Directed Acyclic Graphs (DAGs)	are Bayesian Networks<br>Meaning there are no cyclic paths from any node back to itself	
Some variables are observed, others are hidden/latent	Example observed: labels of a training set<br>Example hidden: learned weights of a model	
PGNs are generative models	allow us to sample from<br>the probability distribution it defines	
ncestral sampling	is a simple sampling method well<br>suited to PGNs	
Conditional independence in PGN	is the PGN mechanism to<br>show information in terms of interesting aspects of<br>probability distributions	
BLOCKING PATHS	When a path is blocked, no information can flow<br>through it<br>This means that observing C, if it blocks a path A-C-B, it<br>means there is no added value in observing A, and B is<br>fully determined by C	
SEQUENCE DATA	Sequence data is data that comes in a particular order<br>Opposite of independent, identical distributed (i.i.d.)<br>Strong correlation between subsequent elements<br>DNA<br>Time series<br>Facial Expressions<br>Speech Recognition<br>Weather Prediction<br>Action planning	
1st order Markov models	restricted to encoding sequential<br>correlation on previous element only	
A Latice/Trellis diagram visualises	state transitions over time<br>Also good tool to to visualise optimal path through states<br>(Viterbi Algorithm)i	
EMISSION PROBABILITIES	Probabilities of observed variables	
ACQUIRING EMISSIONS	Wide range of options to model ****** probabilities:<br>Discrete tables<br>Gaussians<br>Mixture of Gaussians<br>Neural Networks/RVMs etc to mode	
What is the idea behind Find-S algorithm? What are Problems and what are advantages?	idea: finding maximally specific hypotheses<br>Problems:<br>- learns nothing from negative examples, <br>- cannot tell whether it learned a concept, <br>- cannot tell whether training data is inconsistent<br>Good: picks maximally specific h (but depending of H there might be several solutions).	
Describe possible disadvantages of the Find-S- algorithm.	learns nothing from negative examples, <br>cannot tell whether it learned a concept, <br>cannot tell whether training data is inconsistent	
Provide the most specific hypothesis which is learned according to the Find-S algorithm when using the examples below. Provide the individual learning steps, i.e., provide the most specific hypothesis after each learning step.  Example a1 a2 a3 Classification 1 s o p true 2 s r t true 3 t r p false 4 t o p false	S0={<∅,∅,∅>}<br>S1={< s, o, p>}<br>S2={< s, ?, p>}<br>S3={< s, ?, ?>}<br>→ is this right???	
When is hypothesis h consistent with training examples D of target concept c?	hypotheses h is consistent with training examples D of target concept c iff h(x) = c(x) (correctly classified) for all training examples x; c(x)) element D<br>Consistent(h;D) <==> all (x; c(x)) element D : h(x) = c(x)	
What is the version space?	The version space VS(H;D) with respect to the hypothesis space H and training examples D is the subset of hypotheses<br>from H consistent with all training examples in D (i.e. version space = all consistent hypothesis).<br>VS(H;D) = {h element H | Consistent(h;D)}	
What is the idea, problems and advantages of the List-then-eliminate algorithm?	idea: start with all hypothesis, then for each example eliminate the inconsistent hypotheses<br>for a large VS one needs many or few quite informative examples, if VS is ∅ there are inconsistencies<br>Good: computes complete VS (ideally only one hypothesis remains)<br>Problems: can only be applied to finite H, requires enumerating all hypothesis<br>→ impractical for real problems	
What are the two boundaries of the version space?	boundaries of the version space:<br>- general boundary G of VS(H;D) is the set of maximally general members<br>- specific boundary S of VS(H;D) is the set of its maximally specific members<br>every member of the VS lies between (including) these boundaries	
What is the candidate-Elimination algorithm?	Candidate Elimination is a learning algorithm that, in each step, tries to generate a description which is consistent with all previously observed examples in a training set. That description could hypothetically then be used to classify examples outside the training set.<br><br>idea: compute whole VS. Like list-then-eliminate start with complete VS but do not name them explicitly. Instead<br>represent VS by its boundaries. Start with most general G0 <?; ?; ?; ? > and most specific S0 <∅,∅,∅,∅ >. Those<br>delimit the whole VS. Now for each training example specialize G and generalize S until they overlap.	
Given the general boundary G={Strong,?,?} and the specific boundary S={Strong, sunny, warm}v{Strong, cloudy, cool}, which we learned using the Candidate Elimination algorithm. Provide the complete version space, including more general than relations. Provide a definition of your choice of displaying more general than relations	Answer right???<br>VS = {<Strong,?,?>,<Strong, sunny, ?>, <Strong,cloudy, ?>,<Strong, ?,warm>,<Strong, ?,cool>,<Strong, sunny, warm>, <Strong, cloudy cool>}<br>The most general boundary in this example is <Strong,?,?>, having less '?'s makes the boundary more specific.	
What is an inductive bias?	The inductive bias of a machine learning algorithm is the set of assumptions that must be added to the observed data to get a logical deduction from them.<br>That means that it is some preference of the algorithm for a specific set of hypotheses based on a set of training observations.	
Why an inductive bias?	The hypothesis space limits what the algorithm can find. E.g. by choosing conjunctive hypothesis we have biased the learner. However, when representing all concepts (disjunction of all positive examples), we would learn nothing.<br>We would only write the data differently. There would be no generalization possible and convergence would only be achieved when all possible instances would have been presented.<br>How is generalization achieved? The 'inductive leap' came about via the independence of the attribute underlying the<br>construction of H.<br>- bias-free learning systems make no a-priori assumptions ! it can only collect examples without generalization<br>- inductive learning makes sense only with prior assumptions (bias)!<br>- learning is simply: collect examples, interpolate among the examples according to the inductive bias, actively acquire examples following the suggestions from the version space<br>- for every applied learning system the inductive bias should be clear!	
Which of the learning algorithms you heard about in the lecture (Candidate Elimination and Find-S) has the stronger bias?	The inductive bias of the Candidate Elimination algorithm is the assumption that the target concept is contained in the given hypothesis space.<br>The inductive bias of the Find-S Algorithm is that the resulting hypothesis labels all new instances as negative instances unless the opposite is entailed by its prior knowledge from the training set. This has a really big impact as negative examples are ignored completely. This means Find-S has the stronger bias.	
"What is the inductive bias of a learner? Provide an example using the „weather"" problem, which was discussed in the lecture"		
What is the inductive bias of the nearest neighbor classifier?	assume that most of the cases in a small neighborhood in feature space belong to the same class. Given a case for which the class is unknown, guess that it belongs to the same class as the majority in its immediate neighborhood. This is the bias used in the k-nearest neighbors algorithm. The assumption is that cases that are near each other tend to belong to the same class.	
What is the idea of decision trees?	The idea of a decision tree is to classify data by a sequence of interpretable steps. Each node tests a value and each<br>branch stands for one of the values of this attributes. Each endnode than provides a classification.	
decision trees: top-down induction	learning a decision tree is finding the best order to ask the attribute values (best means we<br>want a small tree → information gain)	
What is the problem domain of decision trees?	learning a discrete target function for instances describable as attribute-value pairs.<br>Disjunctive hypothesis required. <br>Possible for noisy data. <br>Decision trees can be written as a set of rules (e.g. as disjunction of conjunction of attribute values: each path is one conjunction, combine all paths with disjunction).	
What is the idea of ID3 learning algorithm?	idea: find best attribute by the distribution over the examples. Put the best one at the root and the possible values as branches. Search second best value for each of the branches...	
Provide Pseudocode for ID3 learning algotithm	while not perfect classification do<br> A ← decision attribute with highest Gain<br> node ← A as decision attribute<br> for all value of A → new descendant of node<br> sort training examples according to leaf nodes<br> iterate over new nodes<br>end while	
Explain Hypothesis space search by ID3	ID3 searches the tree that builds up possible decision trees. Since this space is complete, the target hypothesis is surely in there. Output is a single hypothesis (not the version space) → no queries to resolve among competing hypotheses. No backtracking implemented → ends up in local maxima. Statistically-based search choices → robust to noisy data. Disadvantage: all examples needed for every choice, no incremental learning.	
What is the inductive bias in ID3?	H is power set of instances of X → unbiased search? NO, short trees are preferred (corresponds to Occams razor), high info gain attributes near root are preferred. Bias is preference for some hypotheses rather than a restriction of hypothesis space.	
What does it mean if some features( x1 and x2) do not appear in the decision trees?	Sepal length and sepal width are not relevant for the classification. This might be either because they are redundant or because they are independent of the class.	
Tree 2 only has a 96% accuracy on the training set. Why might this tree still be preferable over tree 1?	Tree 1 is probably overfitted to this specific dataset, i.e. it has not only captured the structure but also the noise in the data. It probably won't generalize as well as the second tree.<br>Another advantage of tree 2 is that it is faster at classifying new data since less computations have to be made. This difference is hardly noticeable however.	
How can we avoid overfitting?	Stop growing when data split is no more statistically significant OR grow tree & post-prune.	
What is reduced error pruning?	remove nodes to achieve better generalization on test data. Pruning node n: remove subtree of n and make n a leaf node, assigning most common classification of its affiliated training examples. Check all nodes for pruning, actually remove the one that results in highest performance increase (greedy). Do while performance on test data increases. properties: produces smallest version of most accurate tree / removes nodes produced by noise (noise per definition not present in test data). If few data, use post pruning instead.	
What is rule post pruning?	build decision tree (allow overfitting), convert tree to rules (one rule for each path from root to leaf), prune each rule (remove any preconditions that improve accuracy n test data), sort final data by accuracy on validation set and apply them in this order for new classification. why pruning rules? only paths are prunde, not entire substrees → more sensitive pruning / no hierarchy while pruning, even pruning of root node possible / better readability	
how can we obtain binary attributes in continuous valued attributes?	to include continuous valued attributes, define thresholds to obtain binary attribute. Thresholds should be chosen to gain info: sort of attribute sets over examples, find boundaries where classification changes, set thresholds at boundaries.	
What is the problem with attributes with many values in classification? What is a solution for this problem?	if an attribute has many values, Gain tends to select it (even if nonsense, because it enables perfect classification). However, this prevents good generalization.<br><br>One solution: GainRatio instead of Gain:<br>St is subset of S for which A has value vi and A has n different values in total. SplitInformation is the entropy with respect to the attribute values.<br>'normalizing the Gain'. GainRatio favors attribute with fewer values, if two attributes yield same gain. GainRatio not defined for attributes with same value for all examples (zero denominator), but they are useless anyway and have to be excluded.	
Which methods can be used if we have missing attributes in decision trees?	- if node n tests A, assign most common values of A among other examples sorted to n<br>- assign most common value of A among other examples with same target value<br>- assign probability pi to each possible value vi of A (prob estimated from value distribution of examples assigned to n).<br>- Assign fraction pi of examples with missing values to each descendant in tree.	
Explain what entropy and information gain is used for	he decision which attribute to choose is based on entropy: <br><br>In many machine learning applications it is crucial to determine which criterions are necessary for a good classification. Decision trees have those criterions close to the root, imposing an order from significant to less significant criterions. One way to select the most important criterion is to compare its information gain or its entropy to others.	
|Example| a1 | a2 | Classification| | 1 | A | D | + | | 2 | A | E | - | | 3 | B | D | + | | 4 | C | D | + | | 5 | B | E | + |  Calculate the entropy E(Sa) for the given the table , where Sa is the subset of S for which an atribute X has the value v. X=(a1,a2). This is, calculate the entropy for each attribute value. It is sufficient to provide the form s-log2(y). Exact calculations of the logarithm is not necessary.  What is the information gain of a1 and a2 relative to the given training examples?		
What can cause outliers?	- measurement and technical errors (cut-o e.g. may lead to high concentration of values at the boundaries)<br>- unexpected true effect (can be modeled by two or more overlaid distributions<br>P(x) = (1 -p) * Pa(x) + p * Pb(x) p << 1<br>- data with inherent high variability (can be modeled by distribution with broad flanks.<br>There are different types of outliers which can have different causes. They could arise through measurement or technical errors when collecting data. This may be connected to having a sharp cut-off in regard to the range of measurements, which could lead to a high concentration of values at the artificial boundaries of an experiment. However they may also show us a true underlying effect in our data that we didn't expect or account for. This might be the case when we are treating the measurements as a single distribution, when in reality there are actually two underlying distributions. Lastly, our distribution might actually naturally have a high variance, which makes outliers or extreme values a natural part of the distribution.	
What is the problem with Outlieres?	Outliers can drastically spoil statistics, especially in small data sets. There are some measures, that are robust against outliers even without explicit detection (e.g. median).	
What do we do with them (in general)? Z-value and Rosner Test	"Usually outliers are detected & removed. But to do this, we first need to define what is regular. Most often we use normal distribution here, for multivariate data, clustering algorithms with normal distribution assumed for each cluster can be used.<br><br>First, we need to detect probable outliers. In order to decide which data points we want to declare as an outlier we have to find a model for regular, meaning ""not outlying"", data points. What we do most of the time is to assume a normal distribution underlying the data (or a multivariate distribution where each cluster is normally distributed).<br><br>One option is to calculate the z-value for each data point (a measure of the distance from the mean in terms of the standard deviation) -- data points with a high z-value would be regarded outliers, a common threshold would be a z value bigger than 3. This can be improved by using the median instead of the mean and tweaking the threshold. The Rosner test takes it one step further by iteratively calculating z-values and removing found outliers until none can be found anymore. This can be done one outlier at a time or k outliers at a time for more efficiency. <br><br>A different approach would be to not remove the outliers completely, but to weight them according to the z-values. And lastly an alternative for complete removal would be to fill up the emerging gaps with values that fit the distribution better."	
How does the z-test work?	detect outliers vie z-values:<br>zt =|xt -mu|/ sigma<br>zt is a measure for the distance of xt from the mean mu's normalized with the standard deviation sigma. Normally, data with Z > 3 are considered outliers. Improvement: outliers use mu, use median instead (commonly with threshold 3,5 then)	
What is the Rosner test? Describe its purpose and provide its formal definition?	The Rosner test is an iterative procedure to remove outliers of a data set via a z-test<br>while new outliers are found do<br> calculate mean mu or median m and SD sigma<br> find data point xit* with largest z-value: i* = argmaxtzt<br> if xt* is an outlier then remove xt*<br> end if<br>end while	
What to do with outliers?	- removal: simple, but loss of information <br>- weight according to z-values<br>- remove outliers and fill up gaps with methods following	
What are pro's and con's of the Eukledian distance?	pro: simple and frequent measure<br>con: no individual weighting of components	
What are pro's and con's of the Pearson distance?	pro: weights dimensions according to their standard deviation<br>con: correlated vector components are overweighted	
What is the idea and what are pro's and con's of the Mahalanobis distance?	idea: scale distances using the covariance matrix C<br>Pro: scale & translation invariant / if C is unit matrix → Euclidian distance<br>Con: scaling might destroy structure within data<br>The points of equal Mahalanobis distance to a center form an ellipsoid	
What ais the idea of the Manhattan distance? (aka city block distance)	Hamming distance (# of positions where two binary strings dier) is equal to Manhattan distance for binary	
What is the idea of the Chebyshev distance? (aka Maximum/chessboard distance)	idea: minimum number of moves a king needs between two positions on a chessboard	
What is the p-norm?	General norm<br>E.g. p=2 --> Euclidean distance<br>p=1 --> Manhattan distance<br>p--> inf maximum distance	
What is the idea behind nominal scales? What is a possible problem and solution?	So far, all dist. measures relied on the topology of R^n. But there are data with other topologies (angular attributes...).<br>Solution: embed different topologies into R^n<br><br>nominal scales: map nominal attributes to real values. (stone;wood; metal) → ((1, 0, 0), (0, 1, 0), (0, 0, 1)) <br>problem: for large n of attribute values, dimensionality becomes too high, a solution would be to choose normalized random vectors instead.	
Describe in your own words: How does the EM-algorithm deal with the missing value problem?	In the EM-Algorithm all known values are considered via their likelihood depending on the distribution. In the same way hidden (i.e. missing) values are considered as depending on the probability distribution and additionally on the known values. So the complete distribution can be seen as the product of two probability distributions (known and missing values).<br><br>The algorithm searches for the parameters that maximize the log-likelihood. As they depend on the missing values, those are averaged out. In an iterative procedure the estimated parameter is improved (M-step) followed by averaging over the missing values using the obtained parameter (E-step). This will lead the estimation of the parameter to converge to a local maximum which hopefully is close to the real parameter value. The principle in handling missing values here is to not try to regain them somehow, but to invent values from a model obtained through the probability distribution. In the best case this does not lead to information loss, although it generally does. However, this at least makes the existing values technically usable.	
What is the motivation behind clustering?	Clusters are basic structures. Additionally, clusters in some feature spaces may indicate closeness of the data on a semantic level. Clustered data implies rules. Compression can be achieved by transmitting only cluster centers. However, it is not always trivial to define clusters, this depends on the scale and the shape one wants to achieve.	
What are possible distance measures of clusters?	minimum distance: Dmin(X, Y ) <br> maximum distance: Dmax(X, Y )<br> mean of all distances: Dmean(X, Y )<br> distance of centers: Dmean(X, Y )<br><br>D = pdist2(X,Y) returns a matrix D containing the Euclidean distances between each pair of observations in the mx-by-n data matrix X and my-by-n data matrix Y. Rows of X and Y correspond to observations, columns correspond to variables. D is an mx-by-my matrix, with the (i,j) entry equal to distance between observation i in X and observation j in Y. The (i,j) entry will be NaN if observation i in X or observation j in Y contain NaNs.	
What is the bias in cluster algorithms?	All clustering algorithms have a bias:<br>- the bias prefers a certain cluster model that compromises scale & shape of the clusters<br>- optimally the bias can be chosen explicitly, but usual it is partly built in in the algorithm<br>- the adjustable parameters are usually processing parameters, not model parameters<br>- the connection between the parameters and the cluster model has to be inferred from the way the algorithm is working<br>- hierarchical clustering solves the problem for the scale parameter by having all different scale solutions present in an ordered way	
What are two complementary methods in hierachical clustering?	- agglomerative clustering: start with each data point as a cluster, then merge recursively bottom up<br>- divisive clustering: start with all data points as a single cluster, split clusters recursively top down<br>The result is a dendrogram representing all data in a hierarchy of clusters.	
Provide a pseudocode algorithm for agglomerative hierarchical complete linkage clustering	Initialization: assign each of n data elements to a cluster Ci i = 1...n<br>while n > 2 do<br> find the pair of clusters Ci , Cj , i < j that optimizes the linkage criterion<br> merge: Ci ← CiU<br> if j < n then Cj ← Cn<br> end if<br> n - -<br>end while<br>Optimizing the linkage criterion requires a distance measure. This is were the algorithm can be modified.	
Name different linkage criterions	- single linkage clustering: uses minimum cluster distance. Prefers chaining<br>- complete linkage clustering: uses the maximum cluster distance. Prefers compact clusters<br>- average linkage clustering (UPGMA): uses mean cluster distance.<br>- centroid clustering: uses centroid distance. Clusters are repr. by their centroids / real valued attributes needed for centroid computation / when joining clusters,. resulting centroid is dominated by the cluster with more members	
What is the difference between single- and complete-linkage clustering?	Single-linkage tends to chain clusters along the data. That is why it combines the points in the center area with those in the bottom right corner.<br><br>Complete-linkage prefers compact clusters and thus combines each of the point heavy areas individually without merging them.	
Explain the idea behing Ward's minimum variance clustering. What are properties?	Idea: merge the two clusters for which the increase in total variance is minimized<br>This approach is optimization based. However, it can be implemented by a distance measure<br>Properties: prefers spherical clusters and clusters of similar size. Robust against noise but not against outliers.	
Explain the idea behind minimum variance clustering	Idea: For merging, do not only take inter-cluster distance into account but also consider size of the clusters (preferring<br>small ones)	
What are the properties of hierachical clustering?	- any distance measure can be used<br>- we only need the distance matrix (not the data)<br>- no parameters<br>- efficiency: agglomerative O(n^3) (optimized SLINK O(n^2)) / divisive: O(2^n) (optimized CLINK O(n^2))<br>- resulting dendrogram offers alternative solutions (but has to be analyzed)<br>- cut off at different levels of dendrogram may be necessary to get comparable clusters<br>- outliers are fully incorporated	
Provide a pseudocode for basic maximization algorithm	(note:~x = vektor x)<br>Initialization: partition data somehow into clusters C1...Cn<br>while stop criterion not reached do<br> Choose an example ~x at random, denote its cluster as C(~x)<br> Randomly select a target cluster Ct<br> compute the change of the goodness function: DeltaE = E('~x element Ct')- E('~x element C(~x)')<br> if Delta E > 0 then<br> Put ~x from C(~x) to Ct<br> else<br> Put ~x from C(~x) to Ct with probability e^(belta Delta E)<br> end if<br> increase beta<br>end while	
What are properties of the basic maximization algorithm?	- maybe caught in local optima<br>- depends on initial partitioning<br>- to escape local optima, 'downhill' steps are accepted with probability ebelta Delta E<br>- simulated annealing: initially small  allows frequent downhill steps, increasing it makes them more unlikely<br>- for the following optimization criteria, only W needs to be computed, due to A = B +W	
"What is meant by ""Compressing by Clustering""?"	dea: given we have a data set consisting of d-dimensional vectors that shall be transmitted over some channel where<br>bits per data point depend on dimension d. We can now cluster our data, transmit the cluster centers once and then<br>only transmit for each data point the cluster that represents it best. A small number of clusters has high compression<br>but bad quality, a high number of clusters vice versa.	
What is the idea of k-means clustering?	idea: Divide dataset D into clusters C1...CK which are represented by their K centers of gravity (aka means) ~w1... ~wK and then minimize the quadratic error<br>Iterative K-means:<br>Start with randomly chosen reference vectors, assign data to best match reference vector, update reference vectors by<br>shifting them to the mean of their cluster, stop if cluster centers haven't moved more element	
What are properties of k-means?	- number of clusters is the only parameter (implicitly defines scale and shape). - Greedy optimization → local optima, depending on initial conditions. <br>- Fast algorithm.	
What is the idea behing soft clustering?	So far: clusters as sets of data points belonging to their respective centers.<br>→ disjoint clusters / hard clustering (each point assigned to ONE cluster) Drawback → no way to express uncertainty<br>about an assignment.<br>Soft clustering idea: describe data by a probability distribution P(~x). A data point is assigned to a cluster by probabilities (expressing uncertainty). Clusters have no boundaries and are represented by Gaussians.	
What are properties of EM-algorithm?	EM yields only local optima <br>computationally much more expensive than K-means <br>precautions against collapse of Gaussian to a single point necessary <br>K-means can provide useful initialization for ~muk, local PCA for Ck <br>There are K! equivalent solutions → parameter identification might be difficult	
What is the idea behind Conceptual clustering?	idea: employs idea of clustering and decision tree learning for unsupervised classifcation.<br>Most known algorithm: COBWEB. Motivated by the drawbacks of ID3 and inspired by cognitive classifcation: category formation is strongly connected to forming prototypical concepts (basic level category and generalizations and specializations of it). <br>Ideas of COBWEB:<br>- unsupervised learning<br>- incremental learning<br>- probabilistic representation: gradual assignment of objects to categories<br>- no a priori fixed number of categories<br>- realized by global utility function which determines: # of categories / # of hierarchical levels / assignment of objects to categories	
What are the curse of dimensionality and its implication for pattern classification?  Explain how this phenomenon could be used to one's advantage	Curse of dimensionality describes the phenomenon that in high dimensional vector spaces, two randomly drawn vectors will almost always be close to orthogonal to each other. This is a real problem in data mining problems, where for a higher number of features, the number of possible combinations and therefore the volume of the resulting feature space exponentionally increases.<br><br>In such a high dimensional space, data vectors from real data sets lie far away from each other (which means dense sampling becomes impossible, as there aren't enough samples close to each other). This also leads to the problem that pairs of data vectors have a high probability of having similar distances and to be close to orthogonal to each other. The result is that clustering becomes really difficult, as the vectors more or less stand on their own and distance measures cannot be applied easily.<br><br>This is actually an advantage if you want to discriminate between a high number of individuals (see Bertillonage, where using only 11 features results in a feature space big enough to discriminate humans), but if you want to get usable information out of data, such a 'singling out' of samples is a great disadvantage.	
Explain in your own words the concepts of descriptive and intrinsic dimensionality	Intrinsic dimensionality exists in contrast to the descriptive dimensionality of data, which is defined by the numbers of parameters used to produce or represent the raw data (i.e. the number of pixels in an unprocessed image).<br><br>Additionally to this representive dimensionality, there is also a (most of the time smaller) number of independent parameters which is necessary to describe the data, always in regard to a specific problem we want to use the data on. <br>For example: a data set might consist of a number of portraits, all with size 1920x1080 pixels, which constitutes their descriptive dimensionality. To do some facial recognition on these portraits however, we do not need the complete descriptive dimension space (which would be way too big anyway), but only a few independent parameters (which we can get by doing PCA and looking at the eigenfaces). <br>This is possible because the data never fill out the entire high dimensional vector space but instead concentrate along a manifold of a much lower dimensionality.	
What is the curse of dimensionality?	combinatorical explosion: n^d (volume of resulting space) combinations for d variables with<br>n values each, which makes n^d points necessary to sample the whole space !--> sampling for large d becomes impossible. Any real data set will not be able to will a high dimensional space	
What are properties of high dimensional spaces?	random pairs of vectors are likely to have similar distances and be close to<br>perpendicular. Also the volume of the surface layer dramatically increases compared to the volume of the inner part (overall probability that one dimension has an extreme value increases).	
What are aims of dimension reduction?	- find local dimensionalities of the data manifold<br>- find new coordinate system to represent the data manifold and project the data to it<br>- get rid of empty parts in the space<br>- new parameters may be more meaningful	
What is the idea of PCA?	- find subspace that captures most of the data variance. <br>- Unsupervised. <br>- Given: data set D = {~x1, ~x2,...}, ~xi element R^d<br>with zero mean: < ~x >=<br>sum over xi(~xi) = 0<br>--> PCA finds m < d orthonormal vectors ~p1...~pm such that ~pi are the directions of the largest variance of D.	
What are the features of PCA?	The eigenvectors are called principal components, which can be interpreted as features, receptive fields or filter kernels. Expansion after the m < d largest eigenvectors is the optimal linear method to minimize the mean square reconstruction error	
PCA: How can we find a suitable number m of eigenvectors?	look for aprupt jumps in the spectrum of eigenvalues indicating a suitable cut off.<br>PCA does not generate structure - it only makes existing structure accessible.	
For data structures is normal PCA appropriate?	linear data structures<br>Problems occur if data structure is non-linear. Better solution here is local PCA	
What is the idea behind local PCA?	first clustering, than PCA in each cluster, or better, iteratively improve position of cluster centers and local PCs.<br>For continous, non-clustered data:<br>--> no continous description of the manifold --> different clusterings are possible, leading to entirely different local projection	
What are principal curves?	principal curves: can handle nonlinear distributions via nonlinear basis functions. Data is projected on the principal<br>curve. However, an appropriate dimensionality and <br>exibility parameter have to be found.	
What is the difference between PCA and principal curves?	PCA:<br>mean square error function for a data set given by a probability density P(~x):<br>E=1/2*Integral(~x- Sum(a1(~x)*~pt)^2*P(~x)d~x))<br>Approximate the manifold by m vectors ~pi, find coeffcients ai(~x) for each ~x<br><br>Principal Curves:<br>Generalize approximation to a parameterized surface ~X (a1,..., a2| ~w) of m dimensions. The vector ~w element of R^n --> parameters that determine the shape of the surface minimizing<br>E =1/2*Integral((~x-~X(a1(~x))...am(~(x)j ~w))^2*P(~x)d~x)<br>The m parameters ai(~x) determine the point on the surface of ~x that best matches ~x and have to be computed for each ~x individually (in a 2D example dataset, there is only one parameter, since m = 1 and ~X is a curve.)<br>The number n of parameters in ~w are responsible for the ability of ~X to t a manifold (small n underfit, large n<br>overfit). For a good fit, additional smoothness constraints should be used. ~w can be fitted using e.g. gradient descent (normally stochastic approximation is used (downhill step over one single sample), since otherwise each step would require integration over all data).	
Kohonen Net	too complicated --> Lernen auf Lücke	
What are common choices on which to decide the number of dimensions to project the data?	- Eigenvalue magnitudes: Find the cut-off depth. This is useful for classification problems, especially for problems to be solved by computers.<br>- Visualization: Choose the number of dimensions which is useful to visualize the data in a meaningful way. This choice depends a lot on your problem definition. For printing 2D is usually a good choice - but maybe your data is just very nice for !D already. Or maybe you are using a glyph plot (see sheet 06) which can represent high dimensional data.<br>- Classification results: In the Eigenfaces assignment below we figured out that the number of principal components (and thus the number of dimensions) can have a crucial impact on classification rates. It is thus an option to fine tune the number of dimensions for a good classification result on some training set.	
How many principal components are there at most when you apply the PCA with the 20 training face images provided? How many principal components were there for the 16 binary images if we made a PCA on all of them?	There are at most 20 principal components possible for the face images, but only four principal components for the binary images.	
Why do we need data visualization techniques and what are techniques to visualize high dimensional data?	Sometimes it is necessary to visualize high dimensional data and a projection via PCA or similar methods might not help enough: We might lose information in a 2D projection.<br><br>In those cases it is useful to come up with other representations of data which we could potentially print on a sheet of paper.<br><br>Techniques are usually glyphs, but different kinds of projection might already be enough (taking information loss into account).	
Why did Chernoff use faces for his representation? Why not something else, like dogs or houses?	Humans are exceptionally good at face recognition. It is very easy to realize if one eye is bigger than another or eye brows are closer together in face-like images for humans than for example figuring out differences in windows sizes or changes in roof skewness between houses.	
Explain at least one other data visualization technique from the lecture	- Scatterplot matrix: Scatter data into plots for each combination of two attributes.<br>- Glyphs: Map data dimensions onto parameters for geometrical figures, e.g. star glyphs, arrows. Properties could be lengths, widths, orientations, colors, ...<br>- Parallel coordinates: Use feature dimensions as one axis and feature values as another. Plot datapoints as lines.<br>- Projections: Several different techniques to project the data: PCA, scaling strategies, ...	
What is a scatterplot matrix?	Matrix of 2D plots of all possible combinations of available dimensions. If displaying all axes is infeasible, PCA may<br>yield suitable directions.	
What are Glyphs?	Maps each dimension onto a parameter of a geometrical gure. Glyphs are normally perceived as a whole ! extracting<br>information of glyphs requires training!<br>Examples: star glyphs, parallel coordinates, Chernov faces.	
What is the idea behind a projection pursuit? What is interesting? What is the procedure? Name four criteria to measure teh deviation of a distribution from the standardized normal distribution. What are Problems?	idea: project onto 2-3 selected directions like PCA, but choose directions that exhibit interesting structure.<br>what is interesting? variance / non-Gaussian distribution (structure) / clusters<br>procedure:<br>1. select 1 to 3 directions (by PCA or simply original dimensions)<br>2. project onto these directions & get density P(~x) of projected data<br>3. compute index how 'interesting' (according to some criterion) the data is<br>4. maximize index by search for better directions<br>criteria:<br>- Firedman-Turkey-Index<br>minimized if P is a parabolic function similar to norm. distribution<br>- Hermite/ Hall Index<br>minimized when P is a standarized normal distribution<br>- Natural Hermite Index<br>like Hermite Index only higher weighting of the center<br>- Entropy Index<br>minimized by standardized normal distribution<br>Problems:<br>maximization requires estimation of density P(~x) of the projected data. Methods are Kernel density estimation (Parzen windows) / orthonormal function expansion	
What is the idea behind multidimensional scaling?	idea: find a lower dimensional manifold such that projection preserves the structure of the data as good as possible.<br>We must define structure. Important: distances between data points.<br>Given R^D and lower dimensional space R^d find a mapping  : R^D--> R^d such that the distances between data points in R^D are well approximated by the distances of the projections of those<br>data points in R^d.	
What are the properties of formal neurons?	- activity communicated via axon is represented as real number x (aka spiking freq)<br>- for a neuron with d inputs --> ~x element of R^d is the input vector<br>- each input xi is weighted by a weight wi<br>- activation is the sum of the weighted inputs<br>- output y is then given by feeding the activation into an activation function: y = y(s)	
Name and explain the three types of learning in artificial neural networks	Unsupervised Learning: no teacher, unlabeled examples. Effect of learning is coded in the learning rules.<br>Supervised Learning: Teacher/labeled examples. Learning is directed at mapping the input part of the examples to the label as an output.<br>Reinforcement Learning: Weak teacher: agent tries to reach goal and only gets feedback if goal has been reached or not. Agent has to find way (create mapping) itself.<br>More realistic learning becomes popular: weakly supervised and semi-supervised learning: pre structuring of data with<br>unsupervised learning, use of rare labeled data after unsupervised learning.	
Explain Hebb's rule?	increase weight wi according to the product of the activation of the neuron and the input via this channel i<br>So far, weights can become arbitrarily large. To prevent this, there are several solutions:<br> Decay Term (including constant forgetting):<br>Delta~w = epsilon *y(~x~w)~x - gamma~w<br> Dynamic normalization to |~w| = 1:<br>Delta~w = epsilon *y(~x~w)~x - gamma~w*( ~w^2 - 1)<br> Explicit normalization to |~w| = 1:<br>~w^new = (~w^old+Delta~w)/(|<br>~w^old+Delta~w|)<br>Oja's rule, uses weight decay y^2:<br>Delta~w = epsilon * y(~x~w)(~x - ~y(~x~w) ~w)	
What is the effect of Hebb's rule on a pair of neurons?	The connection between two neurons, represented by the weight of the postsynaptic neuron, will increase during<br>training until an equilibrium with the decay term is reached. Then, the weight is proportional to the correlation of the<br>activity of the neurons.	
What is the effect of Hebb's rule on the weight vector?	~W converges to the eigenvector of C with the largest eigenvalue.<br>Hebbain learning finds the largest principal component similar to PCA<br>Compared to a winner takes it all rule, the Hebb-trained neurons are affected by all stimuli: close input has less effect<br>than far input. This is why ~w is adjusted according to the data variance.	
"What is called ""the anti Hebb rule""? Explain!"	Habituation<br>~w has a parallel and an orthogonal component to ~x. For continous training with the same ~x the parallel component<br>becomes 0, while the orthogonal component does not change.<br>The anti-Hebb rule leads to habituation: ~w becomes orthogonal to the repeated stimulus --> ~w filters out new stimuli.<br>For several habituated stimuli, only the ~w component orthogonal to the space spanned by those stimuli can pass the<br>filter.	
Name and explain two ways to extract more principal components ~v from D	1. succesive application of single Hebb neurons: extract ~v1, project D to space orthorgonal to ~v1 and extract ~v2 and so on<br>--> single neurons need less steps (only get the 'correct' input for them. Good for sequential training<br>2. Method by Sanger: chain of laterally coupled neurons, each trained by Hebb's rule. First neuron gets unfiltered input, second gets input minus direction of the first weight vector and so on. --> each step requires training of the complete chain, while first neurons are not properly trained, later neurons receive input where PC's with<br>larger eigenvalues are not filtered out correctly. Good for parallel training.	
What is a perceptron able to do? What is it not able to do?	A perceptron represents a d-1 dimensional decision surface, a hyperplane othorgonal to ~w.<br>Necessary conditon: only solvable with a perceptron if data is linearly seperable. This is the case for many basic logical operations, except for XOR (XOR can be solved by distortion of feature space or adding of further input channels like x3 = x1 * x2)	
What is the idea behind Multilayer Perceptons?	idea: solve nonlinear seperation tasks with nonlinear separatrices & classes covering disjoint parts by combining several perceptrons and also generalize to several outputs	
Give the sigmoid function and its first derivative. Why is it used for Multi-Layer Perceptrons?	σ(t)=1/(1+e^(−t))<br>∂σ/∂t=σ(t)(1−σ(t))<br>The sigmoid function is commonly used because of its nice analytical properties: Its domain is [0,1], it is non-linear, strictly monotonous, continuous, differentiable and the derivative can be expressed in terms of the original function at the given point. This allows us to avoid redundant calculations. The sigmoid function is a special case of the more general Logistic function which can be found in many different fields: Biology, chemistry, economics, demography and recently most prominently: artificial neural networks.	
Describe the training of a perceptron and describe two modes of learning	Perceptron is iteratively trained using labled data D = (~x, ~y), ~x^n element R^d<br>Perceptron training rule:<br>Delta ~w = epsilon (t - y)~x<br>Convergence can be shown if learning rate epsilon is sufficiently small (and task is solvable by a perceptron). The learning rule can be derived from minimizing the mean squared error.<br>Two models of learning:<br>-batch mode: gradient descent with respect to entire training set:<br>Delta~w =epsilon Sum((ti-y(~xi))~xi)<br>- incremental mode: gradient descent with respect to one example (~xi, ti)<br>Delta~w = (ti - y(~xi))~xi<br>For small : incremental mode can be shown to approximate batch mode arbitrarily close.	
What is the general srchitecture of an MLP?	- input layer (Layer 0): one neuron for each dimension of input vector (input neurons only represent input)<br>- at least one hidden layer (L1...LH), hidden layer can have different numbers of neurons<br>- output layer(LH+1): one node per dimension of the output<br>- feed forward architecture: only connections from layer k to i with k < i<br>- more notation: neurons in layer i: 1(i)...N(i) / output of neuron i in layer k: oi(k) / weight from neuron k in<br>layer n to neuron i in layer m: wik(m, n)<br><br>Sigmoid activation functions σ are used (succession of linear transforms is itself a single linear transform, so nothing to gain here). σ enforces a decision, soft step required (backpropagation requires dierentiability). Squashing maps<br>incoming info to smaller range.	
training MLP + Backpropagation pseudocode	Use same error function as before & minimize by gradient descent. Problem: all derivatives on the path from wik(m,n) to output layer required. The backpropagation algorithm provides a scheme for ecient computation of all required derivatives and weight adaptations.<br><br>initialize ~w randomly<br>while stop criterion is met do<br> propagate ~x forward trough net to obtain ~y<br> compute error ti - yi(~x) between actual output and desired output for each output dimension i<br> Propagate errors backwards trough net to find 'responsible' weights<br> update weights<br>end while<br><br>weight of neuron j is adapted in proportion to activation of neuron in previous layer to which it is connected %<br>weighted errors it causes at the output.<br>This complex scheme is necessary since target values are only available for the outputs, not the hidden layer neurons<br>(so a 'target value' has to be constructed). BP-algorithm performs a stochastic apprximation of gradient descent for<br>error function E.	
What are problems with minimization in MLPs?  What are ways to avoid local minima?	Minimization here is still computationally expensive, suffers from local optima, is diffcult to terminate (good fit but<br>no overfitting).<br>Ways to avoid local minima:<br>- repeat training with different initial weights to find different basins of attraction<br>- annealing: add noise, e.g. every n learning steps: wji(k + 1, k) = wji(k + 1, k) + T  Gji(k + 1, k)<br>G is a Gaussian random variable with mu= 0, T is the temperatur<br>Annealing improves minimization but requires longer learning.<br>- Step size adaptation: increase  in epsilon at regions and decrease in steep terrain<br>- momentum: Delta wji(k + 1, k)(t))epsilon deltaj(k + 1)oi(k) + wji(k + 1, k)(t - 1)<br>t is a step counter, so direction of step t-1 is kept to some degree. This avoids abrupt changes of direction and<br>thereby counteracts stoping at minor minima and oscillations.<br><br>Weight decay: overly large weights are problematic, they lead to binary decisions of single neurons. Therefore an<br>additional quadratic regularization term can be added to the error function to avoid large weights. This leads to a<br>decay part in the learning rule.	
How does Backpropagation in MLPs work?	Multilayer perceptrons (MLPs) can be regarded as a simple concatenation (and parallelization) of several perceptrons, each having a specified activation function σ and a set of weights wij. The idea that this can be done was discovered early after the invention of the perceptron, but people didn't really use it in practice because nobody really knew how to figure out the appropriate wij. The solution to this problem was the discovery of the backpropagation algorithm which consists of two steps: first propagating the input forward through the layers of the MLP and storing the intermediate results and then propagating the error backwards and adjusting the weights of the units accordingly.<br><br>An updating rule for the output layer can be derived straightforward. The rules for the intermediate layers can be derived very similarly and only require a slight shift in perspective - the mathematics for that are however not in the standard toolkit so we are going to omit the calculations and refer you to the lecture slides.<br><br>We take the least-squares approach to derive the updating rule, i.e. we want to minimize the Loss function <br>L=1/2*(y−t)^2<br>where t is the given (true) label from the dataset and y is the (single) output produced by the MLP. To find the weights that minimize this expression we want to take the derivative of L w.r.t. wi where we are now going to assume that the wi are the ones directly before the output layer<br>∂L/∂wi=(y−t)oi*y(1−y)	
What are the steps of the algorithm of implementing an MLP?	1.Initialize your MLP. <br>Use as many input neurons as there are dimensions in the data. Input neurons always expect 1D input. Then create neurons for each hidden and the output layer. Each neuron in the hidden and output layers expects as many inputs as there are neurons in the layer before them.<br><br>2.Initialize the neurons' weights. <br>For each neuron in layers 1...LH+1 initialize the weights to small random values <br><br>3.Implement the activation (feed-forward) step. <br>A.Decompose the input into its components and pass them to the correct input neuron.<br>B.Each input neuron passes its unprocessed input to the next layer. That means each neuron in layer 1 receives all outputs from each input layer as its own input. <br>oi(0)=xi<br>C.Calculate the weighted sums of their inputs and apply their activation function σ for each neuron in the layers 1...LH+1. This is best done iteratively layer by layer, as each layer's input is the output of its preceding layer (Note: wj0(k,k) denotes the bias for neuron j in layer k): <br>D.The resulting oi(LH+1) are the outputs yi for each output neuron i.<br><br>4.Implement the adaption (backpropagation) step. A.Compute the error between the target and output components to calculate the error signals δi(LH+1) :<br>δi(LH+1)=oi(LH+1) (1−oi(LH+1)) (ti−oi(LH+1))<br>B. Calculate the error signals δi(k) for each hidden layer k, starting with k=LH and going down to k=1. <br>C. Adapt the weights for each neuron in the hidden and output layers. <br>Δwji(k+1,k)=ϵδj(k+1)oi(k)	
How do you find the appropriate architecture for your MLP? What do layer 1, 2, and 3 define? Are there restrictions regarding the number of nodes?	Funashi: arbitrary bounded continous mapping can be approximated with arbitrary precision with one hidden layer<br>with sigmoidal activation functions and a layer with linear output functions<br>Cybenko: 2 hidden layers are sufficient to approximate any function with arbitrary precision (however, layers migth<br>be huge)<br>How so?<br>--> 1st layer defines hyperplanes<br>--> 2nd layer defines ANDs over the hyperplanes (convex areas)<br>--> 3rd layer defines ORs over convex areas<br>No restrictions on number of nodes, BUT:<br>--> less nodes than input layer may destroy degrees of freedom (if present in the data)<br>--> more nodes may facilitate representation but cannot invent additional degrees of freedom<br>Hidden layer may serve to discover features in the input data (more dimensions than needed etc)	
MLP encoder	General result: for an arbitrary distributions of vectors, the n neurons of the hidden layer (aka bottleneck) converges<br>to span the subspace of the input space which is spanned by the n principal components with the largest eigenvectors.	
Sortierarfgabe? Neural Architectures	In the following we will look at N x N connectivity matrices, since they comprise the complete wiring information<br>- fully connected <br>--> higly complex dynamics (chaotic)<br>-sparsely connected <br>--> some statements about dynamics are possible, interesting case<br>- diagonal matrix <br>--> boring, each neuron only connected to itself<br>- tridiagonal matrix <br>--> chain of N neurons, each neuron has forward & backward coupling to it's neighbours (and itself)<br>- lower triangular matrix <br>--> feed forward network, no recurreny, type of MLP, diagonal = 0 so no slef coupling<br>- block diagonal <br>--> seperated local networks<br>- block diagonal + sparse connections <br>--> small world networks<br>- symmetric matrix <br>--> Hopeld networks, dynamics converge to point attractors	
Describe recurrent networks	Feed-forward networks can be computed sequentially (updating), since there are no cycles --> they are 'timeless'<br>Not possible for recurrent networks (due to cycles) --> recurrent networks are dynamical systems, time is important.<br>They can either be described continously by differential equations or discrete by the use of synchronous (next timestep for all neurons) or asynchronous updating (randomly updating neurons).<br>Phase space: space of all possible states of a network (all possible activation vectors)<br>Evolution of the system is trajectory threw the state space<br>Basic scenarios:<br>--> convergence to point attractor<br>--> convergence to limit cycle<br>--> convergence to strange attractor<br>--> chaos	
What are radial basis functions?	Radial basis functions are all functions that fullfill the following criteria:<br><br>The value of the function for a certain point depends only on the distance of that point to the origin or some other fixed center point. In mathematical formulation that spells out to: ϕ(x)=ϕ(∥x∥) or ϕ(x,c)=ϕ(∥x−c∥). Notice that it is not necessary (but most common) to use the norm as the measure of distance.	
What is the structure of a RBFN?	RBFN's are networks that contain only one hidden layer. The input is connected to all the hidden units. Each of the hidden units has a different radial basis function that is sensitive to ranges in the input domain. The output is then a linear combination of the outpus ot those functions.	
How is a RBFN trained?	Note: all input data has to be normalized.<br><br>Training a RBFN is a two-step process. First the functions in the hidden layer are initialized. This can be either done by sampling from the input data or by first performing a k-means clustering, where k is the number of nodes that have to be initialzed.<br><br>The second step fits a linear model with coefficients wi to the hidden layer's outputs with respect to some objective function. The objective function depends on the task: it can be the least squares function, or the weights can be adapted by gradient descent.	
What do both models (RBFN and MLP) have in common? Where do they differ?	RBFN: <br> - non-linear layered feedforward network<br>- hidden neurons use radial basis functions, output neurons use linear function<br>- universal approximator <br>- learning usually affects only one or some RBF <br><br>MLP<br>- non-linear layered feedforward network<br>- input, hidden and output-layer all use the same activation function<br>- universal approximator<br>- learning affects many weights throught the network	
When would you use a RBFN instead of a Multilayer Perceptron?	RBFNs are more robust to noise and should therefore be used when the data contains false-positives.	
What is the idea behind instance based learning?	idea: simply store the training examples D = (~xn,~tn), ~xn element R^d,n ,	
Name and explain two simple approaches of instance based learning.	Nearest neighbour algorithm<br>Training: Memorize all examples<br>Application: for new ~x find best match and give output for of this best match.<br>K-nearest neighbour algorithm<br>for unknwon ~x find set S of nearest neighbours of stored examples. <br>Discrete valued output: vote <br>Continous output:<br>use mean	
What are the properties of instance based learning?	1. plain nearest neighbour --> hard boundaries (assigns new output to Voronoi tesselation cell)<br>k-nearest --> allows continous transitions (new, unseen outputs)<br>2. suitable k depends on local intrinsic data dim<br>3. Training: very fast / requires memory (no compr) / no info wasted / no params or complex procedures<br>4. application: may be slow (when many exampes stored) / sensitive to errors & noise	
What us the idea behind distance weighted k-nearest neighbours?	idea: nearer neighbours are more important.<br>weight average with distance to the input with inverse distance as weight<br>cool thing: now neighbours can be the entire set of examples	
What is the idea behind Locally weighted Regression?	Construct better local approximation of ~y(~x) by computing t function in the region around the samples<br>Two choices: what fit function (linear, quadratic,...) & what error function (what will be minimized? local!!!)	
What are properties of local methods in instance based learning	In MLP like ANN's single weight adaptations might influence performance of the whole net (all ouput channels). They<br>are a very delicate and non robust structure. 'Death' aka removal of single neurons might have drastic consequences<br>for the network.<br>Local method networks are far more robust, since computation of output only (or mainly) relies on local units and<br>can be nicely compensated for by other units. Also adaptation has only local effects.	
How is learning in a self-organizing map achieved? (As opposed to techniques used in MLP?)	In self-organizing maps the nodes take part in competitive learning. They compete for each input and a winner is dertermined whos weights (and the weights of his neighbors) are the only weights that are adapted. MLPs use error correction learning where a delta of the output to a target value is computed and used to adapt all weights in the network.	
What would be an alternative to initializing nodes randomly in self-organizing maps?	The nodes/weights can be sampled from the subspace spanned by the larges principal components. With this method learning should become faster since the nodes already have a good initial fit to the structure of the data. This method only works if the dataset is not essentially non-linear-	
Why are self-organizing maps possibly interesting for cognitive scientists in general?	It could be argued that self-organizing maps work in a way similar as the brain when it handels different sensory input in different parts of the brain. The areas themselves are topologically structured in a way that similar inputs activate the same area (just like the SOMs as well)	
How does the LDA classifier work? What restrictions have to be fullfilled by the data for this method to work and why?	The LDA classifier assumes two normally distributed classes of data with the same covariance matrices each. It subtracts the mean of the two distribution from each other and normalizes by the inverse variance. <br>Taking the inner product of the weight (the normalized difference function) with the new data point yields either a positive or a negative value which can be compared to the threshold to determine the estimator for the class of the new data point.	
How does the nearest neighbor classifier work? When would you use it and how is it trained?	For a new sample the nearest neighbor classifier searches for the corresponding nearest data point in our training data.<br>You would use it when memory and runtime timings are not of great importance, as training is instant: You just store the training data. However, classification becomes a computationally more expensive task.	
Name some differences between a SVM and a MLP. When would you use which?	SVM:<br>- linear separatrix (unless using kernel trick)<br>- binary classifier (extension to cascade possible)<br>- no online training<br>- can deal with outliers: slack variables<br>MLP:<br>- non-linear separatrix<br>- multiple classes possible<br>- online training possible<br>- outliers affect the whole network	
Well-posed Learning Problem	A computer program is said to learn from (E)xperience E with respect to some (T)ask T and some (P)erformance measure P, if its performance on T, as measured by P, improves with experience E.	
Machine Learning	Field of study that gives computers the ability to learn without being explicitly programmed.	
Machine Learning broad definition	Field of study that gives computers the ability to learn without being explicitly programmed.	
Abstract Essence of ML	Representation + Evaluation + Optimisation	
Machine Learning	Learning from experience. It's also called supervised learning, were experience E is the supervision.	
Pattern Recognition	Finding patterns without experience. It's also called unsupervised learning.	
Unsupervised Learing	- We only have xi values, but no explicit target labels.<br>- You want to do 'something' with them.	
Unsupervised Learning Tasks	- Outlier detection: Is this a 'normal' xi ?<br>- Data visualization: What does the high-dimensional X look like?<br>- Association rules: Which xij occur together?<br>- Latent-factors: What 'parts' are the xi made from?<br>- Ranking: Which are the most important xi ?<br>- Clustering: What types of xi are there?	
Classification	ML task where T has a discrete set of outcomes. Often classification is binary.<br>Examples:<br>• face detection<br>• smile detection<br>• spam classification<br>• hot/cold	
Regression	ML task where T has a real-valued outcome on some continuous sub-space<br>Examples:<br>• Age estimation<br>• Stock value prediction<br>• Temperature prediction<br>• Energy consumption prediction	
Labels	Values that h aims to predict<br>Example:<br>• Facial expressions of pain<br>• Impact of diet on astronauts in space<br>• Predictions of house prices	
Training algorithm	Given a model h with Solution Space S and a training set {X,Y}, a learning algorithm finds the solution that minimizes the cost function J(S)	
Features/Attributes	Measurable values of variables that correlate with the label y<br>Examples:<br>• Sender domain in spam detection<br>• Mouth corner location in smile detection<br>• Temperature in forest fire prediction<br>• Pixel value in face detection	
Cost Function	Squared error cost function. J(S)	
Local minima	The smallest value of the function. But it might not be the only one.	
General classification problem	If classes are disjoint, i.e. each pattern belongs to one and only one class then input space is divided into decision regions separated by decision boundaries or surfaces	
Decision surfaces are	• Linear functions of x<br>• Defined by (D-1) dimensional hyperplanes in the D dimensional input space.	
Linear Separability	Linearly separable data:<br>• Datasets whose classes can be separated by linear decision surfaces<br>• Implies no class-overlap<br>• Classes can be divided by e.g. lines for 2D data or planes in 3D data	
Orthogonality	- Two vectors and are orthogonal if they're perpendicular<br>- If their inner product is 0:<br>a · b = 0	
LDA	- Linear Discriminant Analysis<br>- Most commonly used as dimensionality reduction technique in the pre-processing step for pattern-classification and machine learning applications.<br>- The goal is to project a dataset onto a lower-dimensional space with good class-separability in order avoid overfitting	
Training LDA objective:	Find (i.e. learn) that minimizes some error function on the training set.<br><br>Significant approaches:<br>• Least squares<br>• Fisher<br>• Perceptron	
Artificial Neural Nets	• Feed-forward neural network/Multilayer Perceptron one of many ANNs<br>• We focus on the Multilayer Perceptron<br>• Really multiple layers of logistic regression models	
The simplest ANNs consist of	• A layer of D input nodes<br>• A layer of hidden nodes<br>• A layer of output nodes<br>• Fully connected between layers	
Curse of Dimensionality	The curse of dimensionality refers to how certain learning algorithms may perform poorly in high-dimensional data.<br><br>First, it's very easy to overfit the the training data, since we can have a lot of assumptions that describe the target label (in case of supervised learning). In other words we can easily express the target using the dimensions that we have.<br><br>Second,we may need to increase the number of training data exponentially, to overcome the curse of dimensionality and that may not be feasible.<br><br>Third, in ML learning algorithms that depends on the distance, like k-means for clustering or k nearest neighbors, everything can become far from each others and it's difficult to interpret the distance between the data points.	
EXTREME Dimensionality Case	In an extreme, degenerate case, if D > n, each example can be uniquely described by a set of feature values.	
Hidden layer(s) can	- Have arbitrary number of nodes/units<br>- Have arbitrary number of links from input nodes and to output nodes (or to next hidden layer)<br>- There can be multiple hidden layers	
Hidden Unit Activation	"Common functions for are unit step, sigmoid or logistic and tanh         <div><img src=""quizlet-LIWgIrDQ684G5rSt21wdAA_m.png"" /></div>         "	
RELU	"Rectified Linear Unit <br>New trend, responsible for great deal of Deep Learning success. Advantages:<br>• No 'vanishing gradient' problem<br>• Can model any positive real value<br>• Can stimulate sparseness         <div><img src=""quizlet-bv637WUJigjS3lT8Su9shg_m.jpg"" /></div>         "	
Output layer can be	• Single node for binary classification<br>• Single node for regression<br>• n nodes for multi-class classification	
Network Topology	Variations include:<br>• Arbitrary number of layers<br>• Fewer hidden units than input units (causes in effect dimensionality reduction, equivalent to PCA)<br>• Skip-layer connections<br>• Fully/sparsely interconnected networks	
Training a network	Training a NN involves finding the parameters that minimize some error function<br><br>Choice of activation function depends on the output variables:<br>- Unity for regression<br>- Logistic sigmoid for (multiple independent) binary classification<br>- Softmax for exclusive (1-of-K) multiclass classification	
NN Error Functions	Regression:<br>- Binary classification<br>- Multiple independent binary Classification:<br>- Multi-class classification<br>(mutually exclusive):	
Gradient points in the direction of	Steepest Ascent	
How to train ANN	An error function on the training set must be minimized. This is done by adjusting:<br>- Weights connecting nodes.<br>- Parameters of non-linear functions h(a).	
Eigenvalue	Given an invertible matrix , an eigenvalue equation can be found in terms of a set of orthogonal vectors , and scalars such that:<br>M	
Derivative	Measure of how fast function value changes withe the change of the argument. So if you have the function f(x)=x^2 you can compute its derivative and obtain a knowledge how fast f(x+t) changes with small enough t. This gives you knowledge about basic dynamics of the function	
Gradient	Gradient shows you in multidimensional functions the direction of the biggest value change (which is based on the directional derivatives) . So given a function i.e. g(x,y) = -x+y^2 you know, that it is better to minimize the value of x, while strongly maximize the value of y. This is a base of gradient based methods, like steepest descent technique.	
Batch Gradient descent	"- Vanilla gradient descent, aka batch gradient descent<br>- Make small change in weights that most rapidly improves task performance<br><br>Gradient descent computes the gradient of the cost function w.r.t. to the parameters θ for the entire training dataset<br><br>- Can be very slow<br>- Intractable for datasets that don't fit in memory<br>- Doesn't allow us to update our model online, i.e. with new examples on-the-fly.<br>- guaranteed to converge to the global minimum for convex error surfaces and to a local minimum for non-convex surfaces.         <div><img src=""quizlet-Mp4GBIHBeg4ZdeKq.5QX1A_m.png"" /></div>         "	
On-line Gradient Descent	"On-line (or Schotastic) gradient descent also known as incremental gradient descent updates parameter one data point at a time.<br>- Handles redundancy better. (Batch GD has redundancy)<br>- Usually much faster than Batch GD.<br>- SGD performs frequent updates with a high variance that cause the objective function to fluctuate heavily<br>- Can deal with new data better.<br>- Good chance of escaping local minima. However, when we slowly decrease the learning rate, SGD shows the same convergence behaviour as batch gradient descent         <div><img src=""quizlet-Mp4GBIHBeg4ZdeKq.5QX1A_m.png"" /></div>         "	
Backpropagation	- Used to calculate derivatives of error function efficiently<br>- Errors propagate backwards layer by layer	
Backprop is for:	Arbitrary feed-forward topology<br>Differentiable nonlinear activation functions<br>Broad class of error function	
Error Backpropagation	1. Apply input vector to network and propagate forward<br>2. Evaluate d(k) for all output units<br>3. Backpropagate d's to obtain d(j) for all hidden units<br>4. Evaluate error derivatives as:	
Regularization	Regularization is a technique used in an attempt to solve the overfitting problem in statistical models.	
Regularization	- Maximum likelihood generalization error (i.e. cross-validation)<br>- Regularized error (penalize large weights)<br>- Early stopping	
Deep Learning	- Basically a Neural Network with Many hidden layers<br>- Can be used for unsupervised learning and dimensionality reduction	
What is Deep Learning?	Definition:<br>• Hierarchical organization with more than one (non-linear)<br>hidden layer in-between the input and the output variables<br>• Output of one layer is the input of the next layer	
Deep learning methods	(Deep) Neural Networks<br>• Convolutional Neural Networks<br>• Restricted Boltzmann Machines/Deep Belief Networks<br>• Recurrent Neural Networks	
Convolutional Neural Networks	Type of feed-forward artificial neural network in which the connectivity pattern between its neurons is inspired by the organization of the animal visual cortex, whose individual neurons are arranged in such a way that they respond to overlapping regions tiling the visual field.	
How is deep neural network optimized?	Optimized through gradient descent! (Forward-Backward algorithm)<br>- Penalize complex solutions to avoid overfitting	
Cost function - ℓ2 norm	"In order to avoid over-fitting, one common approach is to add a penalty term to the cost function. Common choices are the ℓ2-norm, given as: <br><br>Where C0 is the unregularized cost         <div><img src=""quizlet-FXZDCC8SZA9h9fSazq-i7w_m.png"" /></div>         "	
Cost function - ℓ1 norm	"         <div><img src=""quizlet-ltrypgtCDkFZeGLYSUi2aw_m.png"" /></div>         "	
Dropout	A very different approach to avoiding over-fitting is to use an approach called dropout. <br>Here, the output of a randomly chosen subset of the neurons are temporarily set to zero during the training of a given mini-batch. This makes it so that the neurons cannot<br>overly adapt to the output from prior layers as these are not always present. It has enjoyed wide-spread adoption and massive empirical evidence as to its usefulness.	
Cost function - Euclidean distance	Distance measure between a pair of samples p and q in an n-dimensional feature space	
Cost function - Manhattan or City block distance	Calculate the distance between real vectors using the sum of their absolute difference. Also called City Block Distance	
Basic Decision Tree	Decision trees apply a series of linear decisions, that often depend on only a single variable at a time. Such trees partition the input space into cuboid regions, gradually refining the level of detail of a decision until a leaf node has been reached, which provides the final predicted label.	
Tree components	Root node, branch, node, leaf node.	
Branching Factor	Branching factor of node at level L is equal to the number of branches it has to nodes at level L + 1	
CART	Classification And Regression Trees	
Six general questions to decide on decision tree algorithm:	1. How many splits per node (properties binary or multi valued)?<br>2. Which property to test at each node?<br>3. When to declare a node to be leaf?<br>4. How to prune a tree that has become too large (and when is a tree too large)?<br>5. If a leaf node is impure, how to assign a category label?<br>6. How to deal with missing data?	
Tree variaties	Trees are called monothetic if one property/variable is considered at each node, polythetic otherwise	
What trees are preferable?	We prefer simple, compact trees, following Occam's Razor	
How to make trees compact?	To do so, we will seek to minimise impurity of data reaching<br>descendent nodes	
Occam's Razor	All things being equal - the simplest explanation is the best	
The Principle of Plurality	Plurality should not be posited without necessity.	
The Principle of Parsimony	It is pointless to do with more what is done with less.	
Misclassification Impurity	Minimum probability that training example will be misclassified at node N	
Bayes' Error	- The Bayes Error rate is the theoretical lowest possible error rate for a given classifier and a given problem (dataset).<br>- For real data, it is not possible to calculate the Bayes Error rate,<br>although upper bounds can be given when certain assumptions on<br>the data are made.<br>- The Bayes Error functions mostly as a theoretical device in Machine Learning and Pattern Recognition research.	
Generalisation	Generalization is the desired property of a classifier to be able to predict the labels of unseen examples correctly. A hypothesis generalizes well if it can predict an example coming from the same distribution as the training examples well.	
Overfitting	A hypothesis is said to be overfit if its prediction performance on the training data is overoptimistic compared to that on unseen data. It presents itself in complicated decision boundaries that depend strongly on individual training examples.	
Stopping Criteria	Reaching a node with a pure sample is always possible but usually not desirable as it usually causes over-fitting.	
Three common ways to decide when to stop splitting decision tree	- Validation set<br>- Cross-validation<br>- Hypothesis testing (chi-squared statistic)	
Evaluation Procedures	• For large datasets, a single split is usually sufficient.<br>• For smaller datasets, rely on cross validation	
Validation set Criterian	Split training data in a training set and a validation set (e.g. 66% training data and 34% validation data). Keep splitting nodes, using only the training data to learn<br>decisions, until the error on the validation set stops going<br>down.	
Cross-validation	In k-fold cross-validation, a dataset is split into k roughly equally sized partitions, such that each example is assigned to one and only one fold. At each iteration a hypothesis is learned using k-1 folds as the training set and predictions are made on the k'th fold. This is repeated until a prediction is made for all k folds, and an error rate for the entire dataset is obtained.<br>Cross-validation maximises the amount of data available to train and test on, at cost of increased time to perform the evaluation.<br>• Training Data segments between different folds should never overlap<br>• Training and test data in the same fold should never ovelap<br>Error estimation can either be done per fold separately, or delayed by collating all predictions per fold.	
Cross-validation criterion	Split training data in a number of folds. For each fold, train on all other folds and make predictions on the held-out test fold. Combine all predictions and calculate error. If error has gone down, continue splitting nodes, otherwise, stop	
Pruning	First fully train a tree, without stopping criterion<br>After training, prune tree by eliminating pairs of leaf nodes for which the impurity penalty is small	
Multivariate Trees	Instead of monothetic decisions at each node, we can learn polythetic decisions. This can be done using many linear classifiers, but keep it simple!	
Missing Attributes	It is common to have examples in your dataset with missing attributes/variables.<br>One way of training a tree in the presence of missing attributes is removing all data points with any missing attributes.<br>A better method is to only remove data points that miss a required attribute when considering the test for a given node for a given attribute.<br>This is a great benefit of trees (and in general of combined models,)	
ID3	Interactive dichotomizer version 3<br>Used for nominal, unordered, input data only.<br>Every split has branching factor , where is the number of values a variable can take (e.g. bins of discretized variable) has as many levels as input variables	
C4.5	- Successor of ID3.<br>- Multiway splits are used.<br>- Statistical significant split pruning.	
Regression Trees	- Trained in a very similar way<br>- Leaf nodes are now continuous values - the value at a leaf node is that assigned to a test example if it reaches it<br>- Leaf node label assignment is e.g. mean value of its data sample<br>Problem: nodes make hard decisions, which is particularly undesired in a regression problem, where a smooth function is sought.	
Model Combination View	• Decision Trees combine a set of models (the nodes)<br>• In any given point in space, only one model (node) is responsible for making predictions<br>• Process of selecting which model to apply can be described as a sequential decision making process corresponding to the traversal of a binary tree	
Random forests	1. Very good performance (speed, accuracy) when abundant data is available.<br>2. Use bootstrapping/bagging to initialize each tree with different data.<br>3. Use only a subset of variables at each node.<br>4. Use a random optimization criterion at each node.<br>5. Project features on a random different manifold at each node.	
Measures of classification accuracy	Classification Error Rate<br>Cross Validation<br>Recall, Precision, Confusion Matrix<br>Receiver Operator Curves, two-alternative forced choice	
Estimating hypothesis accuracy	Sample Error vs. True Error<br>Confidence Intervals	
Sampling Theory Basics	Binomial and Normal Distributions<br>Mean and Variance	
Comparing Hypotheses	t-test<br>Analysis of Variance (ANOVA) test	
Simple data splits	- Fixed train, development and test sets<br>- Bootstrapping<br>- Cross-validation	
Fixed train, development and test sets	- Randomly split data into training, development, and test sets.<br>- Does not make use of all data to train or test<br>- Good for large datasets	
Bootstrapping	Estimating the sampling distribution of an estimator by resampling with replacement from the original sample.	
Cross-validation	- Randomly split data into n folds and iteratively use one as test set<br>- All data used to test, and almost all to train<br>- Good for small sets	
Evaluation procedure for single split or cross validation	- For large datasets, a single split is usually sufficient.<br>- For smaller datasets, rely on cross validation	
Overfitting can occur when	- Learning is performed for too long (e.g. in Neural Networks)<br>- The examples in the training set are not representative of all possible situations (is usually the case!)<br>- Model parameters are adjusted to uninformative features in the training set that have no causal relation to the true underlying target function.	
Confusion Matrix	Easy to see if the system is commonly mislabelling one class as another	
Classification measures - Error Rate	Common performance measure for classification problems<br>1. Success: Instance's class is predicted correctly (True Positives (TP) / Negatives (TN)).<br>2. Error: Instance's class is predicted incorrectly (False Positives (FP) / Negatives (FN)).<br>3. False positives - Type I error. False Negative - Type II error.<br>4. Classification error rate: Proportion of instances misclassified over the whole set of instances.	
F-measure	Comparing different approaches is difficult when using multiple evaluation measures (e.g. Recall and Precision)<br>F-measure combines recall and precision into a single measure	
accuracy	(TP + TN)/ (TP + TN + FP + FN)	
accuracy may not be useful measure in cases where	1- There is a large class skew<br>2- There are differential misclassification costs - say, getting a positive wrong costs more than getting a negative wrong.<br>3- We are interested in a subset of high confidence predictions	
TPR - True Positive Rate - Recall	TP/actual Positive = TP/TP + FN	
False Positive Rate	FP/actual negative = FP/TN + FP	
Specificity		
Sensitivity		
ROC Curve	"Receiver Operator Characteristic (ROC) curves plot<br>TP vs FP rates         <div><img src=""quizlet-Xnkw0GvQyBFIyKyPldsHaA_m.png"" /></div>         "	
Hypothesis Quality	- We want to know how well a machine learner, which<br>learned the hypothesis as the approximation of the target<br>function , performs in terms of correctly classifying novel,<br>unseen examples<br>- We want to assess the confidence that we can have in this classification measure	
The true error of hypothesis h	Probability that it will misclassify a randomly drawn example from distribution : D<br>However, we cannot measure the true error. We can only estimate it by observing the sample error eS	
SAMPLE ERROR	In statistics, sampling error is incurred when the statistical characteristics of a population are estimated from a subset, or sample, of that population.	
A Bernoulli trial	- It is a trial with a binary outcome, for which the probability that the outcome is 1 equals p (think of a coin toss of an old warped coin with the probability of throwing heads being p).<br>- A Bernoulli experiment is a number of Bernoulli trials performed after each other. These trials are i.i.d. by definition.	
Binomial distribution	In probability theory and statistics, the binomial distribution with parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent yes/no experiments, each of which yields success with probability p.	
Normal distribution	- The Normal distribution has many useful properties. It is fully described by it's mean and variance and is easy to use in calculations.<br>- The good thing: given enough experiments, a Binomial distribution converges to a Normal distribution.	
t-test	Assesses whether the means of two distributions are statistically different from each other	
Significance level	Significance level α%: α times out of 100 you would find a statistically significant difference between the distributions even if there was none. It essentially defines our tolerance level.<br>If the calculated t value is above the threshold chosen for statistical significance then the null hypothesis that the two groups do not differ is rejected in favor of the alternative hypothesis: the groups do differ.	
Tests for comparing distributions	- t-test compares two distributions<br>- ANOVA compares multiple distributions<br>- If NULL-hypothesis is refuted, there are at least two distributions with significantly different means<br>Does NOT tell you which they are!	
Latent variables	- Latent variables are variables that are 'hidden' in the data. They are not directly observed, but must be inferred.<br>- Clustering is one way of finding discrete latent variables in data.	
Discrete latent variables	Hidden variables that can take only a limited number of discrete values (e.g. gender or basic emotion).	
Clustering Applications	- Market segmentation<br>- Social Network Analysis<br>- Vector quantization<br>- Facial Point detection	
K-Means Clustering	Informally, goal is to find groups of points that are close to each other but far from points in other groups<br>• Each cluster is defined entirely and only by its centre, or mean value µk	
K-Means Algorithm	1. Assign each xi to its closest mean.<br>2. Update the means based on assignment<br>3. Repeat until convergence	
K-Means Issues	Convergence is guaranteed but not necessarily optimal - local minima likely to occur<br>• Depends largely on initial values of uk.<br>• Hard to define optimal number K.<br>• K-means algorithm is expensive: requires Euclidean distance computations per iteration.<br>• Each instance is discretely assigned to one cluster.<br>• Euclidian distance is sensitive to outliers.	
ROBBINS-MONRO	•Addresses the slow update speed of the M-step in K-means<br>•Uses linear regression (see lecture 1)	
K-medoids clustering	Addresses issue with quadratic error function (L2-norm, Euclidean norm)<br>Replace L2 norm with any other dissimilarity measure (V...)	
Random Initialization	- Randomly Initialize K-Means clusters using actual instances as cluster centers<br>- Run K-Means and store centers and final Cost function<br>- Pick clusters of iteration with lowest Cost function as optimal solution<br>- Most useful if K < 10	
Choosing K	Elbow method<br>• Visual inspection<br>• 'Downstream' Analysis	
Probability Theory Recap	p(x) = marginal distribution<br>p(x,y) = joint distribution<br>p(x|y) = conditional distribution	
Mixture of Gaussians	Simple formulation: density model with richer representation than single Gaussian	
i.i.d.	Independent and identically distributed random variables	
EM Algorithm issues	• Takes a long time<br>• Often initialised using k-Means	
Data Mining	- Quest to extract knowledge and/ or unknown interesting patterns from apparently unstructured data.<br>aka Knowledge Discovery from Data (KDD)<br>• Data mining bit of a misnomer - information/ knowledge is mined, not data.	
Knowledge Discovery Process	1. Data cleaning - remove noise and inconsistencies<br>2. Data integration - combine data sources<br>3. Data selection - retrieve relevant data from db<br>4. Data transformation - aggregation etc. (cf. feature extraction)<br>5. Data mining - machine learning<br>6. Pattern Evaluation - identify truly interesting patterns<br>7. Knowledge representation - visualize and transfer new knowledge	
ARFF	Attribute-Relation File Format	
HDF5	• Much more complex file format designed for scientific data handling<br>• It can store heterogeneous and hierarchical organized data.<br>• It has been designed for efficiency.	
DM Types of data	• Relational databases<br>• Data warehouses<br>• Transactional databases<br>• Object-relational databases<br>• Temporal/sequence/time-series databases<br>• Spatial and Spatio-temporal databases<br>• Text & Multimedia databases<br>• Heterogeneous & Legacy databases<br>• Data streams	
DM Functionalities	Concept/Class description<br>• Characterization<br>• Discrimination<br>• Frequent patterns/ Associations/ Correlations<br>• Classification and Regression (Prediction)<br>• Cluster analysis<br>• Outlier analysis<br>• Evolution analysis	
The goal of data mining is to	Find interesting patterns!. An interesting pattern is:<br>1. Easily understood.<br>2. Valid on new data with some degree of certainty.<br>3. Potentially useful.<br>4. Novel.	
DM Objective Interest	Support: P(X U Y )<br>Percentage of transactions that a rule satisfies<br><br>Confidence: P(Y | X)<br>Degree of certainty of a detected association, i.e. the probability that a transaction containing X also contains Y	
DM Subjective Interest	Subjective measures require a human with domain knowledge to provide measures:<br>• Unexpected results contradicting apriori beliefs<br>• Actionable<br>• Expected results confirming hypothesis	
DM systems can be divided into types based on a number of variables	• Kinds of databases<br>• Kinds of knowledge<br>• Kinds of techniques<br>• Target applications	
DM task primitives	DM task primitives forms the basis for DM queries.<br>DM primitives specify:<br>• Set of task-relevant data to be mined<br>• Kind of knowledge to be mined<br>• Background knowledge to be used<br>• Interestingness measures and thresholds for pattern evaluation<br>• Representation for visualizing discovered patterns.	
DM query languages	• DM query language incorporates primitives<br>• Allows flexible interaction with DM systems<br>• Provides foundation for building user-friendly GUIs<br>• Example: DMQL	
DM integration with DBS/ Data Warehouses	• No coupling - DMS will not utilize any DB/DW system functionality<br>• Loose coupling - Uses some DB/DW functionality, in particular data fetching/storing<br>• Semi-tight coupling - In addition to loose coupling use sorting, indexing, aggregation, histogram analysis, multiway join, and statistics primitives available in DB/DW systems<br>• Tight coupling	
Dirty data	incomplete<br>noisy<br>inconsistent	
Causes of incomplete data	"• ""Not applicable"" data value when collected<br>• Different considerations between the time when the data was collected and when it is analyzed.<br>• Human/ hardware/ software problems"	
Causes of noisy data (incorrect values)	• Faulty data collection instruments<br>• Human or computer error at data entry<br>• Errors in data transmission	
Causes of inconsistent data	• Different data sources<br>• Functional dependency violation (e.g., modify linked data)	
Importance of cleaning data	If you have good data, the rest will follow	
Data quality measures	Multi-Dimensional Measure of Data Quality<br>• A well-accepted multidimensional view:<br>• Accuracy<br>• Completeness<br>• Consistency<br>• Timeliness<br>• Believability<br>• Value added<br>• Interpretability<br>• Accessibility<br>• Broad categories:<br>• Intrinsic, contextual, representational, and accessibility	
Major DM prep tasks	- Data cleaning : Fill in missing values, smooth noisy data, identify or remove outliers, and resolve inconsistencies<br>- Data integration : Integration of multiple databases, data cubes, or files<br>- Data transformation : Normalisation and aggregation<br>- Data reduction : Obtains reduced representation in volume but produces the same or similar analytical results<br>- Data discretization : Part of data reduction but with particular importance, especially for numerical data	
Noisy data	Noise is a random error or variance in a measured variable	
Techniques for canceling out noise	1. Binning - First sort data, then distribute over local bins<br>2. Regression - Fit a parametric function to the data (e.g. linear or quadratic function)<br>3. Clustering	
Noisy data - Binning	Cancelling noise by binning:<br>- Sort data<br>- Create local groups of data<br>- Replace original values by:<br>______ The bin mean<br>______ The closest min/max value of the bin	
Noisy data - Regression	Canceling noise by regression:<br>1. Fit a parametric function to the data using minimization of e.g. least squares error<br>2. Replace original values by the parametric function value	
Noisy data - Clustering	Canceling noise by clustering<br>- Cluster data into N groups<br>- Replace original values by means of clusters<br>OR: <br>- Use to detect outliers	
Data Integration	• Entity identification problem<br>• Redundancy detection<br>• Correlation analysis<br>• Detection and resolution of data value conflicts<br>• e.g. weight units, in/exclusion of taxes	
Data Transformation	Data transformation alters original data to make it more suitable for data mining.<br>• Smoothing (noise cancellation)<br>• Aggregation<br>• Generalisation<br>• Normalisation<br>• Attribute/feature construction	
Itemsets	simply a set of items (cf set theory)	
Mining frequent patterns	• One approach to data mining is to find sets of items that appear together frequently: frequent itemsets<br>• To be frequent some minimum threshold of occurrence must be exceeded<br>• Other frequent patterns of interest:<br>____ frequent sequential patterns<br>____ frequent structured patterns	
Association Rules	Reflect items that are frequently found (purchased) together, i.e. they are frequent itemsets<br>• Information that customers who buy beer also buy crisps is e.g. encoded as:<br>beer ) crisps[support = 2%, confidence = 75%]	
Support and Confidence	Are measures of pattern interestingness	
Rule support	support(A -> B) = P(A u B)	
Rule confidence	confidence(A -> B) = P (B|A)	
Frequent Itemset	• Absolute support of an itemset is its frequency count<br>• Relative support is the frequency count of the itemset divided by the total size of the dataset	
Min-max normalization	• Enables cost-function minimization techniques to function properly, taking all attributes into equal account<br>• Transforms all attributes to lie on the range [0, 1] or [-1, 1]<br>• Linear transformation of all data	
z-score normalisation	Better terminology is zero-mean normalization<br>• min-max normalization cannot cope with outliers, z-score normalization can.<br>• Transforms all attributes to have zero mean and unit standard deviation.<br>• Outliers are in the heavy-tail of the Gaussian.<br>• Still a linear transformation of all data.	
Data reduction	Should remove what's unnecessary, yet otherwise maintain the distribution and properties of the original data<br>• Data cube aggregation<br>• Attribute subset selection (feature selection)<br>• Dimensionality reduction (manifold projection)<br>• Numerosity reduction<br>• Discretization	
Attribute subset selection	Feature selection<br>Feature selection is a form of dimensionality reduction in ML, hence the DM term 'dimensionality reduction' for manifold projection is problematic.<br>Approaches:<br>• Exact solution infeasible<br>• Greedy forward selection<br>• Backward elimination<br>• Forward-backward<br>• Decision tree induction	
Numerosity Reduction	Reduces the number of instances rather than attributes.<br>Much more dangerous, as it risks changing the data distribution properties.<br>• Parametrization<br>• Discretization<br>• Sampling	
Data Discretization	Grouping a possibly infinite space to a discrete set of possible values<br>For categorical data:<br>________ Super-categories<br>For real numbers:<br>________ Binning<br>________ Histogram analysis<br>________ Clustering	
Instance Reduction	Reduces the number of instances rather than attributes.<br>Much more dangerous, as it risks changing the data distribution properties<br>• Duplicate removal<br>• Random sampling<br>• Cluster sample<br>• Stratified sampling	
Complex Itemsets	The general rule procedure for finding frequent item sets would be:<br>1. Find all frequent itemsets<br>2. Generate strong association rules<br>However, this is terribly costly, with the total number of item sets to be checked for 100 items being	
Simpler Method for complex itemset	Closed frequent itemset: X is closed if there exists no super-set Y such that Y has the same support count as X<br>Maximal frequent itemset: X is frequent, and there exist no supersets Y of X that are also frequent	
Apriori algorithm	Apriori algorithm is a fast way of finding frequent itemsets	
Rule based learning	Equivalent in expression power to traditional (mono-thetic) decision trees, but with more flexibility<br>• They produce rule sets as solutions, in the form of a set of IF... THEN rules	
Predicates	A logic statement, generally as boolean logic	
Rulesets	• Single rules are not the solution of the problem, they are members of rule sets<br>• Rules in a rule set cooperate to solve the problem. Together they should cover the whole search space	
Evaluating Rules	• A good rule should not make mistakes and should cover as many examples as possible<br>Complexity: Favour rules with simple predicates (Occam's Razor)	
Evaluating RuleSets	A complete rule set should be good at classifying all the training examples<br>Complexity: Favour rule sets with the minimal number of rules.	
Learning Rulesets	Learning rules sequentially, one at a time<br>• Also known as separate-and-conquer<br>Learning all rules together<br>• Direct rule learning<br>• Deriving rules from decision trees	
There are three reasons to reduce the dimensionality of a feature set	1. Remove features that have no correlation with the target distribution<br>2. Remove/combine features that have redundant correlation with target distribution<br>3. Extract new features with a more direct correlation with target distribution.	
Degrees of freedom of variability	Number of ways data can change/ number of separate transformations possible	
Intrinsic dimensionality	Subspace of data space that captures degrees of variability only, and is thus the most compact possible representation	
Feature Selection	Feature Selection returns a subset of original feature set. It does not extract new features.<br>Benefits:<br>• Features retain original meaning<br>• After determining selected features, selection process is fast<br>Disadvantages:<br>• Cannot extract new features which have stronger correlation with target variable	
Search Methods	• Exhaustive<br>• Greedy forward selection<br>• Greedy backward elimination<br>• Forward-backward approach	
Filter Scores	• Correlation<br>• Mutual information<br>Entropy<br>• Classification rate<br>• Regression score	
Mutual Information	Gives a measure of how 'close' two components of a joint distribution are to being independent	
Forward Selection	1. Start with empty SF set and candidate set being all original features<br>2. Find feature with highest filter score<br>3. Remove feature from candidate set<br>4. Add feature to SF set<br>5. Repeat steps 2-4 until convergence	
Backward Elimination	1. Start with complete SF set (contains all original features)<br>2. Find feature that, when removed, reduces the filter score least<br>3. Remove feature from SF set<br>4. Repeat steps 2-3 until convergence	
Forward-backward algorithm	First applies Forward selection and then filters redundant elements using backward elimination	
CFS	• Correlation based feature selection (CFS) selects features in a forward-selection manner.<br>• Looks at each step at both correlation with target variable and already selected features.	
PCA	• Manifold projection<br>• Assumes Gaussian latent variables and Gaussian observed variable distribution<br>• Linear-Gaussian dependence of the observed variables on the latent variables<br>• Also known as Karhunen-Loève transform	
PCA requires calculation of	• Mean of observed variables<br>• Covariance of observed variables<br>• Eigenvalue/eigenvector Computation of covariance matrix	
ANN feature selection	• Artificial Neural Networks can implicitly perform feature selection<br>• A multi-layer neural network where the first hidden layer has fewer units (nodes) than the input layer<br>• Called 'Auto-associative' networks	
Parametric methods	• Many methods learn parameters of prediction function (e.g. linear regression, ANNs)<br>• After training, training set is discarded.<br>• Prediction purely based on learned parameters and new data.	
Memory-based methods	• Uses all training data in every prediction (e.g. kNN)<br>• Becomes a kernel method if using a non-linear example comparison/ metric	
Kernel	Shortcut that helps us do certain calculation faster which otherwise would involve computations in higher dimensional space.	
Kernel methods	Map a non-linearly separable input space to another space which hopefully is linearly separable<br>• This space is usually higher-dimensional, possibly infinitely<br>• The key element is that they do not actually map features to this space, instead they return the distance between elements in this space<br>• This implicit mapping is called the (Definition) Trick	
Kernel methods	Kernel methods map a non-linearly separable input space to another space which hopefully is linearly separable<br>• This space is usually higher dimensional, possibly infinitely<br>• Even the 'non-linear' kernel methods essentially solve a linear optimization problem!!!!	
Kernel trick	The key element of kernel methods is that they do not actually map features to this space, instead they return the distance between elements in this space This implicit mapping is called the (definition)	
Sparse Kernel Methods	• Must be evaluated on all training examples during testing<br>• Must be evaluated on all pairs of patterns during training<br> - Training takes a long time<br> - Testing too<br> - Memory intensive (both disk/ RAM)<br>Solution: sparse methods	
Three ways of constructing new kernels	Direct from feature space mappings<br>Proposing kernels directly<br>Combination of existing (valid) kernels<br>• multiplication by a constant<br>• exponential of a kernel<br>• sum of two kernels<br>• product of two kernels<br>• left/right multiplication by any function of x/x'	
Commonly used kernels	• Linear kernel<br>• Polynomial kernel<br>• Gaussian kernel<br>(Gaussian kernel is probably the most frequently used kernel out there - Gaussian kernel maps to infinite feature space)	
Sparse kernel methods	• Must be evaluated on all training examples during testing<br>• Must be evaluated on all pairs of patterns during training<br>• Training takes a long time<br>• Testing too<br>• Memory intensive (both disk/RAM)<br>Solution: sparse methods	
Maximum margin classifier	Classifier which is able to give an associated distance from the decision boundary for each example.	
Linearly-separable SVM	Satisfying solution (e.g. perceptron algorithm): finds a solution, not necessarily the 'best'<br>Best is that solution that promises maximum generalizability	
Slack variable	Slack variables introduced to solve optimization problem by allowing some training data to be misclassified<br>Slack variables en >= 0 give a linear penalty to examples lying on the wrong side of the d.b.: point on correct side of db<br>|tn ! y(xn)|, otherwise	
Relevance Vector Machines	Model the typical points of a data set, rather than atypical( a la density estimation) while remaining a (very) sparse (like heat map) representation<br>Returns a true posterior<br>Naturally extends to multi-classification<br>Fewer parameters to tune	
SVM Margin is defined as	The minimum distance between decision boundary and any sample of a class	
SVMs seek a decision boundary	That maximizes the margin	
Maximum margin classifiers	- This turns out to be a solution where decision boundary is determined by nearest points only<br>- Minimal set of points spanning decision boundary sought<br>- These points are called Support Vectors	
Small set of SVs means that	Our solution is now sparse	
Non-linearly Separable Problem	Usually problems aren't linearly separable (not even in feature space)<br>'Perfect' separation of training data classes would cause poor generalization due to massive overfitting	
Soft Margin	We have effectively replaced the hard margin with a soft margin<br>New optimization goal is maximizing the margin while penalizing points on the wrong side of d.b.	
Multiclass SVM	SVM is an inherently binary classifier. Two strategies to use SVMs for multiclass classification:<br>- One-vs-all<br>- One-vs-one<br>Problems:<br>- Ambiguities (both strategies)<br>- Imbalanced training sets (one-vs-all)	
One-class SVM	- Unsupervised learning problem<br>- Similar to probability density estimation<br>- Instead of a pdf, goal is to find smooth boundary enclosing a region of high density of a class	
Prior Probability	- Probability of encountering a class without observing any evidence<br>- Can be generalized for the state of any random variable<br>- Easily obtained from training data (i.e. counting)	
Joint Probability	- Joint probability is the probability of encountering a particular class while simultaneously observing the value of one or more other random variables<br>- Can be generalized for the state of any combination of random variables	
Bayes' Theorem	posterior = (likelihood x prior)/evidence	
Minimum Error Rate	Goal is to minimise error rate	
Normal Density	By far the most (ab)used density function is the Normal or Gaussian density	
All probability theory can be expressed in terms of two rules	- Product rule<br>- Sum rule	
Directed PGN	Edges have direction (Bayesian Network)	
Undirected PGN	No edge direction (Markov Random Field)	
Directed Acyclic Graphs (DAGs)	are Bayesian Networks. Meaning there are no cyclic paths from any node back to itself	
Some variables are observed, others are hidden/latent	Example observed: Labels of a training set<br>Example hidden: Learned weights of a model	
PGNs are generative models	Allow us to sample from the probability distribution it defines	
Ancestral sampling	is a simple sampling method well suited to PGNs	
Conditional independence in PGN	is the PGN mechanism to show information in terms of interesting aspects of probability distributions	
Blocking Paths	When a path is blocked, no information can flow through it<br>This means that observing C, if it blocks a path A-C-B, it means there is no added value in observing A, and B is fully determined by C	
Sequence Data	Sequence data is data that comes in a particular order<br>Opposite of independent, identical distributed (i.i.d.)<br>Strong correlation between subsequent elements<br>- DNA<br>- Time series<br>- Facial Expressions<br>- Speech Recognition<br>- Weather Prediction<br>- Action planning	
1st order Markov models	Restricted to encoding sequential correlation on previous element only	
A Latice/Trellis diagram visualizes	state transitions over time<br>Also good tool to to visualize optimal path through states<br>(Viterbi Algorithm)	
Emission Probabilities	Probabilities of observed variables	
Acquiring emissions	Wide range of options to model ****** probabilities:<br>- Discrete tables<br>- Gaussians<br>- Mixture of Gaussians<br>- Neural Networks/RVMs etc to mode	
Perceptron Algorithm	"Perceptron is modeled after neurons in the brain. It has m input values (which correspond with the m features of the examples in the training set) and one output value. Each input value x_i is multiplied by a weight-factor w_i. If the sum of the products between the feature value and weight-factor is larger than zero, the perceptron is activated and 'fires' a signal (+1). Otherwise it is not activated.<br />The weighted sum between the input-values and the weight-values, can mathematically be determined with the scalar-product <w>. To produce the behaviour of 'firing' a signal (+1) we can use the signum function sgn(); it maps the output to +1 if the input is positive, and it maps the output to -1 if the input is negative.<br /><br />Thus, this Perceptron can mathematically be modeled by the function y = sgn(b+ </w><w>). Here b is the bias, i.e. the default value when all feature values are zero.         <div><img src=""quizlet-3PQBxmo2q4m6L2IeBD4nWw_m.png"" /></div> </w>"	