2018_04_16
  MORNING:
    - exported data to csv
    - built initial file structure for problem exploration
    - wrote function to strip html
      - also strips any formulas with <w, x> format
    - wrote function to read csv, apply names
    - wrote function to return dataframe w/o html

  AFTERNOON:
    - collapsed dataframe into single record with both question and answer text
    - Performed topic modeling with LDA, LSI and NMF
      - Discovered that many of my flashcards have error messages due to the export from anki, due to latex not being installed
    - attempting to resolve latex issues with anki to see if i can get a clean import
      - resolved latex issue related to bad data export
    - Currently, there are about 4200 unique words
    - Switched from CountVectorizer to TfidfVectorizer
      - set max document frequency to 80% to drive down commonly occurring words
    - attempting to remove commonly occurring latex words
      - exploring word counts in TfidfVectorizer
      - creating wordcloud function so I can see prominent (and meaningless) words
        - generated wordclouds for raw text and for text after removing html

2018_04_17
  MORNING:
    - consider removing \item, \begin, \end, and other document formatting tags, but not other math-meaningful latex
      - removed item
        -generated wordcloud
      - removed all document latex, chose to leave in latex pertaining to formulas
        - generated wordcloud
    - investigating nan values (110 records)
      - don't want to drop nans as the index to the original cards is meaningful
      - the first nan is a meaningful card that has had its string removed
      - the error is not occurring in the cleaning function
      - it turns out that the answer column has some nan values.
        - correcting this by preprocessing nan values with replacing nan values with ' ' blank space

THEN: look over pipeline notebook from Chris

CONSIDER: replace latex operations with meaningful words
